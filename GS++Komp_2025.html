<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><meta http-equiv=Content-Type content="text/html; charset=utf-8"><html><head><title>Kompendium Grundschutz++ (Beta)</title></head><body><h1><em>Kompendium Grundschutz++ (Beta)</em></h1><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Practice</th><th align="right">#Groups</th><th align="right">#Controls</th></tr><tr valign="top"><td>GC: Governance und Compliance</td><td align="right">9</td><td align="right">35</td></tr><tr valign="top"><td>STM: Strukturmodellierung</td><td align="right">8</td><td align="right">14</td></tr><tr valign="top"><td>UMS: Umsetzung</td><td align="right">6</td><td align="right">16</td></tr><tr valign="top"><td>VRB: Verbesserung</td><td align="right">5</td><td align="right">9</td></tr><tr valign="top"><td>PERF: Monitoring-Evaluation</td><td align="right">5</td><td align="right">29</td></tr><tr valign="top"><td>ARCH: Architektur</td><td align="right">9</td><td align="right">61</td></tr><tr valign="top"><td>SENS: Sensibilisierung</td><td align="right">12</td><td align="right">85</td></tr><tr valign="top"><td>REA: Sicherheitsvorfallsbehandlung</td><td align="right">3</td><td align="right">23</td></tr><tr valign="top"><td>NOT: Notfallplanung</td><td align="right">4</td><td align="right">37</td></tr><tr valign="top"><td>ASST: Informationen und Assets</td><td align="right">7</td><td align="right">58</td></tr><tr valign="top"><td>TEST: Änderungen und Tests</td><td align="right">5</td><td align="right">35</td></tr><tr valign="top"><td>PERS: Personal</td><td align="right">6</td><td align="right">30</td></tr><tr valign="top"><td>BES: Beschaffungsmanagement</td><td align="right">8</td><td align="right">105</td></tr><tr valign="top"><td>DEV: Entwicklung</td><td align="right">7</td><td align="right">34</td></tr><tr valign="top"><td>KONF: Konfiguration</td><td align="right">15</td><td align="right">158</td></tr><tr valign="top"><td>DLS: Dienstleistersteuerung</td><td align="right">4</td><td align="right">18</td></tr><tr valign="top"><td>GEB: Gebäudemanagement</td><td align="right">11</td><td align="right">78</td></tr><tr valign="top"><td>BER: Berechtigung</td><td align="right">7</td><td align="right">78</td></tr><tr valign="top"><td>DET: Detektion</td><td align="right">6</td><td align="right">82</td></tr><tr valign="top"><td align="left">&sum; = <b>19</b></td><td align="right"><b>137</b></td><td align="right"><b>985</b></td></tr></table><h1>GC: Governance und Compliance</h1><p>Die Praktik Governance und Compliance stellt sicher, dass Informationssicherheitsstrategien mit den übergeordneten Zielen der Institution und regulatorischen Anforderungen im Einklang stehen. Sie vereint die strategische Steuerung der Informationssicherheit mit der systematischen Identifikation und Integration externer sowie interner Anforderungen.  Diese Praktik definiert den strategischen Rahmen für die Informationssicherheit und beantwortet die Fragen nach dem <b>„Was“</b> und <b>„Warum“</b> von Anforderungen und Sicherheitsmaßnahmen. Sie gewährleistet die Einbindung der obersten Führungsebene in wichtige Entscheidungen zur Informationssicherheit und stellt sicher, dass alle relevanten gesetzlichen, regulatorischen und vertraglichen Vorgaben identifiziert und berücksichtigt werden.  Während Governance und Compliance die strategische Ausrichtung und die Anforderungen definiert, übernehmen die operativen Praktiken wie Strukturmodellierung und Umsetzung die konkrete Ausgestaltung.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>GC.1: Grundlagen</td><td align="right">1</td></tr><tr valign="top"><td>GC.2: Kontext</td><td align="right">5</td></tr><tr valign="top"><td>GC.3: Informationsverbund</td><td align="right">3</td></tr><tr valign="top"><td>GC.4: Sicherheitsorganisation</td><td align="right">5</td></tr><tr valign="top"><td>GC.5: Leitlinie</td><td align="right">5</td></tr><tr valign="top"><td>GC.6: Kommunikation</td><td align="right">3</td></tr><tr valign="top"><td>GC.7: Vorgehensweisen</td><td align="right">11</td></tr><tr valign="top"><td>GC.8: Ressourcen</td><td align="right">1</td></tr><tr valign="top"><td>GC.9: Dokumentenlenkung</td><td align="right">1</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>35</b></td></tr></table><h2>GC.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.1.1: Errichtung und Aufrechterhaltung eines ISMS</td><td><p>Governance und Compliance MUSS ein Verfahren zur Errichtung und Aufrechterhaltung eines ISMS nach <i>BSI Grundschutz++</i> verankern.</p></td><td><p>Unter „etabliert“ bzw. „errichtet“ ist hier zu verstehen, dass die Anforderungen an das ISMS standardkonform umgesetzt wurden.  Unter <b>„aufrechterhalten“</b> ist hier zu verstehen, dass die Einhaltung der Anforderungen kontinuierlich überprüft wird und bei Bedarf Gegenmaßnahmen eingeleitet werden.  Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr></table><h2>GC.2: Kontext</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.2.1: Analyse der interessierten Parteien</td><td><p>Governance und Compliance MUSS ein Verfahren zum Ermitteln der interessierten Parteien und ihrer Bedürfnisse und Erwartungen an das ISMS verankern.</p></td><td><p>Alle relevanten externen und internen interessierten Parteien sind ermittelt. Die externen interessierten Parteien umfassen beispielsweise: Gesetzgeber, Aufsichtsbehörden, Kunden, Dienstleister, Gesellschaft/Öffentlichkeit. Die internen interessierten Parteien umfassen beispielsweise: Geschäftsführung, Mitarbeiter, Führungskräfte, Betriebsrat/Personalrat).</p></td></tr><tr valign="top"><td>GC.2.2: Verfahren und Regelungen</td><td><p>Governance und Compliance MUSS ein Verfahren zur Sammlung, Integration und Priorisierung aller für das Informationssicherheitsmanagement relevanten Rahmenbedingungen verankern.</p></td><td><p>Das Compliance Management stellt sicher, dass alle gesetzlichen, regulatorischen und vertraglichen Verpflichtungen im Bereich der Informationssicherheit eingehalten werden. Identifizieren, überwachen und bewerten Sie Verpflichtungen, um rechtliche Konsequenzen, finanzielle Verluste oder Reputationsschäden zu vermeiden. Aufgrund der hohen Komplexität des modernen Rechts ist für die Rechtspflege ist eine eigene Rechtsabteilung oder die Beauftragung von Mitgliedern der rechtsberatenden Berufe zweckmäßig. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>GC.2.2.1: Gesetzliche Verpflichtungen</td><td><p>Governance und Compliance SOLLTE gesetzliche Verpflichtungen, welche die Verarbeitung von Informationen durch die Institution betreffen, dokumentieren.</p></td><td><p>Gesetzliche Verpflichtungen, welche die Verarbeitung von Informationen durch die Institution betreffen, sind dokumentiert. Gesetzliche Verpflichtungen meint alle Pflichten, die sich unmittelbar aus dem Recht ergeben, inklusive des Verfassungsrechts, Europarechts und Verordnungen. Relevante gesetzliche Verpflichtungen können sich je nach Institution z. B. aus Grundrechten, Cyber Resilience Act, Data Act, Data Markets Act, NIS, DSGVO, BDSG, TKG, TDDDG oder GeschGehG ergeben. Beachten Sie dabei auch Verpflichtungen, die sich mittelbar auswirken wie die Arbeitsstättenverordnung oder allgemeine Regelungen zur Fürsorgepflicht.</p></td></tr><tr valign="top"><td>GC.2.2.2: Anhörung zuständiger Stellen</td><td><p>Governance und Compliance SOLLTE für die Einhaltung gesetzlicher Verpflichtungen in der Informationsverarbeitung zuständige Stellen in der Institution bei der Dokumentation der Compliance-Verpflichtungen anhören.</p></td><td><p>Für die Einhaltung gesetzlicher Verpflichtungen in der Informationsverarbeitung zuständige Stellen in der Institution wurden bei der Dokumentation der Compliance-Verpflichtungen angehört. Hierunter können z. B. Rechtsabteilung, Datenschutzbeauftragte, Brandschutzbeauftragte oder Fachverantwortliche bei branchenspezifischen Vorschriften fallen.</p></td></tr><tr valign="top"><td>GC.2.2.3: Vertragliche Verpflichtungen</td><td><p>Governance und Compliance SOLLTE vertragliche Verpflichtungen, welche die Verarbeitung von Informationen durch die Institution betreffen, dokumentieren.</p></td><td><p>Vertragliche Verpflichtungen, welche die Verarbeitung von Informationen durch die Institution betreffen, sind dokumentiert. Vertragliche Verpflichtungen meint alle Pflichten, die sich aus rechtlich bindenden Vereinbarungen ergeben, unabhängig davon, ob diese als Vertrag bezeichnet werden oder nicht.</p></td></tr></table><h2>GC.3: Informationsverbund</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.3.1: Definition des Informationsverbunds</td><td><p>Governance und Compliance MUSS den nachvollziehbar abgegrenzten Informationsverbund auf Basis des Kontextes und Anforderungen der interessierten Parteien sowie der daraus hergeleiteten Risikoziele dokumentieren.</p></td><td><p>Die Abgrenzung ist wie folgt zu verstehen: Organisatorisch wird dargestellt, welche Organisationsbereiche, Rollen und Personen sowie Aufgaben, Tätigkeiten oder Prozesse in den Informationsverbund (Geltungsbereich/Scope) gehören. Technisch ist erkennbar, welche Anwendungen, Systeme sowie Netze im Informationsverbund sind. Infrastrukturell sind die Standorte, Gebäude und Räumlichkeiten im Informationsverbund dargestellt. Eine vollständige Auflistung einzelner Zielobjekte ist dabei selten sinnvoll, da diese häufig angepasst werden müsse. Stattdessen ist es zweckmäßig, eine nachvollziehbare Definition zu nutzen, z.B. anhand von Unternehmensbesitz, Organisationseinheiten oder Ländergrenzen. Wichtig ist, dass möglichst eindeutig erkennbar wird, ob Zielobjekte innerhalb oder außerhalb des Informationsverbunds sind.</p></td></tr><tr valign="top"><td>GC.3.2: Festlegen der Schnittstellen</td><td><p>Governance und Compliance MUSS Schnittstellen des Informationsverbunds zu externen Prozessen dokumentieren.</p></td><td><p>Im Informationsverbund sind die organisatorischen, technischen und infrastrukturellen Schnittstellen dargestellt.  Für eine eindeutige Abgrenzung sind im Informationsverbund die Schnittstellen definiert. Wie bei der Beschreibung des Informationsverbund selbst, sind auch hier organisatorische, technische sowie infrastrukturelle Schnittstellen berücksichtigt.</p></td></tr><tr valign="top"><td>GC.3.3: Überblick über den Informationsverbund</td><td><p>Governance und Compliance SOLLTE einen Überblick über den Informationsverbund dokumentieren.</p></td><td><p>Um einen Überblick über den Informationsverbund zu erhalten, werden Systeme, Anwendungen und Schnittstellen betrachtet und den relevanten Geschäftsprozessen zugeordnet. Die Ergebnisse werden in Form einer verständlichen Übersicht (z.B. Dashboard, Systemlandkarte, Risikoprofil) aufbereitet. Die IT-Leitung stellt sicher, dass diese Übersicht regelmäßig aktualisiert und dem Management zur Verfügung gestellt wird, sodass Handlungsbedarfe und Prioritäten klar erkennbar sind.</p></td></tr></table><h2>GC.4: Sicherheitsorganisation</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.4.1: Festlegung von Rollen und Zuständigkeiten</td><td><p>Governance und Compliance MUSS die Rollen und Zuständigkeiten im Rahmen des ISMS mit den notwendigen Qualifikationen, Aufgaben und Kompetenzen (bzw. Befugnissen) zuweisen.</p></td><td><p>Im Rahmen des ISMS sind die Rollen hinsichtlich Aufgaben, der dafür notwendigen Qualifikation und der notwendigen Befugnisse festgelegt. Eine zentrale Rolle wäre beispielsweise der <b>„Informationssicherheitsbeauftragte“</b> (ISB).</p></td></tr><tr valign="top"><td>GC.4.2: Vermeidung von Interessenskonflikten</td><td><p>Governance und Compliance MUSS Maßnahmen zur Vermeidung von Interessenskonflikten bei der Festlegung von Rollen und Zuständigkeiten des ISMS verankern.</p></td><td><p>Für die Vermeidung von Interessenskonflikten wird insbesondere die Zuordnung konkurrierender Rollen (bspw. ausführender und prüfender oder freigebender Rollen) vermieden. Dies erfolgt beispielsweise durch eine entsprechende Etablierung von Rollen in die Aufbauorganisation (z. B. Informationssicherheitsbeauftragter als Stabstelle). Es können aber auch weitere Maßnahmen (z. B. Vier-Augen-Prinzip) genutzt werden.</p></td></tr><tr valign="top"><td>GC.4.3: Festlegen einer Sicherheitsorganisation</td><td><p>Governance und Compliance MUSS die Sicherheitsorganisation für das ISMS mit den festgelegten Rollen, Zuständigkeiten sowie auch Gremien verankern.</p></td><td><p>Ziel der Sicherheitsorganisation ist es, die relevanten Bereiche eines ISMS sowie die relevanten Schnittstellen zu anderen Bereichen (z. B. Datenschutz, physische Sicherheit, Geheimschutz oder Arbeitsschutz) vollständig und wirksam in der Institution abzubilden.</p></td></tr><tr valign="top"><td>GC.4.4: Sicherstellen der Qualifikation</td><td><p>Governance und Compliance MUSS ein Verfahren zur Sicherstellung der Qualifikation von Rollen- und Verantwortungsträgern verankern.</p></td><td><p>Für jeden Rollen- und Verantwortungsträger sind die Anforderungen und Fähigkeiten festgelegt.</p></td></tr><tr valign="top"><td>GC.4.5: Stellvertreterregelungen</td><td><p>Governance und Compliance MUSS Stellvertreterregelungen für alle relevanten Rollen und Zuständigkeiten im ISMS zuweisen.</p></td><td><p>Eine längere Handlungsunfähigkeit zentraler Sicherheitsrollen kann Auswirkungen auf die Informationssicherheit haben.</p></td></tr></table><h2>GC.5: Leitlinie</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.5.1: Festlegen von Zielen für die Informationssicherheit</td><td><p>Governance und Compliance MUSS auf Basis der identifizierten Rahmenbedingungen konkrete und messbare Ziele für die Informationssicherheit verankern.</p></td><td><p>Die Ziele müssen zur Institution passen sowie messbar und konkret sein, z.B.: 98% der aktiven Endgeräte im Netzwerk der Institution verfügen über eine aktuelle Antivirensoftware, deren Signaturdatenbank nicht älter als 24 Stunden ist.</p></td></tr><tr valign="top"><td>GC.5.1.1: Festlegen einer Sicherheitsstrategie</td><td><p>Governance und Compliance SOLLTE eine grundlegende Strategie zur Erreichung der Ziele für die Informationssicherheit verankern.</p></td><td><p>Die Leitlinie für Informationssicherheit enthält insbesondere die ISMS-Politik der Institution.</p></td></tr><tr valign="top"><td>GC.5.2: Verpflichtung der obersten Leitung</td><td><p>Governance und Compliance MUSS die Verpflichtung der obersten Leitung verankern.</p></td><td><p>Die Verpflichtung der obersten Leitung beinhaltet die Übernahme der Gesamtverantwortung, die Bestätigung und Überwachung der Informationssicherheitsziele bezüglich der Organisationsziele und die Förderung des ISMS. Die Förderung des ISMS erfolgt durch Beteiligung (z. B. Führungsentscheidungen), Bestätigung der Informationssicherheitsorganisation, Unterstützung der Integration des ISMS, Bereitstellung von Ressourcen (z. B. finanzielle, personelle, technische, infrastrukturelle) und die Unterstützung der kontinuierlichen Verbesserung</p></td></tr><tr valign="top"><td>GC.5.3: Erstellung einer Leitlinie</td><td><p>Governance und Compliance MUSS eine für die Institution passende Leitlinie zur Informationssicherheit dokumentieren.</p></td><td><p>Die Leitlinie für Informationssicherheit enthält insbesondere die Gesamtverantwortung und Verpflichtung der obersten Leitung, Informationssicherheitsziele, eine Informationssicherheitsstrategie, die Benennung der Rollen und Zuständigkeiten sowie die Verpflichtung zur kontinuierlichen Verbesserung</p></td></tr><tr valign="top"><td>GC.5.4: Freigabe der Leitlinie</td><td><p>Governance und Compliance MUSS die Freigabe der Leitlinie für Informationssicherheit durch die Institutionsleitung dokumentieren.</p></td><td/></tr></table><h2>GC.6: Kommunikation</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.6.1: Festlegung der Kommunikation</td><td><p>Governance und Compliance MUSS die relevanten Vorgaben zur internen und externen Kommunikation verankern.</p></td><td><p>Für die relevante Kommunikation im Rahmen eines ISMS sind die Eckpunkte (Wer, Wann, mit wem, wie etc.) festgelegt.  Dies beinhaltet ebenfalls die Identifikation der relevanten Behörden und der relevanten Kontakte sowie die Festlegung von Zuständigkeiten für die Kommunikation.</p></td></tr><tr valign="top"><td>GC.6.1.1: Externer Austausch zur Informationssicherheit</td><td><p>Governance und Compliance SOLLTE Verfahren zum externen Austausch zur Informationssicherheit verankern.</p></td><td><p>Um auch andere Perspektiven wahrzunehmen und Eindrücke zu erhalten, findet ein externer Austausch statt. Hierzu können beispielsweise Branchenverbände, Fachforen oder andere Einrichtungen genutzt werden.</p></td></tr><tr valign="top"><td>GC.6.2: Kommunikation im Projektmanagement</td><td><p>Governance und Compliance SOLLTE ein Verfahren zur Etablierung der Informationssicherheit in das Projektmanagement verankern.</p></td><td><p>Die relevanten Sicherheitsorgane werden an bestimmten Punkten im Verlauf eines Projekts mit Sicherheitsrelevanz, wie beispielsweise bei der Einführung eines neuen IT-Systems oder einer neuen Software, eingebunden. Zu welchen Zeitpunkten – etwa während der Beschaffung oder vor der Produktivsetzung – eine Beteiligung der Sicherheitsorgane erfolgt, ist festgelegt.</p></td></tr></table><h2>GC.7: Vorgehensweisen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.7.1: Festlegen von Vorgehensweisen</td><td><p>Governance und Compliance MUSS die Verfahren des ISMS sowie die Zuständigkeiten dokumentieren.</p></td><td><p>Der Umfang der Dokumentation ist dem Umfang der Institution angemessen. Die Verfahren beinhalten insbesondere das Risikomanagement, die Etablierung von Änderungen im ISMS, die Dokumentenlenkung, die Leistungsbewertung und Auditierung, kontinuierliche Verbesserung sowie reaktive Verfahren (Sicherheitsvorfallsbehandlung; Notfallmanagement). In kleineren Institutionen kann dies beispielsweise in einem Dokument erfolgen. In größeren Institutionen können hier entsprechend auch Prozesse definiert werden.</p></td></tr><tr valign="top"><td>GC.7.1.1: Änderungen im ISMS</td><td><p>Governance und Compliance MUSS ein Verfahren zur Etablierung von Änderungen im ISMS verankern.</p></td><td><p>Änderungen im ISMS erfolgen geplant und strukturiert. Wenn beispielsweise Parameter im Risikomanagement verändert werden, kann dies Auswirkungen auf die Vergleichbarkeit und Nachvollziehbarkeit der Risikoanalysen sowie die Integrität im Rahmen der Managementbewertung zur Folge haben.</p></td></tr><tr valign="top"><td>GC.7.2: Freigabe von Vorgehensweisen</td><td><p>Governance und Compliance SOLLTE die Freigabe der Verfahren für das ISMS durch die Institutionsleitung dokumentieren.</p></td><td/></tr><tr valign="top"><td>GC.7.3: Freigabe des Managementberichtes</td><td><p>Governance und Compliance MUSS den Managementbericht durch die Institutionsleitung autorisieren.</p></td><td/></tr><tr valign="top"><td>GC.7.4: Methodik für das Risikomanagement</td><td><p>Governance und Compliance MUSS eine einheitliche Methodik für das Informationssicherheitsrisikomanagement auf Basis des Kontextes und Anforderungen der interessierten Parteien sowie der daraus hergeleiteten Risikoziele verankern.</p></td><td><p>Die Risikomanagementmethodik kann frei gewählt werden, SOLL jedoch für Informationssicherheitsrisiken anwendbar sein.</p></td></tr><tr valign="top"><td>GC.7.5: Definition des Risikoeigentümers</td><td><p>Governance und Compliance MUSS in der Methodik für das Risikomanagement die Rolle des Risikoeigentümers mit den notwendigen Aufgaben und Befugnissen verankern.</p></td><td><p>Der Risikoeigentümer ist derjenige, der für die Behandlung eines Risikos die Verantwortung trägt und die Befugnis hat, Entscheidungen zur Behandlung des Risikos zu treffen.</p></td></tr><tr valign="top"><td>GC.7.6: Kritikalitätskriterien</td><td><p>Governance und Compliance MUSS einheitliche Kriterien für die Kritikalität von Geschäftsprozessen bzw. -aktivitäten und Informationen in der Risikomanagementmethodik verankern.</p></td><td><p>Kritikalitätskriterien dienen der Bewertung potenzieller Schäden bei einer Beeinträchtigung der Schutzziele Vertraulichkeit, Integrität oder Verfügbarkeit. Eine Orientierung an den Geschäfts- und Schutzzielen der Institution unterstützt eine konsistente Einschätzung. Dabei bietet es sich an, klar definierte und nachvollziehbare Stufen (z. B. niedrig, mittel, hoch) für unterschiedliche Schadensszenarien wie zum Beispiel finanzielle Verluste, Reputationsschäden oder rechtliche Konsequenzen festzulegen.</p></td></tr><tr valign="top"><td>GC.7.7: Schutzbedarfseinstufung</td><td><p>Governance und Compliance SOLLTE die grundsätzliche erste Schutzbedarfseinstufung für die wesentlichen Geschäftsprozesse und Informationen der Institution durch die Institutionsleitung verankern.</p></td><td><p>Hiermit ist eine erste, grundsätzliche Schutzbedarfseinstufung für die kritischen Geschäftsprozesse und Informationsarten gemeint, welche die Institutionsleitung  unter Berücksichtigung der Geschäftsziele vornimmt. Dies dient als Orientierungsrahmen für die Auswahl einer geeigneten Blaupause. Diese grundlegende Einstufung erfolgt in den Stufen der Sicherheitsniveaus: <b>„normal“</b> (also Stand der Technik allgemein) oder <b>„erhöht“</b>. Ohne eine solche initiale Einstufung könnte es passieren, dass wesentliche Prozesse – etwa die Verarbeitung von Personaldaten, Forschungsunterlagen oder Finanztransaktionen – entweder unterschätzt oder übermäßig abgesichert werden. Im ersten Fall kann ein Verlust oder eine Manipulation erhebliche Schäden nach sich ziehen, wie z. B. Reputationsverlust, regulatorische Sanktionen oder den Abbruch kritischer Dienstleistungen. Im zweiten Fall werden dagegen Ressourcen ineffizient gebunden, was die Handlungsfähigkeit der Institution beeinträchtigen könnte. Mit einer klaren Festlegung durch die Leitung wird sichergestellt, dass die Relevanz geschäftskritischer Informationen und Abläufe nicht allein in Fachbereichen unterschiedlich bewertet wird, sondern auf einer institutionell getragenen Grundlage erfolgt.</p></td></tr><tr valign="top"><td>GC.7.8: Kriterien für die Risikobeurteilung</td><td><p>Governance und Compliance MUSS einheitliche Kriterien für die Beurteilung von Risiken in der Risikomanagementmethodik verankern.</p></td><td/></tr><tr valign="top"><td>GC.7.9: Kriterien für die Risikoakzeptanz</td><td><p>Governance und Compliance MUSS einheitliche Kriterien für die Risikoakzeptanz in der Risikomanagementmethodik verankern.</p></td><td/></tr><tr valign="top"><td>GC.7.10: Freigabe des Risikomanagements</td><td><p>Governance und Compliance MUSS die Freigabe des Verfahrens, der Rollendefinitionen und der Kriterien des Risikomanagements durch die Institutionsleitung dokumentieren.</p></td><td/></tr></table><h2>GC.8: Ressourcen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.8.1: Verfahren zur Ressourcenplanung</td><td><p>Governance und Compliance MUSS ein Verfahren zur kontinuierlichen, wirtschaftlichen Planung von Ressourcen für das ISMS verankern.</p></td><td><p>Die Ressourcenplanung berücksichtigt die personellen, finanziellen und materiellen bzw. technischen Ressourcen.</p></td></tr></table><h2>GC.9: Dokumentenlenkung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GC.9.1: Richtlinie zur Dokumentenlenkung</td><td><p>Governance und Compliance MUSS ein Verfahren zur Lenkung der Dokumente im Rahmen des ISMS über den kompletten Lebenszyklus von Dokumenten verankern.</p></td><td><p>Ziel eines Verfahrens zur Dokumentenlenkung ist die Sicherstellung der Nachvollziehbarkeit von Dokumenten. Das Verfahren stellt hierbei die Nachvollziehbarkeit über den gesamten Lebenszyklus des Dokuments sicher. Dies beinhaltet die Erstellung bzw. Übernahme (z. B. aus <b>„Alt-Dokumenten“</b> oder externen Dokumenten) der Dokumente mit Titel, Autor, Dokumenteneigentümer, Sicherheitsklassifikation, Erstelldatum sowie einheitlicher Formate. Des Weiteren beinhaltet dies die Steuerung mit einem Änderungsmanagement (Versionierung), einer einheitlichen Veröffentlichung, einer angemessen geschützten Ablage und ggf. auch Archivierung sowie einer Rücknahme.</p></td></tr></table><h1>STM: Strukturmodellierung</h1><p>Die Praktik Strukturmodellierung bildet die Grundlage für eine systematische Analyse der Informationssicherheit einer Institution.   Ziel der Strukturmodellierung ist aus dem Stand der Technik-Kompendium eine individuelles Anforderungspaket für die Institution zu generieren. Auf Basis der Geschäftsprozesse und Informationen wird der individuelle Schutzbedarf festgelegt. Mit der Zuordnung einzelner Praktiken und Zielobjekte erfolgen eine Auswahl von Anforderungen auf der Grundlage des vorgegebenen Schutzniveaus. Blaupause unterstützen die Filterung der Anforderungen. Eine Klassifizierung des Schutzbedarfs der Zielobjekte erfolgt auf Anforderungsebene. Die individuelle Anpassung der Anforderungen durch Auswahlmöglichkeit erleichtern eine Skalierung. Eine Erweiterung des Anforderungspakets durch spezifischen Anforderungen erhöht die Flexibilität. Für diese Anforderungen ist eine Risikobetrachtungen erforderlich. Die Strukturmodellierung liefert essentielle Eingangsdaten für die nachgelagerten Praktiken wie Umsetzung und Monitoring-Evaluation und ermöglicht eine zielgerichtete und risikoorientierte Planung von Anforderungen und Sicherheitsmaßnahmen.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>STM.1: Informationssicherheitsanalyse</td><td align="right">1</td></tr><tr valign="top"><td>STM.2: Blaupausen</td><td align="right">2</td></tr><tr valign="top"><td>STM.3: Zielobjektklassen</td><td align="right">1</td></tr><tr valign="top"><td>STM.4: Asset Management</td><td align="right">1</td></tr><tr valign="top"><td>STM.5: Modellierung</td><td align="right">3</td></tr><tr valign="top"><td>STM.6: Anforderungen</td><td align="right">2</td></tr><tr valign="top"><td>STM.7: Vereinfachte Risikobewertung</td><td align="right">1</td></tr><tr valign="top"><td>STM.8: Vertiefende Risikoanalyse</td><td align="right">3</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>14</b></td></tr></table><h2>STM.1: Informationssicherheitsanalyse</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.1.1: Vorgehensweise Identifikation des Schutzbedarfs</td><td><p>Strukturmodellierung MUSS eine geeignete Vorgehensweise zur Identifikation des Schutzbedarfs der Geschäftsprozesse oder Informationen im Hinblick auf Schutzziele (Vertraulichkeit, Integrität und Verfügbarkeit) auf Basis des definierten Informationsverbundes und Kritikalitätskriterien verankern.</p></td><td><p>Das Ergebnis ist eine kurze Übersicht des Schutzbedarfs, der zu verarbeitenden Informationen und Relevanz (externe Vorgaben) der Geschäftsprozesse.</p></td></tr></table><h2>STM.2: Blaupausen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.2.1: Auswahl von Blaupausen</td><td><p>Strukturmodellierung MUSS auf Basis von passenden Blaupausen die Anforderungen auf den Informationsverbund einschränken.</p></td><td><p>Die Auswahl der Blaupause erfolgt unter Berücksichtigung der ersten Einschätzung des Schutzbedarfs (siehe GC.7.5.1). Anhand von Blaupausen erfolgt eine vordefinierte Auswahl sowie ein vordefinierter Zuschnitt der Praktiken (Reduktion sowie auch Ergänzungen der Praktiken) aus unterschiedlichen Perspektiven. Die Perspektiven können beispielsweise sein: - Größe der Organisation  - Branche  - besondere gesetzliche Anforderungen  Falls es keine passende Blaupause gibt, ist immer eine individuelle Blaupause für die Institution anzulegen.</p></td></tr><tr valign="top"><td>STM.2.1.1: Erstellung einer individuellen Blaupause</td><td><p>Strukturmodellierung SOLLTE eine selbst generierte Blaupause verankern.</p></td><td><p>Institutionen können eine eigene Blaupause erstellen und anwenden. Dies ist besonders dann erforderlich, wenn es keine einschlägige Blaupause für die eigene Branche oder Anwendungsfall gibt.</p></td></tr></table><h2>STM.3: Zielobjektklassen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.3.1: Identifikation der grundlegenden Zielobjektklassen</td><td><p>Strukturmodellierung SOLLTE die Zielobjektklassen des Informationsverbunds dokumentieren.</p></td><td><p>Bei der Erstellung einer individuellen Blaupause oder bei der Ergänzung von bestehenden Blaupausen mit zusätzlichen Anforderungen muss die Zielobjektvererbung des Kompendiums GS++ berücksichtigt werden. Ausgangspunkt hierbei sind die Zielobjekte. Die Abgrenzung des Informationsverbunds ist dabei zu berücksichtigen.</p></td></tr></table><h2>STM.4: Asset Management</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.4.1: Identifikation der Assets der Prozesse mit erhöhtem Schutzbedarf</td><td><p>Strukturmodellierung MUSS die Assets der Geschäftsprozesse mit erhöhtem Schutzbedarf dokumentieren.</p></td><td><p>Assets, für die ein erhöhter Schutzbedarf identifiziert wurde, sind zu dokumentieren, da für diese eine Risikoanalyse durchzuführen ist.  Die Identifikation der Assets mit erhöhtem Schutzbedarf kann beispielsweise aus einer Configuration Management Database (CMDB) erfolgen. Für den normalen Schutzbedarf ist nicht zwingend eine Zuordnung der Assets zu Geschäftsprozessen bzw. eine Abbildung von Abhängigkeiten untereinander erforderlich, da dies implizit für Anforderungen mit normalem Sicherheitsniveau durch das Kompendium GS++ gegeben ist. Ergebnis ist eine Übersicht über alle Assets mit erhöhtem Schutzbedarf.</p></td></tr></table><h2>STM.5: Modellierung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.5.1: Modellierung der Praktiken</td><td><p>Strukturmodellierung MUSS die ausgewählten Anforderungen den jeweiligen Zielobjekten bzw. Zielobjektklassen und die Anforderungen den Assettypen bzw. Assets zuweisen.</p></td><td><p>Die einschlägigen Anforderungen aus der anzuwendenden Blaupause sind den entsprechenden Zielobjekten bzw. Geschäftsprozessen zuzuordnen.</p></td></tr><tr valign="top"><td>STM.5.1.1: Ergänzung optionaler Praktiken und Anforderungen</td><td><p>Strukturmodellierung SOLLTE die in der Blaupause nicht enthaltenen (optionalen) Praktiken und Anforderungen aus dem Kompendium auf Anwendbarkeit überprüfen.</p></td><td><p>Optionale Praktiken sind z. B. Entwicklung und Dienstleistersteuerung. Nicht durch die Blaupause vorgegebene optionale Praktiken können relevante Inhalte für den Informationsverbund liefern und sollten bei Bedarf ergänzend modelliert werden. Dies gilt auch für Anforderungen aus den übrigen Praktiken, die nicht in die Blaupause aufgenommen wurden.</p></td></tr><tr valign="top"><td>STM.5.2: Begründung nicht-modellierter Praktiken und Anforderungen</td><td><p>Strukturmodellierung MUSS die Begründung nicht modellierter Praktiken und Anforderungen nachvollziehbar dokumentieren.</p></td><td><p>Für alle Praktiken und Anforderungen einer Blaupause, die nicht modelliert wurden, ist eine nachvollziehbare Begründung für die Nichtmodellierung anzugeben.  Beispielsweise. sind die Praktiken Entwicklung und Dienstleistersteuerung (optionale Praktiken) nur dann heranzuziehen, wenn die Institution diese benötigt.</p></td></tr></table><h2>STM.6: Anforderungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.6.1: Gesetzliche Verpflichtungen integrieren</td><td><p>Strukturmodellierung SOLLTE gesetzliche Verpflichtungen, welche die Verarbeitung von Informationen durch die Institution betreffen, dokumentieren.</p></td><td><p>Die gesetzlichen Verpflichtungen werden im Rahmen der Praktik <b>„Governance und Compliance“</b> identifiziert. Diese Anforderungen sind – soweit nicht bereits enthalten – in der Blaupause zu ergänzen.</p></td></tr><tr valign="top"><td>STM.6.2: Vertragliche Verpflichtungen integrieren</td><td><p>Strukturmodellierung SOLLTE vertragliche Verpflichtungen, welche die Verarbeitung von Informationen durch die Institution betreffen, dokumentieren.</p></td><td><p>Die vertraglichen Verpflichtungen wurden im Rahmen der Praktik <b>„Governance und Compliance“</b> identifiziert. Diese Anforderungen sind – soweit nicht bereits enthalten – in der Blaupause zu ergänzen.</p></td></tr></table><h2>STM.7: Vereinfachte Risikobewertung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.7.1: Durchführung einer vereinfachten Risikobewertung</td><td><p>Strukturmodellierung MUSS die Assets, für die es keine einschlägigen Anforderungen im Kompendium oder in der Blaupause gibt, dokumentieren.</p></td><td><p>Es kann Assets bzw. Assetklassen geben, die durch die Anforderungen nicht oder nicht vollständig abgebildet werden. Diese sind zu dokumentieren, da für diese eine Risikoanalyse durchzuführen ist. Im Rahmen der Risikoanalyse werden dann eigene Anforderungen bzw. Maßnahmen identifiziert.</p></td></tr></table><h2>STM.8: Vertiefende Risikoanalyse</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>STM.8.1: Durchführung von Risikoanalysen</td><td><p>Strukturmodellierung MUSS für Assets, die einen erhöhten Schutzbedarf aufweisen, eine vertiefende Risikoanalyse verankern.</p></td><td><p>Für Assets, die einen erhöhten Schutzbedarf haben, muss eine vertiefende Risikoanalyse z. B. nach BSI Standard 200-3 oder ISO 27005 durchgeführt werden. Im Rahmen der Risikoanalyse werden dann zusätzliche Anforderungen bzw. Maßnahmen identifiziert, um dem erhöhten Risiko entgegenzuwirken.</p></td></tr><tr valign="top"><td>STM.8.2: Freigabe der Risikobehandlung</td><td><p>Strukturmodellierung SOLLTE die in der Risikoanalyse getroffenen Entscheidungen zur Risikobehandlung durch die Risikoeigentümer dokumentieren.</p></td><td><p>Ziel ist es, Risikoentscheidungen nachvollziehbar aufzuzeichnen, damit sie später durch die Institutionsleitung freigegeben werden und die Freigabe dokumentiert werden kann.</p></td></tr><tr valign="top"><td>STM.8.3: Konsolidierung der ergänzenden Anforderungen</td><td><p>Strukturmodellierung SOLLTE ergänzende Anforderungen bzw. Maßnahmen aus der Risikoanalyse in der Blaupause dokumentieren.</p></td><td><p>Die im Rahmen der Risikoanalyse identifizierten Anforderungen sind dem BSI zur Aufnahme in das Kompendium Grundschutz++ zu übersenden. Kann eine Aufnahme in das Kompendium Grundschutz++ nicht erfolgen, so wird ein eigener Anforderungskatalog neben der angewendeten Blaupause erstellt.</p></td></tr></table><h1>UMS: Umsetzung</h1><p>Die Praktik Umsetzung sorgt für die systematische Planung, Implementierung und Dokumentation von Anforderungen bzw. der Sicherheitsmaßnahmen, die aus der Strukturmodellierung und Risikobewertung abgeleitet wurden. Sie stellt sicher, dass identifizierte Sicherheitsanforderungen effektiv in die organisatorischen und technischen Prozesse integriert werden. Diese Praktik umfasst die detaillierte Planung von Maßnahmen, die Festlegung von Verantwortlichkeiten und Zeitplänen sowie die Bereitstellung notwendiger Ressourcen. Zudem beinhaltet sie die Nachverfolgung der Implementierung und die Dokumentation der umgesetzten Maßnahmen.  Während die Praktik Strukturmodellierung die notwendigen Anforderungen identifiziert und die Praktik Monitoring-Evaluation die Wirksamkeit der Maßnahmen überprüft, konzentriert sich die Umsetzung auf die effiziente und effektive Realisierung der erforderlichen Sicherheitsmaßnahmen.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>UMS.1: Wahrung von Compliance</td><td align="right">3</td></tr><tr valign="top"><td>UMS.2: Umsetzungscheck</td><td align="right">1</td></tr><tr valign="top"><td>UMS.3: Restrisikobewertung</td><td align="right">1</td></tr><tr valign="top"><td>UMS.4: Realisierungsplan</td><td align="right">4</td></tr><tr valign="top"><td>UMS.5: Freigabeverfahren</td><td align="right">4</td></tr><tr valign="top"><td>UMS.6: Fortschrittsverfolgung</td><td align="right">3</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>16</b></td></tr></table><h2>UMS.1: Wahrung von Compliance</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>UMS.1.1: Prävention von Verstößen</td><td><p>Umsetzung SOLLTE Verfahren zur Prävention gegen Verstöße verankern.</p></td><td><p>Verfahren können z. B. zielgruppengerechte Schulungen der für die Umsetzung und Einhaltung zuständigen Personen, die Berücksichtigung der Compliance-Verpflichtungen bei Freigabe- und Testprozessen sowie die Förderung einer konstruktiven Fehlerkultur sein.</p></td></tr><tr valign="top"><td>UMS.1.2: Aufgabenzuweisung</td><td><p>Umsetzung SOLLTE zu jeder Verpflichtung die zu ihrer Einhaltung erforderlichen Aufgaben zuweisen.</p></td><td><p>Hierbei sind jeder für das ISMS relevanten Verpflichtung Aufgaben und Rollen zuzuordnen um sicherzustellen, dass alle Verpflichtungen in den Prozessen berücksichtigt wurden. Darüber hinaus sind auch die Anforderungen zu <b>„Autorisierung von Ausnahmen“</b> und <b>„Dokumentation von Ausnahmen“</b> zu beachten.</p></td></tr><tr valign="top"><td>UMS.1.3: Anweisung zur Einhaltung</td><td><p>Umsetzung für Nutzende MUSS diese zur Einhaltung der dokumentierten Verpflichtungen anweisen.</p></td><td><p>Dies gilt insbesondere bei der Planung und Konzeption von Geschäftsprozessen, Anwendungen und IT-Systemen oder bei der Beschaffung von IT-Produkten und Dienstleistungen. Hierbei sind auch die Anforderungen zu <b>„Autorisierung von Ausnahmen“</b> und <b>„Dokumentation von Ausnahmen“</b> zu beachten.</p></td></tr></table><h2>UMS.2: Umsetzungscheck</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>UMS.2.1: Überprüfung des Umsetzungsstatus</td><td><p>Umsetzung MUSS den Umsetzungsstatus der Anforderungen der verschiedenen Praktiken vollständig überprüfen.</p></td><td><p>Der Umsetzungsstatus einer Anforderung kann grundsätzlich nur „umgesetzt“ („ja“) oder „nicht umgesetzt“ („nein“) sein, da eine Anforderung nur einen Aspekt enthält.</p></td></tr></table><h2>UMS.3: Restrisikobewertung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>UMS.3.1: Bewertung des Restrisikos</td><td><p>Umsetzung SOLLTE ein Verfahren für die Bewertung des bestehenden Restrisikos durch die nicht umgesetzten Anforderungen verankern.</p></td><td><p>Die Risiken der Nichtumsetzung von Anforderungen können auch konsolidiert werden, um diese für die Institutionsleitung nachvollziehbarer zu machen.</p></td></tr></table><h2>UMS.4: Realisierungsplan</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>UMS.4.1: Planung der Umsetzung</td><td><p>Umsetzung MUSS ein Verfahren zur Festlegung von Maßnahmen für die Umsetzung der bisher nicht umgesetzten Anforderungen des Anforderungspakets als Ergebnis der Praktik Strukturmodellierung verankern.</p></td><td><p>Das Verfahren ist auf die Organisation abzustimmen. Dabei empfiehlt es sich zu prüfen, ob Maßnahmen etabliert sind, die mehrere Anforderungen zugleich abdecken. Ebenso kann das Verfahren genutzt werden, um Synergieeffekte zu erschließen, indem ähnliche Defizite in anderen Bereichen identifiziert und mit gemeinsamen Lösungen adressiert werden.</p></td></tr><tr valign="top"><td>UMS.4.2: Priorisierung von Maßnahmen</td><td><p>Umsetzung MUSS eine Priorisierung der festgelegten Maßnahmen verankern.</p></td><td><p>Es ist eine geeignete Priorisierung der Anforderungen und Maßnahmenumsetzung vorzunehmen. Gesetzliche Verpflichtungen und Compliance, der Umsetzungsaufwand einer Anforderung bzw. Maßnahme oder die Risikomitigierung der Anforderungen können bei der Priorisierung helfen.</p></td></tr><tr valign="top"><td>UMS.4.3: Benennung von Umsetzungszuständigen</td><td><p>Umsetzung MUSS Zuständige für die Umsetzung der bisher nicht umgesetzten Anforderungen eindeutig zuweisen.</p></td><td><p>Die Anforderungen sind den jeweils zuständigen Bereichen bzw. Abteilungen oder Personen in der Institution zuzuordnen, damit man eine Zuordnung der Zuständigkeit für die Anforderung ableiten kann. Zuständigkeitsbereiche können in einzelnen Anforderungen direkt addressiert sein, sie sind dann als „Personen oder Rollen“ benannt.</p></td></tr><tr valign="top"><td>UMS.4.4: Festlegung von Umsetzungsfristen</td><td><p>Umsetzung MUSS ein realistisches Zieldatum für die Umsetzung der bisher nicht umgesetzten Anforderungen verankern.</p></td><td><p>Zur Nachverfolgung des Status der Umsetzung einer Anforderung sind verbindliche Umsetzungsfristen zu dokumentieren. Die Einhaltung dieser Fristen muss nachgehalten werden. Bei Überschreitung der Fristen sind geeignete Maßnahmen einzuleiten.</p></td></tr></table><h2>UMS.5: Freigabeverfahren</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>UMS.5.1: Bestätigung des Restrisikos</td><td><p>Umsetzung SOLLTE die Kenntnisnahme des Restrisikos durch die Risikoeigentümer dokumentieren.</p></td><td><p>Durch nicht umgesetzte Anforderungen entsteht ein Restrisiko, von dem der Risikoeigentümer Kenntnis haben SOLL. Der Risikoeigentümer SOLL dieses Risiko bis zur Umsetzung bewusst tragen. Grundlage hierfür ist der Umsetzungsplan.</p></td></tr><tr valign="top"><td>UMS.5.2: Freigabe der Umsetzungsplanung</td><td><p>Umsetzung MUSS die Freigabe der Umsetzungsplanung durch die Risikoeigentümer dokumentieren.</p></td><td><p>Auf der Grundlage des Umsetzungsplans ist eine systematische und transparente Umsetzung der Anforderung bzw. Sicherheitsmaßnahmen möglich. Der Umsetzungsplan enthält z. B.  - die Anforderungsbeschreibung, - das Zielobjekt bzw. den Anwendungsbereich - die verantwortliche Stelle - Start und Zieldatum (Fristen) - Prioritäten  - Status der Umsetzung - ergänzende Aktivitäten z. B. Schulungen - Risiken inkl. Begründung (Was bleibt offen? Was wurde nicht umgesetzt und warum?) - Ressourcenplanung - Abhängigkeiten zu anderen Anforderungen  - Datum der Freigabe und Unterschrift des Risikoeigentümers. Der Umsetzungsplan dient als Grundlage für die Fortschrittskontrolle, die Berichterstattung und Audits.</p></td></tr><tr valign="top"><td>UMS.5.3: Autorisierung von Ausnahmen</td><td><p>Umsetzung MUSS Ausnahmegenehmigungen für Verpflichtungen durch eine zuständige Person oder Rolle autorisieren.</p></td><td><p>Bei Zielkonflikten zwischen Verpflichtungen müssen diese gegeneinander abgewogen und falls erforderlich Ausnahmegenehmigungen eingeholt werden. Zur Entscheidungsfindung kann eine Risikoabschätzung vorgenommen werden. Hierbei sind auch die Anforderungen zur <b>„Aufgabenzuweisung“</b> und <b>„Anweisung zur Einhaltung“</b> zu berücksichtigen.</p></td></tr><tr valign="top"><td>UMS.5.4: Dokumentation von Ausnahmen</td><td><p>Umsetzung MUSS Ausnahmegenehmigungen mit Begründung dokumentieren.</p></td><td><p>Um rechtlich bedeutsame Entscheidungen zur Informationsverarbeitung später nachvollziehen und ggf. anpassen zu können, ist eine Dokumentation dieser Entscheidungen wichtig. Die Dokumentation muss nicht separat von Geschäftsprozessen vorgenommen werden. Vielmehr ist es sogar empfehlenswert, Geschäftsprozesse und Entscheidungsdokumentation zu integrieren, z. B. in CMDBs, Aktenverzeichnissen, Commit-Messages oder Ticketsystemen. Hierbei sind auch die Anforderungen zur <b>„Aufgabenzuweisung“</b> und <b>„Anweisung zur Einhaltung“</b> zu berücksichtigen.</p></td></tr></table><h2>UMS.6: Fortschrittsverfolgung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>UMS.6.1: Nachverfolgung des Umsetzungsfortschritts</td><td><p>Umsetzung MUSS ein Verfahren für die Nachverfolgung der Umsetzung von Maßnahmen verankern.</p></td><td><p>Es wird empfohlen, dass der Prozess zur Fortschrittsverfolgung der Umsetzung von Anforderungen bzw. Sicherheitsmaßnahmen folgende Aspekte umfasst: - Planung und Definition: Zielsetzung, KPI-Definition und detaillierte Umsetzungsplanung. - Implementierung: Start der Umsetzung mit klarer Verantwortlichkeit und initialer Bestandsaufnahme. - Überwachung: Regelmäßiges Status-Reporting, Soll-Ist-Vergleiche und KPI-Messungen. - Bewertung und Anpassung: Ursachenanalyse, Korrekturmaßnahmen und regelmäßige Kommunikation an Stakeholder. - Dokumentation und Lessons Learned: Abschlussdokumentation und kontinuierliche Verbesserung mittels PDCA-Zyklus. Eine strukturierte Vorgehensweise gewährleistet, dass Fortschritte transparent nachvollzogen werden, Abweichungen frühzeitig erkannt und der Sicherheitsstatus stetig verbessert werden kann.</p></td></tr><tr valign="top"><td>UMS.6.2: Wirksamkeitsprüfung der Umsetzung</td><td><p>Umsetzung SOLLTE die Wirksamkeit der umgesetzten Maßnahmen überprüfen.</p></td><td><p>Die Wirksamkeitsprüfung stellt sicher, dass umgesetzte Anforderungen bzw. Maßnahmen tatsächlich die angestrebten Schutzziele erreichen. Sie umfasst die Bewertung, ob Risiken reduziert, gesetzliche Anforderungen erfüllt und Prozesse verbessert wurden. Bei unzureichender Wirksamkeit müssen Maßnahmen angepasst und erneut bewertet werden.</p></td></tr><tr valign="top"><td>UMS.6.3: Fortschreibung des Umsetzungsplans</td><td><p>Umsetzung MUSS ein Verfahren zur Fortschreibung des Umsetzungsplans verankern.</p></td><td><p>Der Umsetzungsplan muss regelmäßig nachverfolgt, aktualisiert und freigegeben werden.</p></td></tr></table><h1>VRB: Verbesserung</h1><p>Die Praktik Verbesserung gewährleistet die kontinuierliche Weiterentwicklung und Optimierung des Informationssicherheitsmanagementsystems. Sie nutzt die Erkenntnisse aus dem Monitoring und der Evaluation, um die Wirksamkeit der Sicherheitsmaßnahmen zu erhöhen.  Diese Praktik umfasst die Planung und Umsetzung von Korrektur- und Vorbeugungsmaßnahmen. Ziel ist es, einen Prozess der kontinuierlichen Verbesserung zu etablieren, der flexibel auf neue Bedrohungen und veränderte Rahmenbedingungen reagieren kann. Die Verbesserung schließt den PDCA-Zyklus ab und leitet gleichzeitig einen neuen Zyklus ein, indem sie Impulse für Anpassungen in den Praktiken Governance und Compliance, Strukturmodellierung und Umsetzung gibt. Sie stellt sicher, dass das ISMS dynamisch bleibt und sich an veränderte Anforderungen und Bedrohungen anpasst.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>VRB.1: Wahrung von Compliance</td><td align="right">1</td></tr><tr valign="top"><td>VRB.2: Prozesse des ISMS</td><td align="right">4</td></tr><tr valign="top"><td>VRB.3: Maßnahmen</td><td align="right">2</td></tr><tr valign="top"><td>VRB.4: Umsetzungsplanung</td><td align="right">1</td></tr><tr valign="top"><td>VRB.5: Bewertung</td><td align="right">1</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>9</b></td></tr></table><h2>VRB.1: Wahrung von Compliance</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>VRB.1.1: Behandlung von Verstößen</td><td><p>Verbesserung SOLLTE ein Verfahren zur Behandlung von Verstößen verankern.</p></td><td><p>Je nach Verstoß sind Maßnahmen unterschiedlicher Intensität denkbar, vom Mitarbeitergespräch über Abmahnungen oder den Entzug bestimmter Aufgaben und Berechtigungen bis hin zur außerordentlichen Kündigung oder Meldung bei Ermittlungsbehörden. Relevant ist hierbei insbesondere die Prognose, ob in Zukunft mit weiteren Verstößen durch die Person zu rechnen ist. Dabei besteht ein enger Bezug zu den Rechten und Freiheiten der Betroffenen, z. B. der Verhältnismäßigkeit von arbeitsrechtlichen Maßnahmen.Im Zweifelsfall ist es sinnvoll, die rechtsberatenden Berufe zu konsultieren.</p></td></tr></table><h2>VRB.2: Prozesse des ISMS</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>VRB.2.1: Verfahren zur kontinuierlichen Verbesserung</td><td><p>Verbesserung MUSS ein Verfahren zur kontinuierlichen Verbesserung des ISMS verankern.</p></td><td><p>Dieses Verfahren ist ein Prozess, welcher sich im PDCA-Zyklus von der Praktik Strukturmodellierung über die Umsetzung bis hin zum Monitoring und der Evaluierung erstreckt.</p></td></tr><tr valign="top"><td>VRB.2.1.1: Umgang mit Nichtkonformitäten</td><td><p>Verbesserung MUSS eine Methode zur Überprüfung von Nichtkonformitäten hinsichtlich Ursachen und Wiederauftreten verankern.</p></td><td><p>Ziel ist es gezielt und nachhaltig auf Abweichungen reagieren zu können. Konkret bedeutet das:<br/>- Identifikation der Nichtkonformität: Abweichung von Anforderungen (z.B. aus Normen, internen Richtlinien, Prozessen oder Auditergebnissen) wird erkannt und dokumentiert.<br/>- Ursachenanalyse (Root Cause Analysis): Ermittlung, warum die Nichtkonformität entstanden ist, z.B. durch Methoden wie:     <br/>- 5-Why-Methode      <br/>- Ishikawa-Diagramm (Fishbone)      <br/>- Fehlerbaum-Analyse<br/>- Wirkungsanalyse: Bewertung, welche Auswirkungen die Nichtkonformität auf Informationssicherheit, Prozesse oder Geschäftsziele hat<br/>- Ableitung und Umsetzung von Korrekturmaßnahmen: Maßnahmen gezielt auf die Ursachen ausrichten – nicht nur Symptome beheben<br/>- Nachverfolgung: Kontrolle, ob die Maßnahmen die Ursache dauerhaft beseitigt und die Nichtkonformität nicht erneut auftritt (z.B. durch erneute Auditierung oder KPI-Monitoring).</p></td></tr><tr valign="top"><td>VRB.2.1.2: Umgang mit Verbesserungspotentialen</td><td><p>Verbesserung SOLLTE eine Methode zur Überprüfung und Bewertung von Verbesserungspotentialen unter Berücksichtigung von  Risiken verankern.</p></td><td><p>Die Methode beinhaltet z. B.:<br/>-	Bewertung des Umfelds der Institution (z. B. Bewertung der Gefährdungslage)<br/>-	Auswertung des Umsetzungsplans <br/>-	Auswertung von Auditergebnissen<br/>-	Auswertung von Sicherheitsvorfällen<br/>-	Ad hoc-Eingaben (z. B. akute Verbesserungspotentiale)</p></td></tr><tr valign="top"><td>VRB.2.1.3: Anpassung des ISMS</td><td><p>Verbesserung SOLLTE die Nichtkonformitäten hinsichtlich der Notwendigkeit zur Anpassung des ISMS überprüfen.</p></td><td><p>Es ist zu überprüfen, ob Auswirkungen auf die Anforderungen bzw. Sicherheitsmaßnahmen durch Fehler,  Mängel oder Verfahrensabweichungen in Bezug auf die Informationssicherheit des ISMS bestehen.</p></td></tr></table><h2>VRB.3: Maßnahmen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>VRB.3.1: Korrekturmaßnahmen</td><td><p>Verbesserung MUSS angemessene Korrekturmaßnahmen zur Beseitigung der Ursachen von Fehlern verankern.</p></td><td><p>Wenn bei Sicherheitsprüfungen (Kontrollen, Audits) nicht umgesetzte oder wirkungslose Maßnahmen festgestellt werden, dann sind eine Analyse der Ursachen und geeignete Korrekturmaßnahmen notwendig. Je nach Ursache kommen folgende Maßnahmen in Betracht: organisatorische Anpassungen, personelle Maßnahmen (z. B. Schulungen, Sensibilisierung, ggf. disziplinarische Schritte), infrastrukturelle Änderungen (z. B. bauliche Anpassungen), technische Anpassungen (z. B. an Hardware, Software oder Netzinfrastruktur), sowie das Einholen und Umsetzen von Entscheidungen von der Institutionsleitung  oder nachgeordneter Führungskräfte.</p></td></tr><tr valign="top"><td>VRB.3.2: Verbesserungsmaßnahmen</td><td><p>Verbesserung SOLLTE angemessene Maßnahmen zur Nutzung von Verbesserungspotentialen unter Berücksichtigung von  Risiken verankern.</p></td><td><p>Angemessene Maßnahmen zur Nutzung von Verbesserungspotenzialen im ISMS sind gezielte Aktivitäten, die geeignet sind, Schwächen zu beseitigen oder Prozesse, Kontrollen und Sicherheitsmaßnahmen wirksamer, effizienter oder robuster zu gestalten – unter Berücksichtigung von Ressourcen, Risiko und Nutzen. Hinweis: Die Angemessenheit der Maßnahmen bemisst sich an ihrer Wirksamkeit zur Verbesserung der Informationssicherheit, ihrer Verhältnismäßigkeit (Kosten-Nutzen) und der praktischen Umsetzbarkeit im Kontext der Organisation.  Beispiele für angemessene Maßnahmen: Prozessoptimierung:<br/>- Verschlankung oder Automatisierung von Sicherheitsprozessen <br/>- Einführung standardisierter Abläufe (z. B. Checklisten, Workflows, Tools). Technische Verbesserungen:<br/>- Einsatz neuer oder sichererer Technologien <br/>- Aktualisierung oder Austausch veralteter Systeme<br/>- Schulungen und Awareness:<br/>- Verbesserte Sicherheitsbewusstseinskampagnen, zielgruppengerechte Trainings.<br/>- Lessons Learned aus Vorfällen und Audits gezielt vermitteln etc.</p></td></tr></table><h2>VRB.4: Umsetzungsplanung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>VRB.4.1: Priorisierung von Maßnahmen</td><td><p>Verbesserung MUSS in dem Umsetzungsplan Maßnahmen zur Verbesserung verankern.</p></td><td><p>Maßnahmen zur Verbesserung müssen in den Umsetzungsplan einfließen. Dort werden die Zuständigen für die Umsetzung,  Zieldatum der Umsetzung, die Anforderungsbeschreibung, das Zielobjekt bzw. den Anwendungsbereich,  die verantwortliche Stelle,  Start- und Zieldatum (Fristen),  Prioritäten,  Status der Umsetzung,  ergänzende Aktivitäten z. B. Schulungen, Risiken inkl. Begründung (Was bleibt offen? Was wurde nicht umgesetzt und warum?), Ressourcenplanung, Abhängigkeiten zu anderen Anforderungen, sowie Datum der Freigabe und Unterschrift des Risikoeigentümers nachverfolgt.</p></td></tr></table><h2>VRB.5: Bewertung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>VRB.5.1: Bewertung der erreichten Verbesserung</td><td><p>Verbesserung MUSS ein Verfahren zur Bewertung der Maßnahmen zur Verbesserung unter Berücksichtigung von  Risiken verankern.</p></td><td><p>Die Bewertung kann beispielsweise durch interne Audits, die Messung von Key Performance Indicators (KPIs) vor und nach der Maßnahmenumsetzung oder durch technische Überprüfungen erfolgen. Im Ergebnis ist das Sicherheitsniveau der Institution transparent dargestellt und Trends der Verbesserung des Sicherheitsniveaus, insbesondere auch durch die Vergleichbarkeit mit vorigen Bewertungen, ableitbar.</p></td></tr></table><h1>PERF: Monitoring-Evaluation</h1><p>Die Praktik Monitoring-Evaluation stellt durch kontinuierliche Überwachung und systematische Bewertung sicher, dass die implementierten Sicherheitsmaßnahmen wirksam sind und die Sicherheitsziele der Organisation erreicht werden. Sie liefert Erkenntnisse über den aktuellen Sicherheitszustand und identifiziert Verbesserungspotentiale.  Im Rahmen dieser Praktik werden regelmäßige Sicherheitsaudits, kontinuierliches Monitoring von Sicherheitsereignissen sowie periodische Überprüfungen und Bewertungen des ISMS durchgeführt. Sie entspricht der <b>„Check-Phase“</b> im PDCA-Zyklus und dient dazu, Abweichungen von den definierten Zielen zu erkennen.  Die Ergebnisse der Monitoring-Evaluation fließen direkt in die Praktik Verbesserung ein, wo konkrete Maßnahmen zur Behebung identifizierter Schwachstellen und zur kontinuierlichen Weiterentwicklung des ISMS abgeleitet werden.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>PERF.1: Prozesse des ISMS</td><td align="right">7</td></tr><tr valign="top"><td>PERF.2: Audits</td><td align="right">7</td></tr><tr valign="top"><td>PERF.3: Managementbewertungen</td><td align="right">11</td></tr><tr valign="top"><td>PERF.4: Monitoring</td><td align="right">3</td></tr><tr valign="top"><td>PERF.5: Blaupausen</td><td align="right">1</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>29</b></td></tr></table><h2>PERF.1: Prozesse des ISMS</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERF.1.1: Verfahren und Regelungen</td><td><p>Monitoring-Evaluation MUSS Verfahren und Regelungen zur Messung und Bewertung der Leistung des ISMS verankern.</p></td><td><p>Die bei der Festlegung des Verfahrens und der Regelungen im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>PERF.1.1.1: Auswertung der Gefährdungslage</td><td><p>Monitoring-Evaluation SOLLTE die Gefährdungslage in Bezug auf geänderte Rahmenbedingungen überprüfen.</p></td><td><p>Die Auswertung der Gefährdungslage in Bezug auf Veränderungen dient dazu, sicherzustellen, dass neue oder veränderte Bedingungen (z.B. organisatorisch, technisch, gesetzlich) auch neue Gefährdungen mit sich bringen können und diese im ISMS berücksichtigt werden. Konkrete Prüfpunkte: - Technische Veränderungen: Einführung neuer IT-Systeme, Software, Netzwerktechnologien oder Cloud-Dienste führen ggf. zu neuen Bedrohungen - Organisatorische Veränderungen: z.B. Outsourcing, neue Standorte, Umstrukturierungen, neue Schnittstellen oder Verantwortlichkeiten - Rechtliche/regulatorische Änderungen: neue Gesetze (z.B. NIS2, DSGVO-Anpassungen), Branchenvorgaben führen zu neuen Compliance-Risiken - Veränderte Bedrohungslage: neue Angriffsarten, aktuelle Sicherheitsvorfälle, CERT-Warnungen → Aktualisierung der Gefährdungskataloge notwendig. Was ist zu tun: - Regelmäßige Überprüfung der Gefährdungslage (z.B. halbjährlich oder anlassbezogen). - Anpassung der Risikoanalyse bei identifizierten neuen Gefährdungen - Ableitung neuer Schutzmaßnahmen oder Nachbesserung bestehender - Dokumentation der Prüfung und Ergebnisse im ISMS.</p></td></tr><tr valign="top"><td>PERF.1.1.2: Auswertung des Umsetzungsplans</td><td><p>Monitoring-Evaluation SOLLTE den Umsetzungsplan in Bezug auf den Fortschritt, die Einhaltung oder die Überschreitung von Umsetzungsdaten und der inhaltlichen Korrektheit regelmäßig überprüfen.</p></td><td><p>Die Überprüfung eines Umsetzungsplans beinhaltet, ob Sicherheitsmaßnahmen vollständig, termingerecht und wirksam sowie inhaltlich korrekt umgesetzt wurden und ob sie die angestrebten Schutzziele erreichen. Dabei sind insbesondere der Umsetzungsstand, Abweichungen, Restrisiken und die Wirksamkeit der Maßnahmen systematisch zu überprüfen und für Managemententscheidungen auszuwerten. Umsetzungsdaten umfassen z.B. Fälligkeitsdatum, bis wann eine bestimmte Maßnahme umgesetzt sein muss, Meilensteine im Projektplan oder vereinbarte Endtermine für Kontrollen, Prüfungen oder technische Implementierungen.</p></td></tr><tr valign="top"><td>PERF.1.1.3: Auswertung von Auditergebnissen</td><td><p>Monitoring-Evaluation SOLLTE die Umsetzung von festgelegten Maßnahmen aus Auditergebnissen in Bezug auf den Fortschritt, die Einhaltung oder die Überschreitung von Umsetzungsdaten und der inhaltlichen Korrektheit regelmäßig überprüfen.</p></td><td><p>Die Auswertung von Auditergebnissen dient dazu, systematische Abweichungen, Schwachstellen und Verbesserungspotenziale im Informationssicherheitsmanagement zu identifizieren. Im Audit festgestellte Abweichungen, Hinweise und Empfehlungen werden ausgewertet, nach ihrer Bedeutung geordnet und in konkrete Maßnahmen überführt. Diese Maßnahmen werden anschließend überwacht und ihre Umsetzung nachverfolgt.</p></td></tr><tr valign="top"><td>PERF.1.1.4: Auswertung von  Verbesserungen</td><td><p>Monitoring-Evaluation SOLLTE die Umsetzung von Verbesserungsmaßnahmen in Bezug auf den Fortschritt, die Einhaltung oder die Überschreitung von Umsetzungsdaten und der inhaltlichen Korrektheit regelmäßig überprüfen.</p></td><td><p>Die Auswertung von Verbesserungsmaßnahmen im Informationssicherheitsmanagement dient dazu, den Nutzen und die Wirksamkeit bereits umgesetzter Korrektur- oder Optimierungsmaßnahmen zu bewerten. Dabei wird geprüft, ob die Maßnahme das angestrebte Ziel erreicht hat, bestehende Risiken reduziert wurden und ob sich weitere Anpassungen oder Folgeaktivitäten ergeben, um die Sicherheit kontinuierlich zu erhöhen.</p></td></tr><tr valign="top"><td>PERF.1.1.5: Auswertung von Sicherheitsvorfällen</td><td><p>Monitoring-Evaluation SOLLTE umgesetzte Maßnahmen als Folge von Sicherheitsvorfällen überprüfen.</p></td><td><p>Bei der Auswertung von Sicherheitsvorfällen müssen Ursachen, Auswirkungen, Reaktionen und Schwachstellen systematisch analysiert werden, um gezielte Verbesserungsmaßnahmen abzuleiten. Wichtig ist, dass sowohl die Wirksamkeit der Sofortmaßnahmen als auch die Umsetzung und Nachhaltigkeit der Folgemaßnahmen überprüft werden.</p></td></tr><tr valign="top"><td>PERF.1.1.6: Überwachung der Einhaltung von Verpflichtungen</td><td><p>Monitoring-Evaluation SOLLTE die Einhaltung von Verpflichtungen <i>regelmäßig</i> sowie anlassbezogen überprüfen.</p></td><td><p>Es wird regelmäßig überprüft, ob die Compliance gewährleistet ist, z.B. durch die Einhaltung gesetzlicher, regulatorischer oder vertraglicher Verpflichtungen.</p></td></tr></table><h2>PERF.2: Audits</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERF.2.1: Aufbau und Pflege eines Auditprogramms</td><td><p>Monitoring-Evaluation MUSS ein Verfahren zum Aufbau und zur Pflege eines oder mehrerer Auditprogramme verankern.</p></td><td><p>Ein Audit kann in unterschiedlichen Formen durchgeführt werden – beispielsweise als internes Audit durch eigene Mitarbeitende, als externes Audit durch unabhängige Dritte (z. B. für Zertifizierungen), als Überwachungs- oder Wiederholungsaudit, oder als Sonderaudit bei Sicherheitsvorfällen. Ziel ist es, die Einhaltung von Sicherheitsanforderungen, die Wirksamkeit von Maßnahmen sowie mögliche Schwachstellen zu prüfen.</p></td></tr><tr valign="top"><td>PERF.2.1.1: Erstellen eines Auditsplans</td><td><p>Monitoring-Evaluation SOLLTE für jedes durchzuführende Audit einen Auditplan dokumentieren.</p></td><td><p>Der Auditplan (audit plan) legt vorab die Ziele, den Umfang (Geltungsbereich, Zielobjekte), die Methoden (Auditkriterien), Rollen und Zuständigkeiten, sowie den genauen Ablauf dieser Überprüfung fest. Auditmethoden sind die spezifischen Vorgehensweisen und Techniken, die ein Auditor zur Sammlung und Bewertung von Prüfungsnachweisen (audit evidence) einsetzt. Die Auswahl der Methode hängt vom jeweiligen Prüfziel ab und umfasst häufig eine Kombination aus mehreren Ansätzen, wie zum Beispiel: (1) die Befragung von Mitarbeitern (Interviews), um Prozessabläufe und Verantwortlichkeiten zu verstehen, (2) die (automatisierte und manuelle) Durchsicht von Dokumenten wie Richtlinien, Konzepten und Protokollen zur Überprüfung der Vorgabenkonformität, (3) die direkte Beobachtung von Prozessen, um die tatsächliche Umsetzung einer Kontrolle zu verifizieren, sowie (4) technische Analysen, welche die Überprüfung von Systemkonfigurationen, die Auswertung von Logdateien oder die Durchführung von Stichproben bei Berechtigungen beinhalten können. Der Zweck dieser Anforderung ist es, eine strukturierte und nachvollziehbare Vorgehensweise bei jeder Prüfung zu gewährleisten. Ohne einen solchen Plan könnte eine Überprüfung chaotisch verlaufen, wichtige Bereiche übersehen oder Ressourcen ineffizient eingesetzt werden, was unentdeckte Schwachstellen zur Folge haben kann. Ein detaillierter Auditplan kann hingegen sicherstellen, dass alle relevanten Aspekte systematisch abgedeckt werden und schafft eine klare Erwartungshaltung sowie Verbindlichkeit für die Auditoren und die geprüften Stellen der Institution. Bewährt hat sich dabei eine chancen- und risikenorientierte Ressourcenverteilung, d.h. die Betrachtung genau jener Anforderungen, bei denen voraussichtlich ein hoher Mehrwert für die Risikoanalyse durch das Audit zu erwarten ist. Für Details siehe ISO/IEC 19011-Reihe.</p></td></tr><tr valign="top"><td>PERF.2.2: Planen von internen Audits</td><td><p>Monitoring-Evaluation MUSS im Auditprogramm die Planung der internen Audits risikoorientiert dokumentieren.</p></td><td><p>Ziel ist es, die Einhaltung von Sicherheitsanforderungen, die Wirksamkeit von Maßnahmen sowie mögliche Schwachstellen zu prüfen. Es muss die Effektivität und Effizienz aller angewandten Anforderungen sinnvoll geprüft werden.</p></td></tr><tr valign="top"><td>PERF.2.3: Auswahl des Auditteams</td><td><p>Monitoring-Evaluation MUSS ein Verfahren zur Auswahl von fachlich geeigneten und unabhängigen Auditoren verankern.</p></td><td><p>Bei der Auswahl von Auditoren ist zu empfehlen insbesondere Fachkompetenz, Unabhängigkeit und Erfahrung zu berücksichtigen. Das Team muss über technisches und organisatorisches Wissen, Kenntnisse relevanter Normen und gesetzliche Anforderungen sowie die Fähigkeit zur objektiven, methodischen Bewertung verfügen, ohne in die zu prüfenden Prozesse direkt involviert zu sein.</p></td></tr><tr valign="top"><td>PERF.2.4: Umfang von Audits</td><td><p>Monitoring-Evaluation MUSS in angemessenem Umfang Audits verankern.</p></td><td><p>Der Umfang eines Audits beschreibt, was, wie und in welchem Rahmen geprüft wird. Dazu gehören der organisatorische und technische Geltungsbereich (z. B. Standorte, Abteilungen, IT-Systeme), der Prüfzeitraum,  sowie die eingesetzten Prüfmethoden wie Interviews, Dokumentensichtung oder Systemtests. Der Auditumfang wird vor Beginn des Audits klar definiert, um den Ablauf gezielt zu planen und die Ergebnisse nachvollziehbar zu dokumentieren.</p></td></tr><tr valign="top"><td>PERF.2.5: Erstellen von Auditberichten</td><td><p>Monitoring-Evaluation MUSS Auditergebnisse in Berichten dokumentieren.</p></td><td><p>Ein Auditbericht muss nachvollziehbar, vollständig und strukturiert dokumentieren, wie das Audit durchgeführt wurde und welche Ergebnisse erzielt wurden. Er enthält Angaben zum Auditziel, Auditumfang, Auditteam, Auditmethoden, den bewerteten Bereichen sowie eine übersichtliche Darstellung der Feststellungen inklusive Abweichungen, Verbesserungspotenzialen und der Bewertung der Wirksamkeit der umgesetzten Sicherheitsmaßnahmen.</p></td></tr><tr valign="top"><td>PERF.2.5.1: Einheitliches Bewertungsschema</td><td><p>Monitoring-Evaluation SOLLTE für Feststellungen in Audits ein einheitliches Bewertungsschema verankern.</p></td><td><p>Das Bewertungsschema soll die einheitliche Bewertung und die Vergleichbarkeit von Auditergebnissen sicherstellen.</p></td></tr></table><h2>PERF.3: Managementbewertungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERF.3.1: Eignungsprüfung</td><td><p>Monitoring-Evaluation MUSS das ISMS der Institution hinsichtlich Eignung, Angemessenheit und Wirksamkeit <i>regelmäßig</i> sowie anlassbezogen überprüfen.</p></td><td><p>Damit die Institutionsleitung fundierte Entscheidungen zur Steuerung des Informationssicherheitsprozesses treffen kann, ist ein prägnanter Managementbericht erforderlich. Darin werden die wesentlichen Eckpunkte zum Stand der Informationssicherheit übersichtlich aufbereitet. Der Bericht SOLL: kurz, klar und verständlich sein, relevante Informationen bzw. Entwicklungen enthalten, nicht überfrachtet sein d.h. den Fokus auf das Wesentliche legen. So kann die Leitung gezielt Maßnahmen priorisieren und Ressourcen effektiv einsetzen. Es muss unter anderem deutlich werden, ob der beabsichtigte Sicherheitszweck wirksam erfüllt wird.</p></td></tr><tr valign="top"><td>PERF.3.2: Ergebnisse von Folgemaßnahmen</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der den Status von Folgemaßnahmen vorangegangener Managementbewertungen enthält, dokumentieren.</p></td><td><p>Die Evaluierung von Folgemaßnahmen früherer Managementbewertungen dient der Prüfung, ob geplante Maßnahmen umgesetzt und ihre Ziele erreicht wurden. Dabei müssen Status, Wirksamkeit und mögliche Abweichungen nachvollziehbar dokumentiert und in die aktuelle Managementbewertung eingebunden werden. Die Ergebnisse dieser Überprüfungen basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.3: Geänderte Rahmenbedingungen</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der geänderte Rahmenbedingungen mit Auswirkungen auf das Informationssicherheitsmanagement berücksichtigt, dokumentieren.</p></td><td><p>Die Ergebnisse der Überprüfung der Rahmenbedingungen – wie rechtliche, organisatorische, technische oder wirtschaftliche Veränderungen – müssen systematisch erfasst und auf ihre Auswirkungen auf das ISMS bewertet werden. Relevante Änderungen sind in der Managementbewertung einzubeziehen, da sie Einfluss auf die Risikobewertung und erforderliche Anforderungen bzw. Sicherheitsmaßnahmen haben können. Die Ergebnisse dieser Überprüfungen basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.4: Erfolge und Probleme</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der bisherige Erfolge und Probleme (z. B. Sicherheitsvorfälle) beim Informationssicherheitsprozess berücksichtigt, dokumentieren.</p></td><td><p>Die Ergebnisse müssen im ISMS-Prozess berücksichtigt werden, um daraus gezielte Verbesserungen abzuleiten. Sie dienen als wichtige Eingaben für die Managementbewertung und unterstützen die Weiterentwicklung der Sicherheitsstrategie. Zu Erfolgen zählen z.B. wirksam umgesetzte Maßnahmen, erreichte Sicherheitsziele, erfolgreiche Audits/Prüfungen oder eine nachweisbare Reduktion von Risiken. Die Ergebnisse dieser Überprüfungen basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.5: Interne Überprüfungen und Audits</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der Ergebnisse interner Überprüfungen und Audits enthält, dokumentieren.</p></td><td><p>Bei der Evaluierung müssen die Ergebnisse interner Überprüfungen und Audits dokumentiert werden, um festzustellen, ob das ISMS wirksam umgesetzt und aufrechterhalten wird. Dabei sind insbesondere identifizierte Abweichungen, Verbesserungspotenziale und umgesetzte Korrekturmaßnahmen nachvollziehbar darzustellen. Die Ergebnisse dieser Überprüfungen basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.6: Eignungsprüfung bisheriger Sicherheitsmaßnahmen</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der eine Bewertung enthält, ob sich die Sicherheitsmaßnahmen zur Erreichung der Sicherheitsziele als geeignet erwiesen haben oder ob Maßnahmen geändert oder ergänzt werden müssen, dokumentieren.</p></td><td><p>Zur Bewertung, ob Sicherheitsmaßnahmen zur Erreichung der Sicherheitsziele geeignet sind, müssen die Maßnahmen systematisch den jeweiligen Zielen zugeordnet und ihre Wirksamkeit anhand konkreter Nachweise (z.B. Auditergebnisse, Vorfallanalysen, Tests) überprüft werden. Werden Defizite festgestellt, sind die Maßnahmen entsprechend anzupassen, zu ergänzen oder durch geeignetere zu ersetzen. Die Ergebnisse dieser Überprüfung sind nachvollziehbar zu dokumentieren und in den Managementbericht einzubringen und basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.7: Rückmeldung von Stakeholdern</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der Rückmeldungen von Kunden, Geschäftspartnern, Mitarbeitern oder der Öffentlichkeit zu Sicherheitsaspekten  bei der Bewertung berücksichtigt, dokumentieren.</p></td><td><p>Betroffene Personen wie z.B. Kunden, Geschäftspartner und die Öffentlichkeit sollen aktiv zu Sicherheitsaspekten befragt oder deren Feedback systematisch erfasst werden, z.B. über Umfragen, Beschwerden, Supportanfragen oder öffentliche Bewertungen. Dieses Feedback ist auf Relevanz und Auswirkungen für das ISMS zu prüfen, zu dokumentieren und bei Bedarf in Risikoanalysen und Verbesserungsmaßnahmen einzubeziehen. Verantwortliche müssen sicherstellen, dass Rückmeldungen zeitnah ausgewertet und bei der Weiterentwicklung der Sicherheitsmaßnahmen berücksichtigt werden. Die Ergebnisse dieser Überprüfungen basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.8: Status des Realisierungsplans</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der Berichte über die Reduzierung bestehender Umsetzungsdefizite und der damit verbundenen Risiken (Status des Realisierungsplans) dokumentieren.</p></td><td><p>Die Überprüfung von Umsetzungsdefiziten und Risiken ist im ISMS ein zentraler Bestandteil des Monitorings und der Evaluierung. Monitoring sorgt für die kontinuierliche Beobachtung des Fortschritts bei Maßnahmenumsetzung, während die Evaluierung die Wirksamkeit dieser Maßnahmen bewertet und bei Bedarf Anpassungen empfiehlt. So wird sichergestellt, dass Risiken nachhaltig reduziert und Sicherheitsziele erreicht werden. D. h. der Status des Realisierungsplans muss fortlaufend überprüft werden. Die Ergebnisse dieser Überprüfungen basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.9: Verbesserungen</td><td><p>Monitoring-Evaluation SOLLTE die Ergebnisse dieser Überprüfungen in einem Managementbericht, der die Ergebnisse der Bewertung in Form von Verbesserungen in das ISMS einfließen lässt, dokumentieren.</p></td><td><p>Hier ist zu dokumentieren, 1. ob identifizierte Verbesserungsmaßnahmen tatsächlich umgesetzt wurden (z.B. Änderungen an Prozessen, technische Anpassungen, Schulungen). 2. in welcher Form diese Maßnahmen ins ISMS eingeflossen sind, also ob sie dokumentiert, im Risikomanagement berücksichtigt und in den Steuerungsprozessen verankert wurden. 3. ob die Verbesserungen die angestrebte Wirkung zeigen, also zur Reduzierung von Risiken oder zur Erreichung der Sicherheitsziele beitragen. 4. ob die Maßnahmen dauerhaft aufrechterhalten und kontinuierlich überwacht werden, um nachhaltige Verbesserungen sicherzustellen. Die Ergebnisse dieser Evaluierung sind nachvollziehbar zu dokumentieren und bilden die Grundlage für weitere Entscheidungen im Rahmen des kontinuierlichen Verbesserungsprozesses und basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.10: Maßnahmenvorschläge</td><td><p>Monitoring-Evaluation MUSS die Ergebnisse dieser Überprüfungen in einem Managementbericht, der priorisierte Maßnahmenvorschläge mit realistischen Abschätzungen zum erwarteten Umsetzungsaufwand enthält, dokumentieren.</p></td><td><p>Maßnahmenvorschläge müssen daraufhin überprüft werden, ob sie wirksam zur Risikoreduktion beitragen und mit vertretbarem Aufwand umsetzbar sind. Dabei sind Nutzen, Kosten, technischer und organisatorischer Aufwand realistisch abzuschätzen und in Relation zueinander zu bewerten, um fundierte Entscheidungen zur Umsetzung und Priorisierung treffen zu können. Die Ergebnisse dieser Überprüfungen basieren auf den vorab erstellten Auditberichten sowie der geforderten Eignungsprüfung.</p></td></tr><tr valign="top"><td>PERF.3.11: Bericht an die Institutionsleitung</td><td><p>Monitoring-Evaluation MUSS die Institutionsleitung über den Stand des Managementsystems <i>regelmäßig</i> anhand des Managementberichtes informieren.</p></td><td><p>Sinn und Zweck der Anforderung liegt darin, die Leitungsebene regelmäßig und nachvollziehbar über den Sicherheitsstatus sowie über wesentliche Entwicklungen zu informieren. Damit kann die Leitung faktenbasiert Entscheidungen treffen, Prioritäten setzen und Ressourcen zielgerichtet bereitstellen. Ohne einen solchen Bericht könnte ein kritisches Risiko unbemerkt bleiben oder verspätet adressiert werden, etwa wenn wiederholt unbefugte Zugriffe auf sensible Daten auftreten. Ein gut aufbereiteter Bericht kann hingegen Transparenz schaffen, Verantwortlichkeiten verdeutlichen und Vertrauen in die Steuerung der Institution fördern. Zur Umsetzung ist ein fester Rhythmus für die Erstellung des Managementberichts zu etablieren, etwa quartalsweise oder anlassbezogen nach einem schweren Vorfall. Der Bericht kann eine verdichtete Darstellung enthalten, zum Beispiel in Form von übersichtlichen Kennzahlen (Anzahl relevanter Vorfälle, Zeit bis zur Entdeckung, Erfüllungsgrad definierter Sicherheitsmaßnahmen) und Trendanalysen. Ergänzend kann eine einheitliche Vorlage genutzt werden, die eine klare Struktur vorgibt, sodass die Leitungsebene schnell die entscheidenden Punkte erkennt. Technisch kann dies durch den Einsatz gängiger Office-Tools unterstützt werden, etwa durch die Visualisierung von Trends in Diagrammen. Prozessual können Rückfragen und Diskussionen in einer kurzen Managementrunde eingeplant werden, um den reinen Informationsfluss zu einem aktiven Austausch zu machen.</p></td></tr></table><h2>PERF.4: Monitoring</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERF.4.1: Sicherheitsvorfälle</td><td><p>Monitoring-Evaluation MUSS ein Verfahren zur Erkennung von Sicherheitsvorfällen verankern.</p></td><td><p>Dieses Verfahren SOLL klare Meldewege, technische Überwachungsmechanismen (z. B. Log-Analyse, Intrusion Detection), Verantwortlichkeiten sowie Kriterien zur Klassifikation von Vorfällen enthalten. So wird gewährleistet, dass sicherheitsrelevante Ereignisse frühzeitig erkannt, bewertet und in den ISMS-Verbesserungsprozess eingebunden werden.</p></td></tr><tr valign="top"><td>PERF.4.2: Schwachstellen</td><td><p>Monitoring-Evaluation MUSS ein Verfahren für den Umgang mit Schwachstellen unter Berücksichtigung des Risikos verankern.</p></td><td><p>Schwachstellen müssen systematisch erfasst, auf ihre sicherheitsrelevante Bedeutung geprüft und in die Risikoanalyse des ISMS übernommen werden. Daraus abgeleitete Maßnahmen sind zu priorisieren, umzusetzen und im Rahmen des Monitorings und der Evaluierung regelmäßig auf ihre Wirksamkeit hin zu überprüfen sowie zu dokumentieren.</p></td></tr><tr valign="top"><td>PERF.4.3: Risiken</td><td><p>Monitoring-Evaluation MUSS ein Verfahren für Erfassung und die Reaktion auf aktuelle Risiken und ihre Berücksichtigung im Risikomanagement verankern.</p></td><td><p>Ein Verfahren zur Erfassung und Reaktion auf aktuelle Risiken im ISMS muss folgende Punkte sicherstellen:<br/>- Laufende Risikobeobachtung: Überwachung interner und externer Informationsquellen<br/>- Dokumentation neu erkannter Risiken: Erfassung in einem Risikoregister mit Beschreibung und Bewertung<br/>- Aktualisierung der Risikoanalyse: Einschätzung von Eintrittswahrscheinlichkeit und Schadenshöhe<br/>- Ableitung und Priorisierung von Maßnahmen: Festlegen geeigneter Gegenmaßnahmen mit Verantwortlichkeiten<br/>- Einbindung ins Risikomanagement: Integration der neuen Risiken in bestehende Prozesse<br/>- Rückmeldung an das Management: Regelmäßige Berichterstattung zur aktuellen Risikolage und Wirksamkeit der Maßnahmen</p></td></tr></table><h2>PERF.5: Blaupausen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERF.5.1: Verifikation der Blaupausen</td><td><p>Monitoring-Evaluation SOLLTE die angewendete Blaupause im Hinblick auf die Berücksichtigung der relevanten Praktiken <i>regelmäßig</i> überprüfen.</p></td><td><p>Die Blaupausen reduzieren den Aufwand, geeignete Praktiken auszuwählen und die darin enthaltenen Anforderungen auf die eigenen Bedürfnisse zuzuschneiden. Sie stellen jedoch keine Garantie dar, dass eine Institution alle relevanten Praktiken berücksichtigt hat. Daher ist es empfehlenswert, nach Anwendung der Blaupausen eine Qualitätssicherung durchzuführen. Eine enge Abstimmung mit den zuständigen Fachbereichen trägt dabei wesentlich zu einer sachgerechten und vollständigen Umsetzung bei.</p></td></tr></table><h1>ARCH: Architektur</h1><p>Die Praktik Architektur definiert die grundlegende Struktur sowie die Sicherheitsprinzipien der IT-Infrastruktur und leitet daraus Anforderungen für einzelne IT-Komponenten ab – etwa für Anwendungen oder IT-Systeme. Ziel ist es, eine sichere und skalierbare Basis zu schaffen.  Im Rahmen dieser Praktik werden Sicherheitsanforderungen systematisch in die Gesamtarchitektur eingebettet. Dazu gehören die Gestaltung der Netzarchitektur sowie die Entwicklung übergreifender Konzepte, beispielsweise für Kryptografie oder den Schutz vor Schadsoftware.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>ARCH.1: Grundlagen</td><td align="right">5</td></tr><tr valign="top"><td>ARCH.2: Netzdesign</td><td align="right">17</td></tr><tr valign="top"><td>ARCH.3: Wireless LAN</td><td align="right">4</td></tr><tr valign="top"><td>ARCH.4: Zugangsbeschränkungen</td><td align="right">5</td></tr><tr valign="top"><td>ARCH.5: Perimeterschutz</td><td align="right">17</td></tr><tr valign="top"><td>ARCH.6: Vertraulichkeit und Integrität im Weitverkehrsnetz</td><td align="right">2</td></tr><tr valign="top"><td>ARCH.7: Dedizierte Systeme</td><td align="right">3</td></tr><tr valign="top"><td>ARCH.8: Ausfallsicherheit</td><td align="right">3</td></tr><tr valign="top"><td>ARCH.9: Kapazitätsmanagement</td><td align="right">5</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>61</b></td></tr></table><h2>ARCH.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.1.1: Verfahren und Regelungen</td><td><p>Architektur MUSS Verfahren und Regelungen zur Architektur des Netzes und damit verbundener Infrastrukturen verankern.</p></td><td><p>Die Netzarchitektur ist der strukturierte Entwurf einer Netzinfrastruktur, einschließlich der IT-Systeme und verbundsbezogenen Schutzmechanismen darin. Hierzu gehören die Segmentierung und Filterung von kabelgebundenen und kabellosen Netzen, Netzmanagement sowie die Redundanz wichtiger Systeme für eine ausreichende Gewährleistung der Verfügbarkeit. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik. Empfehlenswert ist ein Design des Netzes nach dem Zero-Trust-Prinzip (siehe BSI Positionspapier Zero-Trust). Dennoch sind Netzgrenzen zur Isolierung durch Filterung oder Zugbrücken bei Angriffen weiterhin sinnvoll. Weitere Informationen zur Absicherung von Netzen sind in ISO/IEC 27033 zu finden.</p></td></tr><tr valign="top"><td>ARCH.1.1.1: Dokumentation</td><td><p>Architektur MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>ARCH.1.1.2: Zuweisung der Aufgaben</td><td><p>Architektur MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>ARCH.1.1.3: Bekanntgabe</td><td><p>Architektur MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>ARCH.1.2: Regelmäßige Überprüfung</td><td><p>Architektur MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr></table><h2>ARCH.2: Netzdesign</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.2.1: Netzsegmente</td><td><p>Architektur für Netze SOLLTE eine Unterteilung des internen Netzes in Netzsegmente unter Berücksichtigung der Anforderungen der Institution und des Schutzbedarfes verankern.</p></td><td><p>Relevant sind dabei (falls vorhanden) auch WLANs/SSIDs, IoT-Geräte wie vernetzte Kühlschränke, Hausleittechnik, operative Technologien, Industrielle Steuerungssysteme oder Netze zum Zugriff auf Speichersysteme (Storage Area Network, SAN). Die Anforderung gilt auch, wenn die Systeme nur noch als VMs oder Container existieren. Die Segmentierung kann hier in die virtuelle Netzwerk‑Ebene verlagert werden, sodass die Segmentierung weder vom Hypervisor noch von den Workloads umgangen wird. Die Einteilung in Segmente kann anhand einer Klassifizierung von Netzen erfolgen (z.B. nach Schutzbedarf der dort verarbeiteten Daten oder nach Risikoklassen angeschlossener Systeme) erfolgen. Beispiele hierfür sind Internet-Domäne, Endgeräte-Domäne, Domäne für zentrale Serverdienste, Domäne für Systeme hoher Vertraulichkeit. Alternativ können auch organisatorische Domänen verwendet werden, z.B. Personalwesen, Marketing, Finanzverwaltung, Innere Verwaltung. Die Filterkriterien können sich nach den Sicherheitsanforderungen der jeweiligen Netze im Einzelnen oder nach einer vorgenommenen Klassifikation der Netze richten. Hierzu gehören insbesondere die Anforderungen zur Authentifizierung und Autorisierung von Assets.</p></td></tr><tr valign="top"><td>ARCH.2.2: Einschränkung von Verbindungen zwischen Segmenten</td><td><p>Architektur für Netze SOLLTE Verbindungen zwischen Netzsegmenten anhand von <i>Kriterien</i> einschränken.</p></td><td><p>Dient dem Ziel, die Angriffsfläche innerhalb interner und externer Netze zu reduzieren und die Ausbreitung potenzieller Schadsoftware oder unberechtigter Zugriffe einzudämmen. Ohne solche Begrenzungen könnte ein einzelner kompromittierter Bereich direkten Zugriff auf weitere sensible Segmente erhalten und dadurch Geschäftsprozesse massiv beeinträchtigen. Beispielsweise benötigt ein Endgerät Verbindungen zu internen Servern und Druckern, während Gäste lediglich auf den Internetanschluss Zugriff benötigen. Im Blick auf weitreichende Sicherheitsvorfälle ist hier insbesondere die Trennung interner Netzsegmente vom Internet zu beachten. Diese Regeln können auf Kriterien wie Gerätetyp (z. B. Laptop, IoT-Gerät), Benutzerrolle (z. B. Administrator, Gast), physischem Anschlussort oder Uhrzeit basieren. Eine klare Trennung von Benutzergruppen über VLANs oder dynamische ACLs erhöht die Sicherheit und Transparenz. Für die Einführung in eine bestehende Umgebung kann ein gestuftes Vorgehen gewählt werden: (1) Zunächst wird ein Überwachungsmodus (<b>„Audit-Only“</b>) aktiviert, der protokolliert, welche Zugriffe durch eine strengere Richtlinie verweigert würden, ohne sie tatsächlich zu blockieren. (2) Anschließend werden diese Protokolle analysiert, um legitime, für den Geschäftsbetrieb notwendige Zugriffe zu identifizieren und diese gezielt in die jeweiligen Rollen und Berechtigungsgruppen aufzunehmen. (3) Erst wenn keine legitimen Zugriffe mehr in den Protokollen als <b>„verweigert“</b> auftauchen, wird die Richtlinie scharf geschaltet und blockiert aktiv alle nicht explizit erlaubten Zugriffe.</p></td></tr><tr valign="top"><td>ARCH.2.2.1: Externe Netzanschlüsse</td><td><p>Architektur für Netze SOLLTE Verbindungen über externe Netzanschlüsse einschränken.</p></td><td><p>Dient dazum, die Angriffsfläche zu reduzieren, unerwünschte Ein- und Ausleitungen zu begrenzen und das Risiko von Datenabflüssen zu minimieren. Für mobile Systeme kann dies z.B. über das Erzwingen einer VPN-Verbindung ins gefilterte Netz der Institution oder über die Verwendung eines direkten Internetzugangs erfolgen, welcher über einen Direct-Internet-Access Agenten abgesichert ist.</p></td></tr><tr valign="top"><td>ARCH.2.2.2: Gastnetz</td><td><p>Architektur für Netze SOLLTE Verbindungen zwischen Gastnetz und internem Netz einschränken.</p></td><td><p>Wenn Gäste der Institution sich mit dem internen Netz verbinden, könnten Schadprogramme in das Netz gelangen oder unbeabsichtigte Datenflüsse über die Verbindung fließen. Daher ist es sinnvoll, einen vom übrigen Netz getrennten Gastzugang einzurichten, z.B. in Besprechungs-, Veranstaltungs- und Schulungsräumen. Wenn die Einschränkungen von Gastnetzen lockerer sind als die interner Netze am gleichen Standort, so zeigt die Erfahrung, dass auch interne Mitarbeitende gerne auf Gastnetze zurückgreifen. Dadurch könnte es zur Umgehung der internen Schutzmaßnahmen kommen. Daher ist es empfehlenswert, für das Gastnetz gleiche oder strengere Einschränkungen zu wählen oder die Nutzung des Gastnetzes durch Mitarbeitende technisch oder organisatorisch zu beschränken.</p></td></tr><tr valign="top"><td>ARCH.2.2.3: Segmentierung von Servern und Clients</td><td><p>Architektur für Hostsysteme SOLLTE Verbindungen von und zu Clients einschränken.</p></td><td><p>Die Anforderung gilt auch, wenn die IT-Systeme nur noch als VMs oder Container existieren. Die Segmentierung kann hier in die virtuelle Netzwerk‑Ebene verlagert werden, sodass die Segmentierung weder vom Hypervisor noch von den Workloads umgangen wird. Die Anforderung kann auch physisch durch dedizierte Infrastruktur für VDI/Client‑VMs umgesetzt werden. Um die klare Trennung sicherzustellen wird empfohlen kein Bridging zwischen Port‑Groups sowie auf dem voiirtuellen Switch keinen promiscuous Mode zu verwenden.</p></td></tr><tr valign="top"><td>ARCH.2.2.4: VoIP-Netz</td><td><p>Architektur für Netze KANN eine oder mehreren separate Netzdomänen zur Trennung von Daten- und VoIP-Kommunikation installieren.</p></td><td><p>Werden sowohl Telefonie als auch andere Daten über dasselbe Netz geführt, so könnte dies bei einem Netzausfall dazu führen, dass keine Kommunikation mehr möglich ist, auch nicht zur Meldung oder Behebung der Störung. Die Wahrscheinlichkeit kann durch getrennt betriebene Voice- und Datennetze verringert werden. Für weitere Details siehe „Kompendium für organisationsinterne Telekommunikationssysteme mit erhöhtem Schutzbedarf".</p></td></tr><tr valign="top"><td>ARCH.2.2.5: OT-Systeme</td><td><p>Architektur für OT-Systeme SOLLTE für diese ein oder mehrere separate Netzsegmente installieren.</p></td><td><p>IT- und OT-Systeme haben typischerweise sehr unterschiedliche Risikoprofile (IT: Schnellebig, viele Cybersicherheitsmechanismen, OT: Stabilität, weniger Cybersicherheitsmechanismen, beispielsweise industrielle Steuerungssysteme und Gebäudeautomationstechnik). Insbesondere der Zugriff auf OT-Funktionen (z.B. Öffnung zentraler Schließanlage) ist mit erhöhtem Risiko verbunden und könnte auch versehentlich z.B. durch Portscanner ausgelöst werden. Stattdessen ist es empfehlenswert, den Zugriff zu solchen Netzen nur über dafür vorgesehene Quellen zu ermöglichen (z.B. Sprungserver, bestimmte auslösende OT-Systeme).</p></td></tr><tr valign="top"><td>ARCH.2.2.6: Demilitarisierte Zone</td><td><p>Architektur für Netze SOLLTE eine demilitarisierte Zone installieren.</p></td><td><p>Unter einer Demilitarisierten Zone versteht man in diesem Kontext ein logisch oder physisch getrenntes Teilnetz, in dem Systeme mit exponierten Diensten – wie Webserver, Mail-Gateways oder VPN-Endpunkte – betrieben werden. Systeme der Institution, die sowohl aus dem öffentlichen Netz als auch aus dem internen Netz erreichbar sind, werden in einer demilitarisierten Zone (DMZ) so betrieben, dass (1) der Netzverkehr zwischen dem System und dem öffentlichen Netz gefiltert wird und (2) der Netzverkehr zwischen dem System und anderen internen Netzen gefiltert wird. Eine DMZ kann sowohl durch dedizierte Hardware-Firewalls als auch durch virtuelle Netzwerksegmente umgesetzt werden. Ohne eine solche Trennung könnte ein kompromittierter Webserver direkt als Sprungbrett ins interne Netz dienen oder Schadsoftware könnte sich ungehindert auf sensible Systeme ausbreiten. Mit einer DMZ kann eine Institution hingegen erreichen, dass kompromittierte Systeme isoliert bleiben und sicherheitskritische interne Netze weiterhin geschützt sind.</p></td></tr><tr valign="top"><td>ARCH.2.2.7: Management-Netz</td><td><p>Architektur für Netze SOLLTE ein oder mehrere Management-Netze installieren.</p></td><td><p>Ein Management-Netz ist ein physisch oder durch Netzfilter separiertes Netzsegment, das dediziert für die Überwachung, Verwaltung und Wartung von IT-Systemen bestimmt ist. Es ist von anderen Produktions- und Datennetzen getrennt, um den Zugriff auf kritische Verwaltungsfunktionen zu schützen und die Verfügbarkeit dieser Zugänge auch bei Problemen im restlichen Netz zu sichern. Dies gilt auch für virtualisierte Systeme. Im Kontext der Containerisierung empfiehlt es sich, administrative Zugänge auf Applikations-Container immer über die Container-Runtime erfolgen zu lassen.</p></td></tr><tr valign="top"><td>ARCH.2.2.8: Segmentierung von Test und Betrieb</td><td><p>Architektur für Netze SOLLTE Verbindungen zwischen Testumgebungen und Betrieb einschränken.</p></td><td><p>Entwicklungs-, Staging- und Testumgebungen haben oft geringere Sicherheitsvorkehrungen als Produktivsysteme. Eine saubere Trennung zwischen Test- und Produktivumgebung verhindert Übergriffe auf das Produktivsystem und vermeidet Ressourcenkonflikte.</p></td></tr><tr valign="top"><td>ARCH.2.2.9: Segmentierung von IPV4 und IPv6</td><td><p>Architektur für IT-Systeme SOLLTE Verbindungen zwischen IPv4 und IPv6 einschränken.</p></td><td><p>IPv4 und IPv6 sind grundlegende Netzprotokolle, die unterschiedliche Protokollstacks und Sicherheitseigenschaften haben. Eine Trennung von IT-Systemen mit IPv4 und IPv6 erschwert es Angreifern, Schwachstellen der Protokolle auszunutzen oder zu kombinieren und verringert die Wahrscheinlichkeit von Fehlern durch Wechselwirkungen.</p></td></tr><tr valign="top"><td>ARCH.2.2.10: Drucker-Netz</td><td><p>Architektur für Drucker SOLLTE Verbindungen von und zu anderen Systemen einschränken.</p></td><td><p>Drucker können Schwachstellen aufweisen, die Angreifer ausnutzen, z.B. veraltete Firmware oder ungesicherte Netzprotokolle. Durch die Segmentierung wird die Angriffsoberfläche reduziert und die Netzüberwachung erleichtert. Die Umsetzung kann physisch oder durch VLANs erfolgen.</p></td></tr><tr valign="top"><td>ARCH.2.2.11: Mikrosegmentierung</td><td><p>Architektur für IT-Systeme KANN Verbindungen zu allen anderen IT-Systemen einschränken.</p></td><td><p>Mikrosegmentierung ist die Unterteilung des Netzes in möglichst kleine Segmente (z.B. pro IT-System oder Server-Anwendung). Für jedes dieser Segmente wird die erlaubte Kommunikation definiert und gefiltert. Mikrosegmentierung sorgt dafür, dass z.B. zwei medizinische Geräte mit gleicher Rolle zwar ins gleiche VLAN dürfen, aber nicht direkt miteinander kommunizieren dürfen. Die Umsetzung kann mit dynamischen VLANs, softwaredefinierten Netzwerken (SDN) oder Netzwerk-Firewalls auf Host-Ebene erfolgen. Die Mikrosegmentierung begrenzt Angriffe, die sich lateral ausbreiten.</p></td></tr><tr valign="top"><td>ARCH.2.2.12: Physische Segmentierung</td><td><p>Architektur für Netze KANN den physischen Zugang auf diese einschränken.</p></td><td><p>Obwohl sich eine virtuelle Vernetzung immer größerer Beliebtheit erfreut, können Konfigurationsfehler oder Sicherheitslücken dabei leichter zu einer Umgehung der Netztrennung führen, als wenn die Netze bereits auf physischer Ebene voneinander getrennt werden.</p></td></tr><tr valign="top"><td>ARCH.2.2.13: Sprungserver</td><td><p>Architektur KANN Sprungserver installieren.</p></td><td><p>Ein Sprungserver (englisch „jump server“ oder „jump host“) ist ein speziell abgesicherter Server, der als einzig vorgesehener Einstiegspunkt in ein Verwaltungsnetz oder zu administrierten Systemen dient. Alle administrativen Sitzungen laufen über diesen zentralen Knotenpunkt, wodurch die Angriffsfläche reduziert und die Nachvollziehbarkeit erhöht wird. Ohne Sprungserver könnte ein Angreifer beispielsweise über kompromittierte Administrator-Notebooks unbemerkt direkt auf zentrale Systeme zugreifen und dort Manipulationen durchführen. Ein Sprungserver kann hingegen alle Management-Zugriffe zentral kanalisieren, sodass verdächtige Aktivitäten leichter erkannt und im Nachhinein nachvollzogen werden können. Praktische Umsetzungen können sein: (1) der Einsatz eines dedizierten, gehärteten Servers mit restriktiven Firewall-Regeln, (2) die Nutzung von Mehrfaktor-Authentisierung und zentralem Benutzer-Management auf dem Sprungserver, (3) eine verpflichtende Session-Aufzeichnung oder Protokollierung sämtlicher Administrationsvorgänge.</p></td></tr><tr valign="top"><td>ARCH.2.3: Netzplan</td><td><p>Architektur für Netze SOLLTE einen Netzplan einschließlich interner Segmente, externer Netzanschlüsse und deren Verwendungszweck dokumentieren.</p></td><td><p>Ein Netzplan (engl. network diagram) stellt eine schematische Darstellung der logischen und physischen Struktur von Kommunikationsnetzen dar und bildet die Grundlage für Transparenz im Betrieb. Er kann einen zentralen Beitrag zur Informationssicherheit leisten, da er Transparenz über die Struktur, Verbindungen und Schutzbedarfe einer Netzwerkumgebung schafft. Ein aktueller Netzplan, aus dem sich gut die Netzstruktur erkennen lässt, ermöglicht es Anschlüssen mit hohem Risiko oder von einzelnen Ausfallstellen (Single Points of Failure) auf einen Blick zu erkennen. Die Aufteilung in Netzdomänen ermöglicht es, verschiedene Zonen mit unterschiedlichen Schutzanforderungen – z.B. Büro-IT, Produktionsnetz, Managementnetz – getrennt zu betrachten und gezielt zu schützen. Die Erfassung Externer Netzanschlüsse – etwa zu Partnernetzen, Cloud-Diensten oder dem Internet – hilft, potenzielle Angriffspunkte zu identifizieren und gezielte Schutzmaßnahmen zu planen. Beispiele für interne Netzsegmente können klassische Trennungen wie IT-Office-Netze, SCADA-/Leittechnik-Netze oder DMZs für externe Zugriffe sein. Dabei sollten auch virtuelle Netze und virtuelle Switche berücksichtigt werden, ebenso wie Container-Infrastrukturen. Als externe Netzanschlüsse kommen etwa VPN-Gateways, dedizierte Providerverbindungen, Fernwartungszugänge oder Cloud-Endpunkte in Frage. Dabei sind nicht nur die auf den ersten Blick relevanten Datennetze, sondern auch andere Telekommunikationsanbindungen wie ISDN-Leitungen, Mobilfunkausweichstrecken oder WLAN Roaming von Clients relevant. Der Verwendungszweck beschreibt, warum ein Segment oder Anschluss existiert – etwa für Produktivsysteme, Entwicklung, Administration oder Gastzugänge. Der Zweck von Netzsegmenten kann durch einen sprechenden Namen dokumentiert werden, z.B. Management-Netz, OT-Netz, Internetanschluss, Netz der Finanzverwaltung. Dies hilft, Zuständigkeiten und Zugriffsrechte klar zuzuordnen, z.B. anhand von Geschäftsprozessen, Organisationseinheiten oder Zielgruppen (z.B. Gäste, Vertrieb, Leitung). Dabei sind, falls vorhanden, auch WLANs/SSIDs, IoT-Geräte wie vernetzte Kühlschränke, Hausleittechnik, operative Technologien oder Industrielle Steuerungssysteme zu berücksichtigen.  Für die Umsetzung ist es nicht erforderlich jedes Subnetz einzeln an Grafik zu visualisieren. Vielmehr kann es hilfreich sein, Netzpläne auf einem abstrahierten Level zu halten, z.B. als logische Übersicht mit Domänen, Segmenten und Übergängen (bereinigter Netzplan). Eine Visualisierung als Layer-Modell (z.B. Infrastruktur-, Kommunikations- und Applikationsebene) kann zusätzliche Einblicke schaffen. Informationen können aus Netzwerkmanagementsystemen, Konfigurationsdateien oder Asset-Management-Tools gewonnen werden. Die Pflege kann als wiederkehrende Aufgabe in Prozesse eingebettet oder im Rahmen von Änderungen (z.B. Change Management) angestoßen werden. Auch eine einfache Pflege in Tabellenform oder als visuelle Skizze kann sinnvoll sein – entscheidend ist die Klarheit und Aktualität.</p></td></tr><tr valign="top"><td>ARCH.2.4: Topologieüberwachung</td><td><p>Architektur für Netze SOLLTE die Einhaltung der Netzarchitektur <i>regelmäßig</i> überprüfen.</p></td><td><p>Unbeabsichtigte Netzverbindungen können z.B. über falsch gesteckte Kabel, WLAN auf Clients oder Modems im öffentlichen Telefonnetz (PSTN) an einer TK-Anlage entstehen. Die Anforderung kann durch Netzscans, Software zur Topologieüberwachung oder Protokollanalyse umgesetzt werden. Hierbei sind auch virtualisierte Systeme auf VM-Hosts zu berücksichtigen.</p></td></tr></table><h2>ARCH.3: Wireless LAN</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.3.1: Netzabdeckung</td><td><p>Architektur für WLANs SOLLTE die Netzabdeckung testen.</p></td><td><p>Drahtlose Netzanbindungen sind schwerer zu schützen als kabelgebundene Netze, da der Perimeter des Netzes schwerer zu erkennen ist. Das erschwert es, die Netzverfügbarkeit zu gewährleisten und gleichzeitig den Zugang zum Netz vor unbefugtem Zugriff oder Störungen zwischen Netzen zu schützen. Zudem können Wände und andere strahlende Geräte wie Mikrowellen-Geräte oder Bluetooth-Sender den Empfang beeinträchtigen. Ein Test des Empfangs an wichtigen Standorten unter realen Bedingungen hilft, die WLAN-Qualität zu gewährleisten.  Der Empfang in den verschiedenen Frequenzbändern kann dabei unterschiedlich ausfallen. Für weitere Informationen, siehe Allgemeinzuteilungen von Frequenzen für Mobilfunkanwendungen, DECT, WLAN, CB-Funk und ähnliche Anwendungen der Bundesnetzagentur. Abdeckungsbereich ist der Bereich, in dem das WLAN mit gewöhnlichen Endgeräten genutzt werden kann. Relevant ist dabei auch die Abdeckung aller Orte, an denen sich Gäste aufhalten, sowie an Orte an denen gerade kein Empfang gewünscht ist, z.B. Serverräume oder abhörsichere Räume.</p></td></tr><tr valign="top"><td>ARCH.3.2: Einschränkung in Sicherheitsbereichen</td><td><p>Architektur für WLANs KANN in Sicherheitsbereichen die Ausstrahlung einschränken.</p></td><td><p>Hierzu gehören beispielsweise abhörsichere Räume oder Serverräume, von denen aus keine Daten ins Internet gesendet werden sollen. Dies kann z.B. durch die Reduktion der Sendeleistung in benachbarten Räumen oder die Isolierung der Räume erfolgen.</p></td></tr><tr valign="top"><td>ARCH.3.3: SSIDs</td><td><p>Architektur für WLANs SOLLTE institutionsspezifische SSIDs aktivieren.</p></td><td><p>Viele WLAN-Geräte bringen ab Werk eingestellte Netznamen (Default SSID) mit, aus denen sich häufig Rückschlüsse auf eingesetzte Geräte oder sogar Zugangsdaten ziehen lassen. Eigene SSIDs können Nutzenden die Zuordnung der Netze zur Institution oder deren Unterscheidung erleichtern, wenn hierfür sprechende Namen konfiguriert werden (z.B. <b>„Institutionsname-Gastnetz“</b>).</p></td></tr><tr valign="top"><td>ARCH.3.4: Verschlüsselung</td><td><p>Architektur für WLANs SOLLTE die Netzanbindung <i>nach einem anerkannten Standard</i> verschlüsseln.</p></td><td><p>Ohne eine sichere Verschlüsselung könnte ein Angreifer durch „Sniffing“ sensible Inhalte wie Passwörter, E-Mails oder Geschäftsdaten abfangen oder sogar schadhaften Datenverkehr in die Kommunikation einschleusen. Ebenso könnte ein schwacher oder veralteter Standard wie WEP einem Angreifer ermöglichen, das WLAN-Passwort innerhalb weniger Minuten zu knacken und damit vollständigen Netzzugang zu erlangen. Eine zeitgemäße und wirksame Verschlüsselung kann dagegen die Vertraulichkeit und Integrität der Kommunikation sicherstellen und bietet Schutz vor Angriffen wie „Man-in-the-Middle“-Manipulationen oder unerwünschtem Zugriff über „Rogue Clients“. Netzanbindung bedeutet hier, dass nicht nur die über das Netz transportierten Daten verschlüsselt werden, sondern auch die Kommunikation selbst, z.B. die Adressen kommunizierender Geräte. Anerkannten Standards meint z.B. WPA3-Enterprise mit 802.1X und EAP-TLS. Für Details siehe IEEE 80211, WPA3.</p></td></tr></table><h2>ARCH.4: Zugangsbeschränkungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.4.1: Netzzugangskontrolle</td><td><p>Architektur für Interne Netzsegmente SOLLTE den Zugriff von IT-Systemen auf das Netzsegment im Einklang mit den zugehörigen Anforderungen des Identitäts- und Berechtigungsmanagements authentifizieren.</p></td><td><p>Unautorisierte Systeme könnten Ausgangspunkt von Angriffen sein oder zu unbeabsichtigten Störungen im Netz führen. Netzwerkzugangskontrolle (Network Access Control, NAC) bietet eine wirksame Möglichkeit, den Zugriff auf Netzwerke kontrolliert zu steuern, insbesondere in schützenswerten Bereichen wie Management-Netzen, Produktionssystemen oder Forschungsumgebungen. Die Auswahl der Netzbereiche für die Netzzugangskontrolle richtet sich nach dem Schutzbedarf oder Risikoprofil. Dabei empfiehlt sich zu dokumentieren, welche Zonen mit NAC abgesichert werden und warum andere bewusst nicht berücksichtigt werden (z.B. aufgrund technischer Einschränkungen oder fehlender Relevanz). Die Umsetzung kann (1) auf Zertifikaten basieren (X.509, EAP‑TLS or mTLS), (2) auf Zugangskonten basieren (IEEE 802.1X, RADIUS), (3) auf dynamischen Prüfungen basieren (z.B. Sicherheitspatches). Eine Authentifizierung, die nur auf MAC-Adressen basiert, gilt dagegen nicht mehr als zeitgemäß, da MAC-Adressen sehr leicht ausgelesen und auf Systemen eingestellt werden könnten und so unberechtigte IT-Systeme zu leicht auch Zugang erhalten. Wenn Systeme die Netzzugangskontrolle nicht oder nur unzureichend unterstützen, ist für solche Systeme anstelle einer Netzzugangskontrolle die Nutzung eines eigenen Netzsegmentes empfehlenswert. Für die Verbindung zwischen RADIUS-Servern, Switches und Verzeichnisdiensten kommen Protokolle wie RadSec, IPsec oder LDAPS in Betracht. Die Verwendung nur einer einzigen Serverkonfigurationen (z.B. ein gemeinsamer RADIUS-Server für NAC und VPN) führt zu Komplexität und Angriffspunkten. Daher werden getrennte Systeme empfohlen. Dies gilt insbesondere bei unterschiedlichen Schutzklassen im LAN/WLAN oder Büro-/Produktionsnetz. Bei WLANs kann die Umsetzung in größeren Umgebungen mittels 802.1X (WPA3-Enterprise) und an kleineren Zugangspunkten oder Gastnetzen durch SAE (WPA3-Personal) erfolgen. Da es sich um eine automatisierte Sicherheitsrichtlinie handelt, ist hier auch die Anforderung zur Überwachung solcher Richtlinien anwendbar. Überwachungskriterien sind hier z.B. die Erreichbarkeit des RADIUS-Servers, die Antwortzeiten, die Last auf Access-Switches und andere Metriken. Für die Überwachung der Integrität ist insbesondere die Authentifizierung oder deren Fehlschlag relevant, z.B. viele abgelehnte Authentisierungen, plötzliche Deaktivierung eines Supplicants. Durch synthetische Anfragen an Testkonten kann die gesamte Authentisierungskette regelmäßig geprüft werden. Die Formulierung <b>„im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik IDM festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>ARCH.4.1.1: Dynamische Netzzugangskontrolle</td><td><p>Architektur für Interne Netzsegmente SOLLTE den Zugriff von IT-Systemen auf das Netzsegment anhand <i>dynamischer Kriterien</i> im Einklang mit den zugehörigen Anforderungen des Identitäts- und Berechtigungsmanagements authentifizieren.</p></td><td><p>Bei der dynamischen Netzzugangskontrolle (Posturing oder Dynamic NAC) wird vor dem Netzzugang auch der Zustand des IT-Systems geprüft, z.B. der aktuelle Patchlevel des Systems oder von Erkennungssignaturen. Hierzu gehört auch die softwaredefinierte Netzzugangskontrolle, die dynamisch auf Aktivitäten des Systems oder aktuelle Threat Intelligence reagieren kann. Empfehlenswert ist es hierbei, die Konfiguration der Systeme automatisiert vorzunehmen, z.B. über eine automatische Supplicant-Konfiguration beim Rollout und die Zuweisung von Zertifikaten über Enrollment-Dienste. Die Formulierung <b>„im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik IDM festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>ARCH.4.1.2: Quarantäne</td><td><p>Architektur für Interne Netzsegmente KANN ein Quarantänenetz für nicht authentifizierte IT-Systeme installieren.</p></td><td><p>Wenn Systeme aufgrund bestimmter Voraussetzungen sich nicht authentifizieren (z.B. installierte Sicherheitsupdates oder weil sie keine 802.1X-Anmeldung unterstützen), kann ein vollständiges blockieren aller Netzverbindungen die Verfügbarkeit erforderlicher Geschäftsprozesse unmöglich machen. Um IT-Systemen einen eingeschränkten Zugang zu Netzressourcen zu ermöglichen – etwa damit diese die Voraussetzungen durch den Download von Updates erfüllen können – kann ein Quarantänenetz eingerichtet werden, das z.B. Zugang zu bestimmten Downloadservern oder eine Meldung des Problems ermöglicht.</p></td></tr><tr valign="top"><td>ARCH.4.2: Autorisiertes Routing</td><td><p>Architektur für Netze SOLLTE Routing-Verbindungen durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Dient der Kontrolle von Netzarchitekturen, um unbeabsichtigte oder böswillige Änderungen zu verhindern. Ohne eine solche Freigabe könnte ein Angreifer durch unbemerkte Manipulation von Routing-Einträgen den Datenverkehr umleiten, abhören oder blockieren; auch ein ungeschulter Administrator könnte versehentlich falsche Routen konfigurieren, wodurch kritische Dienste ausfallen könnten. Die Autorisierung kann sicherstellen, dass jede Änderung nachvollziehbar geprüft, dokumentiert und nur nach sachgerechter Bewertung umgesetzt wird, wodurch die Integrität und Verfügbarkeit der Netze erhöht werden kann.  Im konkreten Kontext bedeutet „Routing-Verbindungen“ die Konfiguration von Pfaden, über die Datenpakete zwischen Netzsegmenten oder über Gateways weitergeleitet werden. „Autorisieren“ bedeutet hier die formale Freigabe nach einer sachlichen und fachlichen Prüfung, typischerweise durch Rollen wie (1) Netzwerkarchitekt, (2) IT-Sicherheitsbeauftragter oder (3) Leiter IT-Betrieb. Eine Institution kann dies umsetzen, indem sie (1) eine dokumentierte Freigabeprozedur für alle Routing-Änderungen etabliert, (2) Änderungen technisch über ein Ticket- oder Change-Management-System prüfen und protokollieren lässt, (3) rollenbasierte Zugriffsrechte in Routern und Firewalls so einschränken kann, dass nur autorisierte Personen Konfigurationsänderungen durchführen, und (4) automatisierte Plausibilitätsprüfungen oder Peer-Reviews nutzen kann, um fehlerhafte oder unsichere Routen frühzeitig zu erkennen.  Die Autorisierung kann entweder einzelne Routen (z.B. für Netz A zwischen Router B und C), als auch bestimmte Routing-Regeln (z.B. Default-Routing über die zentrale Firewall) autorisieren. Sinnvoll ist es dabei das Prinzip <b>„so allgemein wie für den Betrieb nötig, so spezifisch wie für die Sicherheit möglich“</b> als Faustregel anzuwenden. Bei der Verwendung dynamischer Routing-Algorithmen kann die Anforderung umgesetzt werden, indem eingeschränkte Bereiche freigegeben werden, z.B. <b>„dynamisches Routing im Bereich 10.x.x.x)“</b>.</p></td></tr><tr valign="top"><td>ARCH.4.3: Authentifizierung von Routingprotokollen</td><td><p>Architektur für Netze SOLLTE Änderungen an Routing-Tabellen im Einklang mit den zugehörigen Anforderungen des Identitäts- und Berechtigungsmanagements authentifizieren.</p></td><td><p>Hierzu zählt z.B. die Authentifizierung von BGP/OSPF-Sitzungen zur Verhinderung von Route Hijacking, BGP origin validation with RPKI oder OSPF/ISIS/BGP MD5 or TTL+hMAC authentication. Die Formulierung <b>„im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik IDM festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr></table><h2>ARCH.5: Perimeterschutz</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.5.1: Einschränkung und Inspektion von Verbindungen</td><td><p>Architektur für Netze SOLLTE Verbindungen zwischen IT-Systemen einschränken.</p></td><td><p>Über Netverbindungen können unbeabsichtigte Verbindungen aufgebaut werden oder netzbasierte Angriffe über das Internet gegen die Institution erfolgen. Unerwünschter Datenverkehr nach außen können z.B. private IP-Adressen (RFC 1918 leakage), Multicasting, TCP/UDP Ports für veraltete, angreifbare Protokolle oder ICMP-Verkehr sein. Die Beschränkung der Verbindung zwischen IT-Systemen kann sowohl durch zustandsbehaftete Paketfilter, als auch mit Application Layer Gateways umgesetzt werden. Empfehlenswert ist eine Kombination aus Allowlisting, IP-Reputationslisten, Deep Packet Inspection und Durchsatzratenbegrenzung. Hierbei können Verbindungen auch nach Kategorien autorisiert werden (z.B. anhand von IP-Subnetzen oder Voraussetzungen wie per Zertifikat authentifzierten IT-Systemen). Damit dabei keine unnötigen Verbindungen zugelassen werden, ist es wichtig, die Kategorisierung möglich genau zu wählen (z.B. möglichst einzelne Subnetze statt des ganzen Netzes oder nur bestimmte Ports oder Anwendungen zuzulassen).</p></td></tr><tr valign="top"><td>ARCH.5.1.1: Blockieren anfälliger Netzprotokolle</td><td><p>Architektur für Netze SOLLTE anfällige Netzwerkprotokolle blockieren.</p></td><td><p>Anfällig sind Netzprotokolle, wenn sie veraltete oder gar keine Algorithmen zur Verschlüsselung oder Integritätsprüfung verwenden. Hierzu gehören Protokolle wie Telnet, SMB v1, SNMP v1/v2c. Für aktuelle Verschlüsselungsalgorithmen siehe BSI TR 02102.</p></td></tr><tr valign="top"><td>ARCH.5.1.2: Netzbasierte Angriffe</td><td><p>Architektur für Netze SOLLTE bekannte netzbasierte Angriffsmethoden blockieren.</p></td><td><p>Netzbasierte Angriffe verwenden Netzwerktechnologien (typischerweise auf OSI Layer 2-3), z.B. Fragmentierungsangriffe. Beispiele für mögliche Maßnahmen sind DHCP snooping, ARP/Dynamic ARP Inspection, IP-source guard, BPDU guard, root guard, port-security (sticky MAC).</p></td></tr><tr valign="top"><td>ARCH.5.1.3: TCP-basierte Angriffe</td><td><p>Architektur für Netze SOLLTE bekannte TCP-basierte Angriffsmethoden blockieren.</p></td><td><p>TCP ist das am meisten verwendete Protokoll für die zuverlässige Datenübertragung. Durch TCP-basierte Angriffe können IT-Systeme gehackt oder Daten unbemerkt ausgeleitet werden. Beispiele sind TCP Session Hijacking (ACK-number guessing), Overlapping-Segment Attacks, TCP Reset (RST) Injection, Xmas-tree Scanning. Die Anforderung kann durch Blockieren solcher Verbindungen oder nur bestimmter Mechanismen umgesetzt werden.</p></td></tr><tr valign="top"><td>ARCH.5.1.4: UDP-basierte Angriffe</td><td><p>Architektur für Netze SOLLTE bekannte UDP-basierte Angriffsmethoden blockieren.</p></td><td><p>UDP-basierte Angriffsmethoden (englisch: known UDP-based attack vectors) sind hierbei Techniken zu verstehen, die das User Datagram Protocol (UDP) ausnutzen. UDP ist das am meisten verwendete Protokoll für die Übertragung von Datenstreams. Aufgrund seiner verbindungslosen Eigenschaft ermöglicht UDP eine sehr schnelle Datenübertragung und wird daher oft für zeitkritische Anwendungen wie Videostreaming, VoIP oder DNS-Anfragen verwendet. Genau diese Eigenschaft macht es jedoch anfällig für Missbrauch, da die Absenderadresse leicht gefälscht werden kann (IP-Spoofing).  Beispiele für Angriffe sind Sequence Number Guessing, DHCP Starvation und UDP Hole-Punching Abuse. Die Anforderung kann durch Blockieren solcher Verbindungen oder nur bestimmter Mechanismen umgesetzt werden.</p></td></tr><tr valign="top"><td>ARCH.5.1.5: Deaktivierung von Split Tunneling</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE Split Tunneling blockieren.</p></td><td><p>Um eine durchgehende Kontrolle und Absicherung des Netzverkehrs zu gewährleisten, muss verhindert werden, dass IT-Clients während einer aktiven Verbindung zum internen Netz gleichzeitig ungeschützten Zugriff auf das öffentliche Internet oder andere Netzwerke haben. Dies schließt sogenannte „Split Tunneling“-Konfigurationen aus, bei denen nur ausgewählter Datenverkehr über das VPN geleitet wird, während anderer Datenverkehr (z. B. Webzugriffe) über das lokale Netzwerk oder die Internetverbindung des Clients erfolgt.</p></td></tr><tr valign="top"><td>ARCH.5.1.6: Blockieren direkter Management-Verbindungen</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE Verbindungen zu Management-Schnittstellen blockieren.</p></td><td><p>Zum Internet offene Management-Schnittstellen werden von Angreifern durch Scans leicht gefunden und sind häufig Ziel von Angriffen. Deshalb ist es sinnvoll, alle eingehenden Verbindungen zu Management-Schnittstellen aus externen Netzen zu blockieren, einschließlich der Verwaltung von VPN- und Firewallsystemen selbst. Wenn eine Administration dieser Systeme aus der Ferne erforderlich ist, so kann dieser Zugriff stattdessen über ein VPN in das interne Netz hergestellt werden, wobei auch hiermit ein erhöhten Risiko für Angriffe einhergeht.</p></td></tr><tr valign="top"><td>ARCH.5.1.7: Edge-Routing</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE dynamische Routingprotokolle blockieren.</p></td><td><p>Dynamische Routingprotokolle könnten versehentlich oder durch Angriffe unerwünschte Verbindungen ermöglichen. An den Übergangen zu externen Netzen sind statische Default-Routen deshalb die bessere Alternative.</p></td></tr><tr valign="top"><td>ARCH.5.1.8: Inspektion verschlüsselter Verbindungen</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE den Inhalt unverschlüsselter und verschlüsselter Verbindungen basierend auf der Art des Inhalts einschränken.</p></td><td><p>Verschlüsselte Verbindungen wie VoIP über TLS oder HTTPS-Anfragen können über Sicherheitsproxies oder die Inspektion auf den Endstellen der Verbindungen inspiziert werden. Ein Proxy bzw. Proxy-Server ist ein Vermittler im Netz, der zwischen dem Client und einer Netzressource, wie einer Webseite, fungiert. Er dient als Brücke zwischen dem Client und dem Server, wobei Anfragen und Antworten stellvertretend abgewickelt werden. Proxys können Datenverkehr filtern, blockieren, oder auch speichern, um die Netzwerkleistung zu optimieren. Systeme zur Filterung von Webinhalten gehören zu den häufigsten Arten von Proxyservern, die zur Vermittlung des Internetzugangs eingesetzt werden. Diese Server können TCP-Sitzungen protokollieren und die Zugriffskontrolle durch Blockieren bestimmter URLs, IP-Adressen oder Domänennamen erzwingen. Institutionen können Web-Proxys mit benutzerdefinierten Erlaubnis- und Sperrlisten konfigurieren, um den Zugriff auf der Grundlage von Richtlinien zu regeln. Es ist jedoch zu beachten, dass Proxyserver die Nutzung virtueller privater Netzwerke (VPN) beeinträchtigen und je nach Implementierung Risiken wie Man-in-the-Middle-Angriffe (MitM) mit sich bringen können. Beispiel-Implementierungen sind Squid, Nginx, Privoxy.</p></td></tr><tr valign="top"><td>ARCH.5.1.9: Filterung von DNS</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE unerwünschte Inhalte in DNS-Verbindungen einschränken.</p></td><td><p>Unerwünschte Inhalte sind DNS-Anfragen oder -Antworten, die für Geschäftsprozesse unnötige oder sogar schädliche Daten enthalten, z.B. Verbindungen zu bekannten Malware-Domains oder zu Werbe- oder Telemetriediensten. Dies kann entweder nach dem Allowlist- oder Denylist-Ansatz erfolgen. Listen bekannter schädlicher Domains können über Threat Intelligence-Feeds oder spezielle DNS-Lösungen wie Pihole bezogen werden.</p></td></tr><tr valign="top"><td>ARCH.5.1.10: Webfilterung</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE den Zugriff auf Webinhalte anhand von <i>Kriterien</i> einschränken.</p></td><td><p>Das World Wide Web ist für zahlreiche Geschäftsprozesse essenziell. Andererseits wird das Web von Angreifern auch für die Verbreitung von illegalen Inhalten, Schadprogrammen oder Phishing verwendet. Durch unkontrollierten Webzugriff könnten etwa Schadcode, Phishing oder Datenabfluss in die Institution gelangen. Kriterien meint hier die festgelegten Maßstäbe, nach denen externe Verbindungen zu Webinhalten gefiltert oder eingeschränkt werden. Im Fachjargon spricht man von filtering criteria oder access control policies. Solche Kriterien können beispielsweise Inhaltskategorien (z. B. Glücksspiel, soziale Netzwerke, Streaming), Reputationsbewertungen von Domains (z. B. „malicious“ oder „suspicious“ laut Threat-Intelligence-Feeds), oder technische Eigenschaften (z. B. bekannte IP-Ranges, Länderzugehörigkeit, verwendete Protokolle/Ports, Signaturen) sein. Sinnvoll ist eine Kombination verschiedener Kriterien. Die Anforderung kann über Filterung im Browser, auf Systemen oder an Netzgrenzen umgesetzt werden (z.B. durch Firewalls, Sicherheitsproxies oder VPN-Gateways).</p></td></tr><tr valign="top"><td>ARCH.5.1.10.1: Bekannte schädliche Inhalte</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE bekannte schädliche Inhalte einschränken.</p></td><td><p>Hierzu gehören beispielsweise Schadprogramme, Phishing, Malware Command & Control Server. Zur Einschränkung kann auf öffentlich verfügbare Sperrlisten für solche Webseiten, auf Filtersysteme spezialisierter Hersteller von Firewalls und ähnlichen Systemen oder auf Daten aus der Threat Intelligence zurückgegriffen werden.</p></td></tr><tr valign="top"><td>ARCH.5.1.10.2: Bekannte illegale Inhalte</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE bekannte illegale Inhalte einschränken.</p></td><td><p>Gerade bei größeren Webdiensten kann es vorkommen, dass hierüber immer wieder vereinzelt illegale Inhalte verbreitet werden, obwohl der Dienst selbst von einer legitimen Institution betrieben wird. In solchen Fällen empfiehlt es sich, die Filterung möglich passgenau vorzunehmen (also soweit möglich nur bestimmte Seiten, Seitenbereiche oder Subdomains zu filtern) und den Anbieter über die illegalen Inhalte zu informieren.</p></td></tr><tr valign="top"><td>ARCH.5.1.10.3: Speicherdienste</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE Speicherdienste einschränken.</p></td><td><p>Ausnahmen können sinnvoll sein, wenn es nach den Geschäftsprozessen erforderlich ist, die Daten öffentlich zur Verfügung zu stellen oder diese mit anderen Institutionen über den Speicherdienst auszutauschen.</p></td></tr><tr valign="top"><td>ARCH.5.1.11: P-A-P-Struktur</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE eine P-A-P-Struktur für eingehende und ausgehende Verbindungen installieren.</p></td><td><p>Die P-A-P-Struktur besteht aus 2 Paketfiltern (P) und einem Filter auf Anwendungsebene (A), die durch Hardware getrennt sind und alle Verbindungen auf Anwendungsebene filtern. In Hardware getrennte Systeme sind hier solche, die jeweils über eigene Rechenkomponenten (CPU, RAM, etc.) verfügen und nur über Netzverbindungen zusammenhängen. Dies minimiert die Angriffsfläche für übergreifende Angriffe wie Covert Channel oder Side Channel.</p></td></tr><tr valign="top"><td>ARCH.5.2: Produktdiversität</td><td><p>Architektur für Externe Netzanschlüsse KANN für die Filterung diverse Produkte unterschiedlicher Hersteller für eingehende und ausgehende Verbindungen installieren.</p></td><td><p>Wenn nur gleichartige Filtersysteme verwendet werden, könnten Angreifer eine Schwachstelle zweimal hintereinander ausnutzen, um Netzzugang zu erhalten. Der Einsatz verschiedener, voneinander unabhängiger Hersteller hintereinander verringert die Wahrscheinlichkeit, dass beide Systeme gleichzeitig anfällig sind.</p></td></tr><tr valign="top"><td>ARCH.5.3: Blockieren direkter öffentlicher Verbindungen</td><td><p>Architektur für IT-Systeme SOLLTE direkte Verbindungen von diesen ins öffentliche Netz blockieren.</p></td><td><p>Direkte Verbindungen sind hier alle Verbindungen, die nicht von der Filterung erfasst werden. Die Anforderung ist für Firewallsysteme umgesetzt, wenn deren eingehende Verbindungen ebenfalls vollständig gefiltert werden, bevor sie Daten an Systemschnittstellen senden können.</p></td></tr></table><h2>ARCH.6: Vertraulichkeit und Integrität im Weitverkehrsnetz</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.6.1: Kontrollierte Verbindungsführung</td><td><p>Architektur für Externe Netzanschlüsse KANN eine  <i>physisch oder logisch</i> kontrollierte Verbindungsführung für Weitverkehrsverbindungen aktivieren.</p></td><td><p>Unter einer physisch kontrollierten Verbindungsführung kann in diesem Kontext die Verwendung dedizierter Leitungswege (Dark Fiber), sowie Hardware-Komponenten wie Router, Firewalls oder Trennstellen verstanden werden, die den Zugriff auf Leitungen oder Ports unmittelbar begrenzen. Eine logisch kontrollierte Verbindungsführung kann durch softwarebasierte Mechanismen wie VLANs, VPN-Tunnel oder Routing-Regeln erfolgen, die den Datenverkehr unabhängig von der physischen Leitung steuern. Ohne eine kontrollierte Verbindungsführung könnte ein Angreifer über eine ungeschützte oder direkt angebundene Leitung in interne Systeme eindringen und dort Schadsoftware platzieren, Daten manipulieren oder vertrauliche Informationen abziehen. Ebenso könnte durch eine unzureichend kontrollierte Verbindung ein Ausfall der Netzstabilität eintreten, etwa wenn über eine falsch konfigurierte Schnittstelle großflächiger Datenverkehr einbricht und produktive Systeme beeinträchtigt. Eine kontrollierte Architektur kann dagegen Angriffsflächen reduzieren, Datenströme nachvollziehbar machen und die Sicherheit der Informationsflüsse zwischen Institution und externen Partnern oder Netzanbietern erhöhen. Die Umsetzung kann beispielsweise durch klar definierte Übergabepunkte zum externen Netz erfolgen, an denen sämtliche eingehenden und ausgehenden Verbindungen zentral zusammenlaufen und durch Filter- oder Segmentierungsmechanismen geprüft werden.</p></td></tr><tr valign="top"><td>ARCH.6.2: Verschlüsselung von Weiterverkehrsverbindungen</td><td><p>Architektur für Externe Netzanschlüsse SOLLTE Verbindungen ins Weitverkehrsnetz nach <i>einem anerkannten Standard</i> verschlüsseln.</p></td><td><p>Ohne ein etabliertes Verschlüsselungsverfahren könnte sensible Kommunikation im Klartext übertragen werden, was Angreifern ein einfaches Mitlesen ermöglichen könnte – etwa durch Abhören in einem öffentlichen WLAN, durch kompromittierte Router eines Providers oder durch staatliche Massenüberwachung. Auch die unbemerkte Manipulation von Datenpaketen auf dem Weg zwischen Institution und Gegenstelle könnte die Integrität der übermittelten Inhalte gefährden und beispielsweise zu manipulierten Geschäftsdaten oder Schadcode-Einschleusungen führen. Der Einsatz von anerkannten Standards zur Verschlüsselung kann Vertraulichkeit und Integrität wahren, indem die Inhalte für Unbefugte unlesbar bleiben und Kommunikationspartner einander zuverlässig identifizieren können. So kann beispielsweise sichergestellt werden, dass eine entfernte Niederlassung tatsächlich mit der Zentrale verbunden ist und nicht mit einem Angreifer, der den Datenverkehr umleitet. Im Kontext externer Netzanschlüsse bezeichnet „Weitverkehrsnetz“ typischerweise öffentliche Netze wie das Internet oder auch gemietete WAN-Verbindungen über Telekommunikationsanbieter, die institutionsextern betrieben und potenziell unsicher sind. Anerkannte Standards sind z.B. TLS, IPsec oder WireGuard, die regelmäßig überprüft und weit verbreitet eingesetzt werden. Eine Institution kann diese Anforderung durch konkrete Maßnahmen umsetzen, z. B. indem sie Site-to-Site-VPNs zwischen Standorten einrichtet, Remote-Zugriffe von Mitarbeitenden ausschließlich über VPN-Gateways mit Zwei-Faktor-Authentisierung ermöglicht und auch Cloud-Dienste konsequent über gesicherte Verbindungen anbindet.</p></td></tr></table><h2>ARCH.7: Dedizierte Systeme</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.7.1: Dedizierte Server</td><td><p>Architektur für Anwendungen SOLLTE Serverdienste ausschließlich auf für die Anwendung dedizierten Hostsystemen platzieren.</p></td><td><p>Hiermit ist gemeint, dass nicht mehrere Server-Anwendungen auf einem Betriebssystem (oder sogar auf Endgeräten) laufen. Dies kann auch durch die Verwendung von virtuellen Maschinen oder Containern realisiert werden.</p></td></tr><tr valign="top"><td>ARCH.7.2: Dedizierte Hardware</td><td><p>Architektur für Hostsysteme KANN diese auf dedizierter Hardware platzieren.</p></td><td><p>Um die Verfügbarkeit ausreichender Ressourcen sicherzustellen und zyklische Abhängigkeiten zu vermeiden (z.B. einen VM-Host, dessen Domain Controller auf ihm selbst virtualisiert wird).</p></td></tr><tr valign="top"><td>ARCH.7.3: Entwicklungs- und Testumgebungen</td><td><p>Architektur für Virtualisierungslösungen SOLLTE Entwicklungs- und Testumgebungen nicht auf produktiven Hostsystemen platzieren.</p></td><td><p>Entwicklungs- und Testumgebungen sind dabei Umgebungen, in denen Software noch nicht ausgereift ist, sondern aktiv entwickelt, angepasst oder erprobt wird. Der Sinn der Vorgabe liegt darin, dass instabile oder absichtlich manipulierbare Testsysteme nicht auf denselben Hostsystemen betrieben werden sollten, auf denen produktive Anwendungen laufen. Andernfalls könnte ein Fehler in experimenteller Software dazu führen, dass der Hypervisor oder das Host-Betriebssystem beeinträchtigt wird und produktive Daten oder Dienste in Mitleidenschaft gezogen werden. Ebenso könnte Schadcode, der in einer Testumgebung eingebracht wird, unerwartet in produktive Netze durchgreifen. Durch die Trennung kann sichergestellt werden, dass ein Ausfall oder eine Kompromittierung in Entwicklungsumgebungen nicht die Stabilität und Vertraulichkeit produktiver Systeme gefährdet. Zur praktischen Umsetzung kann eine Institution Entwicklungs- und Testumgebungen auf dedizierte Virtualisierungshosts auslagern, die physisch oder logisch getrennt von den produktiven Hosts betrieben werden. Zusätzlich kann eine Institution Richtlinien zur Lifecycle-Kennzeichnung von VMs einführen (z. B. „dev“, „test“, „prod“ im Namen oder Tagging), um die klare Trennung auch in größeren Umgebungen praktikabel zu machen.</p></td></tr></table><h2>ARCH.8: Ausfallsicherheit</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.8.1: Redundanz im Kernnetz</td><td><p>Architektur für Netze SOLLTE für das Kernnetz redundante Netzkomponenten installieren.</p></td><td><p>Ziel hierbei ist es, dass beim Ausfall eines Systems oder einer Systemkomponente die Netzanbindung stets weiterhin funktionsfähig bleibt (Single-Point-of-Failure).</p></td></tr><tr valign="top"><td>ARCH.8.2: Redundante TK-Anbindung</td><td><p>Architektur für Externe Netzanschlüsse KANN redundante TK-Anbindungen für eingehende und ausgehende Verbindungen installieren.</p></td><td><p>Telekommunikationsanbindungen sind z.B. SIP-Trunks zum öffentlichen Telefonnetz (PSTN). Für weitere Details siehe „Kompendium für organisationsinterne Telekommunikationssysteme mit erhöhtem Schutzbedarf".</p></td></tr><tr valign="top"><td>ARCH.8.3: Redundante Server</td><td><p>Architektur für Anwendungen KANN für die Funktionsfähigkeit der Anwendung erforderliche Server-Systeme redundant installieren.</p></td><td><p>Redundanz ist gegeben, wenn sowohl das System als auch seine Netzanbindung redundant vorhanden sind. Das System selbst ist nur redundant, wenn auch seine Datenspeicher und Stromversorgung redundant ausgelegt sind. Automatische Umschaltung meint das Failover. Die Anforderung kann durch netzbasierte Load Balancer oder serverseitige automatisch Umschaltung umgesetzt werden (z.B. durch Hello-Pakete).</p></td></tr></table><h2>ARCH.9: Kapazitätsmanagement</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ARCH.9.1: Dimensionierung der Netzanbindung</td><td><p>Architektur für Netze SOLLTE eine bedarfsgerechte Netzanbindung installieren.</p></td><td><p>Für die Verfügbarkeit und Leistungsfähigkeit kritischer Geschäfts‑ und Fachverfahren ist eine bedarfsgerechte Netzanbindung erforderlich. Durch das strukturierte Erfassen des Bedarfes kann eine Institution frühzeitig Engpässe erkennen, Ausfallrisiken minimieren und eine wirtschaftliche Auslegung ihrer Anschlüsse erreichen. Gleichzeitig lässt sich so eine belastbare Grundlage für Kapazitäts‑, Notfall‑ und Budget‑Planungen schaffen, ohne sich allein auf starre Hersteller‑ oder Provider‑Vorgaben zu verlassen. Relevant ist hierbei die gesamte Netzstrecke zwischen Servern und IT-Clients, zumindest bis zum Internet-Anschluss der Institution. Beispiele für den Anwendungsbereich können sehr unterschiedlich ausfallen: In einem Call‑Center kann sich der Bedarf aus der Anzahl zeitgleich aktiver Soft‑Phones ableiten, deren Codec‑Bandbreite sowie der gewünschten Gesprächsqualität (Latenz < Antwortzeit in ms). In einem Forschungslabor kann die Anbindung darauf basieren, dass täglich große Datensätze mit einer bestimmten maximalen Bandbreite in Gbit/s zu Kooperationspartnern repliziert werden. Auch eine E‑Learning‑Plattform kann berücksichtigen, dass zu Semesterbeginn Studierende gleichzeitig parallele Video‑Streams in HD abrufen, während administrative Dienste weiterhin innerhalb einer bestimmten Antwortzeit in ms reagieren sollen. Dabei ist es sinnvoll, die Netzanbindung an realistische Belastungsszenarien anzupassen.</p></td></tr><tr valign="top"><td>ARCH.9.2: Lastverteilung</td><td><p>Architektur für Anwendungen KANN eine <i>netzbasierte oder serverbasierte</i> automatische Lastverteilung aktivieren.</p></td><td><p>Netzbasierte Lastverteilung bedeutet hier, dass ein dedizierter Netzwerkdienst – z. B. über Load-Balancer oder Layer-4/Layer-7-Komponenten – den eingehenden Datenverkehr dynamisch auf mehrere Server oder Dienste verteilt. Serverbasierte Lastverteilung bedeutet dagegen, dass die beteiligten Systeme selbst Mechanismen bereitstellen, um Anfragen untereinander weiterzugeben oder zu koordinieren, etwa durch eingebaute Proxy- oder Cluster-Funktionalitäten. Der Zweck einer solchen Verteilung liegt in der Absicherung der Verfügbarkeit: Ein plötzlicher Anstieg von Benutzeranfragen könnte ansonsten einzelne Systeme überlasten und zu Ausfällen führen; ebenso könnte ein Defekt in einem Knoten die Gesamtleistung stark beeinträchtigen. Mit geeigneter Lastverteilung kann die Stabilität der Anwendung verbessert und ein unterbrechungsfreier Betrieb unterstützt werden. Zur Umsetzung kann die Institution netzbasierte Verfahren einsetzen, etwa (1) hardware- oder softwaregestützte Load-Balancer, die eingehende Verbindungen nach konfigurierbaren Regeln verteilen, (2) DNS-basierte Verfahren, bei denen Abfragen gezielt auf unterschiedliche Zielsysteme geleitet werden, oder (3) virtuelle Appliances in virtualisierten oder Cloud-nahen Umgebungen. Serverbasierte Verfahren können etwa durch den Einsatz von Cluster-Software, eingebaute Reverse-Proxy-Funktionen in Webservern oder den Einsatz von Message-Queues realisiert werden. Dabei kann eine Institution darauf achten, dass Monitoring-Funktionen integriert sind, um Engpässe frühzeitig zu erkennen, und dass Konfigurationen für Failover-Szenarien getestet werden. Auch ein gestuftes Testen der Lastverteilung unter realitätsnahen Bedingungen kann helfen, die Wirksamkeit sicherzustellen.</p></td></tr><tr valign="top"><td>ARCH.9.3: Automatische Skalierung</td><td><p>Architektur für Anwendungen KANN eine automatische Skalierung der von der Anwendung verwendeten Computerinstanzen anhand von <i>Schwellwerten</i> aktivieren.</p></td><td><p>Automatische Skalierung ist die Fähigkeit einer Anwendungsarchitektur, die Anzahl der von einer Anwendung genutzten Serverinstanzen dynamisch und automatisiert zu erhöhen oder zu verringern. Grundlage für diese Anpassungen sind definierte Schwellwerte, die beispielsweise auf Metriken wie CPU-Auslastung, Speichernutzung oder Antwortzeiten beruhen können. Damit wird festgelegt, bei welchen messbaren Bedingungen zusätzliche Server gestartet oder wieder abgeschaltet werden. Typische Werte für Schwellwerte können etwa „80 % durchschnittliche CPU-Auslastung über 5 Minuten“, „weniger als 500 MB freier Arbeitsspeicher“ oder „Antwortzeit über 2 Sekunden bei mehr als 100 gleichzeitigen Anfragen“ sein. Ohne Auto-Scaling könnte es vorkommen, dass Anwendungen unter hoher Last nicht mehr reagieren, Datenverlust entsteht oder ganze Dienste für Nutzer unerreichbar werden. Umgekehrt kann Auto-Scaling helfen, Kosten und Ressourcen zu optimieren, indem ungenutzte Server wieder abgeschaltet werden. Eine sinnvolle Umsetzung kann beispielsweise durch den Einsatz von cloudbasierten Skalierungsgruppen erfolgen, die auf klar definierte Metriken reagieren, oder durch Virtualisierungsplattformen, die zusätzliche Instanzen automatisch bereitstellen. Praktische Tipps sind etwa (1) die Definition realistischer und getesteter Schwellwerte auf Basis historischer Lastprofile, (2) die Einrichtung von Stresstests, um das Verhalten bei Erreichen der Schwellwerte zu validieren, und (3) die Einführung von Alarmierungen, die Administratoren über ungewöhnlich häufiges Hoch- oder Runterskalieren informieren können. So kann die Institution sicherstellen, dass Auto-Scaling verlässlich funktioniert und gleichzeitig eine ökonomische Ressourcennutzung gewährleistet bleibt.</p></td></tr><tr valign="top"><td>ARCH.9.4: Content Delivery Network</td><td><p>Architektur für Anwendungen KANN ein Content Delivery Network installieren.</p></td><td><p>Ein Content Delivery Network (CDN) ist ein Netz geographisch verteilter Server, welches Inhalte wie Webseiten und große Mediendateien auch bei hoher Last skaliert zur Verfügung stellt. CDNs sind sinnvoll für weltweit hochverfügbare Server-Anwendungen, da so Lastspitzen und DDoS-Angriffe abgemildert werden. Ein CDN kann selbst umgesetzt oder durch einen entsprechenden Dienstleister übernommen werden.</p></td></tr><tr valign="top"><td>ARCH.9.5: Schutz gegen volumetrische DoS-Angriffe</td><td><p>Architektur für Netze KANN Schutzmaßnahmen gegen volumetrische DoS-Angriffe aktivieren.</p></td><td><p>Volumetrische Angriffe können z.B. durch die Verwendung von Anycast-DNS, Upstream Rate Limiting, On-Premise- oder Cloud-Scrubbing, BGP FlowSpec-Filter, Auto-Null-Routing oder Remotely Triggered Blackholing abgewehrt werden.</p></td></tr></table><h1>SENS: Sensibilisierung</h1><p>Die Praktik Sensibilisierung sorgt dafür, dass alle Mitarbeitenden über die Leitlinie zur Informationssicherheit sowie relevanten Informationssicherheitsrichtlinien, -verfahren und -bedrohungen informiert sind. Ziel ist es, ein sicherheitsbewusstes Verhalten im Arbeitsalltag zu fördern und zu verankern.  Der Fokus liegt auf der Schaffung eines Verständnisses für die Bedeutung der Informationssicherheit innerhalb der Institution. Gleichzeitig wird die notwendige Qualifikation für den sicheren Betrieb und die Nutzung von Anwendungen und IT-Systemen vermittelt, um Fehler zu vermeiden.  Die Praktik Personalmanagement stellt sicher, dass Informationssicherheitsaspekte während des gesamten Beschäftigungszyklus von Mitarbeitenden berücksichtigt werden, während Sensibilisierung speziell auf die kontinuierliche Weiterbildung und Sensibilisierung im Bereich Informationssicherheit abzielt.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>SENS.1: Grundlagen</td><td align="right">5</td></tr><tr valign="top"><td>SENS.2: Grundlegende Sensibilisierung</td><td align="right">10</td></tr><tr valign="top"><td>SENS.3: Schutz vor Schadprogrammen</td><td align="right">3</td></tr><tr valign="top"><td>SENS.4: Authentisierung</td><td align="right">9</td></tr><tr valign="top"><td>SENS.5: Umgang mit Informationen</td><td align="right">6</td></tr><tr valign="top"><td>SENS.6: Umgang mit Datenträgern</td><td align="right">2</td></tr><tr valign="top"><td>SENS.7: Umgang mit spezifischen Zielobjekten</td><td align="right">25</td></tr><tr valign="top"><td>SENS.8: Physische Sicherheit</td><td align="right">9</td></tr><tr valign="top"><td>SENS.9: Mobiles Arbeiten</td><td align="right">7</td></tr><tr valign="top"><td>SENS.10: Administration</td><td align="right">5</td></tr><tr valign="top"><td>SENS.11: Sensibilisierung der Leitungsebene</td><td align="right">3</td></tr><tr valign="top"><td>SENS.12: Spezifische Risiken</td><td align="right">1</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>85</b></td></tr></table><h2>SENS.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.1.1: Verfahren und Regelungen</td><td><p>Sensibilisierung MUSS Verfahren und Regelungen zur rollenspezifischen Schulung und Sensibilisierung verankern.</p></td><td><p>Zweck ist es, internen und externen Nutzenden die korrekte Verarbeitung von schützenswerten Informationen sowie die sichere Bedienung von IT-Systemen und Anwendungen nahezubringen. Ohne Sensibilisierung könnte etwa ein Administrator durch Unachtsamkeit kritische Systemkonfigurationen offenlegen, eine Pflegekraft könnte Patientendaten in unsicheren Kanälen weitergeben oder ein Beschäftigter im Einkauf könnte auf täuschend echt wirkende Phishing-Mails hereinfallen. Durch passgenaue Schulungen kann dagegen erreicht werden, dass Mitarbeitende die für ihre Aufgaben relevanten Gefahren frühzeitig erkennen, geeignete Schutzmaßnahmen anwenden und damit einen aktiven Beitrag zur Informationssicherheit leisten. Zweckmäßig ist es, im Rahmen der Ersteinweisung dazu Schulungen durchzuführen und um jährliche Information über aktuelle Neuerungen zu ergänzen. Zur Ergänzung und Erinnerung sind z.B. Poster oder Kampagnen sinnvoll. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>SENS.1.1.1: Dokumentation</td><td><p>Sensibilisierung MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>SENS.1.1.2: Zuweisung der Aufgaben</td><td><p>Sensibilisierung MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>SENS.1.1.3: Bekanntgabe</td><td><p>Sensibilisierung MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>SENS.1.2: Erfolgsmessung</td><td><p>Sensibilisierung SOLLTE den Erfolg der Sensibilisierung anhand <i>objektivierter Kriterien</i> <i>regelmäßig</i> überprüfen.</p></td><td><p>Zur Erfolgsmessung sind sowohl quantitative als auch qualitative Kriterien heranzuziehen, die unabhängig nachvollziehbar und überprüfbar sind. Erfolg zeigt sich dabei sowohl im erworbenen Wissen der Zielgruppen zur Informationssicherheit als auch in der tatsächlich umgesetzten Praxis von Schutzmaßnahmen.</p></td></tr></table><h2>SENS.2: Grundlegende Sensibilisierung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.2.1: Schutzziele</td><td><p>Sensibilisierung für Nutzende SOLLTE zu den Schutzzielen Verfügbarkeit, Vertraulichkeit und Integrität sensibilisieren.</p></td><td><p>Für die grundlegende Schulung kann z.B. auf den Online-Kurs des BSI zum IT-Grundschutz zurückgegriffen werden.</p></td></tr><tr valign="top"><td>SENS.2.2: Meldewege</td><td><p>Sensibilisierung für Nutzende SOLLTE zu den Meldewegen und Informationsquellen bei Fragen informieren.</p></td><td><p>Zur Bekanntgabe von Meldewegen gehört, welche Meldewege (z.B. Adresse, Rufnummer, Ticketsystem) zur Verfügung stehen und welche weiteren Informationsquellen (z.B. Wissensmanagement im Intranet, Dienstanweisungen, Betriebshandbuch, Chatbots) relevante Informationen zur Informationssicherheit enthalten.</p></td></tr><tr valign="top"><td>SENS.2.3: Verschlüsselung und Signatur</td><td><p>Sensibilisierung für Nutzende von Anwendungen SOLLTE zur Bedienung von Verschlüsselungs- und Signaturfunktionen sensibilisieren.</p></td><td><p>Viele Anwendungen zur Kommunikation bieten Funktionen zur Verschlüsselung oder digitalen Signatur (z.B. Verifikation der Ende-zu-Ende-Verschlüsselung per QR-Code im Messenger, Digitale Signatur von E-Mails). Verschlüsselung kann symmetrisch (gleicher Schlüssel ist auf beiden Seiten bekannt) oder asymmetrisch (ein öffentlicher und ein privater Schlüssel) erfolgen. Digitale Signaturen ermöglichen es, die Herkunft einer Nachricht zu überprüfen und Manipulationen zu erkennen.</p></td></tr><tr valign="top"><td>SENS.2.4: Nutzung unautorisierter Assets</td><td><p>Sensibilisierung für Nutzende SOLLTE die Nutzung unautorisierter Assets untersagen.</p></td><td><p>Die Nutzung unautorisierter Assets bezeichnet hier den Einsatz von IT-Systemen, Datenträgern, Anwendungen oder Cloud-Diensten, die nicht durch die Institution freigegeben und inventarisiert sind. Hierzu gehört auch der Anschluss privater Peripheriegeräte wie Tastaturen oder das Telefonieren mit nicht autorisierten Telefonen. Der Sinn und Zweck der Anforderung liegt darin, unkontrollierte Schatten-IT und damit verbundene Risiken zu reduzieren. So könnte etwa ein unautorisiertes USB-Gerät Schadsoftware einschleusen, oder eine nicht genehmigte Cloud-Anwendung könnte zu unbemerkten Datenabflüssen führen. Besteht ein Bedarf an Assets, dann können die festgelegten Meldewege genutzt werden. Bei der Beschaffung von Assets sind die Verfahren und Regelungen des Assetmanagements zu beachten.</p></td></tr><tr valign="top"><td>SENS.2.4.1: Verbindung unautorisierter IT-Systeme</td><td><p>Sensibilisierung für Nutzende SOLLTE die Verbindung unautorisierter IT-Systeme mit internen Netzen oder Schnittstellen untersagen.</p></td><td><p>Unautorisierte IT-Systeme sind solche, die von der Institution nicht für den Einsatz in den Netzen der Institution vorgesehen sind. Werden solche Geräte mit internen Netzen verbunden, so besteht das Risiko, dass sich hierüber Schadcode verbreitet oder unerwünschte Netzverbindungen aufgebaut werden. Das betrifft sowohl kabelgebundene Verbindungen als auch Funkverbindungen wie WLAN oder Bluetooth.</p></td></tr><tr valign="top"><td>SENS.2.5: Zuständigkeitsbereiche</td><td><p>Sensibilisierung für Nutzende SOLLTE zu Schutzbedarf und Schnittstellen in ihrem Zuständigkeitssbereich sensibilisieren.</p></td><td><p>Hiermit ist der Schutzbedarf des Zuständigkeitsbereichs des jeweiligen Nutzenden gemeint. Die Schnittstellen zu anderen Zuständigkeitsbereichen und deren entsprechender Schutzbedarf ist ebenfalls zu betrachten.</p></td></tr><tr valign="top"><td>SENS.2.6: Umgehung von Sicherheitsfunktionen</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen die Umgehung von Sicherheitsfunktionen sensibilisieren.</p></td><td><p>Selbst die ausgefeiltesten Sicherheitssysteme werden wirkungslos, wenn Anwender diese durch Eigeninitiative oder mangelndes Verständnis umgehen. Umgehungshandlungen könnten beispielsweise dazu führen, dass Schadprogramme durch Deaktivieren des Virenschutzes ins System gelangen, oder Angreifer über unsichere Verbindungen Zugang erhalten, wenn neue Verbindungen eigenmächtig geschaffen werden. Der Begriff <b>„Umgehung von Sicherheitsfunktionen“</b> umfasst dabei alle Handlungen, bei denen implementierte technische oder organisatorische Schutzmaßnahmen außer Kraft gesetzt, deaktiviert oder auf andere Weise ihrer Schutzwirkung beraubt werden, z.B. durch Rooting/Jailbreaking oder Verwendung nicht autorisierter Anwendungen oder Geräte. Wenn für eine Tätigkeit Funktionen benötigt werden, die durch Sicherheitsmechanismen verhindert werden, ist stattdessen eine Abstimmung über die festgelegten Meldewege sinnvoll.</p></td></tr><tr valign="top"><td>SENS.2.7: Änderung von Konfigurationen</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen die unautorisierte Änderung sicherheitsrelevanter Konfigurationen sensibilisieren.</p></td><td><p>Sicherheitsrelevante Konfigurationen umfassen dabei alle Einstellungen, die direkten Einfluss auf die Sicherheit haben, wie Firewall-Regeln, Benutzerrechte, Verschlüsselungsparameter, Netzwerkkonfigurationen oder Sicherheitssoftware-Einstellungen. Besteht ein Bedarf zur Änderung (z.B. Einschalten bislang deaktivierter Funktionen, Akzeptanz von Verschlüsselungszertifikaten) so ist stattdessen ein Gespräch mit den für Informationssicherheit zuständigen Stellen in der Institution sinnvoll um einen sicheren Betrieb zu ermöglichen.</p></td></tr><tr valign="top"><td>SENS.2.8: Melden von Ereignissen</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Melden von sicherheitsrelevanten Ereignissen anweisen.</p></td><td><p>Ohne ein Bewusstsein für die Bedeutung solcher Meldungen könnte ein Vorfall wie ein Phishing-Versuch, ein auffälliges Verhalten in einem IT-System oder der Verlust eines mobilen Endgeräts unbemerkt bleiben und gravierende Auswirkungen nach sich ziehen. Umgekehrt kann eine geschulte Aufmerksamkeit verhindern, dass Schwachstellen unentdeckt bleiben, und kann so die Widerstandsfähigkeit der Institution stärken. Sicherheitsrelevante Ereignisse sind hier Beobachtungen oder Abweichungen, die auf eine mögliche Beeinträchtigung der Informationssicherheit hinweisen – beispielsweise technische Probleme wie Systemausfälle und Virenfunde, aber auch verdächtige Aktivitäten von Personen wie z.B. unbefugte Zugriffe auf Systeme oder Daten oder unbekannte Personen in Sicherheitsbereichen. Eine geeignete Umsetzung kann durch unterschiedliche Maßnahmen unterstützt werden: (1) einfache und klar sichtbare Meldewege, z. B. eine zentrale Funktionsmailadresse oder eine Notfallhotline, (2) kurze Schulungen oder Awareness-Kampagnen mit praxisnahen Beispielen, die verdeutlichen, welche Vorfälle gemeldet werden können, (3) niedrigschwellige Hilfsmittel wie Poster, Bildschirm-Hinweise oder Quick-Reference-Karten, die den Meldeprozess in Erinnerung rufen. Für eine Umsetzung kann die BSI IT-Notfallkarte „Verhalten bei IT-Notfällen“ genutzt werden.</p></td></tr><tr valign="top"><td>SENS.2.8.1: Melden von Fehler- und Warnmeldungen</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Melden von Fehler- und Warnmeldungen sensibilisieren.</p></td><td><p>Unerwartete Fehler- oder Warnmeldungen könnten ein Indiz für weitreichendere Störungen oder sogar einen Angriff sein. Das Melden von Fehler- oder Warnmeldungen ist daher im Zweifel eine gute Idee nicht nur um den Betrieb aufrecht zu erhalten, sondern auch um die Informationssicherheit zu gewährleisten.</p></td></tr></table><h2>SENS.3: Schutz vor Schadprogrammen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.3.1: Schadprogramme</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen die Risiken von Schadprogrammen sensibilisieren.</p></td><td><p>Viele Dateitypen, wie z. B. Office-Dateien mit Makros, Adobe PDF, .exe, .ps1, oder .vbs, können Schadcode enthalten, der bei Ausführung die Kontrolle über das System übernimmt und Angreifern zur weiteren Ausbreitung im Informationsverbund dient.</p></td></tr><tr valign="top"><td>SENS.3.2: Öffnen verdächtiger Dateien</td><td><p>Sensibilisierung für Nutzende KANN zum Öffnen verdächtiger Dateien ausschließlich auf einem isolierten IT-System (Sandbox) sensibilisieren.</p></td><td><p>Eine Sandbox ist ein isoliertes IT-System, das bewusst so gestaltet ist, dass Dateien oder Programme in einer abgeschotteten Umgebung geöffnet und ausgeführt werden, ohne die produktive IT-Infrastruktur zu gefährden. Damit wird ein geschützter Bereich geschaffen, in dem verdächtige Dateien getestet und beobachtet werden, ohne dass Schadsoftware unkontrolliert in interne Systeme gelangt. Der Sinn dieser Anforderung liegt darin, das Risiko unbewusster Schadcode-Ausführung zu reduzieren: Ein unbedachtes Öffnen von E-Mail-Anhängen könnte beispielsweise zu Verschlüsselung durch Ransomware führen, oder ein manipuliertes Office-Dokument könnte eine unbemerkte Datenabflussschleuse öffnen. Als Sandbox kann auch ein virtuelles System auf dem Endgerät genutzt werden, wenn dieses von der Betriebssystemumgebung des Endgerätes isoliert ausgeführt wird.</p></td></tr><tr valign="top"><td>SENS.3.3: Umwandeln verdächtiger Dateien</td><td><p>Sensibilisierung für Nutzende KANN zum Umwandeln verdächtiger Dateien in ein nicht-ausführbares Format vor der weiteren Verwendung sensibilisieren.</p></td><td><p>Das gezielte Umwandeln potenziell schadhafter Dateien in ein nicht-ausführbares Format (engl. defanging) kann helfen, die Ausnutzung von Sicherheitslücken zu verhindern, bevor schädlicher Code aktiv werden kann. Eine Datei gilt dabei als verdächtig, wenn sie aus einer unbekannten oder unzuverlässigen Quelle stammt. Im Kontext dieser Anforderung bedeutet nicht-ausführbares Format (non-executable format), dass die Datei zwar geöffnet oder betrachtet, jedoch nicht direkt ausgeführt werden kann – Beispiele sind PDF ohne eingebettete aktive Inhalte, reines Textformat (.txt) oder Bildformate wie .png/.jpg. Die Umwandlung kann auf unterschiedliche Weise erfolgen, ohne dass dabei möglicher schadhafter Code in der Originaldatei ausgeführt wird. Verdächtige Office-Dokumente können automatisiert in ein PDF umgewandelt oder als Screenshot exportiert werden, bevor der Inhalt zur Ansicht freigegeben wird. Auch das Verwenden von sicheren Cloud-Vorschau-Ansichten, die keine direkte Ausführung erlauben, kann eingesetzt werden. Weitere praktikable Möglichkeiten sind das Umwandeln von ausführbaren Anhängen in komprimierte Archive mit deaktivierter automatischer Entpackung, oder die Nutzung spezieller Konverter-Tools, die potenziell gefährliche Dateiinhalte in ein sicheres Anzeigeformat übertragen. Hilfreich kann auch ein einfaches, intern bereitgestelltes Kurztutorial sein, das typische Umwandlungsschritte für verschiedene Dateitypen erklärt und aufzeigt, woran Nutzende potenzielle Risiken erkennen können.</p></td></tr></table><h2>SENS.4: Authentisierung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.4.1: Personengebundene Authentisierungsmittel</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Umgang mit Authentisierungsmitteln im Einklang mit den zugehörigen Anforderungen des Identitäts- und Berechtigungsmanagements sensibilisieren.</p></td><td><p>Authentisierungsmittel sind alle Methoden oder Technologien, die zur Überprüfung der Identität verwendet werden, z.B. Passwörter, Zugangschipkarte, Ausweis. Um Missbrauch zu vermeiden ist es wichtig, diese (1) geschützt aufzubewahren und niemals weiterzugeben, (2) den Verdacht, dass ein Passwort oder Token kompromittiert sein könnte, sofort zu melden und (3) aufmerksam gegenüber ungewöhnlichen Login-Masken oder Aufforderungen zu sein, die Zugangsdaten außerhalb der gewohnten Systeme einzugeben.</p></td></tr><tr valign="top"><td>SENS.4.1.1: Verdeckte Eingabe</td><td><p>Sensibilisierung für Nutzende SOLLTE zur verdeckten Eingabe von Zugangsdaten sensibilisieren.</p></td><td><p>Werden Zugangsdaten unverdeckt eingegeben, so könnten diese durch Shoulder Surfing kompromittiert werden, etwa in überfüllten Bereichen, Aufzügen oder während Videokonferenzen. Die verdeckte Eingabe umfasst dabei alle Tätigkeiten, die verhindern, dass Unbefugte die Eingabe von Passwörtern, PINs oder anderen Authentifizierungsdaten visuell erfassen können, sei es durch direkte Sichtbarkeit oder durch das Verfolgen von Handbewegungen und Tastaturanschlägen. Beispiele sind die bewusste Positionierung des Körpers oder der Hand als natürlicher Sichtschutz bei der Eingabe, sowie die Nutzung von Sichtschutzfolien auf Bildschirmen in öffentlichen Bereichen oder beim mobilen Arbeiten.</p></td></tr><tr valign="top"><td>SENS.4.1.2: Untersagung von Passwort Recycling</td><td><p>Sensibilisierung für Nutzende SOLLTE die Wiederverwendung von Passwörtern untersagen.</p></td><td><p>Wiederverwendung von Passwörtern bezeichnet  die Nutzung identischer Zugangsdaten für verschiedene Systeme, Dienste oder Anwendungen. Werden identische Passwörter auf unterschiedlichen Systemen eingesetzt, steigt die Wahrscheinlichkeit, dass ein Angreifer mit einem einzigen erlangten Passwort Zugriff auf weitere Konten erhält („Credential Stuffing“). Ein Vorfall könnte beispielsweise darin bestehen, dass ein externer Angreifer durch ein Datenleck bei einem Drittanbieter an ein altes Passwort gelangt und damit Zugang zu internen Diensten erhält, wenn die betroffene Person dieses Passwort mehrfach genutzt hat. Auch im internen Umfeld kann die Wiederverwendung von Passwörtern dazu führen, dass unbefugte Dritte über abgefangene oder mitgehörte Anmeldedaten Zugang zu sensiblen Bereichen erhalten. Die Anforderung zielt also auf eine Reduzierung der Angriffsfläche durch Verhinderung von Kettenreaktionen, die aus nur einem kompromittierten Passwort entstehen können. Mit „Wiederverwendung“ ist sowohl die Verwendung desselben Passworts an verschiedenen Zugangskonten oder IT-Systemen, also auch eine zeitlich wiederholte Nutzung früherer Passwörter gemeint.</p></td></tr><tr valign="top"><td>SENS.4.1.3: Wahl von Passwörtern</td><td><p>Sensibilisierung für Nutzende SOLLTE zur Wahl ausreichend komplexer Passwörter sensibilisieren.</p></td><td><p>Ein Passwort ist ein geheimes Zeichenfolgenkürzel, das als Authentisierungsmerkmal dient und typischerweise aus Buchstaben, Ziffern und Sonderzeichen bestehen kann. Komplexität bedeutet hierbei, dass die Passwortstruktur hinreichend schwer zu Erraten oder durch automatisierte Verfahren zu berechnen ist, etwa durch eine gewisse Länge und die Verwendung unterschiedlicher Zeichenarten. Die Komplexität ist ausreichend, wenn sie den festgelegten Qualitätskriterien für Passwörter entspricht. Einfache oder mehrfach genutzte Passwörter könnten durch erraten, Wörterbuchangriffe oder Datenleaks kompromittiert werden und so zu unautorisierten Zugriffen, Datenverlusten oder Identitätsdiebstahl führen. Die bewusste Wahl starker und einzigartiger Passwörter kann hingegen die Widerstandsfähigkeit gegen Angriffe deutlich erhöhen und so einen wesentlichen Beitrag zum Schutz von Daten und IT-Systemen leisten. Zur Umsetzung kann eine Institution verschiedene Maßnahmen einsetzen: (1) praxisnahe Schulungen und E-Learnings, die anschaulich erläutern, warum Passwörter wie „Sommer2023“ leicht angreifbar sein könnten und wie kreative Passphrasen gebildet werden können, (2) begleitende Tipps in Anmeldemasken, die Hinweise zur Passwortgestaltung geben, ohne konkrete Vorgaben zu erzwingen, (3) die Empfehlung von Passwortmanagern, die den Umgang mit langen und individuellen Kennwörtern erleichtern, (4) prozessuale Begleitung durch Erinnerungen oder kurze Awareness-Kampagnen, etwa durch Plakate, Newsletter oder interaktive Quizformate.</p></td></tr><tr valign="top"><td>SENS.4.1.4: Passwörter nur im Passwortmanager</td><td><p>Sensibilisierung für Nutzende SOLLTE das Speichern oder Aufschreiben von Passwörtern außerhalb von Passwort-Managern untersagen.</p></td><td><p>Weil Passwörter komplex sind und an vielen Stellen verwendet werden kommt es immer wieder dazu, dass sie unbedacht auf Zetteln oder in unverschlüsselten Tabellen notiert werden. Werden Passwörter etwa in Office-Listen, im Browser oder auf programmierbaren Tastaturen und Mäusen gespeichert, so könnten Angreifer diese auslesen und zur Ausbreitung auf Systemen und im Netz verwenden. In einem verschlüsselten Passwort-Manager, der nur mit einem Master-Passwort oder Hardwaretoken entsperrt werden kann, können Zugangsdaten dagegen sicher gespeichert werden. Ein Passwortmanager erleichtert es zudem Passwörter zu erzeugen und den richtigen Webseiten und Anwendungen zuzuordnen.</p></td></tr><tr valign="top"><td>SENS.4.1.5: Biometrische Authentifikation</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen die Fälschbarkeit von biometrischen Authentifizierungsmerkmalen sensibilisieren.</p></td><td><p>Ein Angreifer könnte z.B. einen Fingerabdruck von einer glatten Oberfläche abnehmen und damit ein Gerät missbräuchlich entsperren.</p></td></tr><tr valign="top"><td>SENS.4.1.6: Keine Weitergabe personengebundener Authentisierungsmittel</td><td><p>Sensibilisierung für Nutzende SOLLTE die Weitergabe von personengebundenen Authentisierungsmitteln untersagen.</p></td><td><p>Personengebundene Authentisierungsmittel sind z.B. Passwörter, Private PKI-Schlüssel oder Mehr-Faktor-Authentifizierungstoken wie Smartcards.</p></td></tr><tr valign="top"><td>SENS.4.2: Mehrfachnutzung von Zugängen</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen die Nutzung eines Zugangskontos durch mehrerere Personen sensibilisieren.</p></td><td><p>Insbesondere ist die Nutzung eines Benutzerkontos auf einem Endgerät durch mehrere natürliche Personen problematisch.</p></td></tr><tr valign="top"><td>SENS.4.3: Abmelden nach Nutzung</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Abmelden nach Nutzung sensibilisieren.</p></td><td><p>Bleibt eine Sitzung unbeaufsichtigt angemeldet, könnte dies ausgenutzt werden, um Daten zu manipulieren, zu kopieren oder unbemerkt schädliche Aktionen auszuführen. Ein solches Risiko könnte z.B. in offenen Büroflächen, gemeinsam genutzten Arbeitsplätzen oder bei externen Einsätzen entstehen, etwa wenn jemand kurz den Platz verlässt und ein Dritter die Gelegenheit nutzt, um sensible Unterlagen herunterzuladen oder interne Kommunikationskanäle zu durchsuchen. Dies beinhaltet auch die Sperrung des genutzten IT-Systems nach Nutzung. „Abmelden“ bedeutet in diesem Kontext das gezielte Beenden einer aktiven Benutzeranmeldung – etwa durch Ausloggen aus einer Anwendung, Sperren des Betriebssystems oder Abmelden von einem Fernzugriff –, sodass keine offenen Berechtigungen mehr genutzt werden können. Technische Hinweise wie Tastenkombinationen zum schnellen Sperren des Bildschirms oder kurze Anleitungen für den Logout-Prozess in wichtigen Fachanwendungen können in der Nähe von Arbeitsplätzen, auf Intranetseiten oder in E-Learning-Modulen platziert werden, um die Erinnerung daran wachzuhalten.</p></td></tr></table><h2>SENS.5: Umgang mit Informationen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.5.1: Datenablage</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Einhalten einer strukturierten Datenablage sensibilisieren.</p></td><td><p>Eine strukturierte Datenablage ist eine systematische Organisation von Daten in einer definierten Struktur, z.B. Aktenbestandverzeichnis, Content-Management-System. Dies ist wichtig für eine zentrale Zugriffssteuerung, Datensicherung und effiziente Suche.</p></td></tr><tr valign="top"><td>SENS.5.2: Weitergabe von Informationen</td><td><p>Sensibilisierung für Nutzende von Informationen SOLLTE zu den Voraussetzungen der Weitergabe von Informationen sensibilisieren.</p></td><td><p>Als <b>„Voraussetzungen der Weitergabe“</b> werden die rechtlichen, vertraglichen, technischen und organisatorischen Bedingungen verstanden, die vor der Übermittlung von Informationen an interne oder externe Empfänger erfüllt sein müssen, um Vertraulichkeit und Compliance zu gewährleisten. So werden unkontrollierte Informationslecks und Compliance-Verletzungen verhindert, indem ein Bewusstsein für die Voraussetzungen geschaffen wird, unter denen Informationen an Dritte übermittelt werden dürfen. Hierzu gehört insbesondere, welche Kategorien von Informationen (z.B. Kundendaten) welchen internen und externen Personengruppen (z.B. Dienstleister) über welche Kommunikationskanäle (z.B. E-Mail, telefonisch) unter welchen Voraussetzungen (z.B. Nennung des Kundenkennwortes) weitergegeben werden dürfen.</p></td></tr><tr valign="top"><td>SENS.5.3: Weitergabe von Erreichbarkeiten</td><td><p>Sensibilisierung für Nutzende KANN die Veröffentlichung oder Weitergabe von Erreichbarkeiten an unbefugte Dritte untersagen.</p></td><td><p>Dient dem Schutz vor Social Engineering-Angriffen und der Minimierung von Angriffsflächen durch Informationspreisgabe. Erreichbarkeiten umfassen dabei alle Kontaktinformationen wie Telefonnummern, E-Mail-Adressen, Instant-Messaging-Handles, interne Durchwahlen oder physische Standortangaben von Mitarbeitenden, die Angreifer für gezielte Phishing-Kampagnen, Vishing-Anrufe oder physische Infiltrationsversuche nutzen könnten. Ein Vorfall könnte z.B. entstehen, wenn eine Direktwahl des IT-Betriebs in sozialen Netzwerken preisgegeben wird und Angreifer diese für Pretexting nutzen, um sich als IT-Support auszugeben und Zugangsdaten zu erschleichen, oder wenn durch die Veröffentlichung von Abteilungsstrukturen mit einzelnen Kontaktdaten Angreifer gezielt Führungskräfte für CEO-Fraud identifizieren könnten.</p></td></tr><tr valign="top"><td>SENS.5.4: Rest- und Zusatzdaten</td><td><p>Sensibilisierung für Nutzende SOLLTE zur Vermeidung oder Entfernung von Rest- und Zusatzdaten vor dem Versand sensibilisieren.</p></td><td><p>Rest- und Zusatzinformationen sind z.B. die Metadatenfelder in Office- oder PDF-Dateien, sowie die Änderungshistorie.</p></td></tr><tr valign="top"><td>SENS.5.5: Löschfristen</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Löschen oder Vernichten nach Ablauf der festgelegten Löschfristen anweisen.</p></td><td><p>Werden sensible Informationen über die erforderliche Dauer hinaus gespeichert, könnte die Institution unnötigen Haftungsrisiken ausgesetzt sein – beispielsweise könnte eine Datenschutzbehörde Bußgelder verhängen, wenn personenbezogene Daten entgegen gesetzlicher Vorgaben zu lange vorgehalten werden. Darüber hinaus könnten nicht rechtzeitig gelöschte Geschäftsgeheimnisse oder Kundendaten bei einem Sicherheitsvorfall in falsche Hände geraten, was zu Reputationsschäden, Vertrauensverlust bei Kunden oder sogar zu Wirtschaftsspionage führen kann. Dies ist insbesondere wichtig bei sensiblen Daten wie Passwörtern im Passwortmanager oder Bankzugangsdaten in einer Kundendatenbank. Relevant ist dabei auch das Verständnis dafür, welche Löschfristen für welche Kategorien von Informationen konkret festgelegt sind und wie die Löschung oder Vernichtung vorzunehmen ist. Zu Details der Vorgehensweise siehe auch Praktik <b>„Informations- und Assetmanagement“</b>. Dies gilt auch für den Umgang mit physischen Medien und auch an anderen Standorten, wie z.B. am Mobilen Arbeitsplatz.</p></td></tr><tr valign="top"><td>SENS.5.6: Papiervernichtung</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Vernichten vertraulicher Dokumente nach Ablauf der Löschfrist sensibilisieren.</p></td><td><p>Gemäß ISO/IEC 21964-2 existieren unterschiedliche Sicherheitsstufen für Vernichtung. Die Granularität der Vernichtung richtet sich dabei nach dem Schutzbedarf der Daten. Sinnvoll ist es daher, das Vorgehen zur Vernichtung an der Einstufung der Daten auszurichten.</p></td></tr></table><h2>SENS.6: Umgang mit Datenträgern</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.6.1: Scan angenommener Wechseldatenträger</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Virenscan angenommener Wechseldatenträger anweisen.</p></td><td><p>Datenträger, wie USB-Sticks aus unbekannten oder externen Quellen, können Schadprogramme enthalten. Der Virenscan kann durch eine Datenträgerschleuse oder durch eine Virenprüfung im IT-System selbst umgesetzt werden.</p></td></tr><tr valign="top"><td>SENS.6.2: Verschlüsselung</td><td><p>Sensibilisierung für Nutzende SOLLTE zum Verschlüsseln von Wechseldatenträgern anweisen.</p></td><td><p>Falls Wechseldatenträger zum Austausch vertraulicher Daten verwendet werden, so sind diese vor der ersten Verwendung vollständig zu verschlüsseln. Die Verschlüsselung kann in Hard- oder Software, oder auf Dateiebene erfolgen.</p></td></tr></table><h2>SENS.7: Umgang mit spezifischen Zielobjekten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.7.1: Spezifische Sensibilisierung</td><td><p>Sensibilisierung für Nutzende SOLLTE zu zielobjektspezifischen Schutzmaßnahmen zielgruppengerecht sensibilisieren.</p></td><td><p>Kann dazu beitragen, dass Personen Risiken, die mit ihrer konkreten Tätigkeit, ihrem Arbeitsumfeld oder den von ihnen genutzten Systemen verbunden sind, frühzeitig erkennen und angemessen reagieren können. Ziel ist es auf die spezifischen Schutzbedarfe der jeweiligen Zielobjekte – wie z. B. bestimmte IT-Systeme, Produktionsanlagen, Forschungsdaten oder vertrauliche Kundeninformationen – aufmerksam zu machen. Dazu können sowohl technische als auch organisatorischen Schutzmaßnahmen gehören. Der Begriff „zielgruppengerecht“ meint dabei, dass Inhalte in einer Form, Tiefe und Sprache bereitgestellt werden, die für die jeweiligen Nutzenden verständlich, relevant und handlungsnah sind. Für die Zielgruppengerechtigkeit ist eine Zielgruppenanalyse zweckmäßig. Die Schutzmaßnahmen ergeben sich aus der konkreten Implementierung der Anforderungen durch die Institution.</p></td></tr><tr valign="top"><td>SENS.7.2: Virenscan</td><td><p>Sensibilisierung für Nutzende von Interpersoneller Kommunikation SOLLTE zum Virenscan von Dateien aus externen Quellen sensibilisieren.</p></td><td><p>Dateien aus externen Quellen (z.B. per E-Mail oder Messenger) könnten Schadprogramme enthalten. Bevor diese Dateien geöffnet oder anderweitig verarbeitet werden, ist eine Überprüfung mit einem Virenschutzprogramm oder einem dafür vorgesehenen Prüfsystem (z.B. Datenträgerschleuse) vorzunehmen.</p></td></tr><tr valign="top"><td>SENS.7.3: Automatische Antworten</td><td><p>Sensibilisierung für Nutzende von Interpersoneller Kommunikation SOLLTE gegen die Ausgabe vertraulicher Daten durch AutoReply-Funktionen sensibilisieren.</p></td><td><p>AutoReply-Funktionen – etwa automatische Abwesenheitsnotizen oder Standardantworten in E-Mail- oder Messaging-Systemen – könnten unbeabsichtigt vertrauliche Informationen an unberechtigte Empfänger preisgeben. In der Praxis könnte dies dazu führen, dass sensible Projektdetails, interne Kontaktdaten oder Hinweise auf Abwesenheiten an Angreifer gelangen, die solche Informationen gezielt zur Planung von Social-Engineering-Angriffen oder zur Umgehung von Sicherheitsmaßnahmen nutzen. Im Kontext dieser Anforderung bezeichnet „AutoReply“ die automatische Generierung und Versendung von Nachrichten durch Kommunikationssysteme ohne aktives Zutun der nutzenden Person, typischerweise ausgelöst durch eingehende Nachrichten.</p></td></tr><tr valign="top"><td>SENS.7.4: SPAM - Löschen oder Melden</td><td><p>Sensibilisierung für Nutzende von Interpersoneller Kommunikation SOLLTE zum Löschen oder Melden von SPAM sensibilisieren.</p></td><td><p>Spam – also unerwünschte, oft massenhaft versendete Nachrichten – könnte nicht nur den Posteingang überfluten und Arbeitszeit binden, sondern häufig auch Schadsoftware, Phishing-Links oder betrügerische Inhalte enthalten. Werden solche Nachrichten unbeachtet geöffnet oder beantwortet, könnte dies beispielsweise zu einer unbemerkten Offenlegung vertraulicher Informationen, zur Infektion von Endgeräten oder zur Kompromittierung von Benutzerkonten führen. Spam in E-Mails, Chat-Apps oder SMS kann oft an einer Kombination auffälliger Merkmale erkannt werden: (1) unerwartete oder anonyme Absender, (2) untypische Schreibweisen des Namens oder der Adresse, (3) drängender oder alarmierender Tonfall („sofort handeln“), (4) Links mit ungewöhnlichen oder verkürzten Domains, (5) fehlerhafte oder maschinell wirkende Sprache, (6) unpassende Dateianhänge oder Bilddateien sowie (7) Inhalte, die nicht zum bisherigen Kontext der Kommunikation passen. In Chat-Apps und SMS können zudem (8) fremdsprachige Nachrichten ohne Bezug, (9) Einladungen zu unbekannten Gruppen oder (10) Aufforderungen, auf externe Links zu klicken, verdächtig wirken. Das bewusste Hinterfragen solcher Signale kann helfen, Spam frühzeitig zu erkennen und unschädlich zu machen.</p></td></tr><tr valign="top"><td>SENS.7.5: SPAM - Nichtbeantwortung</td><td><p>Sensibilisierung für Nutzende von Interpersoneller Kommunikation SOLLTE zum Nichtbeantworten von SPAM sensibilisieren.</p></td><td><p>Das Nichtbeantworten von Spam kann  dazu beitragen, die eigene Angriffsfläche zu verringern und das Risiko von Folgeschäden zu minimieren. Spam – im Kontext hier als unerwünschte, massenhaft versendete elektronische Nachrichten verstanden, die oft mit betrügerischen oder schädigenden Absichten einhergehen – kann als Einfallstor für Phishing, Schadsoftware oder Betrugsversuche dienen. Eine Antwort, selbst in Form einer scheinbar harmlosen Rückfrage, kann Angreifenden bestätigen, dass die Adresse aktiv genutzt wird, was zu einer Zunahme der Spam-Flut oder gezielten Social-Engineering-Angriffen führen könnte. Spammer erraten Zieladressen oft nur und erhalten durch die Antwort weitere Hinweise auf Angriffsmöglichkeiten (z.B. Schema gültiger Mailadressen, E-Mail-Signaturen, aktive Server).</p></td></tr><tr valign="top"><td>SENS.7.6: SPAM - Links</td><td><p>Sensibilisierung für Nutzende von Interpersoneller Kommunikation SOLLTE gegen das Öffnen von Links in SPAM sensibilisieren.</p></td><td><p>Spam kann Phishing-Versuche enthalten, die zur Preisgabe sensibler Zugangsdaten verleiten, oder auf Webseiten führen, die Schadsoftware ausliefern. Angreifer versuchen oft, ihre Opfer zum unerwarteten Aufruf von Internetseiten zu drängen und nutzen täuschend echt aussehende Webseiten um Zugangsdaten oder IBAN-Nummern abzufischen. Im Zweifelsfall ist es sinnvoll stattdessen sinnvoll, Rücksprache über andere, bereits bekannte Erreichbarkeiten (z.B. Telefonnummer, bekannter Link im Intranet) zu halten und die Echtheit der Nachricht zu verifizieren, oder über die Meldewege einen potenziellen Vorfall zu melden.</p></td></tr><tr valign="top"><td>SENS.7.7: SPAM - Anhänge</td><td><p>Sensibilisierung für Nutzende von Interpersoneller Kommunikation SOLLTE gegen das Öffnen von Anhängen in SPAM sensibilisieren.</p></td><td><p>Das Öffnens von Anhängen in unerwünschten oder verdächtigen Nachrichten könnte dazu führen, dass Schadsoftware in die Systeme einer Institution gelangt oder vertrauliche Informationen abfließen. Angreifer versuchen oft, ihre Opfer zum Öffnen von Dateien zu drängen und nutzen diese dann, um Schadprogramme auszuführen. Im Zweifelsfall ist es sinnvoll stattdessen sinnvoll, Rücksprache über andere, bereits bekannte Erreichbarkeiten (z.B. Telefonnummer, bekannter Link im Intranet) zu halten und die Echtheit der Nachricht zu verifizieren, oder über die Meldewege einen potenziellen Vorfall zu melden. Nützlich sind zudem kompakte Checklisten, die die wichtigsten Prüfkriterien vor dem Öffnen eines Anhangs aufführen, wie z. B. die Überprüfung der Absenderadresse, die Plausibilität des Inhalts und die Art der Datei.</p></td></tr><tr valign="top"><td>SENS.7.8: Gefälschte E-Mails</td><td><p>Sensibilisierung für Nutzende von E-Mailn SOLLTE zum Erkennen von gefälschten E-Mails sensibilisieren.</p></td><td><p>Spam in E-Mails kann oft an einer Kombination auffälliger Merkmale erkannt werden: (1) unerwartete oder anonyme Absender, (2) untypische Schreibweisen des Namens oder der Adresse, (3) Absendernamen, der nicht zur Absender-Mailadresse passt, (4) drängender oder alarmierender Tonfall („sofort handeln“), (5) Links mit ungewöhnlichen oder verkürzten Domains, (6) fehlerhafte oder maschinell wirkende Sprache, (7) unpassende Dateianhänge oder Bilddateien sowie (8) Inhalte, die nicht zum bisherigen Kontext der Kommunikation passen.</p></td></tr><tr valign="top"><td>SENS.7.9: Aktive Inhalte</td><td><p>Sensibilisierung für Nutzende von Office-Anwendungen SOLLTE zur Überprüfung aktiver Inhalte vor der Aktivierung sensibilisieren.</p></td><td><p>Office-Dateien mit aktiven Inhalten (z.B. Makros) können Schadprogramme enthalten. In diesem Kontext bedeutet „aktive Inhalte“ jegliche Funktionen in Office-Dokumenten, die über reine Text- oder Datenanzeige hinaus eigenständig Code ausführen oder externe Ressourcen ansprechen können. Bei unbekannten oder unerwarteten Dokumenten mit solchen Inhalten ist es sinnvoll, zunächst Rücksprache mit der absendenden Person zu halten, um die Echtheit des Dokumentes zu bestätigen und zu klären, ob die aktiven Inhalte für die Kommunikation zwingend erforderlich sind. Werden aktive Inhalte tatsächlich benötigt, so ist eine Prüfung des Quellcodes vor der Ausführung sinnvoll, die über die Meldewege angestoßen werden kann. Wurde für bestimmte aktive Inhalte bereits eine Freigabe erteilt, so kann deren erneute Prüfung bei jedem Öffnen des Dokumenten entfallen.</p></td></tr><tr valign="top"><td>SENS.7.10: Trennen nicht benötigter Anschlüsse</td><td><p>Sensibilisierung für Nutzende von Virtualisierungslösungen SOLLTE zum Trennen nicht benötigter Verbindungen zwischen Host und virtuellem Gast sensibilisieren.</p></td><td><p>Werden unnötige Verbindungen zwischen Host und Gast nicht getrennt, könnte dies zu unautorisiertem Zugriff auf Daten oder Systeme führen, etwa wenn eine Malware aus dem Gast Zugriff auf Host-Ressourcen erhält oder wenn sensible Dateien versehentlich zwischen beiden Umgebungen ausgetauscht werden. Durch eine saubere Trennung kann das Risiko seitlicher Bewegungen innerhalb der IT-Infrastruktur verringert werden und die Integrität einzelner Arbeitsumgebungen kann erhalten bleiben. DIes betrifft z.B. angeschlossene Geräte und Schnittstellen wie Drucker, USB-Sticks oder auch die Netzanbindung. Auch einfache Checklisten für IT-Personal und Nutzende können helfen, das Bewusstsein zu stärken, dass Komfortfunktionen wie „Drag & Drop“ zwischen Host und Gast zwar praktisch erscheinen, aber potenziell eine unnötige Angriffsfläche eröffnen können.</p></td></tr><tr valign="top"><td>SENS.7.11: Heimliche Aufzeichnung</td><td><p>Sensibilisierung für Nutzende von VK-Anwendungen SOLLTE gegen die heimliche Bild- oder Tonaufzeichnung bei einer Videokonferenz sensibilisieren.</p></td><td><p>Heimliche Aufzeichnungen verletzen die Vertraulichkeit der Kommunikation. Eine Aufzeichnung von Wort und Bild ohne den Willen der Aufgezeichneten kann zudem eine Persönlichkeitsrechtverletzung bis hin zur Straftat (§ 201 StGB) darstellen. Dies gilt auch für Aufzeichnungen, die KI-gestützt ausgewertet werden.</p></td></tr><tr valign="top"><td>SENS.7.12: Öffentliche WLANs</td><td><p>Sensibilisierung für Nutzende von Endgeräten SOLLTE gegen die Risiken der Nutzung öffentlicher WLANs sensibilisieren.</p></td><td><p>„Öffentliches WLAN“ meint frei zugängliche oder nur schwach kontrollierte Funknetze, deren Betreiber, Konfiguration und Schutzmechanismen unbekannt sind. In öffentlichen WLANs übertragenen Datenverkehr könnte von Dritten abgefangen werden. Angriffe wie Man-in-the-Middle, gefälschte Hotspots (Evil Twins), Session-Hijacking oder Phishing über Captive Portals könnten zu Kontoübernahmen, Datenabfluss oder Schadsoftware führen. Dies gilt auch dann, wenn das WLAN verschlüsselt ist.</p></td></tr><tr valign="top"><td>SENS.7.13: Unverschlüsselte WLANs</td><td><p>Sensibilisierung für Nutzende von Endgeräten SOLLTE gegen die Risiken der Nutzung unverschlüsselter WLANs sensibilisieren.</p></td><td><p>Ohne Verschlüsselung könnten die über WLAN übertragenen Daten abgehört werden, z.B. Zugangsdaten, Session-Hijacking, Umleitungen durch DNS-Spoofing oder „Evil-Twins“. Ebenso könnte Schadcode über manipulierte Update-Kanäle oder Portalseiten eingeschleust werden. Im Kontext dieser Anforderung bedeutet „unverschlüsseltes WLAN“ offene Wi-Fi-Netze ohne WPA2/WPA3-Schutz, bei denen ein Captive Portal allein keine Funkstreckenverschlüsselung bereitstellt.</p></td></tr><tr valign="top"><td>SENS.7.14: Unautorisierte WLANs</td><td><p>Sensibilisierung für Nutzende von Endgeräten KANN die Nutzung unautorisierter WLANs untersagen.</p></td><td><p>Zwar sind immer mehr Verbindungen automatisch verschlüsselt, dennoch bergen WLAN-Verbindungen außerhalb der Institution das Risiko, dass Verbindungsdaten abgefangen oder IT-Systeme angegriffen werden.</p></td></tr><tr valign="top"><td>SENS.7.15: Social Engineering Anrufe</td><td><p>Sensibilisierung für Nutzende von TK-Anwendungen SOLLTE gegen Social Engineering Anrufe sensibilisieren.</p></td><td><p>Social Engineering bezeichnet in diesem Zusammenhang die bewusste Täuschung oder Beeinflussung einer Person, um sie zu Handlungen zu bewegen, die im Interesse des Angreifenden liegen, beispielsweise das Preisgeben von Passwörtern, internen Abläufen oder technischen Zugangsdaten. Ein Angriff könnte sich etwa darin äußern, dass sich eine Person am Telefon glaubhaft als IT-Support, Vorgesetzte oder externe Partnerin ausgibt, um den Eindruck einer legitimen Anfrage zu erwecken. Solche Vorfälle könnten zu unbefugtem Zugriff auf interne Systeme, zum Auslösen von Störungen oder zur Vorbereitung weiterer Angriffe führen. Typischerweise sind solche Anrufe daran zu erkenne, dass von unbekannten Personen zu unüberlegten Handlungen gedrängt wird. Hiergegen hilft es, den Gesprächspartner zunächst zu authentifizieren, bevor über vertrauliches gesprochen oder Handlungen angestoßen werden. Angezeigte Rufnummern oder Nutzernamen könnten dagegen manipuliert sein (Caller ID Spoofing) -  sie sind zur Authentifizierung des Gesprächspartners eher nicht geeignet. Das Mithören Dritter ist hier insbesondere im öffentlichen Raum zu bedenken, kann aber auch bei unverschlüsselten Verbindungen auftreten oder beim Gesprächspartner.</p></td></tr><tr valign="top"><td>SENS.7.16: Mailbox-PIN und Co.</td><td><p>Sensibilisierung für Nutzende von TK-Anwendungen SOLLTE zur Vergabe eigener Zugangsdaten zum Zugriff auf Aufzeichnungen sensibilisieren.</p></td><td><p>Der Begriff Zugangsdaten bezeichnet in diesem Kontext die für den Zugriff auf gespeicherte Aufzeichnungen notwendigen Authentisierungsinformationen, wie Passwörter, PINs oder Zugangstokens. Aufzeichnungen sind hierbei gespeicherte Mitschnitte oder Protokolle von Kommunikationssitzungen in TK-Anwendungen (z. B. Mailbox, Sprach-, Video- oder Chat-Verläufe), sofern deren Speicherung aktiviert wurde. Verfügt der Server über keine Funktion zum Speichern von Sprachaufzeichnungen (z.B. Voice-Mailbox mit PIN oder Gesprächsaufzeichnung bei Tastendruck) oder ist diese deaktiviert, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>SENS.7.17: Unverschlüsseltes Telefonieren</td><td><p>Sensibilisierung für Nutzende von TK-Anwendungen SOLLTE gegen die Kommunikation über unverschlüsselte Telekommunikationsverbindungen sensibilisieren.</p></td><td><p>Hilfreich ist es hierbei darüber zu informieren, zu welchen Empfängerkreisen mit welchem Schutzniveau über welche Anwendungen kommuniziert werden kann. Telefonie über das öffentliche Telefonnetz ist noch immer häufig unverschlüsselt, während z.B. viele moderne Messenger-Apps eine Ende-zu-Ende-Verschlüsselung ermöglichen. Relevant ist dabei auch der Aufbau von Konferenzschaltungen: Wählt sich z.B. ein Teilnehmer über das öffentliche Telefonnetz ein, so ist diese Verbindung typischerweise unverschlüsselt, wodurch die Gespräche aller Konferenzteilnehmer abgehört werden können, auch wenn die anderen Teilnehmer über eine verschlüsselte Verbindung in der Konferenz sind.</p></td></tr><tr valign="top"><td>SENS.7.18: Mobiltelefone in Sicherheitsbereichen</td><td><p>Sensibilisierung für Nutzende von Mobiltelefonen KANN das Mitführen von Mobiltelefonen in Sicherheitsbereichen untersagen.</p></td><td><p>Das Mitführen von Mobiltelefonen in besonders geschützten Bereichen kann untersagt werden, um das Risiko unbefugter Informationsabflüsse, unbeabsichtigter Datenaufzeichnungen oder unkontrollierter Funkübertragungen zu reduzieren. Mobiltelefone verfügen heute fast immer über hochauflösende Kameras, Mikrofone, GPS-Module und vielfältige Funktechnologien (z. B. LTE, WLAN, Bluetooth), die sowohl gezielt als auch unbeabsichtigt vertrauliche Informationen erfassen und weitergeben können. So könnte etwa ein Besuchender in einem Forschungsbereich versehentlich sensible Projektdaten fotografieren, oder ein infiziertes Gerät könnte über eine Funkverbindung Schadsoftware ins interne Netz einschleusen. Auch unbeabsichtigte Sprachaufzeichnungen in Besprechungen, die durch Assistenzfunktionen aktiviert werden, könnten sicherheitskritische Informationen in Cloud-Dienste übertragen. Das Verbot oder die Einschränkung des Mitführens in bestimmten Bereichen kann daher ein wirksames Mittel sein, um die Angriffsfläche für Spionage, Sabotage oder unkontrollierte Datenverbreitung deutlich zu verringern.</p></td></tr><tr valign="top"><td>SENS.7.19: Unverschlüsselte SMS oder MMS</td><td><p>Sensibilisierung für Nutzende von Mobiltelefonen KANN den Versand von SMS oder MMS untersagen.</p></td><td><p>SMS und MMS werden in der Regel unverschlüsselt übertragen und daher nicht für sensible Informationen geeignet. Stattdessen kann oft auf verschlüsselte Anwendungen zurückgegriffen werden.</p></td></tr><tr valign="top"><td>SENS.7.20: Authentifzierung von Gesprächspartnern</td><td><p>Sensibilisierung für Nutzende von Informationen SOLLTE zur Authentifizierung von Gesprächspartnern vor der Weitergabe von Informationen sensibilisieren.</p></td><td><p>Die Authentifizierung von Gesprächspartnern ist die verlässliche Verifikation der Identität einer Person, bevor vertrauliche oder schützenswerte Informationen mündlich, telefonisch oder über andere elektronische Kommunikationsmittel weitergegeben werden. Dazu gehört esinsbesondere sicherzustellen, dass die anfragende Person tatsächlich diejenige ist, für die sie sich ausgibt („authentication of interlocutors“). Ziel ist es zu verhindern, dass unberechtigte Dritte durch Täuschung an vertrauliche Inhalte gelangen. Ohne diese Überprüfung könnten Angriffe wie Social Engineering, CEO-Fraud oder Phishing erfolgreich sein – ein Angreifer könnte sich z. B. am Telefon als interner Kollege, vertrauter Dienstleister oder sogar als Behördenvertreter ausgeben, um Zugang zu Kundenlisten, Zugangsdaten oder Projektplänen zu erhalten. Dies gilt insbesondere am Telefon, aber auch in persönlichen Gesprächen mit Unbekannten. Sinnvoll ist es, hierzu ein einheitliches Verfahren zu etablieren, bei dem vor Auskunftserteilung anfragende Personen durch gezielte Rückfragen oder Vergleich mit bekannten Kontaktdaten überprüft werden. Beispiele können sein: (1) Rückruf unter der im internen Verzeichnis hinterlegten Telefonnummer, (2) Abgleich spezifischer interner Referenzen oder Codes, (3) Nachfrage nach Details, die nur legitim Berechtigte kennen können (z.B. Aktenzeichen), oder (4) die Nutzung anderer sicherer Kommunikationskanäle, die bereits für die jeweilige Person verifiziert wurden.</p></td></tr><tr valign="top"><td>SENS.7.21: Rechtsunsicherheit von Faxen</td><td><p>Sensibilisierung für Nutzende von Faxen SOLLTE gegen die Rechtsunsicherheit bei Empfang oder Versand von Faxen sensibilisieren.</p></td><td><p>Faxe enthalten nicht die originale, eigenhändige Unterschrift und erfüllen daher nicht die gesetzliche Schriftform (§ 126 BGB).</p></td></tr><tr valign="top"><td>SENS.7.22: Unverschlüsselte Faxleitungen</td><td><p>Sensibilisierung für Nutzende von Faxen SOLLTE gegen die Risiken der unauthentisierten und unverschlüsselten Faxnutzung sensibilisieren.</p></td><td><p>Da Faxverbindungen in der Regel weder eine Authentifikation des Empfängers noch eine Transportverschlüsselung vornehmen, können diese leicht abgefangen oder manipuliert werden. Dem kann durch eine Ankündigung sowie eine Sende- und Empfangsbestätigung entgegengewirkt werden.</p></td></tr><tr valign="top"><td>SENS.7.23: Geolokation</td><td><p>Sensibilisierung für Nutzende von Endgeräten SOLLTE über Standortbestimmungsfunktionen von mobilen Endgeräten sensibilisieren.</p></td><td><p>Zum Beispiel könnten Webseiten über Schnittstellen von Webbrowsern auf Standort-Sensoren (GPS, Mobilfunk etc.) zugreifen. Auch Mobilfunkanbieter sind in der Lage, Geostandorte über das Mobilfunksignal zu erfassen.</p></td></tr><tr valign="top"><td>SENS.7.24: Zertifikatswarnungen</td><td><p>Sensibilisierung für Nutzende von Webbrowsern SOLLTE gegen das unautorisierte Übergehen einer Zertifikatswarnung bei der Webnutzung sensibilisieren.</p></td><td><p>Zeigt der Browser oder eine andere Anwendung eine Zertifikatswarnung an, dann besteht das Risiko, dass es sich um einen Angriff handelt. Im Zweifel ist es hier angebracht, über die bekannten Meldewege nachzufragen und den Zugang zu bestimmten Seiten oder Anwendungen autorisieren zu lassen.</p></td></tr><tr valign="top"><td>SENS.7.25: Zugang zum Fahrzeug</td><td><p>Sensibilisierung für Nutzende von Fahrzeugen SOLLTE zu Schutzmaßnahmen vor dem Zugang Unbefugter zu Fahrzeugen sensibilisieren.</p></td><td><p>Kann dazu beitragen, unbefugte Nutzung, Manipulation oder Diebstahl von Fahrzeugen und deren Ausrüstung zu verhindern. Dies ist besonders relevant, wenn Fahrzeuge sensible Materialien, technische Geräte, vertrauliche Unterlagen oder digitale Speichermedien enthalten, die bei ungeschütztem Zugang in falsche Hände geraten könnten. Ein unachtsig abgestelltes und nicht verriegeltes Fahrzeug könnte beispielsweise dazu führen, dass wertvolle Ausrüstung entwendet, ein GPS-System manipuliert oder vertrauliche Einsatzpläne aus dem Handschuhfach entnommen werden. Auch das Auslesen elektronischer Schnittstellen (z. B. OBD-Port) könnte möglich sein, wenn ein Fahrzeug ungesichert ist. Im Kontext dieser Anforderung bedeutet „Unbefugte“ jede Person, die nicht ausdrücklich durch die Institution autorisiert ist, Zugang zum Fahrzeug oder dessen Inhalten zu erlangen; „Zugang“ umfasst dabei sowohl den physischen Einstieg in das Fahrzeug als auch den Zugriff auf dessen Inhalte oder elektronische Systeme.  Die Umsetzung dieser Sensibilisierung kann beispielsweise beinhalten, dass Fahrzeug beim Verlassen stets zu verriegeln und wertvolle Gegenstände oder vertrauliche Unterlagen nicht sichtbar im Innenraum zu lassen. Auch das Aktivieren werkseitiger oder nachgerüsteter Alarmanlagen oder Wegfahrsperren ist sinnvoll. Zudem ist es zweckmäßig, Fahrzeuge nur dort abzustellen, wo sie durch Sicherheitsmaßnahmen wie Zugangskontrollen und Alarmanlagen vor unbefugtem Zugriff geschützt sind und die erlaubten Datenlokationen es zulassen.</p></td></tr></table><h2>SENS.8: Physische Sicherheit</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.8.1: Risiken der Nutzung von mobilen Endgeräten</td><td><p>Sensibilisierung für Nutzende von Endgeräten SOLLTE gegen Risiken der Nutzung von mobilen Endgeräten sensibilisieren.</p></td><td><p>Bei der Nutzung mobiler Endgeräte wie Smartphones, Tablets und Laptops ist Vorsicht geboten, da diese Geräte häufig außerhalb gesicherter Umgebungen betrieben werden und dort typischerweise einer höheren Gefährdungslage ausgesetzt sind. Beispiele sind z.B. Abhandenkommen von Geräten oder Zugang von Unbefugten zu Informationen im öffentlichen Verkehr. Durch den konsequenten Einsatz von Gerätesperren, Verschlüsselung, vertrauenswürdigen Netzwerken sowie der geschützten Verwahrung von Geräten kann das Risiko einer unbefugten Nutzung erheblich reduziert werden.</p></td></tr><tr valign="top"><td>SENS.8.2: Schließen von Türen und Fenstern</td><td><p>Sensibilisierung für Nutzende von Gebäuden SOLLTE zum Verschließen von Fenstern und Türen beim Verlassen von Räumlichkeiten anweisen.</p></td><td><p>Durch unverschlossene Türen und Fenster könnten Unbefugte Zutritt erlangen und (in Außenwänden) auch Umwelteinflüsse wirksam werden (Regen, Sturm, Frost), so dass IT, sensible Informationen und andere Werte in Gefahr geraten, zerstört, beschädigt, ausgespäht oder entfernt werden könnten. Sobald die Anwesenheit von Pesonen in einem Raum endet, sind Türen und Fenster daher so  zu schließen, dass von Außen das unbefugte Öffnen und (in Außenwänden) das Eindringen von Umwelteinflüssen verhindert wird. Türen werden z.B. abgeschlossen oder Türschließsysteme in den entsprechenden Betriebszustand gebracht, Fenster ganz geschlossen und verriegelt. Nicht erforderlich ist das Verschließen der Türen von fensterlosen Innenräumen, in denen keine IT, sensible Informationen oder andere Werte aufbewahrt werden, oder wenn Risiken praktisch ausgeschlossen werden können (z.B. Kippen von Außenfenstern in höheren Geschossen bei gutem Wetter vor kurzer Abwesenheit). Dies gilt auch für Gemeinschaftsräume, in denen sich IT-Systeme oder Datenträger befinden, z.B. VK-Konferenzzimmer.</p></td></tr><tr valign="top"><td>SENS.8.3: Mitbringen von IT-Systemen</td><td><p>Sensibilisierung für Nutzende KANN das Mitbringen unautorisierter IT-Systeme untersagen.</p></td><td><p>Fremde IT-Systeme sind ein Risiko, weil sie an das interne Netz angeschlossen, zum Mithören von Gesprächen oder zur Standortverfolgung missbraucht werden können. Relevant sind dabei sowohl Geräte der Mitarbeitenden, als auch von Externen. Dies kann auch durch eine Hinterlegung  von Geräten an der Pforte oder in verschließbaren Fächern am Eingang umgesetzt werden.</p></td></tr><tr valign="top"><td>SENS.8.4: Begleitung Externer</td><td><p>Sensibilisierung für Mitarbeitende von Standorten KANN zur Begleitung von Externen anweisen.</p></td><td><p>Dies dient in erster Linie dazu, unbefugte oder unbeaufsichtigte Zugriffe auf sensible Bereiche, Informationen oder Systeme zu verhindern. Ohne eine solche Begleitung kann es leicht zu Situationen kommen, in denen Externe absichtlich oder versehentlich sicherheitskritische Bereiche betreten, vertrauliche Informationen einsehen oder technische Geräte unsachgemäß manipulieren. Die Begleitung Externer, die wie Interne sicherheitsüberprüft und geschult wurden, ist entbehrlich.</p></td></tr><tr valign="top"><td>SENS.8.4.1: Beaufsichtigung Externer</td><td><p>Sensibilisierung für Mitarbeitende von Standorten SOLLTE zur Beaufsichtigung von Externen in sensiblen Bereichen anweisen.</p></td><td><p>Erhalten Externe wie z.B. IT-Dienstleister Zugang zu Standorten, an denen sensible Informationen verarbeitet werden, so stellt eine Beaufsichtigung sicher, dass Externe nur soweit Zugriff auf diese Informationen erhalten, wie für die Erledigung der Aufgabe erforderlich.</p></td></tr><tr valign="top"><td>SENS.8.5: Verwahrung Intern</td><td><p>Sensibilisierung für Nutzende von Räumen SOLLTE zur sicheren Verwahrung von IT-Systemen und Datenträgern sensibilisieren.</p></td><td><p>Herumliegende vertrauliche Dokumente und Datenträger sind ein leichtes Ziel für Diebe und können versehentlich verloren gehen. Hiergegen hilft die Verwahrung in einem verschlossenen Schrank oder anderweitig entsprechend geschützt. Dies ist besonders wichtig in Räumlichkeiten, welche oft zusammen mit oder ausschließlich von externen Personen genutzt werden, z.B. Konferenz- oder Veranstaltungsräume.</p></td></tr><tr valign="top"><td>SENS.8.6: Rückgabe nicht mehr benötigter Assets</td><td><p>Sensibilisierung für Nutzende SOLLTE zur Rückgabe nicht mehr benötigter Assets anweisen.</p></td><td><p>Dies gilt z.B. bei einem Wechsel der Aufgaben oder der Beendigung des Vertragsverhältnisses zwischen Nutzenden und der Institution.</p></td></tr><tr valign="top"><td>SENS.8.7: Brandschutz</td><td><p>Sensibilisierung für Mitarbeitende SOLLTE zur korrekten Verwendung bereitgestellter Brandschutz-Hilfsmittel sensibilisieren.</p></td><td><p>Hierzu zählt z.B. die Einweisung in die korrekte Verwendung von Handfeuerlöschern, welche in Serverräumen oder Rechenzentren bereitgestellt werden.</p></td></tr><tr valign="top"><td>SENS.8.8: Wasserschutz</td><td><p>Sensibilisierung für Mitarbeitende KANN zur korrekten Verwendung bereitgestellter Wasserschutz-Hilfsmittel sensibilisieren.</p></td><td><p>Ohne ausreichende Kenntnisse könnte ein Mitarbeitender im Ernstfall zögern oder Hilfsmittel falsch anwenden, wodurch wertvolle Geräte ungeschützt bleiben oder unnötige Verzögerungen bei der Eindämmung eintreten könnten. Eine rechtzeitige und richtige Anwendung kann dagegen die Ausbreitung von Wasserschäden begrenzen, Datenverluste vermeiden und den Wiederanlauf kritischer Arbeitsprozesse erheblich erleichtern. Im Kontext dieser Anforderung bedeutet „Wasserschutz-Hilfsmittel“ einfache technische oder organisatorische Werkzeuge, die zur Eindämmung, Ableitung oder Beseitigung von Wasser im Notfall eingesetzt werden können, etwa Sandsäcke, Absperrschotten, Wassermelder oder Tauchpumpen. Konkrete Maßnahmen können sein: (1) Mitarbeitende regelmäßig in kurzen Übungen mit der Handhabung der vorhandenen Hilfsmittel vertraut machen, z. B. das Einsetzen von Absperrschotten an Türen oder den Betrieb einer Tauchpumpe an einem vorbereiteten Testbecken, (2) an den Aufbewahrungsorten der Hilfsmittel laminierte Schritt-für-Schritt-Anleitungen anbringen, die im Ernstfall sofort verständlich sind, (3) visuelle Markierungen oder QR-Codes platzieren, die auf kurze Videosequenzen zur Anwendung verweisen. Auch kleine Tipps können die Wirksamkeit erhöhen, etwa dass Hilfsmittel geordnet nach Dringlichkeit bereitliegen können oder dass bei Tauchpumpen vorab Kabel und Steckdosen auf sichere Reichweite geprüft werden können.</p></td></tr></table><h2>SENS.9: Mobiles Arbeiten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.9.1: Verarbeitung in der Öffentlichkeit</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen die Verarbeitung von vertraulichen Informationen in der Öffentlichkeit sensibilisieren.</p></td><td><p>Die Anforderung zielt darauf ab, das Risiko unbeabsichtigter Informationsabflüsse in öffentlichen Räumen zu reduzieren. Ohne entsprechende Aufmerksamkeit könnte etwa ein unbefugter Dritter vertrauliche Daten über die Schulter mitlesen, Fotos von Bildschirmen aufnehmen oder Gesprächsinhalte mithören, was im schlimmsten Fall zu Identitätsdiebstahl oder geschäftsschädigender Weitergabe von Insiderinformationen führen könnte. Unachtsamkeit könnte dabei z.B. einen Verstoß gegen Arbeitsanweisungen und das Gesetz zum Schutz von Geschäftsgeheimnissen (GeschGehG) darstellen. Im vorliegenden Kontext bedeutet „öffentliche Verarbeitung“ die Nutzung mobiler Geräte wie Laptops, Tablets oder Smartphones in frei zugänglichen Umgebungen, in denen unbekannte Personen mitlesen oder mithören könnten, zum Beispiel in Verkehrsmitteln, Cafés, Flughäfen oder Co-Working-Spaces. Zudem helfen Schutzmaßnahmen wie das Sitzen mit dem Rücken zur Wand oder die Verwendung von Displayschutzfolien und abdeckenden Kopfhörern.</p></td></tr><tr valign="top"><td>SENS.9.2: Vorsicht vor Mithören</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen das Abhören von Gesprächen beim mobilen Arbeiten sensibilisieren.</p></td><td><p>Das Abhören von Gesprächen bezeichnet im Kontext des mobilen Arbeitens das unbefugte Mithören vertraulicher oder sensibler Inhalte durch Dritte, sei es absichtlich (z. B. durch Spionage) oder unbeabsichtigt (z. B. durch zufällige Umstehende). Mobiles Arbeiten ist das Arbeiten an Orten außerhalb der Kontrolle der Institution, wie z. B. im Homeoffice, auf Reisen oder in öffentlichen Bereichen. Ohne entsprechende Vorsicht könnte die Preisgabe geschäftsrelevanter Daten über Produkte, interne Strategien oder persönliche Informationen erfolgen, was im schlimmsten Fall zu wirtschaftlichen Schäden oder Reputationsverlust führen könnte. Das betrifft insbesondere Anrufe und Videokonferenzen. Hierbei hilft es, Gespräche mit vertraulichem Inhalt nach Möglichkeit in geschützte Räume zu verlagern oder, falls dies nicht möglich ist, ihre Sprache bewusst zu kodieren bzw. zu abstrahieren. Technische Hilfsmittel wie Headsets mit Geräuschunterdrückung können die Verständlichkeit für autorisierte Gesprächspartner verbessern, während Umstehende weniger Details wahrnehmen. Auch einfache Verhaltenshinweise wie das Abwenden vom Publikumsverkehr, die Wahl einer Sitzposition mit Abstand zu anderen Personen oder die Nutzung digitaler Chatkanäle anstelle mündlicher Gespräche in unsicheren Umgebungen kann das Risiko verringern.</p></td></tr><tr valign="top"><td>SENS.9.3: Verwahrung außer Haus</td><td><p>Sensibilisierung für Nutzende SOLLTE zur Verwahrung von IT-Systemen und Datenträgern beim mobilen Arbeiten anweisen.</p></td><td><p>Die Verwahrung von IT-Systemen und Datenträgern bedeutet, diese so zu sichern, dass sie nicht unbeabsichtigt verloren gehen, beschädigt oder unbefugt eingesehen werden können. An mobilen Arbeitsplätzen ist das Risiko eines Zugriffs Unbefugter oder Verlustes typischerweise höher als in Bürogebäuden. Dagegen hilft es, alle Hardware und Dokumente so aufzubewahren, dass unbefugter Zugang und unberechtigter Zugriff verhindert wird. Hierzu können z.B. Koffer mit Schloss oder Hotelsafes genutzt werden. Eine regelmäßige Überprüfung dieser Maßnahmen wird empfohlen.</p></td></tr><tr valign="top"><td>SENS.9.4: Mobile Arbeit mit Dokumenten</td><td><p>Sensibilisierung für Nutzende SOLLTE über den sicheren Umgang mit analogen Dokumenten beim mobilen Arbeiten sensibilisieren.</p></td><td><p>Unter analogen Dokumenten sind hier alle physischen Informations- und Datenträger wie Ausdrucke, Notizbücher oder Verträge zu verstehen, die sensible oder vertrauliche Inhalte enthalten. Unbeaufsichtigte oder ungeschützte Dokumente könnten unterwegs leicht verloren gehen oder in unbefugte Hände gelangen, was zu ungewollter Preisgabe interner Informationen führt. Daher ist es sinnvoll (1) Unterlagen unterwegs stets in verschließbaren Taschen oder Mappen zu transportieren und so vor unbefugtem Zugriff zu schützen, (2) beim Arbeiten außerhalb der Institution nur die wirklich notwendigen Ausdrucke mitzunehmen und alle übrigen Dokumente in gesicherten Ablagen zu belassen. (3) Papierstapel durch neutrale Umschläge abzudecken oder in blickdichten Aktenhüllen mitzuführen, sodass neugierige Blicke verhindert werden, (4) temporäre Notizen nach Gebrauch einer sicheren Vernichtung zuzuführen, etwa durch mobile Reißwolf-Lösungen oder durch Rückgabe an eine zentrale Aktenvernichtung. Auch für mitgenommene analoge Dokumente gelten zudem die Regelungen und Verfahren zum Löschen und Vernichten.</p></td></tr><tr valign="top"><td>SENS.9.5: Mitnahme zur mobilen Arbeit</td><td><p>Sensibilisierung für Nutzende SOLLTE gegen die Mitnahme nicht erforderlicher IT-Systeme und Datenträger sensibilisieren.</p></td><td><p>Außerhalb der Institution sind die Möglichkeiten zum Schutz von IT-Systemen und Daten geringer. Es ist daher ratsam, die mitgenommenen Geräte und Dokumente auf das erforderliche Maß zu beschränken und stattdessen nach der Rückkehr intern weiter daran zu arbeiten. Welche IT-Systeme und Datenträger erforderlich sind, ergibt sich aus der Festlegung erlaubter Datenlokationen sowie den Aufgaben der Nutzenden.</p></td></tr><tr valign="top"><td>SENS.9.6: Mitnahme ins Ausland</td><td><p>Sensibilisierung für Nutzende KANN die Mitnahme nicht erforderlicher IT-Systeme und Datenträger bei Auslandsreisen untersagen.</p></td><td><p>Auf Auslandsreisen ist das Risiko für Spionage erhöht und der Rechtsschutz für Betroffene typischerweise geringer, insbesondere im EU-Ausland. Es ist daher ratsam, die mitgenommenen Geräte und sensiblen Informationen auf das für das Geschäft erforderliche Mindestmaß zu beschränken und stattdessen nach der Rückkehr an einem besser geschützten Standort weiter daran zu arbeiten. Welche IT-Systeme und Datenträger erforderlich sind, ergibt sich aus der Festlegung erlaubter Datenlokationen sowie den Aufgaben der Nutzenden. Ist die Nutzung von Informationen oder Assets der Institution im Ausland nicht vorgesehen (vgl. Anforderung Datenlokationen), dann ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>SENS.9.7: Reise- und Sicherheitshinweise</td><td><p>Sensibilisierung für Nutzende SOLLTE zu Reise- und Sicherheitshinweisen des Auswärtigen Amtes bei Auslandsreisen ins außereuropäische Ausland sensibilisieren.</p></td><td><p>Dies kann dazu beitragen, frühzeitig potenzielle Gefahren zu erkennen und das Verhalten an die spezifischen Risiken des Ziellandes anzupassen. Dies umfasst unter anderem Hinweise zu politischen Unruhen, Naturkatastrophen, Kriminalitätslagen oder besonderen Einreise- und Sicherheitsbestimmungen. Ohne solche Kenntnisse könnten Reisende unvorbereitet in Situationen geraten, in denen dienstliche Geräte kompromittiert werden, wenn unsichere Netzwerke genutzt werden. Ebenso könnten fehlende Kenntnisse über lokale Gesetze dazu führen, dass mitgeführte elektronische Geräte bei der Einreise beschlagnahmt oder inspiziert werden. Sinnvoll ist es, sich vor der Arbeitsreisen in das außereuropäische Ausland über aktuelle Reise- und Sicherheitshinweise beim Auswärtigen Amt zu informieren. Ist die Nutzung von Informationen oder Assets der Institution im Ausland nicht vorgesehen (vgl. Anforderung Datenlokationen), dann ist die Anforderung entbehrlich.</p></td></tr></table><h2>SENS.10: Administration</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.10.1: Grundprinzipien der Systemadministration</td><td><p>Sensibilisierung für Administrierende SOLLTE zu den Grundprinzipien der sicheren Administration sensibilisieren.</p></td><td><p>Administriende sind durch ihre weitreichenden Zugangs- und Zugriffsberechtigungen, sowie ihre Verantwortung für die Aufrechterhaltung der Infrastruktur von besonderer Bedeutung für die Informations- und Cybersicherheit. Hier bedeutet „sichere Administration“, dass administrative Tätigkeiten so gestaltet werden, dass Vertraulichkeit, Integrität und Verfügbarkeit der Systeme möglichst gewahrt bleiben. Dazu zählen etwa Zugriffskontrolle und Rechtevergabe nach dem Least-Privilege-Prinzip, Netzwerksegmentierung, Systemhärtung, Loganalyse, Datensicherungen und Monitoring sowie die Vorbereitung für Notfälle. Um dies sicherzustellen ist es wichtig, die festgelegten Regeln (z.B. IT-Betriebskonzept) zu kennen und  auf deren Einhaltung zu achten.</p></td></tr><tr valign="top"><td>SENS.10.2: Umgang mit privilegierten Berechtigungen</td><td><p>Sensibilisierung für Administrierende SOLLTE zum Umgang mit privilegierten Berechtigungen sensibilisieren.</p></td><td><p>Privilegierte Berechtigungen (auch „administrative Rechte“ oder „Root-Berechtigungen“ genannt) ermöglichen weitreichende Systemeingriffe und können bei unsachgemäßer Verwendung schwerwiegende Sicherheitsvorfälle verursachen. Beispielsweise könnte ein Administrator mit Root-Zugriff versehentlich kritische Systemdateien löschen, sensible Daten einsehen, oder bei kompromittierten Zugangsdaten könnten Angreifer durch Lateral Movement ungehindert im Netzwerk agieren. Dies besonders deutlich an realen Vorfällen, bei denen Administratoren durch Social Engineering zum Einsatz ihrer Berechtigungen manipuliert wurden oder durch mangelndes Bewusstsein für Sicherheitsimplikationen ihrer Handlungen Schwachstellen geschaffen haben. Stattdessen ist es sinnvoll, solche Berechtigungen nur zu verwenden, wenn sie für die Aktion erforderlich sind, z.B. durch sudo. Das betrifft auch Zugangsdaten, die in Skripten oder Anwendungen hinterlegt werden: Werden diese beim Aufruf von Kommandozeilenbefehlen oder in Skripten mitgespeichert, könnten sie in Protokollen oder im Prozessspeicher sichtbar sein und missbraucht werden. Sinnvoll ist stattdessen die Verwendung von Passwort-Managern, Umgebugsvariablen oder speziellen Secrets-Management-Lösungen. Dazu gehört auch die regelmäßige Rotation solcher Zugangsdaten bei Dienstekonten (Service Accounts).</p></td></tr><tr valign="top"><td>SENS.10.3: Systemadministration - Sicherheitsvorfälle</td><td><p>Sensibilisierung für Administrierende SOLLTE zu Verfahren und Regelungen bei Sicherheitsvorfällen sensibilisieren.</p></td><td><p>Für die Behandlung und Nachsorge bei Sicherheitsvorfällen sind die festgelegten Verfahren und Regelungen einzuhalten. Hierzu gehört etwa das Erkennen auffälliger Logeinträge, der Umgang mit kompromittierten Administratorpasswörtern oder das strukturierte Sammeln erster Fakten, bevor ein Incident-Response-Team übernimmt. Effektiv kann auch ein klar dokumentiertes Ablaufdiagramm sein, das den Meldeweg und zulässige Sofortmaßnahmen visuell darstellt und in Administrationshandbüchern oder direkt im Ticket-System hinterlegt ist.</p></td></tr><tr valign="top"><td>SENS.10.4: Systemadministration - Strukturierte Verkabelung</td><td><p>Sensibilisierung für Administrierende von Netzen SOLLTE zur strukturierten Verkabelung sensibilisieren.</p></td><td><p>Eine strukturierte Verkabelung kann die Übersichtlichkeit, Fehlertoleranz und Betriebssicherheit von Netzwerken erheblich verbessern. Sie dient dazu, Kabelwege und -anschlüsse einheitlich zu planen, zu dokumentieren und physisch so zu gestalten, dass Fehlverkabelungen, Kabelschäden oder unbefugte Eingriffe erschwert werden. Ohne solche Maßnahmen kann es zu chaotischen Verkabelungen kommen, die Fehlerdiagnosen erschweren, längere Ausfallzeiten verursachen oder im schlimmsten Fall unbemerkt unautorisierte Geräte ins Netz einschleusen lassen. So könnte etwa ein unbeschriftetes Patchkabel versehentlich abgezogen werden, wodurch kritische Systeme offline gehen, oder ein Kabelbündel könnte bei einer unachtsamen Bewegung beschädigt werden, was zu intermittierenden Netzwerkausfällen führt.  Im konkreten Kontext bezeichnet „strukturierte Verkabelung“ ein einheitlich aufgebautes und dokumentiertes System von Kabeln, Anschlüssen und Patchfeldern, das nach anerkannten Standards (z. B. nach DIN EN 50173 und 50174) geplant und umgesetzt wird. Dazu gehören die Auswahl geeigneter Kabel, normgerechte Verlegungswege unter Berücksichtigung von EN 50310 sowie die Einhaltung von Mindestbiegeradien und Trennungsabständen zu elektrischen Leitungen. Administrierende können durch klare Kabelführung, Farbcodierungen, eindeutige Beschriftungen und eine nachvollziehbare Dokumentation ihre Arbeitsumgebung übersichtlicher und sicherer gestalten.</p></td></tr><tr valign="top"><td>SENS.10.5: Systemadministration - Internetnutzung</td><td><p>Sensibilisierung für Administrierende SOLLTE gegen den Internetzugriff über ein Administrationskonto sensibilisieren.</p></td><td><p>Administrationskonten sind im konkreten Kontext privilegierte Benutzerkonten, die erweiterte Rechte für Konfigurations-, Installations- oder Wartungsaufgaben besitzen. Internetzugriff bezeichnet dabei das Herstellen von Verbindungen zu externen Diensten oder Webseiten außerhalb der institutionseigenen Netze. Ein solcher Zugriff mit einem Administrationskonto stellt ein erhebliches Risiko dar: Schadsoftware könnte mit denselben hohen Rechten ausgeführt werden oder Anmeldedaten könnten über unsichere Webseiten abgegriffen werden. Hiervon können Zugriffe ausgenommen werden, die zur Administration des Systems mit diesen Rechten erforderlich sind, z.B. Download von Sicherheitsupdates durch Applikationen, die zur Ausführung administrative Rechte benötigen.</p></td></tr></table><h2>SENS.11: Sensibilisierung der Leitungsebene</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.11.1: Sensibilisierung der Institutionsleitung</td><td><p>Sensibilisierung für Institutionsleitung SOLLTE zur Bedeutung der Informationssicherheit für den Schutz der Geschäftsprozesse sensibilisieren.</p></td><td><p>Informationssicherheit ist kein Selbstzweck, sondern soll die Verarbeitung von Informationen in Geschäftsprozessen zur Erreichung der Geschäftsziele schützen. Weil Umfang und Integration von Informationsverarbeitungen in Geschäftsprozessen zunehmen, sind Datenverluste, Cyberangriffe und andere elementare Gefährdungen eine zunehmend ernste Bedrohung.</p></td></tr><tr valign="top"><td>SENS.11.2: Führen als Vorbild</td><td><p>Sensibilisierung für Führungskräfte SOLLTE zu ihrer Vorbildfunktion bei der Informationssicherheit sensibilisieren.</p></td><td><p>Die Vorbildfunktion von Führungskräften ist entscheidend, um eine robuste Sicherheitskultur zu etablieren und die Einhaltung der geschulten Inhalte im Arbeitsalltag zu gewährleisten.</p></td></tr><tr valign="top"><td>SENS.11.3: Whaling</td><td><p>Sensibilisierung für Führungskräfte SOLLTE gegen gezielte Angriffe auf Führungskräfte sensibilisieren.</p></td><td><p>Gezielte Angriffe auf Führungskräfte, auch Whaling genannt, sind eine besondere Form des Social Engineering, bei der Täter sehr spezifisch auf leitende Personen einer Institution abzielen. Im Gegensatz zu herkömmlichem Phishing sind diese Angriffe stark personalisiert, häufig inhaltlich gut recherchiert und auf die Entscheidungsbefugnisse und den Einfluss der Führungsperson zugeschnitten. Die Täter setzen dabei häufig auf die jeweilige Situation zugeschnittene Social Engineering Techniken wie Spear Phishing (z.B. anhand von Angaben in sozialen Netzwerken), CEO-Fraud oder Deepfakes ein. Ein Vorfall könnte z.B. dazu führen, dass ein CFO durch eine täuschend echte E-Mail zur Freigabe von Überweisungen verleitet wird oder Aktivisten sich eine Videokonferenz mit bekannten Persönlichkeiten erschleichen, um diese bloßzustellen. Zur Verringerung des Risikos können konkrete Hinweise im Alltag beachtet werden: (1) Besonders aufmerksam sollte auf Nachrichten reagiert werden, die Dringlichkeit betonen, ungewöhnliche Geldtransfers verlangen oder auf streng vertrauliche Projekte Bezug nehmen. (2) Absenderadressen sollten sorgfältig geprüft werden – bereits kleine Abweichungen in Domainnamen können Manipulation anzeigen. (3) Zur Bestätigung verdächtiger Anfragen kann ein zweiter, unabhängiger Kommunikationskanal wie ein Rückruf unter offiziell bekannter Nummer genutzt werden. Zusätzlich kann darauf geachtet werden, keine sensiblen Informationen über öffentliche Plattformen preiszugeben, da solche Details als Grundlage für Angriffe dienen könnten. Auch eine feste Routine – etwa keine Zahlungen ausschließlich aufgrund einer E-Mail freizugeben – kann dazu beitragen, auch unter Zeitdruck resilient zu bleiben.</p></td></tr></table><h2>SENS.12: Spezifische Risiken</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>SENS.12.1: Hohe Risiken</td><td><p>Sensibilisierung für Nutzende KANN gegen die in der Risikoanalyse festgestellten hohen Risiken sensibilisieren.</p></td><td><p>Werden in einer Risikoanalyse bei hohem Schutzbedarf spezielle hohe Risiken festgestellt, so sind betroffene Nutzende auf diese Risiken hinzuweisen. Praktische Maßnahmen können (1) interaktive Trainings zu den jeweils relevanten Angriffsmethoden wie Social Engineering oder Ransomware umfassen, (2) Fallbeispiele aus der eigenen Branche einbeziehen, die konkrete Handlungsweisen aufzeigen, oder (3) wiederkehrende Awareness-Impulse wie Übungen einsetzen, die das Gelernte im Alltag verankern.</p></td></tr></table><h1>REA: Sicherheitsvorfallsbehandlung</h1><p>Die Praktik Sicherheitsvorfallsbehandlung sorgt dafür, dass Informationssicherheitsvorfälle effizient erkannt, gemeldet, analysiert und behoben werden, um Schäden zu minimieren und den Normalbetrieb so schnell wie möglich wiederherzustellen.  Diese Praktik ist reaktiv und konzentriert sich darauf, die Auswirkungen von Sicherheitsvorfällen zu minimieren. Sie stellt sicher, dass bei einem Sicherheitsvorfall schnell und effizient gehandelt wird, um den Schaden zu begrenzen.  Andere Praktiken, wie z.B. Architektur, Personal, Sensibilisierung wirken proaktiv und versuchen, Sicherheitsvorfälle durch präventive Maßnahmen zu verhindern oder deren Häufigkeit zu reduzieren.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>REA.1: Grundlagen</td><td align="right">6</td></tr><tr valign="top"><td>REA.2: Reaktion</td><td align="right">15</td></tr><tr valign="top"><td>REA.3: Erkenntnisse</td><td align="right">2</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>23</b></td></tr></table><h2>REA.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>REA.1.1: Verfahren und Regelungen</td><td><p>Sicherheitsvorfallsbehandlung MUSS Verfahren und Regelungen zur Behandlung von Sicherheitsvorfällen verankern.</p></td><td><p>Bei Sicherheitsvorfällen gilt es, schnell und systematisch zu reagieren, um weitere Schäden von Daten, Assets oder Personen abzuwenden. Auch erfahrene Experten benötigen dafür klare Anleitungen, um keine Arbeitsschritte zu vergessen oder rechtlichen Unsicherheiten bei der Ermittlung von Ursachen und Ergreifung von Gegenmaßnahmen ausgesetzt zu sein.  Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>REA.1.1.1: Dokumentation</td><td><p>Sicherheitsvorfallsbehandlung MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>REA.1.1.2: Zuweisung der Aufgaben</td><td><p>Sicherheitsvorfallsbehandlung MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>REA.1.1.3: Bekanntgabe</td><td><p>Sicherheitsvorfallsbehandlung MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>REA.1.2: Regelmäßige Überprüfung</td><td><p>Sicherheitsvorfallsbehandlung MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr><tr valign="top"><td>REA.1.3: Übungen zur Vorfallsbehandlung</td><td><p>Sicherheitsvorfallsbehandlung KANN die Abwehrfähigkeit durch Übungen <i>regelmäßig</i> überprüfen.</p></td><td><p>Komplexere Sicherheitsvorfälle treten auch in größeren Institutionen relativ selten auf. Gleichzeitig erfordern sie dann eine schnelle und kompetente Beurteilung und Behandlung. Um diese sicherzustellen, bietet sich eine regelmäßige Übung an, bei welcher der gesamte Lebenszyklus eines Vorfalls (von der Alarmierung über die Beweissicherung bis zur Nachbehandlung) geübt wird. Beispiele sind Simulationen von Datenleaks, Hacking-Angriffen oder des Ausfalls eines Rechenzentrums. Hierbei sind Übungen effektiver, wenn sie nicht nur theoretisch („nach Papierlage“) vorgenommen werden, sondern soweit wie möglich unter Realbedingungen, z.B. durch das Schwenken auf einen Ausweichsitz zu Zeiten, in denen dadurch keine Geschäftsprozesse beeinträchtigt werden. Zu einer Übung kann sowohl der Umgang mit technischen Werkzeugen als auch mit Verfahrensweisen, Zuständigkeiten im Team und Vertretungsregelungen gehören.</p></td></tr></table><h2>REA.2: Reaktion</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>REA.2.1: Triage und Erstreaktion</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE Meldungen einer Priorität zuweisen.</p></td><td><p>Triage ist ein strukturiertes Vorgehen zur Priorisierung und Ersteinschätzung von Sicherheitsvorfällen, mit dem Ziel, rasch und effizient auf Bedrohungen zu reagieren, Ressourcen gezielt einzusetzen und weitere Schäden zu minimieren. Dabei wird festgestellt, welche Vorfälle sofortige Aufmerksamkeit benötigen, welche weiter analysiert oder beobachtet werden oder irrelevante Fehlalarme sind. Kritische Vorfälle können z.B. ein Virenfund auf einem Server, Ransomwarevorfälle oder Spionage durch professionelle Täter sein. Die Umsetzung kann auch automatisiert durch EDR/SOAR geschehen.   Eine Erstreaktion ist eine schnelle Handlung, die dazu dient, weitere Schäden wie eine Ausbreitung von Angriffen oder Störungen in Geschäftsprozessen zu vermeiden. Sie kann z.B. in der Abschaltung betroffener Systeme, der Deaktivierung eines Zugangskonto, der Information Nutzender über eine Störung oder der Aktivierung eines Ausweichrechenzentrums bestehen.</p></td></tr><tr valign="top"><td>REA.2.2: Automatische Erstreaktion</td><td><p>Sicherheitsvorfallsbehandlung KANN eine automatische Erstreaktion aktivieren.</p></td><td><p>Die automatische Erstreaktion kann je nach Risikoprofil durch institutionseigene Host- oder Network Intrusion Prevention Systeme (HIPS / NIPS) oder eine vergleichbare Cloud-Lösung umgesetzt werden.</p></td></tr><tr valign="top"><td>REA.2.3: Dokumentation von Vorfällen</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE den Vorfall dokumentieren.</p></td><td><p>Hierzu können Ticketsysteme eingesetzt werden.</p></td></tr><tr valign="top"><td>REA.2.4: Diagnosedaten</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE Diagnosemethoden für den Fall, dass der Vorfall sich mit den standardisiert erfassten Informationen nicht ausreichend analysieren lässt, verankern.</p></td><td><p>Der Begriff Diagnosemethoden bezeichnet in diesem Kontext strukturierte Verfahren, Werkzeuge oder Analyseansätze, die eingesetzt werden können, um bei Sicherheitsvorfällen zusätzliche Informationen zu gewinnen, wenn die standardisierten Erstinformationen nicht ausreichen. Der Sinn der Vorschrift liegt darin, die Gefahr zu reduzieren, dass ein Vorfall unvollständig verstanden bleibt und dadurch falsche Entscheidungen getroffen werden. Eine Institution kann die Anforderung durch verschiedene technische und prozessuale Maßnahmen abbilden. So kann sie (1) erweiterte Protokollierungsoptionen aktivieren, etwa durch temporäres Erhöhen von Log-Levels in relevanten Systemen, (2) Datensicherungen einzelner betroffener Systeme, Anwendungen oder Netzwerksegmente vornehmen, um die Nachvollziehbarkeit zu gewährleisten, und (3) spezielle Analysewerkzeuge einsetzen, beispielsweise für Speicherabbilder oder Netzwerkanomalien. Ergänzend kann es sinnvoll sein, ein Playbook mit typischen Diagnosepfaden für häufige Vorfallarten bereitzuhalten, sodass Mitarbeitende bei Bedarf gezielt auf tiefergehende Analysen zurückgreifen können.</p></td></tr><tr valign="top"><td>REA.2.5: IT-Forensik</td><td><p>Sicherheitsvorfallsbehandlung KANN eine forensische Analyse bei Vorfällen, die <i>bestimmte Kriterien</i> erfüllen, ausführen.</p></td><td><p>Bei einer forensischen Analyse werden Beweise gesichert und Erkenntnisse zur Verbesserung von Schutzmaßnahmen gegen künftige Vorfälle gewonnen. Die Kriterien richten sich nach dem Schutzbedarf der betroffenen Informationen, Compliance-Verpflichtungen und dem Risikoprofil der Institution als Ganzes. Kriterien können, z.B. Anzeichen für einen (auch teilweise) erfolgreichen, gezielten Angriff, eine Straftat im Zusammenhang mit der Informationsverarbeitung oder eine Kompromittierung schützenswerter Informationen sein. Die Forensik kann durch eigenes qualifiziertes Personal oder durch einen im Vorfeld festgelegten, im Ernstfall zu beauftragenden Dienstleister geschehen. Zur Vorgehensweise können sowohl technische Werkzeuge, als auch rechtliche Rahmenbedingungen und Dokumentationsvorgaben gehören. Für Details siehe BSI-Leitfaden „IT-Forensik“.</p></td></tr><tr valign="top"><td>REA.2.5.1: Rechtssichere Beweissicherung</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE rechtlich relevante Beweise rechtssicher dokumentieren.</p></td><td><p>Rechtlich relevant sind Beweise, wenn Anzeichen dafür vorliegen, dass bei einem Sicherheitsvorfall gegen Compliance-Verpflichtungen oder interne Arbeitsanweisungen verstoßen wurde. Beispiele sind Vorfälle wie z.B. unberechtigten Zugriffen oder Manipulationen von Daten.  Beweise sind rechtssicher dokumentiert, wenn nachvollziehbar ist, wie sie erhoben wurden und sie außerdem sowohl gegen unautorisierte Einsicht als auch Veränderung geschützt aufbewahrt werden. Die Nachvollziehbarkeit von Veränderungen kann z.B. durch eine kryptografische Signatur oder getrennt aufbewahrte Checksummen sichergestellt werden. Außerdem ist es sinnvoll, die Originaldaten aufzubewahren, z.B. als Originaldatenträger oder Sicherungskopie. Für Details siehe BSI-Leitfaden „IT-Forensik“.</p></td></tr><tr valign="top"><td>REA.2.5.2: Vier-Augen-Prinzip</td><td><p>Sicherheitsvorfallsbehandlung KANN zur Forensik ein Vier-Augen-Prinzip verankern.</p></td><td><p>Wenn IT-Forensische Untersuchungen alleine vorgenommen werden, könnte das dokumentierte Vorgehen und damit die Stichhaltigkeit der Beweise bei einer gerichtlichen Überprüfung angezweifelt werden. Besser ist es, solche Untersuchungen gemeinsam mit einem Zeugen vorzunehmen, der qualifiziert ist zu beurteilen, welche Arbeitsschritte dabei vorgenommen wurden. Der Zeuge beglaubigt insbesondere die Prüfsummen der Dokumentation. Allerdings ist es auch ohne Vier-Augen-Prinzip möglich Belege für ein korrektes Vorgehen zu erbringen, beispielsweise durch Vorlage der unveränderten originalen Speichermedien.</p></td></tr><tr valign="top"><td>REA.2.5.3: Forensik-Dienstleister</td><td><p>Sicherheitsvorfallsbehandlung KANN die Bereitschaft eines Forensik-Dienstleisters binnen <i>einer Frist</i> vereinbaren.</p></td><td><p>Um im Ernstfall eine schnelle Untersuchung von Sicherheitsvorfällen zu ermöglichen, kann die Institution bereits unabhängig von einem Vorfall einen Vertrag mit einem qualifizierten Forensik-Dienstleister abschließen. Die Anforderung ist erst umgesetzt, wenn der Dienstleister für den Ernstfall eine Erstreaktion innerhalb einer bestimmten Frist garantiert. Die Untersuchung aller Ergebnisse kann die Frist überschreiten.</p></td></tr><tr valign="top"><td>REA.2.6: Ursachenanalyse und Behandlung</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE eine Vorgehensweise zur Ursachenanalyse und Behandlung verankern.</p></td><td><p>Um einen Vorfall vollständig beheben zu können, ist es zweckmäßig, zunächst zu analysieren, wie der Vorfall zustande kam (Root Cause Analysis): Welche Personen und Systeme sind betroffen? Welche systematischen Schwachstellen haben zu dem Vorfall geführt? Die Behebung des Vorfalls orientiert sich dann an diesen Erkenntnissen, z.B. durch Schließen der Sicherheitslücken und Wiederherstellung von Daten und Anwendungen.  Je nach Vorfall kann die Behandlung durch das Schließen ausgenutzter Sicherheitslücken, einem Test anderer IT-Systeme auf vergleichbare Schwachstellen oder dem Austausch betroffener IT-Systeme, Anwendungen oder Datenbestände umgesetzt werden. Sind die Originaldaten oder -Systeme nicht mehr zu retten, so kann die Neuinstallation betroffener Systeme und die Wiederherstellung von Daten aus Backups eine Möglichkeit der Behandlung sein.</p></td></tr><tr valign="top"><td>REA.2.6.1: Dokumentation des Vorgehens</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE die zur Behandlung durchgeführten Tätigkeiten dokumentieren.</p></td><td/></tr><tr valign="top"><td>REA.2.6.2: Kommunikation bei Vorfällen</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE eine Vorgehensweise zur Kommunikation bei Vorfällen unter Berücksichtigung von Compliance-Verpflichtungen, Bedürfnissen der interessierten Parteien und der Geschäftsziele verankern.</p></td><td><p>Hierzu gehören beispielsweise Meldepflichten gegenüber Aufsichts- oder Ermittlungsbehörden oder die Information Betroffener. Für personenbezogene Daten siehe auch Art. 34 DSGVO. Für weitere Details siehe ISO/IEC 27035.  Bei den Compliance-Verpflichtungen sind einerseits Verpflichtungen zu beachten, die eine Meldung oder einen bestimmten Umfang für Meldungen fordern (z.B. Art. 33 DSGVO), andererseits aber auch Verpflichtungen zur Wahrung der Vertraulichkeit, z.B. aus dem Datenschutz, vertraglicher Pflichten zur Wahrung fremder Geschäftsgeheimnisse oder der staatlichen Geheimhaltung. Im Zweifelsfall ist hier die Inanspruchnahme interner oder externer Rechtsberatung hier empfehlenswert.</p></td></tr><tr valign="top"><td>REA.2.6.2.1: Information zuständiger Behörden</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE bei Vorfällen die zuständigen Behörden im Einklang mit den Compliance-Verpflichtungen informieren.</p></td><td/></tr><tr valign="top"><td>REA.2.6.3: Koordinierung</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE die Koordinierung bei Vorfällen verankern.</p></td><td><p>Die Koordinierung der Behandlung von Sicherheitsvorfällen dient dazu, die Auswirkungen auf Daten, Systeme oder Personen zu minimieren, Compliance-Verpflichtungen zu erfüllen und die Wirksamkeit von Gegenmaßnahmen zu verstärken.  Hierzu gehören interessierte Parteien wie Aufsichts- und Ermittlungsbehörden, Lieferanten oder Kunden. Für weitere Details siehe ISO/IEC 27035.</p></td></tr><tr valign="top"><td>REA.2.6.4: Service Level</td><td><p>Sicherheitsvorfallsbehandlung KANN Service Level verankern.</p></td><td><p>Service Level bei der Sicherheitsvorfallsbehandlung legen verbindliche Zielvorgaben für Reaktions- und Bearbeitungszeiten fest, z. B. wie schnell ein Sicherheitsvorfall erkannt, bestätigt, eingestuft und gelöst werden muss. Damit wird sichergestellt, dass alle Beteiligten klare Erwartungen an Schnelligkeit und Qualität der Reaktion haben.</p></td></tr><tr valign="top"><td>REA.2.6.5: Eskalation</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE eine Eskalationsleiter verankern.</p></td><td><p>Eine Eskalationsleiter (engl. escalation matrix oder escalation path) bezeichnet in diesem Kontext eine festgelegte Reihenfolge von Melde- und Entscheidungsstufen, die im Falle eines Sicherheitsvorfalls eingehalten wird, um eine zeitgerechte und angemessene Reaktion sicherzustellen. Sie definiert, welche Rollen oder Funktionen bei bestimmten Schweregraden eines Vorfalls informiert, einbezogen oder zur Entscheidung befugt sind. Der Begriff ist hier prozessual zu verstehen, also nicht als hierarchische Personalstruktur, sondern als abgestufter Kommunikations- und Entscheidungsmechanismus innerhalb des Sicherheitsvorfallsprozesses. Der Zweck einer solchen Eskalationsleiter liegt darin, dass sicherheitsrelevante Ereignisse nicht auf operativer Ebene „steckenbleiben“, sondern in ihrer Kritikalität und potenziellen Auswirkung auf höhere Entscheidungsebenen eskaliert werden können. Dadurch kann verhindert werden, dass etwa ein anhaltender Systemausfall, ein möglicher Datenabfluss oder ein Angriff auf kritische Systeme unbemerkt bleibt oder verspätet adressiert wird. Eine wirksam verankerte Eskalationsleiter kann somit sicherstellen, dass die Reaktionszeit kurz, die Zuständigkeiten eindeutig und die Kommunikation nachvollziehbar bleiben. Hier empfiehlt es sich die Anforderung im Zusammenhang mit Notfallplänen, Krisenmanagement und Business Continuity Management zu betrachten – siehe auch Praktik Notfallplanung. Beispiele für Eskalationsstufen: (1) Ereignis, (2) sicherheitsrelevantes Ereignis, (3) sicherheitskritisches Ereignis, (4) Sicherheitsvorfall, (5) Notfall (siehe Notfallplanung), (6) Krise. Die Einstufung erfolgt entsprechend der Definition, die jede Institution für sich festlegt.</p></td></tr></table><h2>REA.3: Erkenntnisse</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>REA.3.1: Verbesserung durch Erkenntnisse</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE bisherige Maßnahmen anhand von Erkenntnissen aus Informationssicherheitsvorfällen <i>regelmäßig</i> überprüfen.</p></td><td><p>Gewonnene Erkenntnisse können technischer, organisatorischer oder menschlicher Natur sein. Dabei ist es zielführend, sich nicht nur auf die unmittelbaren Ursachen zu beschränken (z.B. „Administrierende haben vergessen eine abhängige Komponente zu aktualisieren“), sondern nach den tieferen prozessualen oder technischen Ursachen zu suchen (Root Cause Analysis), z.B. „Abhängigkeiten wurden bislang nicht dokumentiert“. Dabei kann es helfen, wenn alle Beteiligten verstehen, dass es nicht um Schuldzuweisungen geht, sondern um kontinuierliche Verbesserung des ISMS. Neben technischen Verbesserungen sind dabei auch organisatorische Maßnahmen sinnvoll. Beispielsweise können reale Beispiele in Schulungen verwendet werden, was die Bedeutung für die TeilnehmendenDeiDie  verdeutlicht und ähnliche Vorfälle in Zukunft vermeiden hilft.</p></td></tr><tr valign="top"><td>REA.3.1.1: Quantitative Analyse</td><td><p>Sicherheitsvorfallsbehandlung SOLLTE Erkenntnisse zu Art, Umfang und Schäden des Vorfalls dokumentieren.</p></td><td><p>Quantitative Auswertungen von Vorfällen können bei der regelmäßigen Überprüfung verwendet werden, um bei der Verbesserung von Maßnahmen die richtigen Prioritäten zu setzen und so die Eintrittswahrscheinlichkeit oder das Schadensausmaß zukünftiger Vorfälle zu verringern.</p></td></tr></table><h1>NOT: Notfallplanung</h1><p>Die Notfallplanung stellt sicher, dass bei schwerwiegenden Störungen oder Krisen schnell und koordiniert reagiert wird, um den Fortbestand kritischer Geschäftsprozesse und die Wiederherstellung der betroffenen Systeme zu gewährleisten.  Notfallplanung adressiert umfassende Notfälle und Krisensituationen, während die Sicherheitsvorfallbehandlung spezifisch auf Informationssicherheitsvorfälle fokussiert ist. Notfallmanagement ist strategisch und organisatorisch umfassender, während die Vorfallbehandlung auf operative Sicherheitsprobleme eingeht.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>NOT.1: Grundlagen</td><td align="right">6</td></tr><tr valign="top"><td>NOT.2: Besondere Aufbauorganisation</td><td align="right">5</td></tr><tr valign="top"><td>NOT.3: Notfallvorsorge</td><td align="right">6</td></tr><tr valign="top"><td>NOT.4: Datensicherung</td><td align="right">20</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>37</b></td></tr></table><h2>NOT.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>NOT.1.1: Verfahren und Regelungen</td><td><p>Notfallplanung MUSS Verfahren und Regelungen zur Vorsorge für Notfälle der Informationssicherheit verankern.</p></td><td><p>Für ein Managementsystem der Informationssicherheit ist es erforderlich, dass auch für Notfälle vorgesorgt wird, z.B. durch eine Datensicherung, so dass bei einer Naturkatastrophe wichtige Daten wiederhergestellt werden können. Dies kann durch den Aufbau eines dafür vorgesehenen Managementsystems (BCMS) oder die Umsetzung der einzelnen Anforderungen dieser Praktik geschehen. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte, die bei der Festlegung des Verfahrens zu berücksichtigen sind, ergeben sich aus den Anforderungen dieser Praktik. Es empfiehlt sich ebenfalls Wiederherstellungsmöglichkeiten und Alternativen für administrative Zugänge zu betrachten.</p></td></tr><tr valign="top"><td>NOT.1.1.1: Dokumentation</td><td><p>Notfallplanung MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>NOT.1.1.2: Zuweisung der Aufgaben</td><td><p>Notfallplanung MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, so dass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>NOT.1.1.3: Bekanntgabe</td><td><p>Notfallplanung MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>NOT.1.1.4: Business Continuity Management System</td><td><p>Notfallplanung KANN ein <i>Reaktiv-, Aufbau- oder Standard-</i>BCMS nach <i>BSI-Standard 200-4</i> verankern.</p></td><td><p>BCMS steht für Business Continuity Management System, ein Management-System, das Institutionen dabei hilft, die Kontinuität ihrer Geschäftsprozesse bei Störungen oder Krisen sicherzustellen. Es umfasst die Planung, Umsetzung und kontinuierliche Verbesserung von Strategien und Verfahren, um die Resilienz der Institution zu erhöhen und Ausfallzeiten zu minimieren. Beispiele sind der BSI-Standard 200-4 oder die DIN ISO/IEC 22301. Idealerweise werden die Anforderungen der Praktik Notfallplanung durch ein BCMS erbracht. Wenn ein BCMS aufgebaut wird, können die Anforderungen dieser Praktik in das BCMS integriert erfüllt werden. Das BSI empfiehlt dazu in einem ersten Schritt ein Reaktiv-BCMS aufzubauen und mit steigendem Reifegrad ein Standard-BCMS über die Zwischenstufe Aufbau-BCMS anzustreben. Nähere Informationen können dem BSI-Standard 200-4 Kapitel 2.6 BCMS-Stufenmodell (Reaktiv-, Aufbau- und Standard-BCMS) entnommen werden.</p></td></tr><tr valign="top"><td>NOT.1.2: Regelmäßige Überprüfung</td><td><p>Notfallplanung MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr></table><h2>NOT.2: Besondere Aufbauorganisation</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>NOT.2.1: Verfahren und Regelungen</td><td><p>Notfallplanung SOLLTE Verfahren und Regelungen für eine Besondere Aufbauorganisation (BAO) zur Behandlung von Notfällen und Krisen verankern.</p></td><td><p>Eine BAO ermöglicht, in Notfällen und Krisen schnellstmöglich auf das Schadensereignis zu reagieren. Eine BAO gehört zu den originären Aufgaben eines BCMS und SOLL von diesem etabliert werden. Wird bzw. wurde ein BCMS nach BSI-Standard 200-4 aufgebaut (unabhängig von der Stufe), so sind die BAO-betreffenden Anforderungen in der Regel erfüllt und werden im Rahmen des BCMS anhand des BSI-Standards 200-4 detaillierter definiert. Nähere Informationen können dem BSI-Standard 200-4 in Kapitel 5 Aufbau und Befähigung der BAO (R+AS) entnommen werden.  Die einzelnen Regelungen können den untergliederten Anforderungen entnommen werden.</p></td></tr><tr valign="top"><td>NOT.2.1.1: Rollen</td><td><p>Notfallplanung SOLLTE Aufgaben für die BAO einschließlich BAO-Stab und Notfallteams <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die BAO besteht in der Regel aus einem Stab, der die Koordination und Entscheidungsfindung in einem Schadensereignis übernimmt. Der Stab koordiniert ferner die Tätigkeiten der Notfallteams, die die ausgefallenen Ressourcen wieder anlaufen lassen (= in einen Notbetrieb bereitstellen) und die zeitkritischen Geschäftsprozesse in einem Notbetrieb durchführen und bearbeiten. Nähere Informationen können dem BSI-Standard 200-4 in Kapitel 5.1 Aufbau der BAO (R+AS) entnommen werden.</p></td></tr><tr valign="top"><td>NOT.2.1.2: Alarmierung</td><td><p>Notfallplanung SOLLTE die Alarmierung der BAO verankern.</p></td><td><p>In einem Schadensereignis ist es entscheidend, dass die BAO schnellstmöglich alarmiert wird und somit auch schnellstmöglich Entscheidungen treffen kann. Hierzu bedarf es entsprechender vorab vorbereiteter Alarmierungspfade bzw. Pläne. Diese legen fest, wer die BAO (typischerweise zuerst den Stab und anschließend passende Teams) anhand welcher Kriterien alarmieren kann. In der Praxis haben sich hier abgestufte Verfahren etabliert, die anhand von gezielten Fragen eine Vorfilterung ermöglichen. Nähere Informationen hierzu können dem BSI-Standard 200-4 Kapitel 5.2 Detektion, Alarmierung und Eskalation (R+AS) entnommen werden.</p></td></tr><tr valign="top"><td>NOT.2.1.3: Stabsraum</td><td><p>Notfallplanung KANN einen Stabsraum für den Stab installieren.</p></td><td><p>Damit der Stab der BAO im Schadensereignis handlungsfähig ist, benötigt er einen Stabsraum. Der Stabsraum kann ein Raum vor Ort oder eine virtuelle Arbeitsumgebung sein. Nähere Informationen können dem BSI-Standard 200-4 Kapitel 5.6.3 Festlegung eines Stabsraums (R+AS) entnommen werden.</p></td></tr><tr valign="top"><td>NOT.2.1.4: Stabsübung</td><td><p>Notfallplanung KANN die Funktionsfähigkeit der BAO <i>regelmäßig</i>  durch Stabsübungen überprüfen.</p></td><td><p>Da Notfälle nur selten vorkommen, die tatsächliche Funktionstüchtigkeit der BAO dann aber von großer Bedeutung für die Informationssicherheit ist, sind regelmäßige Übungen der BAO sinnvoll. Insbesondere die festgelegte Stabsstruktur (Aufgaben und Rollen), sowie das Funktionieren der Ausstattung sind im Ernstfall von großer Bedeutung. Zur Erprobung ist es zweckmäßig bei jeder Übung typische Szenarien im vollständig besetzten Stab durchzuführen und Notfallteams nur je nach passendem Szenario in die Übung einzubeziehen. Ist eine BAO erst aufgebaut worden, genügen für die Stabsübung in der Regel relativ simple Übungsszenarien wie ein Brand im Rechenzentrum oder ein Ransomware-Vorfall. Mit wachsendem Reifegrad der BAO kann anschließend die Komplexität und Realitätsnähe der Übung steigen. Nähere Informationen können dem BSI-Standard 200-4 Kapitel 13.6 Stabsübung (R+AS) entnommen werden.</p></td></tr></table><h2>NOT.3: Notfallvorsorge</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>NOT.3.1: Wiederanlaufplan</td><td><p>Notfallplanung SOLLTE einen Wiederanlaufplan für zeitkritische Systeme und Anwendungen dokumentieren.</p></td><td><p>Ein Wiederanlaufplan legt fest, wie eine ausgefallene (IT)-Ressource auf ein vorgesehenes Notbetriebsniveau innerhalb einer Wiederanlaufzeit durch Notfallteams zur Verfügung gestellt wird. Besteht ein BCMS, dann werden die zeitkritischen Ressourcen innerhalb der Business Impact Analyse identifiziert und in dieser entsprechende Wiederanlaufzeiten festgelegt. Die ausgewählten BC-Strategien des BCMS bieten ferner den Rahmen für die Wiederanlaufplanung. Besteht kein BCMS, dann können die zeitkritischen IT-Ressourcen anhand der Schutzbedarfsfeststellung (erhöhter Schutzbedarf in der Verfügbarkeit) identifiziert werden. Die Wiederanlaufzeit kann dann nur grob anhand der Ergebnisse der Schutzbedarfsfeststellung geschätzt werden. Nähere Informationen können dem BSI-Standard 200-4 Kapitel 12 Wiederanlauf- und Wiederherstellungsplanung (AS) entnommen werden.</p></td></tr><tr valign="top"><td>NOT.3.2: Geschäftsfortführungsplan</td><td><p>Notfallplanung KANN einen Geschäftsfortführungsplan für zeitkritische Geschäftsprozesse dokumentieren.</p></td><td><p>Ein Geschäftsfortführungsplan (GFP) legt fest, wie ein Geschäftsprozess in einem Notfall in einem Notbetrieb durchgeführt wird. Der Notbetrieb weicht in der Regel vom Normalbetrieb ab, z.B. indem ein geringes Geschäftsniveau (Notbetriebsniveau) angesetzt wird und/oder abweichende Ressourcen eingesetzt werden. Abweichende Ressourcen könnten darin bestehen, dass ein zuvor digital unterstützter Prozess wieder analog durchgeführt wird. Geschäftsfortführungspläne liegen in der grundlegenden Verantwortung eines BCMS und sind daher im Rahmen des ISMS nur optional. Die Ausgestaltung, Planung und näheren Anforderungen der Geschäftsfortführung werden in der Regel im Rahmen des BCMS durchgeführt. Nähere Informationen können dem BSI-Standard 200-4 Kapitel 11 Geschäftsfortführungsplanung (R+AS) entnommen werden.</p></td></tr><tr valign="top"><td>NOT.3.3: Sensibilisierung zum Vorgehen im Notfall</td><td><p>Notfallplanung für Nutzende SOLLTE zur Vorgehensweise in Notfällen und Krisen sensibilisieren.</p></td><td><p>Eine Sensibilisierung für die Vorgehensweise in Notfällen und Krisen (Contingency Training) stellt sicher, dass alle zuständigen Stellen ihre Aufgaben bei einem Schadensereignis kennen. Zweckmäßig ist es, die Detailtiefe der Sensibilisierung auf die unterschiedlichen Aufgaben bei einem Schadensereignis zuzuschneiden. Beispielsweise genügt es für manche Mitarbeitenden zu wissen, welche Erreichbarkeit bei einem Schadensereignis von ihnen erwartet wird.</p></td></tr><tr valign="top"><td>NOT.3.4: Funktionstest</td><td><p>Notfallplanung KANN die tatsächliche Funktionstüchtigkeit von Notfallplänen <i>regelmäßig</i> überprüfen.</p></td><td><p>Eine regelmäßige Überprüfung hilft zu erkennen, ob die verschiedenen Notfallpläne (z. B. Wiederanlaufplan, Geschäftsfortführungsplan) und Notbetriebsressourcen tatsächlich funktionieren und die Zuständigen die Verfahrensweisen beherrschen. Mit der tatsächlichen Funktionstüchtigkeit ist gemeint, dass nicht nur die Aktualität der Pläne betrachtet wird, sondern soweit möglich auch die konkreten Ressourcen geprüft werden (z.B. laufen die Meldewege wie vorgesehen, lassen sich Ausfallleitungen aktivieren, sind Ersatzgeräte nutzbar). Ist hierzu noch nicht die erforderliche Reife erlangt, können in einem ersten Schritt Planbesprechungen, die nur virtuell einen Plan überprüfen, eingesetzt werden. Nähere Informationen können dem BSI-Standard 200-4 Kapitel 13.9 Funktionstest (R optional +AS) und 13.5 Planbesprechung (R optional +AS) entnommen werden.</p></td></tr><tr valign="top"><td>NOT.3.5: Ausweich-Telekommunikation</td><td><p>Notfallplanung SOLLTE Ausweich-Telekommunikationsdienste verankern.</p></td><td><p>Telekommunikationsanbindungen für Daten- und Sprachverbindungen sind im Notfall essenziell, um kritische Geschäftsprozesse auch im Notbetrieb aufrechtzuerhalten und Gegenmaßnahmen koordiniert einleiten zu können. Ausweich-Telekommunikationsdienste können z.B. über den Anschluss anderer Anbieter, Mobilfunk oder Satellitenanschlüsse umgesetzt werden. Hierbei ist sowohl an den Netzanschluss kritischer IT-Systeme als auch an die Erreichbarkeit der im Notfall zuständigen Mitarbeiter und Dienstleister zu denken.</p></td></tr><tr valign="top"><td>NOT.3.6: Sicherheitsmechanismen</td><td><p>Notfallplanung SOLLTE alternative Sicherheitsmechanismen , die in Notfällen greifen, verankern.</p></td><td><p>In Notfällen besteht das Risiko, dass manche Sicherheitsvorkehrungen nicht zur Verfügung stehen. Alternative oder ergänzende Sicherheitsvorkehrungen können in Notfällen helfen die Balance zwischen Vertraulichkeit, Integrität und Verfügbarkeit aufrecht zu erhalten (z.B. Einmalpasswörter, die in einem Safe hinterlegt werden). Hierbei ist insbesondere daran zu denken, dass alternative Sicherheitsvorkehrungen nicht die im Normalbetrieb verwendeten Sicherheitsvorkehrungen untergraben.</p></td></tr></table><h2>NOT.4: Datensicherung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>NOT.4.1: Dokumentation der Quellen</td><td><p>Notfallplanung SOLLTE die zu sichernden Daten dokumentieren.</p></td><td><p>Datensicherungen dienen der Wiederherstellung von Daten nach Vorfällen. Aufgrund der besonderen Bedeutung fordert auch die ISO/IEC 27001 die Sicherung von Informationen in Übereinstimmung mit themenspezifischen Regelungen zur Datensicherung. Hierzu gehört die Regelung, welche Daten konkret gesichert werden (Quellen, Datenkategorien, Umfang). Relevant sind dabei auch Daten, die bei Dienstleistern oder in der Cloud aufbewahrt werden. Die Datensicherung kann auch durch die Sicherung ganzer IT-Systeme, Datenträger oder Netzlaufwerke umgesetzt werden. Es empfiehlt sich auch zu prüfen, wie die Institution ihre Daten, welche bei einem Outsourcing Dienstleister liegen, sichern will. Es ist möglich eine Datensicherung durch den Dienstleister oder auch bei sich selbst zu erstellen.</p></td></tr><tr valign="top"><td>NOT.4.2: Sicherung des Systems</td><td><p>Notfallplanung für IT-Systeme SOLLTE deren Datensicherung <i>regelmäßig</i> ausführen.</p></td><td><p>Zu den erforderlichen Daten können z.B. Konfigurationsdateien des Betriebssystems, Firmware, Lizenzen, Treiber und die Systemdokumentation gehören.  Bei gleichartigen Systemen kann die Anforderung auch durch die Sicherung einer Kopie erfolgen, wenn mit dieser alle IT-Systeme dieser Art funktionsfähig wiederhergestellt werden können.  Die Anforderung kann auch durch die Wiederherstellung aus einem Versionskontrollsystem erfolgen.</p></td></tr><tr valign="top"><td>NOT.4.3: Sicherung der Anwendung</td><td><p>Notfallplanung für Anwendungen SOLLTE deren Datensicherung <i>regelmäßig</i> ausführen.</p></td><td><p>Hierzu können z.B. sowohl die Daten einer Backend-Datenbank, als auch Konfigurationsdateien oder Sicherheitseinstellungen gehören. Bei einer Verzeichnisdatenbank z.B. sind typischerweise sowohl die eigentlichen Verzeichniseinträge wie Benutzer & Gruppenzugehörigkeiten, als auch Metadaten wie Benutzerattribute, Gruppenrichtlinien und Informationen zur Integration von Drittdiensten erforderlich, um die Verzeichnisdatenbank funktionsfähig wiederherzustellen.</p></td></tr><tr valign="top"><td>NOT.4.4: Automatische Datensicherung</td><td><p>Notfallplanung für Daten SOLLTE die Datensicherung durch <i>einen automatisierten Mechanismus</i> ausführen.</p></td><td><p>Ein automatisierter Mechanismus (engl. automated mechanism) ist hier ein technisches Verfahren, das ohne manuelles Zutun in festgelegten Intervallen oder bei bestimmten Ereignissen Sicherungskopien von Daten erstellt und dokumentiert. Er kann z. B. über Skripte, Backup-Software oder systemeigene Dienste umgesetzt werden, die regelmäßig und zuverlässig ausgeführt werden. Der Zweck solcher Mechanismen liegt darin, menschliche Fehlerquellen und Auslassungen zu vermeiden, denn eine manuelle Sicherung könnte in Stresssituationen übersehen werden oder unvollständig sein. Die Vorgabe kann so verhindern, dass im Falle von Schadsoftwarebefall oder Hardwareausfall kritische Daten unwiederbringlich verloren gehen, und sie kann eine schnelle Wiederherstellung der Arbeitsfähigkeit nach einem Vorfall ermöglichen. Ohne Automatisierung könnte eine Institution etwa nach einem Ransomware-Angriff feststellen, dass keine aktuelle Sicherung vorliegt. Die Anforderung ist auch dann erfüllt, wenn zusätzlich manuelle Datensicherungen durchgeführt werden.</p></td></tr><tr valign="top"><td>NOT.4.5: Archivierung langfristig benötigter Daten</td><td><p>Notfallplanung für Daten SOLLTE die Archivierung langfristig benötigter Daten <i>regelmäßig</i> ausführen.</p></td><td><p>Archivierung meint hier die langfristige Aufbewahrung derjenigen Daten, die über längere Zeit benötigt werden, z.B. als Nachweis der Einhaltung rechtlicher Verpflichtungen oder zur Geltendmachung von Ansprüchen. Dabei kann es sich sowohl um analoge Dokumente als auch um digitale Daten handeln. Die meisten Institutionen verarbeiten Daten, die aufgrund von Compliance-Verpflichtungen langfristig gespeichert werden, z.B. handels- und steuerrechtlich relevante Dokumente oder Eigentumsurkunden. Langfristige Daten könnten durch technische Änderungen oder Vorfälle verloren gehen. Zur Umsetzung siehe BSI TR-03125. Sind keine Daten langfristig (z.B. über mehr als 10 Jahre) erforderlich, so ist die Anforderung entbehrlich. Es empfiehlt sich darüber hinaus ein verlustfreies Bildkompressionsverfahren zu nutzen, um eine beweis- und revisionssichere Archivierung zu gewährleisten.</p></td></tr><tr valign="top"><td>NOT.4.5.1: Zum Archiv gehörende Assets</td><td><p>Notfallplanung für Daten SOLLTE die Archivierung von Assets, die zur Verwendung von archivierten Daten erforderlich sind, <i>regelmäßig</i> ausführen.</p></td><td><p>Je nach Art der Daten können zu deren Nutzung z.B. bestimmte (physische oder virtuelle) Assets wie Systeme oder Anwendungen erforderlich sein, z.B. bestimmte Datenbankversionen, kompatible Betriebssysteme und Lizenzen, Anwendungen zur kryptographischen Entschlüsselung der Daten, Konfigurationsdateien oder Betriebsparameter. Wenn Daten für eine lange Zeit aufbewahrt werden, könnte es vorkommen, dass sie nicht mehr lesbar und reproduzierbar sind, weil diese Assets nicht mehr existieren und auch nicht mehr beschafft werden können.</p></td></tr><tr valign="top"><td>NOT.4.5.2: Zum Archiv gehörende Dokumentation</td><td><p>Notfallplanung für Daten SOLLTE die Archivierung von Dokumentationen, die zur Verwendung von archivierten Daten erforderlich sind, <i>regelmäßig</i> ausführen.</p></td><td><p>Hierbei geht es darum, nicht nur die Daten selbst, sondern auch alle begleitenden Informationen („metadata“ oder „supporting documentation“) regelmäßig zu sichern, um deren spätere Nutzbarkeit zu gewährleisten. Dokumentationen sind in diesem Zusammenhang beispielsweise Bedienungsanleitungen, technische Spezifikationen, Konfigurationsdateien oder Verfahrensanweisungen, die notwendig sind, um archivierte Daten auch nach Jahren noch korrekt zu interpretieren oder wiederherzustellen. Die Frequenz ist dabei abhängig von der Kritikalität der Daten und der Änderungsfrequenz der begleitenden Dokumente. Ohne solche begleitenden Unterlagen könnte ein Datenbestand zwar vorliegen, aber praktisch unbrauchbar sein, da die nötigen Kontexte oder technischen Details fehlen.</p></td></tr><tr valign="top"><td>NOT.4.6: Geschützte Aufbewahrung</td><td><p>Notfallplanung SOLLTE eine geschützte Aufbewahrung von Datensicherungen verankern.</p></td><td><p>Eine geschützte Aufbewahrung von Datensicherungen bedeutet, dass Sicherungskopien nicht nur vorhanden sind, sondern auch vor Verlust, Manipulation oder unbefugtem Zugriff bewahrt werden. Dabei wird berücksichtigt, dass Datensicherungen häufig ein attraktives Ziel für Angriffe darstellen und gleichzeitig im Notfall die einzige Möglichkeit zur Wiederherstellung von Systemen und Daten sein können. Beispiele für Schutzmaßnahmen sind die Ablage von Sicherungsmedien in feuer- und wasserfesten Tresoren, die Nutzung getrennter Räumlichkeiten oder externer Rechenzentren mit physischen Sicherheitsvorkehrungen sowie die Verschlüsselung von Backups, wenn diese an externen Standorten oder in Cloud-Umgebungen gespeichert werden. Auch organisatorische Maßnahmen wie eine klare Regelung, wer Zugriff auf die Sicherungen erhält, tragen zum Schutz bei.</p></td></tr><tr valign="top"><td>NOT.4.7: Versionierung</td><td><p>Notfallplanung SOLLTE eine Versionierung der Datensicherung verankern.</p></td><td><p>Versionierung ist die Aufbewahrung nach Zeitpunkten getrennter Versionen der Datensicherung, um auch Daten wiederherstellen zu können, die in der letzten Sicherung bereits gelöscht waren. Bewährt hat sich eine Aufbewahrung von je drei Versionen für die letzten Stunden, dann Tage, dann Wochen, dann Monate – soweit nach Compliance-Anforderungen (z.B. Datenschutz) möglich.</p></td></tr><tr valign="top"><td>NOT.4.8: Verschlüsselung</td><td><p>Notfallplanung SOLLTE die Datensicherung durch <i>einen anerkannten kryptographischen Algorithmus</i> verschlüsseln.</p></td><td><p>Die Datensicherung enthält typischerweise eine große Menge schützenswerter Daten. Durch Verschlüsselung wird die Vertraulichkeit und Integrität geschützter Informationen auch nach einem schwerwiegenden Vorfall gewährleistet. Dies kann besonders bei einem Datenleck (engl. Data Breach) oder Diebstahl von Speichermedien helfen, da die Offenlegung sensibler Daten selbst bei unbefugtem Zugriff verhindert werden kann. Für anerkannte Algorithmen siehe BSI TR-02102. Technisch kann die Festplattenverschlüsselung auf dem Sicherungsspeicher (Disk Encryption) genutzt werden, aber auch die dateibasierte Verschlüsselung jedes einzelnen Sicherungs-Archives. Wichtig ist es, dabei auch auf die Verwaltung der kryptographischen Schlüssel (Key Management) zu achten, damit diese weder einem unbeugten Zugriff ausgesetzt sind, noch der Zugriff auf die Datensicherung im Ernstfall durch fehlende Zugangsdaten unmöglich wird.</p></td></tr><tr valign="top"><td>NOT.4.9: Speichermedien</td><td><p>Notfallplanung SOLLTE dedizierte Speichermedien, die für den festgelegten Aufbewahrungszeitraum geeignet sind, installieren.</p></td><td><p>Dedizierte Speichermedien (engl. dedicated storage media) sind physische oder virtuelle Datenträger, die ausschließlich für Sicherungs- oder Wiederherstellungszwecke genutzt werden und nicht mit produktiven Systemen vermischt sind. Der festgelegte Aufbewahrungszeitraum (engl. retention period) bezeichnet den Zeitraum, in dem gespeicherte Sicherungen oder Kopien revisionssicher und lesbar verfügbar bleiben sollen, beispielsweise mehrere Monate für kurzfristige Recovery-Szenarien oder mehrere Jahre zur Abdeckung regulatorischer Anforderungen. Die Vorschrift zielt darauf ab, dass im Notfall tatsächlich auf funktionierende und vollständige Sicherungen zurückgegriffen werden kann; sie adressiert Risiken wie, dass Daten im Ernstfall durch unzuverlässige oder beschädigte Medien unbrauchbar sein könnten, oder dass durch unzureichende Haltbarkeit von Speichermedien eine Wiederherstellung scheitern könnte. Je nach Zeitraum und Platzbedarf bieten sich z.B. solider Festspeicher, Festplatten, Magnetbänder oder Cloudspeicher an. Bei der Nutzung von Cloudspeichern sind allerdings auch die zusätzlichen Anforderungen an Cloud-Dienste zu berücksichtigen.</p></td></tr><tr valign="top"><td>NOT.4.10: Getrennte Aufbewahrung</td><td><p>Notfallplanung SOLLTE die Datensicherung getrennt von den Originaldaten platzieren.</p></td><td><p>Originaldaten (engl. primary data) sind die produktiven oder operativen Daten, die unmittelbar für die laufenden Geschäftsprozesse verwendet werden. Die Anforderung adressiert damit, dass Kopien oder Sicherungen nicht am gleichen Ort wie die produktiven Systeme und deren Speicher verbleiben. Hintergrund ist, dass ein Vorfall wie ein Brand, ein Wasserschaden oder ein gezielter Einbruch gleichzeitig sowohl die produktiven Systeme als auch die dort aufbewahrten Sicherungen betreffen könnte, wodurch eine Wiederherstellung unmöglich wäre. Die physische Trennung kann dagegen die Verfügbarkeit und Wiederanlaufbarkeit der Daten nach einem Schadensereignis sicherstellen. Die Anforderung gilt auch für die Aufbewahrung bei Cloud-Diensten: Eine Aufbewahrung der Datensicherung bei einem Dienstleister, bei dem auch die Originaldaten liegen, erfüllt die Anforderung NICHT. Bei der getrennten Aufbewahrung von Datensicherung sind häufig praktische und sicherheitsrelevante Herausforderungen zu beachten: Ein ausgelagerter Speicherort ist in gleichem Maße schutzbedürftig gegenüber unbefugtem Zugriff wie der Standort der Originaldaten, da sich darauf oft vollständige und aktuelle Kopien sensibler Informationen befinden. Zudem sind längere Wiederanlaufzeiten möglich, wenn der externe Standort nicht unmittelbar erreichbar ist oder wenn logistische Verzögerungen beim Zugriff auf die ausgelagerten Datenträger auftreten. Auch die Gefahr von Inkonsistenzen steigt, wenn Backups zwar ausgelagert, aber nicht regelmäßig synchronisiert oder bei der Überprüfung beachtet werden.</p></td></tr><tr valign="top"><td>NOT.4.11: Datenträgerarchiv</td><td><p>Notfallplanung SOLLTE ein Datenträgerarchiv installieren.</p></td><td><p>Datenträgerarchive sind verschlossene Räume, die dediziert zur langfristigen Aufbewahrung von Datenträgern bestimmt sind. Die Anforderung gilt auch dann als umgesetzt, wenn zusätzlich zur Datensicherung im Datenträgerarchiv auch noch Kopien existieren, die nicht im Datenträgerarchiv aufbewahrt werden.  Ein wesentlicher Mehrwert von Datenträgerarchiven ist die geschützte Aufbewahrung. Daher zählt ein Datenträgerarchiv nur dann als Mehrwert, wenn das Archiv sich auch in einem anderen Brandabschnitt befindet als die Originaldaten.</p></td></tr><tr valign="top"><td>NOT.4.12: Georedundanz</td><td><p>Notfallplanung KANN die georedundante Aufbewahrung mindestens einer Kopie der Datensicherung verankern.</p></td><td><p>Werden Datensicherungen in der Nähe von Originaldaten aufbewahrt, so könnten beide von Elementaren Gefährdungen wie Überflutungen betroffen sein. Georedundant bedeutet in der Regel 200km Luftlinie oder mehr von den Originaldaten entfernt. Details siehe BSI Kriterien für die Standortwahl von Rechenzentren. Die Anforderung kann auch durch die gegenseitige Aufbewahrung in georedundanten Rechenzentren erfüllt werden.</p></td></tr><tr valign="top"><td>NOT.4.13: Datensouveränität</td><td><p>Notfallplanung für Outsourcing SOLLTE die Datensicherung von Daten, die bei einem Dienstleister verarbeitet werden, nach <i>einem anerkannten Standard</i> <i>regelmäßig</i> ausführen.</p></td><td><p>Dies dient dazu bei einem Ausfall des Dienstleisters die Daten schnell bei einem anderen Dienstleister oder intern weiterverwenden zu können (Interoperabilität in der Exitstrategie). Anerkannt ist hier ein Format, welches auch bei einem anderen Dienstleister verwendet werden kann. Mögliche anerkannte Standards zum Datenaustausch sind z.B. XML, JSON, YAML, CSV, ODF. Eine Sicherungskopie ist unter eigener Hoheit, wenn sie auf Datenträgern im Besitz der Institution aufbewahrt wird, über die dieser Dienstleister keine Kontrolle hat. Relevant sind dabei auch Konfigurationsdateien, Programmcode und Dokumentationen, die zur Verwendung der Daten erforderlich sind.</p></td></tr><tr valign="top"><td>NOT.4.14: Offline-Kopie</td><td><p>Notfallplanung für Daten SOLLTE eine Offline-Kopie <i>regelmäßig</i> ausführen.</p></td><td><p>Eine Offline-Kopie ist eine Datensicherung, die physisch oder logisch von produktiven Systemen und dem laufenden Netzwerk getrennt ist („offline backup“ oder „air-gapped backup“). „Regelmäßig“ bedeutet, dass die Institution in Abhängigkeit von Verfügbarkeit und Kritikalität ihrer Daten feste Intervalle definiert, beispielsweise täglich, wöchentlich oder monatlich. Der Sinn und Zweck dieser Vorgabe liegt darin, sicherzustellen, dass im Falle von Schadsoftwarebefall oder gezielten Angriffen keine gleichzeitige Kompromittierung aller Sicherungskopien stattfinden kann; ein Angriff könnte sonst auch Backups verschlüsseln oder löschen. Eine Offline-Kopie kann dagegen die Wiederherstellung kritischer Systeme nach einem Ransomware-Angriff oder auch nach einem physischen Ausfall, etwa durch Stromschaden oder Brand, unterstützen. Eine Institution kann dies umsetzen, indem sie (1) Backups auf wechselbare Medien wie externe Festplatten, RDX-Kassetten oder Bänder erstellt, die nach dem Backup-Vorgang vom Netzwerk getrennt und sicher aufbewahrt werden, (2) Cloud-Backups so konfiguriert, dass sie durch Write-Once-Read-Many-(WORM)-Speicher geschützt und logisch von aktiven Systemen isoliert sind, oder (3) eine Rotation von Datenträgern einführt, bei der Kopien an einem separaten, physischen Standort verwahrt werden.</p></td></tr><tr valign="top"><td>NOT.4.15: Vorgehen zur Wiederherstellung</td><td><p>Notfallplanung SOLLTE die Vorgehensweise zur Wiederherstellung dokumentieren.</p></td><td><p>Die Dokumentation der Vorgehensweise zur Wiederherstellung dient dazu, im Notfall eine schnelle und geordnete Wiederinbetriebnahme von IT-Systemen und Daten zu ermöglichen. Ohne eine klare Beschreibung der Abläufe kann es zu Verzögerungen, Fehlern oder widersprüchlichen Handlungen kommen, was die Wiederherstellung erheblich erschwert. In einer solchen Dokumentation werden beispielsweise die Reihenfolge der Wiederherstellung kritischer Systeme, die benötigten Datensicherungen und Speicherorte, die erforderlichen Werkzeuge sowie die zuständigen Rollen und Kontaktwege beschrieben. Ergänzend kann auch festgehalten werden, wie die Funktionsfähigkeit nach der Wiederherstellung überprüft wird. Einfache Beispiele sind Schritt-für-Schritt-Anleitungen für die Rücksicherung bestimmter Anwendungen oder Checklisten, die während des Wiederherstellungsprozesses abgearbeitet werden.</p></td></tr><tr valign="top"><td>NOT.4.16: Test der Datensicherung</td><td><p>Notfallplanung für Daten SOLLTE den Erfolg der Datensicherung <i>regelmäßig</i> überprüfen.</p></td><td><p>Die Überprüfung der Vollständigkeit kann durch Statistiken des Datenumfangs plus Stichproben der Daten durchgeführt werden.  Ein Integritätstest prüft, ob die gesicherten Daten ohne Änderungen im Vergleich zum Original vorliegen. Hierzu können je nach Daten auch Berechtigungen und Metadaten gehören, wenn diese für die Rücksicherung erforderlich sind (z.B. Wiederherstellung eines Laufwerks mit Ordnern die verschiedene Zugriffsberechtigungen haben).</p></td></tr><tr valign="top"><td>NOT.4.16.1: Test der Wiederherstellung</td><td><p>Notfallplanung für Daten SOLLTE die Wiederherstellung mindestens anhand von repräsentativen Stichproben <i>regelmäßig</i> überprüfen.</p></td><td><p>Unter „Erfolg der Datensicherung“ ist hier die Vollständigkeit („completeness“) und Integrität („integrity“) der erstellten Backups zu verstehen. Eine fehlerhafte oder unvollständige Sicherung könnte unbemerkt bleiben, wenn nicht aktiv geprüft wird, während eine gezielte Validierung die Sicherheit bietet, dass sich die Daten bei Bedarf in unveränderter Form vorfinden lassen. Damit kann ein gravierender Datenverlust, etwa durch korrupte Sicherungsdateien oder abgebrochene Backup-Jobs, rechtzeitig erkannt und behoben werden. Die Anforderung zielt darauf ab, Risiken durch Scheinsicherheit zu reduzieren – etwa wenn Backup-Prozesse zwar automatisiert laufen, aber unbemerkt leere, fehlerhafte oder inkonsistente Datenbestände erzeugen könnten. Durch eine regelmäßige Überprüfung kann die Institution sicherstellen, dass die gesicherten Daten tatsächlich verwendbar bleiben, und damit das Risiko von Ausfallzeiten oder irreversiblen Informationsverlusten verringern. Konkret umgesetzt werden kann dies z. B., indem (1) Backup-Logs automatisch auf Fehlermeldungen oder Warnungen geprüft werden, (2) Prüfsummenverfahren wie Hashes (z. B. SHA-256) zur Integritätskontrolle eingesetzt werden und (3) stichprobenartige Vergleiche zwischen gesicherten und Originaldateien durchgeführt werden. Die Stichprobe kann sich dabei entweder auf die Wiederherstellung selber (= Wiederherstellung nur einiger Daten) als auch auf den deren Überprüfung (= Öffnen nur einiger Daten) beziehen. Stichproben sind repräsentativ, wenn die Zusammensetzung der Stichprobe von Test zu Test geändert wird und die Wahrscheinlichkeit der Stichprobenauswahl auch der Bedeutung der Daten entspricht. Zweckmäßig ist es dazu, bei der Stichprobenauswahl den Schutzbedarf der Daten zu berücksichtigen: Für besonders wichtige Systeme wie Verzeichnisdienste und für den Geschäftsbetrieb unerlässliche Daten ist eine häufigere Überprüfung erforderlich als für Daten und Systeme, auf die im Notfall auch verzichtet werden kann. Die Anforderung ist auch erfüllt, wenn statt einer Stichprobe eine vollständige Wiederherstellung vorgenommen und geprüft wird. Die Anforderung ist auch dann erfüllt, wenn die Überprüfung durch aktive Verwendung der Daten nach einer Wiederherstellung erfolgt (z.B. durch Inbetriebnahme neuer Server-Container, die aus einer versionierten Datensicherung automatisch angelegt werden).</p></td></tr><tr valign="top"><td>NOT.4.17: Anwendungstest</td><td><p>Notfallplanung für Anwendungen KANN deren Funktionsfähigkeit nach Wiederherstellung <i>regelmäßig</i> überprüfen.</p></td><td><p>Diese Anforderung zielt darauf ab, die Disaster-Recovery-Fähigkeiten einer Anwendung insgesamt zu gewährleisten. Durch regelmäßige Tests der Wiederherstellung aus Backups wird sichergestellt, dass im Ernstfall (Systemausfall, Datenverlust, Cyberangriff) eine funktionierende Wiederherstellung möglich ist. Dabei wird nicht nur die bloße Wiederherstellung getestet, sondern auch die Funktionalität der wiederhergestellten Anwendung verifiziert – inklusive Datenintegrität und korrekte Übernahme der Konfiguration.</p></td></tr></table><h1>ASST: Informationen und Assets</h1><p>Im Rahmen der IT-Komponenten stellt das Asset Management sicher, dass die IT-Komponenten erfasst und inventarisiert werden. Hierbei geht es darum eine Übersicht, über relevante <b>„Assets“</b>, wie Server, Clients, Netzwerkkomponenten sowie auch Datenträger sowie deren Verantwortlichkeiten, Besitzer oder auch Produktlebenszyklus zu haben. Des Weiteren soll im Rahmen des Asset Management auch die Ist-Dokumentation der Komponenten (z.B. Konfiguration, Patch-Level, Kritikalitätsstufen) erfasst werden.  Während die Praktik <b>„Konfiguration“</b> die Parameter einer IT-Komponenten betrachtet und IT-Betrieb die Vorgehensweisen zu Wartung und Pflege von IT-Komponenten, betrachtet Asset Management die Übersicht und Dokumentation aller IT-Komponenten.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>ASST.1: Grundlagen</td><td align="right">5</td></tr><tr valign="top"><td>ASST.2: Inventarisierung</td><td align="right">9</td></tr><tr valign="top"><td>ASST.3: Regelungen zum Gebrauch</td><td align="right">17</td></tr><tr valign="top"><td>ASST.4: Regelungen zum Transfer</td><td align="right">5</td></tr><tr valign="top"><td>ASST.5: Wartung</td><td align="right">7</td></tr><tr valign="top"><td>ASST.6: Rücknahme von Assets</td><td align="right">4</td></tr><tr valign="top"><td>ASST.7: Löschen und Vernichten</td><td align="right">11</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>58</b></td></tr></table><h2>ASST.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ASST.1.1: Verfahren und Regelungen</td><td><p>Informationen und Assets MUSS Verfahren und Regelungen zum Management von Informationen und damit verbundener Assets verankern.</p></td><td><p>Informationsmanagement ist der systematische Umgang mit Informationen während ihres gesamten Lebenszyklus, einschließlich von Regelungen, Prozessen und technischen Verfahren zur Erhebung, Verarbeitung, Speicherung, sowie Löschung und Vernichtung. Dazu gehören z.B. Schutzbedarf, Verarbeitung in den Geschäftsprozessen, Aufbewahrungs- und Löschfristen. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>ASST.1.1.1: Dokumentation</td><td><p>Informationen und Assets MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>ASST.1.1.2: Zuweisung der Aufgaben</td><td><p>Informationen und Assets MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>ASST.1.1.3: Bekanntgabe</td><td><p>Informationen und Assets MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>ASST.1.2: Regelmäßige Überprüfung</td><td><p>Informationen und Assets MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr></table><h2>ASST.2: Inventarisierung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ASST.2.1: Inventar der Informationen</td><td><p>Informationen und Assets SOLLTE ein Inventar der Informationen und damit verbundener Assets dokumentieren.</p></td><td><p>Um die Informationssicherheit zu schützen ist es erforderlich, die zu schützenden Werte systematisch zu erfassen und ihre Verwendung über den gesamten Lebenszyklus nachzuhalten. Sinnvoll ist es hierbei, den Detaillierungsgrad des Inventars angepasst an Schutzbedarf und Risikoprofil des Informationsverbundes zu wählen. Das Inventar kann eine Übersicht der für Geschäftsprozesse relevanten Kategorien von schützenswerten Informationen, z.B. für Kunden Vor- und Nachname, Adresse, IBAN, Telefonnummer, Kundenkennwort als Grundlage haben. Es muss sich allerdings nicht um eine einzige Liste von Informationen und Assets handeln. Um eine leichtere, automatische Pflege des Inventars zu ermöglichen ist es vielmehr sinnvoll, eine Reihe dynamischer Inventare oder Datenbestände möglichst nahe an der Quelle der Informationen zu verwenden, z.B. eine Verzeichnisdatenbank für Zugangskonten und Systeme, eine Anwendung zum Assetmanagement für physische Assets, sowie Dateisysteme oder Datenbanken für einzelne Dateien und Daten. Falls ein datenschutzrechtliches Verarbeitungsverzeichnis für die Erfassung von personenbezogenen Daten besteht, kann es ebenfalls in das Inventar einbezogen werden. Für physische Dokumente kann ein Aktenbestandsverzeichnis eingesetzt werden. Zur Erfassung von Netzen siehe Praktik Architektur. Zur Erfassung von Identitäten, Zugangskonten und Berechtigungen siehe Praktik Berechtigung. Für kurzlebige Informationen, z.B. virtuelle Maschinen, nur on-demand automatisch eingerichtet und wieder gelöscht werden oder händische Notizen, die nicht systematisch verarbeitet werden, ist keine Inventur erforderlich. Für Details zum IT-Assetmanagement siehe ISO/IEC 19770-1.</p></td></tr><tr valign="top"><td>ASST.2.1.1: Informationsverantwortung</td><td><p>Informationen und Assets für Daten SOLLTE die Zuständigkeit für deren Verarbeitung <i>einer zuständigen Person oder Rolle</i> zuweisen.</p></td><td><p>Hiermit ist das Eigentum oder die institutionsinterne Zuständigkeit für die Nutzung und den damit einhergehenden Schutz der jeweiligen Informationen und Assets (Asset Ownership) gemeint. Klare Zuweisungen stellen sicher, dass den Beteiligten nicht nur ihre prozessualen Aufgaben, sondern auch ihre Zuständigkeit für die konkreten Informationen bewusst und die damit verbundenen Pflichten bewusst sind. Dies kann durch dezentrales Nachhalten der Verantwortung nachgehalten werden. Alternativ kann auch eine Gruppierung der Informationen nach Assets wie Anwendungen oder Diensten umgesetzt werden, so dass die Zuständigen für das Asset dadurch auch die Zuständigkeit für die Informationen enthalten, die dort verarbeitet werden.</p></td></tr><tr valign="top"><td>ASST.2.2: Inventar der Systeme</td><td><p>Informationen und Assets SOLLTE ein Inventar der Systeme einschließlich Identifikationsbezeichnung und letztem bekannten Verbleib dokumentieren.</p></td><td><p>Hierbei sind neben physischen Endgeräten auch Hostsysteme, virtuelle Systeme, IoT-Geräte, Funkgeräte und Fahrzeuge relevant, wenn diese für die Verarbeitung von Daten aus dem Informationsverbund bestimmt sind. Als Identifikationsbezeichnung ist z.B. die Identifikationsnummer gemeint. Hierzu zählen z.B. eine Gerätenummer, MAC-Adresse oder DNS-Name, der das System eindeutig und nachvollziehbar identifiziert. Mit Verbleib ist hier z.B. der physische Standort, die Person, das Virtualisierungssystem oder die Netzadresse gemeint, wo das IT-System zu finden ist. Kann durch Integration in das Inventar der Informationen umgesetzt werden. Ein Asset Inventar kann im einfachsten Fall händisch gepflegt werden. Empfehlenswert ist jedoch, auch automatisierte Systeme zum Erfassen von Assetinventar (z.B. DHCP logging, Passive Asset Discovery Tools oder MDM) einzusetzen.</p></td></tr><tr valign="top"><td>ASST.2.2.1: Aufdecken unautorisierter IT-Systeme</td><td><p>Informationen und Assets für Netze SOLLTE das Aufdecken unautorisierter IT-Systeme verankern.</p></td><td><p>Ziel ist sicherzustellen, dass keine unautorisierten Assets im Informationsverbund betrieben werden. Hierzu können z.B. aktive Netzscans (z.B. mit Nmap), passive Analysen des Netzwerkverkehrs oder spezielle Werkzeuge zur Erkennung von unbekannten WLAN-Access-Points (z.B. Kismet) genutzt werden. Zur Behandlung können die gefundenen IT-Systeme beispielsweise aus dem Netz entfernt, in eine Quarantäne verschoben oder nach Überprüfung autorisiert werden.</p></td></tr><tr valign="top"><td>ASST.2.3: Inventar der Anwendungen</td><td><p>Informationen und Assets SOLLTE ein Inventar der Anwendungen einschließlich Produktname, Versionsstand, Herkunft und Lizenzierung dokumentieren.</p></td><td><p>Ein zentrales Inventar der Anwendungen, oft auch als Application Inventory oder Teil des Software Asset Management (SAM) bezeichnet, dient als grundlegende, strukturierte Übersicht aller in der Institution eingesetzten Applikationen. Relevant sind dabei sowohl lokal installierte Anwendungen, als auch solche, die auf Cloud-Servern oder in verteilten Diensten betrieben werden. Hierbei beschreibt die Herkunft nicht nur den Hersteller, sondern auch den Lieferanten oder die Bezugsquelle, um die Vertrauenswürdigkeit bewerten zu können. Die Lizensierung erfasst die rechtliche Grundlage für die Nutzung, einschließlich des Lizenzmodells (z.B. pro Benutzer, pro Gerät, Abonnement), der Anzahl erworbener Lizenzen und deren Gültigkeitsdauer. Häufig sind weitere Angaben sinnvoll, z.B. Beschaffungs- und Installationszeitpunkt, URL, App-Store, Schnittstellen wie z.B. Cloud-APIs oder Datenexporte in andere Anwendungen, auch auf Dateiserver. Ohne eine solche Übersicht könnte die Institution unwissentlich Software mit bekannten, kritischen Schwachstellen einsetzen oder durch den Einsatz nicht lizenzierter Produkte hohe finanzielle und rechtliche Risiken eingehen. Ein gepflegtes Inventar kann hingegen bei neuen Sicherheitswarnungen eine schnelle Auswirkungsanalyse ermöglichen. Zur praktischen Umsetzung kann die Institution eine zentrale Liste, beispielsweise in einer Datenbank oder einem spezialisierten SAM-Tool, aufbauen, die durch verschiedene Quellen gespeist wird. Eine automatisierte Erfassung kann durch technische Werkzeuge erfolgen, wie zum Beispiel durch (1) Netzwerks-Scanner, die installierte Applikationen auf Endgeräten identifizieren, (2) Agenten-basierte Systeme, die kontinuierlich Software-Änderungen melden, oder (3) die Auswertung von Daten aus zentralen Software-Verteilungssystemen. Die Dokumentation kann auch durch eine Liste mit Verweisen umgesetzt werden (z.B. auf die Lizendateien und Schnittstellenkonfiguration).</p></td></tr><tr valign="top"><td>ASST.2.3.1: Autorisierung von Anwendungen</td><td><p>Informationen und Assets für IT-Systeme SOLLTE die Nutzung von Anwendungen auf diesen durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Der Sinn dieser Regelung liegt in der Minimierung von Risiken, die durch unkontrollierte Nutzung entstehen. Durch nicht autorisierte Anwendungen könnte beispielsweise Schadsoftware in die Systeme der Institution eingeschleust, könnten durch Sicherheitslücken in veralteter Software Angriffsvektoren geöffnet oder könnten durch den Einsatz nicht konformer Tools sensible Informationen unkontrolliert abfließen. Ein strukturierter Autorisierungsprozess kann somit die Integrität der IT-Systeme wahren und sicherstellen, dass nur geprüfte, für den Geschäftszweck erforderliche und aus rechtlicher Sicht unbedenkliche Anwendungen zum Einsatz kommen, was die gesamte Angriffsfläche der Institution signifikant reduziert. Relevant sind dabei sowohl lokal installierte Anwendungen, als auch solche, die auf Cloud-Servern oder in verteilten Diensten betrieben werden. Je nach Geschäftsprozessen oder Risikoprofil kann die Autorisierung einzeln für jedes System und jede Anwendung, oder für bestimmte Kategorien von Systemen oder Anwendungen vorgenommen werden (z.B. "Alle Office-Produkte eines bestimmten Herstellers auf Notebooks mit einem bestimmten Betriebssystem). Hierbei ist es sinnvoll, Standard-Anwendungen zu bestimmen, die für alle Nutzenden freigegeben sind und die Verwendung darüber hinausgehender Anwendungen pro Nutzer oder Organisationseinheit zu autorisieren.</p></td></tr><tr valign="top"><td>ASST.2.3.2: Software Bill of Materials (SBOM)</td><td><p>Informationen und Assets für Anwendungen SOLLTE die Software Bill of Materials (SBOM) dokumentieren.</p></td><td><p>Eine Software Bill of Materials (SBOM) ist in diesem Zusammenhang eine strukturierte Liste aller Komponenten, Bibliotheken und Abhängigkeiten, die in einer Anwendung enthalten sind, einschließlich ihrer Versionen und Herkunft. Sie kann dabei sowohl Open-Source- als auch proprietäre Bestandteile erfassen und in maschinenlesbaren Formaten (z. B. SPDX, CycloneDX) vorliegen. Der Zweck dieser Dokumentation liegt darin, Transparenz über die eingesetzten Softwarebestandteile zu schaffen, sodass Abhängigkeiten, potenzielle Schwachstellen oder veraltete Komponenten nachvollziehbar bleiben. Ohne diese Transparenz könnte es bei Sicherheitsvorfällen, Lizenzkonflikten oder fehlender Wartbarkeit zu erheblichen Problemen kommen, während eine gepflegte SBOM die schnelle Identifikation von Risiken, die Minimierung von Vendor Lock-in und die Nachvollziehbarkeit der Software-Lieferkette unterstützen kann. Hierzu kann die BSI TR-03183-2 verwendet werden.</p></td></tr><tr valign="top"><td>ASST.2.3.2.1: Software Discovery</td><td><p>Informationen und Assets KANN die Aktualität des Inventars der Anwendungen durch ein automatisiertes Verfahren <i>regelmäßig</i> überprüfen.</p></td><td><p>Die automatische Aktualisierung des Anwendungsinventars bei Installationen, Konfigurationsänderungen und Deinstallationen dient in erster Linie der vollständigen Transparenz über die IT-Landschaft. Ein aktuelles Anwendungsinventar kann als Grundlage für Compliance-Nachweise, Lizenzmanagement und Schwachstellenanalysen dienen. Die Automatisierung dieses Prozesses verringert dabei den manuellen Verwaltungsaufwand und erhöht die Datenqualität, da menschliche Fehler oder Versäumnisse bei der Dokumentation vermieden werden können. Konkrete Anwendungsfälle können die automatische Erfassung einer neu installierten ERP-Software im Inventar, die Dokumentation einer Konfigurationsänderung an einer Firewall-Anwendung oder die Entfernung einer nicht mehr genutzten Datenbanksoftware aus dem Inventar sein. Auch Updates von Anwendungen, Änderungen an Zugriffsberechtigungen oder Konfigurationsanpassungen aufgrund neuer Sicherheitsanforderungen können als relevante Ereignisse für eine Inventaraktualisierung betrachtet werden. Für die Umsetzung können Software Asset Management (SAM) Tools eingesetzt werden, die über Agenten oder regelmäßige Netzwerk-Scans Änderungen erkennen. Eine Alternative kann die Integration von Deployment- und Konfigurationsmanagement-Systemen mit der CMDB (Configuration Management Database) sein, wodurch jede Änderung automatisch im zentralen Inventar gespiegelt wird. Die Implementierung von Event-Triggern in der IT-Infrastruktur kann ebenfalls dazu beitragen, dass bei definierten Ereignissen eine sofortige Inventaraktualisierung ausgelöst wird. Eine regelmäßige Validierung der Prozesse durch Stichprobenkontrollen kann dabei helfen, die Vollständigkeit und Genauigkeit der automatisierten Inventarisierung zu gewährleisten.</p></td></tr><tr valign="top"><td>ASST.2.4: Klassifizierung</td><td><p>Informationen und Assets für Daten SOLLTE diese einer Schutzbedarfsklasse zuweisen.</p></td><td><p>Klassifizierung dient dazu, Daten entsprechend ihrer Schutzbedürftigkeit systematisch zu ordnen, um angemessene Schutzmaßnahmen zielgerichtet umzusetzen und Risiken effektiv zu reduzieren. Unter Klassifizierung versteht man dabei die Einteilung von Daten in Kategorien, etwa <b>„öffentlich“</b>, <b>„intern“</b>, <b>„vertraulich“</b> oder <b>„streng geheim“</b>, wobei zum Beispiel eine öffentlich zugängliche Marketingbroschüre weniger sensibel ist als personenbezogene Kundendaten, Betriebs- und Geschäftsgeheimnisse oder staatliche Verschlussachen. Anzahl der Klassen und Umfang der Beschreibungen können sich an den ermittelten Risiken und der Menge der verarbeiteten Informationen orientieren. Die Kriterien zur Klassifizierung können sich daran orientieren, mit welchen Schäden eine Kompromittierung der Vertraulichkeit, Integrität oder Verfügbarkeit verbunden wäre, z.B. geschätzte Umsatzverluste, Gefahr für die Allgemeinheit, Schädigung der Rechte und Freiheiten betroffener Personen. Für Assets ist es sinnvoll, diese im Einklang mit der Klassifikation der Informationen ebenfalls in Klassen zu unterteilen, für deren Verarbeitung sie gebraucht werden.</p></td></tr></table><h2>ASST.3: Regelungen zum Gebrauch</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ASST.3.1: Nutzungsvereinbarungen</td><td><p>Informationen und Assets für Nutzende SOLLTE diese zu den Regelungen der Nutzung von Informationen und anderen Assets anweisen.</p></td><td><p>Wenn Nutzende nicht angewiesen werden bestimmte Nutzungsregelungen einzuhalten, dann könnte es zu ungewollten Verstößen gegen die Sicherheitsverfahren kommen. Auch Maßregelungen bei Verstößen werden erschwert, wenn unklar ist, ob Verstöße für die Nutzenden vorher als solche erkennbar waren. Dies gilt insbesondere für externe Personen, die nur durch die Nutzung von Assets mit den Regelungen in Berührung kommen könnten, z.B. Kunden oder Drittunternehmen. Die konkreten Regelungen ergeben sich aus den Maßnahmen zur Umsetzung der anderen Anforderungen dieser Praktik und den Anforderungen zur Sensibilisierung.</p></td></tr><tr valign="top"><td>ASST.3.1.1: Weitergabe von Informationen</td><td><p>Informationen und Assets für Nutzende SOLLTE zur Weitergabe von Informationen nur bei Erforderlichkeit anweisen.</p></td><td><p>Das Need-to-Know-Prinzip ist ein Sicherheitskonzept, das den Zugriff auf Informationen auf das absolut notwendige Maß beschränkt. Es besagt, dass Personen nur dann Zugang zu bestimmten Daten enthalten, wenn diese Informationen für die Erfüllung ihrer konkreten Aufgaben erforderlich sind. Ziel ist es, das Risiko von Datenmissbrauch, -verlust oder unbefugtem Zugriff zu minimieren.</p></td></tr><tr valign="top"><td>ASST.3.1.1.1: Entfernung nicht erforderlicher Rest- oder Zusatzdaten</td><td><p>Informationen und Assets für Daten SOLLTE die Entfernung nicht erforderlicher Rest- oder Zusatzdaten verankern.</p></td><td><p>Hierunter können z.B. Metainformationen wie Bearbeitername oder Geostandort fallen. Handelt es sich um strukturierte Daten, so ist eine automatisierte Entfernung leicht möglich. Für unstrukturierte Daten hat sich eine Kombination aus automatischer Filterung / Regex und manueller Überprüfung bewährt.</p></td></tr><tr valign="top"><td>ASST.3.2: Kennzeichnung</td><td><p>Informationen und Assets SOLLTE die Kennzeichnung von Informationen verankern.</p></td><td><p>Kennzeichnungen helfen dabei sicherzustellen, dass vertrauliche, personenbezogene oder besonders kritische Daten im gesamten Lebenszyklus angemessen behandelt werden – von der Erstellung über die Verarbeitung bis hin zur Archivierung oder Löschung. Hierzu gehört sowohl die Kennzeichnung physikalischer Systeme oder Speichermedien als auch die virtuelle Kennzeichnung, z.B. durch Metadaten oder die Kopfzeile eines Dokumentes. Eine klare Kennzeichnung kann dazu beitragen, unbeabsichtigte Offenlegung, unsachgemäße Weitergabe oder unsichere Verarbeitung zu vermeiden, die Sensibilisierung für den Umgang mit verschiedenen Informationsarten fördern und rechtlichen oder regulatorischen Anforderungen (z. B. DSGVO, Geheimschutz) Rechnung tragen. Beispiele sind Informationen, die einer bestimmten Schutzbedarfsklasse (z. B. „vertraulich“, „intern“) zugeordnet sind. Auch personenbezogene Daten, Forschungsergebnisse, Finanzinformationen, Sicherheitskonzepte oder technische Spezifikationen können einer Kennzeichnungspflicht unterliegen. Die Art der Kennzeichnung kann visuell erfolgen, etwa durch Wasserzeichen, farbige Markierungen, Aufkleber, sowie Kopf-/Fußzeilen oder Metadaten in Dateien. Wichtig ist, dass die Kennzeichnung verständlich, konsistent und leicht erkennbar ist, um ihre Schutzwirkung zu entfalten. Zur Umsetzung ist es nicht erforderlich, dass alle Daten, Systeme oder Speichermedien gekennzeichnet sind sondern nur solche, deren Risikoprofil eine solche Kennzeichnung erforderlich macht - hier ist insbesondere die Vertraulichkeit oder Verfügbarkeit relevant. Dokumentvorlagen, automatisierte Klassifizierungsfunktionen in gängigen Office-Programmen oder Richtlinien in einem DMS können helfen die Einhaltung zu gewährleisten.</p></td></tr><tr valign="top"><td>ASST.3.3: Kennzeichnung ohne vertrauliche Daten</td><td><p>Informationen und Assets für IT-Systeme SOLLTE Kennzeichnung ohne vertrauliche Daten verankern.</p></td><td><p>Enthalten Kennzeichnungen vertrauliche Daten wie den Namen des zugeordneten Mitarbeiters, des Standortes, der Netzstruktur oder der Abteilung, so könnten diese Angaben von Angreifern ausgelesen werden, z.B. über das Netz, per Bluetooth oder durch physisches Ablesen. Die so abgeflossenen Daten könnten Angreifer zur weiteren Ausforschung der Institution oder des Zugangs zu Daten missbrauchen.</p></td></tr><tr valign="top"><td>ASST.3.4: Tainting</td><td><p>Informationen und Assets für Daten KANN eine Markierung durch eingebettete Daten oder Funktionen zur Wiedererkennung zuweisen.</p></td><td><p>Zielt darauf ab, die Nachverfolgbarkeit und Kontextbindung von Daten zu ermöglichen, insbesondere in komplexen IT-Systemen, in denen Daten über viele Verarbeitungsschritte hinweg genutzt, kombiniert oder verteilt werden. Durch die Einbettung spezifischer, erkenntlicher Merkmale (z.B. Metadaten, Marker oder Funktionsventhalten) kann ein Datensatz identifizierbar gemacht werden, ohne dass seine Funktion oder Nutzbarkeit wesentlich eingeschränkt wird. Dies kann bei der Erkennung unerlaubter Datenweitergaben, der Nachverfolgung von Datenflüssen oder bei Sicherheitsanalysen hilfreich sein, insbesondere wenn potenziell sensible oder schützenswerte Daten im Spiel sind. Für welche Daten Tainting gezielt eingesetzt wird kann sich nach deren Klassifizierung oder einer spezifischen Risikoanalyse richten. Beispiele für Tainting-Mechanismen können sein: das Einfügen eines unsichtbaren Wasserzeichens in ein Dokument, das Anhängen kryptografisch prüfbarer Metadaten an Datensätze, Dummy-Datensätze oder das Verwenden von Datencontainern, die sich beim Zugriff oder bei der Weitergabe protokollierend venthalten. Auch das Markieren von Datenbankeinträgen mit zusätzlichen Attributen, die Rückschlüsse auf Herkunft, Vertrauensstufe oder Kontext erlauben, kann eine Form des Taintings darstellen. Ebenso kann bei Programmcode eine Markierung durch sogenannte Taint-Tracking-Systeme erfolgen, die überwachen, welche Eingaben in sicherheitskritische Operationen einfließen. Für die Umsetzung kann der Einsatz strukturierter Datenformate (wie XML oder JSON mit Markierungsfeldern), der Aufbau kontrollierter Datenflüsse mit Protokollierung oder das Nutzen von Middleware-Komponenten mit Tainting-Funktionalität in Betracht gezogen werden. Wichtig ist dabei, dass die Tainting-Informationen robust, interpretierbar und möglichst schwer entfernbar gestaltet werden, um ihre Wirksamkeit zu sichern. Die Wahl geeigneter Methoden hängt stark vom Anwendungskontext, den Schutzbedarfen und den bestehenden Systemarchitekturen ab.</p></td></tr><tr valign="top"><td>ASST.3.5: Verifikation</td><td><p>Informationen und Assets für Informationen KANN die Korrektheit anhand anderer Informationsquellen testen.</p></td><td><p>Wenn die Korrektheit bestimmter Informationen von hohen Bedeutung ist, hilft eine Verifikation aus zweiter Quelle dabei, fundierte und belastbare Entscheidungen in sicherheitsrelevanten Situationen treffen zu können. Durch Verifikation wird das Risiko verringert, dass Fehlinformationen in Geschäftsprozessen oder dem Sicherheitsmanagement weiterverarbeitet werden und sich Fehler so fortsetzen oder Vorfälle übersehen werden. Sie kann insbesondere dazu beitragen, Fehlalarme zu erkennen, Täuschungsversuche (z.B. durch gefälschte Logdaten) zu identifizieren oder die Wirksamkeit von Gegenmaßnahmen zu bewerten. Die Anforderung stärkt somit die Integrität und Qualität der sicherheitsbezogenen Lagebewertung.  Beispiele für Ereignisse können sicherheitsrelevante Systemmeldungen, Alarme aus Intrusion Detection Systemen (IDS), Hinweise auf Datenabflüsse oder ungewöhnliches Nutzerventhalten sein. Informationsquellen können externe Dienstleister, Zeugen, Sicherungskopien oder Sensoren in der physischen Sicherheit sein. Die Verifikation kann sich in solchen Fällen z.B. auf die Gegenprüfung eines IDS-Alarms durch Logdaten anderer Systeme oder durch Replizierbarkeit des Ereignisses in einer Testumgebung beziehen. In der Praxis kann eine Verifikation unter anderem durch Korrelation mehrerer unabhängiger Datenquellen erfolgen. Auch das Einführen von Plausibilitätsprüfungen, standardisierten Analyseverfahren oder temporären Reproduktionsversuchen kann hilfreich sein. Eine strukturierte Dokumentation der Informationsquellen und ihrer typischen Aussagekraft kann ebenfalls zur Umsetzung beitragen.</p></td></tr><tr valign="top"><td>ASST.3.6: Pseudonymisierung</td><td><p>Informationen und Assets für Informationen KANN die Pseudonymisierung vor der Weitergabe verankern.</p></td><td><p>Bei der Pseudonymisierung werden Informationen so verändert, dass sie für den Empfänger nicht mehr dem ursprünglichen Informationswert oder Datensatz zugeordnet werden können, ohne zusätzliche Informationen hinzuzuziehen. Die Weitergabe meint hier jegliche Form des Teilens von Informationen über die Grenzen des Informationsverbundes hinaus – etwa an externe Dienstleister, Behörden oder Partnerinstitutionen – unabhängig davon, ob dies elektronisch, schriftlich oder mündlich geschieht. Anwendungsbeispiele sind personenbezogene Daten oder institutionsinterne IP-Adressbereiche, die zu Diagnosezwecken herausgegeben oder zum Zugriff auf Cloud-Dienste von der Institution verwendet werden. Problematisch ist hierbei oft die funktionsenthaltende Pseudonymisierung, d.h. die Pseudonymisierung derart, dass es bei der beabsichtigten Verwendung zu keinen Problemen durch die Pseudonymisierung kommt. Typische Umsetzungsmaßnahmen können beinhalten: (1) den Einsatz technischer Pseudonymisierungsverfahren wie Hashing oder Tokenisierung, (2) die getrennte, zugriffsbeschränkte Speicherung von Zuordnungstabellen („mapping tables“) in gesicherten Datenräumen oder Datenbanken, und (3) den Einsatz kontrollierter Schlüsselverwaltung, die nur autorisierten Personen eine Re-Identifizierung erlaubt. Auch kann eine Pseudonymisierung in Prozessen oder Schnittstellen fest verankert werden, etwa durch automatisierte Filtermechanismen bei Exporten oder vor externen Übertragungen.</p></td></tr><tr valign="top"><td>ASST.3.7: Anonymisierung</td><td><p>Informationen und Assets für Informationen KANN die Anonymisierung vor der Weitergabe verankern.</p></td><td><p>Bei der Anonymisierung werden Informationen so verändert, dass sie für den Empfänger nicht mehr dem ursprünglichen Informationswert oder Datensatz zugeordnet werden können. Dabei werden gezielt rückverfolgbare Merkmale entfernt oder verfremdet, sodass eine Zuordnung zu einem bestimmten Informationswert der Institution (z.B. einer Person, Systemkonfiguration oder Zugangskonto) nicht mehr möglich ist. Davon abzugrenzen ist die Pseudonymisierung („pseudonymization“), bei der eine Identifizierbarkeit theoretisch weiterhin besteht, etwa durch separate Zuordnungstabellen oder Schlüssel. Die Weitergabe meint hier jegliche Form des Teilens von Informationen über die Grenzen des Informationsverbundes hinaus – etwa an externe Dienstleister, Behörden oder Partnerinstitutionen – unabhängig davon, ob dies elektronisch, schriftlich oder mündlich geschieht. Beispiele sind die Bildung summarischer Statistiken aus personenbezogenen Daten oder die Ersetzung eines Gerätenamens durch eine zufällige Zeichenkette vor der Herausgabe zu Diagnosezwecken.</p></td></tr><tr valign="top"><td>ASST.3.8: Aktualisierung</td><td><p>Informationen und Assets für Daten KANN deren Aktualisierung verankern.</p></td><td><p>Wenn gespeicherte Daten nicht regelmäßig mit Veränderungen abgeglichen werden, nimmt das Risiko von Fehlern in den Daten zu. Ein Abgleich mit Quellen kann durch automatische Vergleichsprozesse (z.B. anhand von Checksummen) vorgenommen werden oder durch eine Versionsverwaltung erleichtert werden.</p></td></tr><tr valign="top"><td>ASST.3.9: Autorisierung von Datenlokationen</td><td><p>Informationen und Assets für Daten SOLLTE Datenlokationen durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Autorisierte Datenlokationen sind virtuelle oder physische Orte, an denen die Speicherung oder anderweitige Verarbeitung der jeweiligen Datenkategorie durch die Institution erlaubt wird. Physische Orten sind z.B. Serverstandorte in der EU, aber auch die organisatorische Regelung zu Standorten wie dem Mobile Arbeitsplatz oder Auslandsreisen außerhalb der EU gemeint. Regelungen könnten hier z.B. sein: <b>„Verarbeitung als vertraulich markierter Daten nur innerhalb von Institutsgebäuden“</b>, <b>„Personenbezogene Daten nur innerhalb der EU“</b>. Je nach Datenart bestehen auch häufig Compliance-Verpflichtungen (z.B. DSGVO, Staatenliste im Sinne von § 13 Abs. 1 Nr. 17 SÜG), durch die erlaubte Datenlokationen beschränkt sind. Virtuelle Datenlokationen (z.B. VoIP-Netz, dom0, Hauptgebäude) sind Verarbeitungssphären.</p></td></tr><tr valign="top"><td>ASST.3.10: Autorisierung von Systemen</td><td><p>Informationen und Assets für Daten SOLLTE für die Informationsverarbeitung verwendete Systeme durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Autorisierte Systeme können einzeln oder als Kategorien von IT-Systemen und Peripherie benannt werden, auf denen bestimmte Daten verarbeitet werden dürfen. Hierzu gehört auch, welche Peripheriegeräte angeschlossen werden dürfen, z.B. z.B. keine Speicherung sensibler Erreichbarkeiten auf einem einfachen Mobiltelefon oder Verarbeitung hochvertraulicher Daten nur auf stationären Endgeräten. Relevant ist dabei auch, ob Bring Your Own Device (BYOD) untersagt oder unter bestimmten Voraussetzungen gestattet ist. Kann entweder einmalig für alle Daten, oder getrennt nach Datenkategorien (z.B. keine personenbezogenen Daten auf Ausleihgeräten) umgesetzt werden.</p></td></tr><tr valign="top"><td>ASST.3.10.1: Autorisierung von Peripheriegeräten</td><td><p>Informationen und Assets für Daten SOLLTE auch Peripheriegeräte autorisieren.</p></td><td><p>Peripheriegeräte sind externe Hardware-Komponenten sowie virtuelle Geräte, die an IT-Systeme angeschlossen oder eingebunden werden, wie USB-Sticks, externe Festplatten, Drucker, Kameras, Smartphones, Tablets, aber auch virtuelle Laufwerke, Software-definierte Netzwerkadapter oder emulierte Hardware-Komponenten. Die Autorisierung von Peripheriegeräten kann Organisationen vor verschiedenen Sicherheitsrisiken schützen, da unkontrollierte Geräte Malware einschleusen, Daten exfiltrieren oder als Einfallstor für Cyberangriffe dienen können. Ein USB-Stick eines Mitarbeiters könnte beispielsweise Schadsoftware enthalten, die sich beim Anschluss automatisch auf das Netzwerk ausbreitet, oder ein nicht autorisierter Drucker könnte vertrauliche Dokumente in ungeschützten Bereichen ausgeben. Die Umsetzung kann durch eine zentrale Geräteregistrierung erfolgen, bei der alle erlaubten Peripheriegeräte erfasst und mit eindeutigen Kennungen versehen werden. Je nach Risikoprofil ist damit die Autorisierung einzelner Geräte oder auch die Freigabe einer Klasse von Peripherie - etwa alle beschafften Tastaturen und Mäuse - sinnvoll. Administrative Prozesse können (1) die Einführung von Antragsverfahren für neue Peripheriegeräte mit Sicherheitsbewertung, (2) die regelmäßige Überprüfung und Aktualisierung der Gerätelisten sowie (3) die Definition von Gerätekategorien mit unterschiedlichen Autorisierungsebenen - etwa vollständig gesperrte USB-Ports für externe Benutzer, eingeschränkte Freigaben für Standard-Arbeitsplätze und erweiterte Berechtigungen für IT-Administratoren - beinhalten. Technisch unterstützt werden kann die Implementierung durch Device Control-Lösungen, die nur autorisierte Geräte basierend auf Hardware-IDs, Herstellerzertifikaten oder digitalen Signaturen erkennen und freischalten. Zusätzlich kann die Implementierung von Logging-Mechanismen zur Nachverfolgung aller Peripheriegeräte-Aktivitäten die Transparenz und Auditierbarkeit der Autorisierungsprozesse erhöhen. Die Autorisierung erfolgt hierbei durch die Personen oder Rollen, welche für die Autorisierung der Systeme zuständig sind.</p></td></tr><tr valign="top"><td>ASST.3.11: Autorisierung von Personen oder Institutionen</td><td><p>Informationen und Assets für Daten SOLLTE den Zugriff von Personen oder Institutionen im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement autorisieren.</p></td><td><p>Ziel dieser Regelung ist es, sicherzustellen, dass nur berechtigte Stellen auf sensible Werte zugreifen, wodurch unautorisierte Einsichtnahme, Manipulation oder Missbrauch verhindert werden kann. Ohne eine klare Kopplung an Identitäts- und Berechtigungsmanagement könnte es zu unkontrollierten Datenabflüssen, Einsicht durch Dritte oder langfristigen Abhängigkeiten von bestimmten Dienstleistern kommen, die den Zugriff einseitig steuern könnten. Eine korrekte Umsetzung kann hingegen Transparenz schaffen und den Zugriff auf Informationen nachvollziehbar, reversibel und sicher gestalten. Umfasst sowohl die Autorisierung eigenen Personals, als auch die Autorisierung externer Dienstleister oder Partner. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Autorisierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt.</p></td></tr><tr valign="top"><td>ASST.3.12: Lagerung physischer Assets</td><td><p>Informationen und Assets für Administrierende SOLLTE zur Lagerung physischer Assets in einem dazu vorgesehenen Lager anweisen.</p></td><td><p>Lagerung meint hier die Aufbewahrung nicht an Nutzende ausgegebener physischer Assets. Die Lagerung kann in verschlossenen Lagerräumen, Schränken oder bei Dienstleistern erfolgen.</p></td></tr><tr valign="top"><td>ASST.3.13: Reserve physischer Assets</td><td><p>Informationen und Assets SOLLTE eine Reserve physischer Assets verankern.</p></td><td><p>Die Beschaffung und Installation von Systemen und deren Peripherie nimmt gewöhnlich eine längere Zeit in Anspruch, weshalb es sinnvoll ist, Ersatzgeräte für Ausfälle bereitzuhalten. Die Menge der Ersatzgeräte reicht aus, wenn sie den voraussichtlichen Bedarf deckt, der bis zur Lieferung und Installation der nächsten Beschaffung vergeht. Der voraussichtliche Bedarf kann aus dem bisherigen Bedarf unter Anpassung an Veränderungen (z.B. Wachstum der Nutzerzahlen) berechnet werden. Typische Assets wären hier z.B. IT-Clients (Desktop PCs/Laptops), Smartphones oder andere häufig genutzte Endgeräte.</p></td></tr><tr valign="top"><td>ASST.3.14: Ausleihe physischer Assets</td><td><p>Informationen und Assets KANN einen ausreichenden Ausleihbestand verankern.</p></td><td><p>Wenn bei bestimmten Ereignissen wie Auslandsreisen, Veranstaltungen oder Sicherheitsvorfällen die regulären Endgeräte nicht verwendet werden können (z.B. aufgrund der Regelungen zu Datenlokationen oder der Vorfallsbehandlung), dann ist es sinnvoll Endgeräte bereitzuhalten, die nur mit den für die Ereignisse notwendigen Anwendungen und Daten ausgestattet sind. Die Menge der Ausleihgeräte ist ausreichend, wenn sie den Bedarf deckt. Der Bedarf kann anhand einer Prognose ermittelt werden, die sich wiederum auf bekannte Statistiken (z.B. Anzahl der Nutzenden, Anzahl der Teilnehmer von Schulungsveranstaltungen, Anzahl Auslandsreisen pro Jahr) stützen kann.</p></td></tr></table><h2>ASST.4: Regelungen zum Transfer</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ASST.4.1: Autorisierung von Schnittstellen</td><td><p>Informationen und Assets für Daten KANN Schnittstellen, über die Informationen ausgetauscht werden, durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Schnittstellen können hier sowohl physikalisch (z.B. Briefversand, regelmäßige Meetings an einem geschützten Ort) als auch virtuell (API, verschlüsselter Cloudspeicher) sein.</p></td></tr><tr valign="top"><td>ASST.4.2: Vertraulichkeit und Integrität beim Transport</td><td><p>Informationen und Assets für Daten SOLLTE Vertraulichkeit und Integrität beim Transport verankern.</p></td><td><p>Transport meint hier sowohl die Datenübertragung per Netz als auch auf physischen Datenträgern (Sneakernet) oder den physischen Transport ganzer Systeme. Zur Umsetzung kann z.B. in Netzen die Transportverschlüsselung und -signierung von E-Mails, Ende-zu-Ende-Verschlüsselung mit PGP genutzt werden. Beim physischen Transport können die vorherige Verschlüsselung von Speichermedien, die Verwahrung von Assets an der Person, Verwahrungsprotokolle, manipulationssichere Verpackungen, Geolocation Tracking oder vertrauenswürdige Kuriere genutzt werden. Die Auswahl der Maßnahmen richtet sich nach dem Schutzbedarf der ausgetauschten Informationen und der Transportart.</p></td></tr><tr valign="top"><td>ASST.4.3: Autorisierung von Veröffentlichungen</td><td><p>Informationen und Assets SOLLTE Veröffentlichungen durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>„Veröffentlichungen“ bezieht sich hier auf jede Form der öffentlichen oder externen Verbreitung von Informationen, sei es durch Pressemitteilungen, Social-Media-Beiträge, wissenschaftliche Publikationen, öffentliche Datensätze oder zur Erfüllung gesetzlicher Informationspflichten. Hierbei besteht das Risiko, dass vertrauliche Informationen unbeabsichtigt veröffentlicht werden. Kriterien zur Veröffentlichung können z.B. das Entfernen von Geschäftsgeheimnissen oder die Freigabe durch bestimmte Stellen innerhalb oder außerhalb der Institution sein. Der Hauptzweck dieser Anforderung ist die Schaffung einer Gatekeeping-Funktion, um den Informationsfluss zu steuern, der die Institution verlässt, und so das Risiko unbefugter oder schädlicher Offenlegungen zu mindern. Ohne diese Kontrolle könnte eine Institution versehentlich sensible Geschäftsdaten, geistiges Eigentum oder vertrauliche Kundeninformationen offenlegen, was zu schwerwiegendem Reputationsschaden, finanziellem Verlust oder rechtlichen Strafen führen könnte. So könnte ein nicht genehmigter Social-Media-Beitrag Details über ein noch nicht veröffentlichtes Produkt preisgeben, ein Forscher könnte versehentlich einen Datensatz mit vertraulichen Informationen veröffentlichen, oder ein Finanzbericht könnte vorzeitig veröffentlicht werden und Marktvolatilität verursachen. Ein sinnvoller Ansatz könnte die Einrichtung eines gestuften Genehmigungsprozesses sein, der auf der Sensibilität der Informationen basiert und sich am Konzept der Vertraulichkeitsanforderungen orientiert. Eine öffentliche Ankündigung von geringer Sensibilität erfordert möglicherweise nur die Genehmigung durch einen Abteilungsleiter, während ein Finanzbericht mit hohem Risiko die Unterschrift mehrerer Führungskräfte, einschließlich des Leiters der Rechtsabteilung und des CISO, erfordert. Um dies zu erleichtern, können Institutionen technische Maßnahmen ergreifen, wie z. B. ein digitales Workflow-System, in dem der Veröffentlichungsstatus eines Dokuments nachverfolgt und verwaltet wird. Dieses System könnte Funktionen umfassen wie: (1) automatisches Routing von Dokumenten an die entsprechenden Genehmiger, (2) eine sichere Überwachung aller Genehmigungen und Ablehnungen, und (3) ein zentrales Repository für alle genehmigten und veröffentlichten Materialien. Aus prozessualer Sicht ist es von Vorteil, eine Veröffentlichungs-Checkliste zu erstellen, die sicherstellt, dass alle relevanten rechtlichen und Compliance-Prüfungen vor der Veröffentlichung durchgeführt werden.</p></td></tr><tr valign="top"><td>ASST.4.4: Nachweis des Zugangs</td><td><p>Informationen und Assets für Daten KANN einen Nachweis des Zugangs protokollieren.</p></td><td><p>Ein Zugangsnachweis stellt sicher, dass bestimmte Nachrichten ihren Empfänger tatsächlich erreicht haben und dieser Zugang im Streitfall nachvollziehbar belegt werden kann. Dies ist insbesondere in rechtlich relevanten Kontexten oder bei Revisionen von Bedeutung – etwa wenn Fristen, Genehmigungen oder vertrauliche Informationen übermittelt werden. Kriterien können sich an der Nachvollziehbarkeit der Integrität der Informationen oder ihrer Rechtswirkung orientieren, z.B. wenn sie einen Vertragsabschluss oder die Bekanntgabe eines Verwaltungsaktes, auslösen. Beispiele hierfür sind arbeitsrechtlich relevante Dokumente wie Abmahnungen oder Kündigungen, Sicherheitsanweisungen, Änderungen an internen Richtlinien, Zugangsdaten zu sicherheitsrelevanten Systemen oder auch technische Anordnungen mit verbindlichem Charakter. Die Kriterien können zusammen mit anderen Kriterien dokumentiert sein, beispielsweise im Rahmen eines Informationssicherheitskonzepts oder Kommunikationsleitfadens. Die Umsetzung dieser Anforderung kann durch verschiedene technische und organisatorische Maßnahmen erfolgen. Dazu gehören u. a. die Nutzung von E-Mail-Systemen mit Empfangsbestätigung, das Verwenden von Systemprotokollen oder speziellen Portalen mit Zugriffsnachweis. Wichtig ist dabei, dass der Nachweis manipulationssicher gespeichert und nachvollziehbar archiviert wird – bis zum Ablauf einer definierten Aufbewahrungsfrist, z. B. drei oder fünf Jahre, je nach rechtlicher oder organisatorischer Vorgabe. Sinnvoll ist es hierbei nicht nur die Tatsache des Zugangs zu einem bestimmten Zeitpunkt sondern auch für den Nachweis relevante Inhalte zu dokumentieren, z.B. Titel, sowie Versand- und Zieladressen der Nachricht. Sie kann je nach Medium auch den Inhalt der Nachricht enthalten.</p></td></tr><tr valign="top"><td>ASST.4.5: Vereinbarungen zum Austausch</td><td><p>Informationen und Assets für Daten SOLLTE Regelungen zum Transfer verankern.</p></td><td><p>Beispielsweise kann es für Geschäfts- und Betriebsgeheimnisse wie Patente sinnvoll sein, eine explizite Vertraulichkeitsvereinbarung abzuschließen, bevor genaue Informationen weitergegeben werden. Hierzu kann z.B. gehören nach welchen Kriterien ausgetausche Informationen zu klassifizieren sind oder wie in eine bestimme Klasse eingestufte Daten zu schützen oder verarbeiten sind. Die Vereinbarung über anzuwendende Sicherheitsanforderungen kann anhand von vorformulierten Vertragstexten erfolgen oder über den Austausch von Sicherheitsanforderungen in strukturierten Datenformaten wie OSCAL. Letzteres hat den Vorteil, dass weiterführende Daten etwa zum Umsetzungsstand ebenfalls leichter gepflegt und ausgetauscht werden können.</p></td></tr></table><h2>ASST.5: Wartung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ASST.5.1: Wartungsbedarf dokumentieren</td><td><p>Informationen und Assets für IT-Systeme SOLLTE den Wartungsbedarf für Systemkomponenten und die zum Betrieb erforderliche Infrastruktur dokumentieren.</p></td><td><p>Wartungsbedarf meint die regelmäßig oder anlassbezogen erforderlichen Maßnahmen zur Instandhaltung, Aktualisierung und Funktionssicherung von Systemkomponenten und der Betriebsinfrastruktur eines IT-Systems. Unter Systemkomponenten sind hier sowohl Hardware-Elemente (Server, Netzwerkkomponenten, Speichergeräte) als auch Software-Elemente (Betriebssysteme, Middleware, Anwendungen) zu verstehen; die Infrastruktur umfasst unterstützende Einrichtungen wie Stromversorgung, Klimatisierung, Kommunikationsschnittstellen oder Brandabschottungen für Kabel- und Rohrdurchführungen. Ziel der Dokumentation ist es, einen strukturierten Überblick über alle Abhängigkeiten, Wartungszyklen und Zuständigkeiten zu schaffen, um sicherzustellen, dass Betrieb und Sicherheit des Systems über den gesamten Lebenszyklus hinweg gewährleistet bleiben. Die Dokumentation des Wartungsbedarfs kann verhindern, dass kritische Komponenten ungeplant ausfallen oder Sicherheitslücken durch versäumte Updates bestehen bleiben. Ohne klare Wartungsinformationen könnte beispielsweise ein Firmware-Update bei einer Netzkomponente übersehen werden, was Angreifern das Eindringen über bekannte Schwachstellen erleichtern könnte. Umgekehrt kann eine dokumentierte Wartungsplanung dazu beitragen, Systemverfügbarkeit und Integrität zu sichern, indem sie planbare Wartungsfenster und Zuständigkeiten ermöglicht. Durch das Zusammenführen der Herstellerangaben mit den vor Ort bekannten Rahmenbedingungen kann frühzeitig erkennbar werden, wann Eingriffe nötig sind, welche Abhängigkeiten bestehen und welche Fachkenntnisse oder Werkzeuge erforderlich sein können. Zum Ressourcenbedarf kann ebenso gehören, dass ein Testsystem bereitgestellt wird, dass administrative Zugänge vorbereitet werden oder dass ein Wartungsdienstleister während der Arbeiten abgesichert fernzugreifen kann. Für die praktische Umsetzung kann es hilfreich sein, einen zentralen Wartungskalender mit Ampel‑Logik zu führen, der sich aus dem Konfigurations‑ oder Asset‑Management speist. Eine Ticket‑ oder Change‑Management‑Lösung kann automatisch Termine auslösen, Erinnerungen versenden und Reports erzeugen.</p></td></tr><tr valign="top"><td>ASST.5.2: Geregelte Wartungen</td><td><p>Informationen und Assets für IT-Systeme SOLLTE die Wartung <i>regelmäßig oder prädiktiv</i> ausführen.</p></td><td><p>„Wartung“ bezeichnet hier sämtliche planmäßigen oder zustandsabhängigen Maßnahmen zur Erhaltung der Funktionsfähigkeit, Sicherheit und Integrität von IT-Systemen, Anwendungen und den zugehörigen physischen wie logischen Assets („maintenance“). Verschleißende Systeme und Infrastrukturen könnten zu Fehlerzuständen und hierdurch zu Ausfallzeiten und Sicherheitsrisiken führen. Das betrifft auch die für das IT-System verwendete Stromversorgung, USV, Klimatechnik, sowie Brandabschottungen für Kabel- und Rohrdurchführungen. Beispiele hierfür können vielfältig sein: Ein Server kann turnusmäßig mit Firmware‑Updates versorgt oder nach einer bestimmten Betriebsdauer auf Staubablagerungen überprüft werden; Netzwerkkomponenten können per Lifecycle‑Plan aktualisiert oder lüfterseitig gereinigt werden; USV‑Batterien können nach Herstellerempfehlung getauscht werden; Software‑Module können per Patch‑Management in ein Wartungsfenster eingeplant werden. Eine „regelmäßige Wartung“ bedeutet hierbei ein turnusmäßiges Vorgehen nach festen Zeitintervallen (Vorausbestimmte Instandhaltungsstrategie), während prädiktive Wartung den tatsächlichen Abnutzungs- oder Belastungszustand auswertet, um Eingriffe bedarfsgerecht zu planen (Prädiktive Instandhaltungsstrategie). Beide Ansätze verfolgen das Ziel, Sicherheits- und Betriebsrisiken zu minimieren, die aus dem Ausfall oder der Fehlfunktion technischer Komponenten resultieren könnten.</p></td></tr><tr valign="top"><td>ASST.5.3: Autorisierung von Wartungen</td><td><p>Informationen und Assets für IT-Systeme KANN Wartungen durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Wartung ist die planbare oder anlassbezogene Änderung an Komponenten (z. B. Patches, Konfigurationsänderungen, Hardwaretausch, Firmware-Updates). Dies betrifft auch den Transfers des Systems oder von Komponenten für Reparatur oder Austausch an einem anderen Ort. Unklare oder fehlende Freigaben für Wartungen könnten zu unkoordinierten Änderungen, ungeplanten Ausfällen, Datenverlust oder der Einschleusung von Schadcode durch interne wie externe Dienstleister führen; außerdem könnten unpassende Zeitfenster oder inkompatible Firmwarestände Vertraulichkeit, Integrität und Verfügbarkeit beeinträchtigen. Zur Umsetzung kann die Institution ein schlankes Freigabeverfahren gestalten, z.B. (1) ein standardisiertes Wartungs-Ticket mit Pflichtangaben (Asset-ID, Maßnahme, Risiko-Einschätzung, Zeitfenster, Back-out-Plan, Ansprechpartner), das über CMDB-Bezüge (Konfigurationsdatenbank) automatisch an Asset-/Service-Owner geroutet und dort freigegeben werden kann; (2) technische Gates, sodass produktive Änderungen erst im Status „autorisiert“ durch CI/CD-Pipelines (Build-/Deployment-Kette), Change-Flags oder Just-in-Time-Privilegien mit zeitlich begrenzten Admin-Konten ausgeführt werden können; (3) ein Katalog vordefinierter, niedrig-riskanter Standardwartungen (z. B. Signatur-Updates, agentenlose Log-Rotation), die vorab genehmigt und ohne Einzelfallprüfung ausgelöst werden können.</p></td></tr><tr valign="top"><td>ASST.5.4: Behandlung als Änderungen und Tests</td><td><p>Informationen und Assets für IT-Systeme SOLLTE zur Wartung erforderliche Änderungen im Einklang mit den Verfahren und Regelungen zum Management von Änderungen verankern.</p></td><td><p>Werden bei Wartungsarbeiten Änderungen vorgenommen, so sind die Verfahren und Regelungen zum Management von Änderungen auch hier anzuwenden. Ein nicht abgestimmter oder ungetesteter Eingriff könnte etwa zu Systemausfällen, Datenverlust oder dem Einbringen von Schwachstellen führen, während ein geordnetes Änderungsmanagement solche Risiken deutlich reduzieren kann. Sinnvoll ist oft ein kurzer Wartungsleitfaden, in dem typische Abläufe (z. B. Vorab‑Backup, Rollback‑Option, Dokumentation des Ergebnisses) hinterlegt werden. Auf diese Weise kann jede Wartung reproduzierbar, überprüfbar und ressourcenschonend gestaltet werden, ohne sich auf konkrete Herstellerprodukte festzulegen.</p></td></tr><tr valign="top"><td>ASST.5.5: Wartungsfenster</td><td><p>Informationen und Assets für IT-Systeme SOLLTE bei voraussichtlichen Verfügbarkeiteinschränkungen durch bevorstehende Wartungen die Nutzenden über Dauer und Umfang der Einschränkungen informieren.</p></td><td><p>Wenn durch Wartungsarbeiten die Verfügbarkeit von Systemen, Anwendungen oder Daten in Geschäftsprozessen beeinträchtigt werden könnte, ist eine Information über die bevorstehende Wartung sinnvoll. Dazu gehört, dass über die Dauer (Beginn und Ende), sowie über den Umfang der Einschränkungen (z.B. betroffene Anwendungen, Netze oder Funktionen) informiert wird. Beispiele sind Firmware- oder Betriebssystemupdates von zentralen Speichersystemen oder Netzkomponenten, der Austausch von Komponenten an zentralen Stromverteilern oder eine Wartung an den Klimasystemen eines nicht redundant ausgelegten Serverraumes.</p></td></tr><tr valign="top"><td>ASST.5.6: Wartung durch Externe</td><td><p>Informationen und Assets für Mitarbeitende KANN bei Wartungen, die von Externen ohne Sicherheitsüberprüfung vorgenommen werden, zur Beaufsichtigung durch internes Personal anweisen.</p></td><td><p>Eine Sicherheitsüberprüfung bezeichnet hier die systematische Bewertung der Vertrauenswürdigkeit und Zuverlässigkeit von externen Dienstleistern oder deren Personal durch background checks, Referenzprüfungen oder formelle Sicherheitsclearance-Verfahren. Externe ohne Sicherheitsüberprüfung umfasst alle Dienstleister, Wartungstechniker oder Support-Personal von Drittanbietern, die nicht durch entsprechende Verfahren zur Vertrauenswürdigkeit validiert wurden. Beaufsichtigung durch internes Personal ist die kontinuierliche Anwesenheit und Überwachung von qualifizierten eigenen Mitarbeitenden während der gesamten Dauer der Wartungsarbeiten, um sowohl fachliche Aufsicht als auch Sicherheitskontrolle zu gewährleisten. Dazu gehört, dass die begleitenden Mitarbeitenden sicherstellen, dass Externe ausschließlich auf die für ihre Wartungsaufgabe notwendigen Systembereiche zugreifen und keine unauthorisierten Aktionen wie das Kopieren von Dateien oder die Installation nicht genehmigter Software durchführen. Externe Wartungskräfte ohne Sicherheitsüberprüfung könnten sonst vertrauliche Informationen einsehen, kopieren oder manipulieren, Malware einschleusen oder unbeabsichtigt Systemkonfigurationen beschädigen. Durch begleitendes internes Personal kann eine Institution kontinuierliche Aufsicht über alle durchgeführten Aktivitäten sicherstellen und gleichzeitig den Wissenstransfer für zukünftige Wartungsarbeiten fördern. Bei einer Fernwartung kann dies z.B. durch das Logging von Diagnose- und Wartungsaktivitäten, sowie die anschließende Überprüfung, dass alle Wartungsverbindungen getrennt sind, geschehen.</p></td></tr><tr valign="top"><td>ASST.5.7: Dokumentation von Wartungen</td><td><p>Informationen und Assets für IT-Systeme SOLLTE Wartungen mit Asset, Anlass, Zeitpunkt, Beteiligten, durchgefürten Maßnahmen und Ergebnissen dokumentieren.</p></td><td><p>Die Dokumentation von Wartungen an IT-Systemen kann Nachvollziehbarkeit, Verantwortlichkeit und Beweisfähigkeit herstellen; ohne sie könnten unerkannte Konfigurationsänderungen, verdeckte Schwachstellen oder verlängerte Ausfälle entstehen. Zur Umsetzung kann die Institution ein schlankes, einheitliches Wartungsprotokoll verwenden, das je Vorgang erfasst: (1) eindeutig referenziertes Asset/CI, Umgebung und betroffener Service, (2) Anlass, Art der Wartung (präventiv/korrektiv/notfall) und geplanter Zeitraum, (3) Verantwortliche, Beteiligte/Dienstleister und Kontakt, (4) geplante Maßnahmen, Backout-Plan sowie definierte Vor-/Nach-Checks, (5) tatsächlich durchgeführte Schritte („as-built“), verwendete Versionen/Images und geänderte Parameter, (6) Messergebnisse/Logs/Screenshots/Hashes als Nachweis, (7) Auswirkungen (Downtime, Kapazität), Abnahme/Testresultat und Freigabe, (8) Verweise auf Tickets/Changes/Störungsmeldungen, (9) Datum/Zeit mit Zeitzone und Protokollversion. Die Erfassung kann in einem vorhandenen Ticket- oder CMDB-Werkzeug stattfinden.</p></td></tr></table><h2>ASST.6: Rücknahme von Assets</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ASST.6.1: Abhandenkommen</td><td><p>Informationen und Assets SOLLTE eine Vorgehensweise beim Abhandenkommen von Assets verankern.</p></td><td><p>Eine Vorgehensweise beim Abhandenkommen von Assets ist ein strukturierter, dokumentierten Reaktionsprozess, der alle notwendigen Schritte und Verantwortlichkeiten für den Umgang mit verloren gegangenen, gestohlenen oder anderweitig außer Kontrolle geratenen Informationswerten nach Eintritt des Verlustereignisses festlegt. Ohne strukturierte Prozesse könnte ein verlorenes Laptop mit Kundendaten zu anhaltenden Datenschutzverletzungen führen, ein gestohlenes Smartphone könnte dauerhaft unbefugten Zugang zu Unternehmensressourcen ermöglichen, oder vergessene Dokumente könnten unkontrolliert Geschäftsgeheimnisse preisgeben. Eine etablierte Vorgehensweise kann durch schnelle Reaktionszeiten und koordinierte Sofortmaßnahmen das bereits eingetretene Schadenspotential begrenzen und die Wiederherstellung der Informationssicherheit beschleunigen. Die Vorgehensweise zur Behandlung kann z.B. die Ortung, Sperrung oder Löschung per Fernzugriff, das Melden bei Ermittlungsbehörden oder lokalen Fundbüros, die Änderung aller betroffenen Zugangsdaten, sowie die Sperre von Authentisierungsmitteln und der enthaltenen SIM-Karte beim Provider beinhalten.</p></td></tr><tr valign="top"><td>ASST.6.2: Rückkehr abhandengekommener Assets</td><td><p>Informationen und Assets SOLLTE eine Vorgehensweise bei Rückkehr von abhandengekommenen Assets verankern.</p></td><td><p><b>„Abhandengekommene Assets“</b> bezeichnen Informationswerte, die ungewollt oder ungeplant außerhalb der direkten Kontrolle der Institution geraten sind - beispielsweise durch Verlust, Diebstahl, vergessene Mitnahme oder andere unbeabsichtigte Ereignisse. Eine <b>„Vorgehensweise bei Rückkehr“</b> meint einen strukturierten Prozess zur systematischen Wiederaufnahme und sicherheitstechnischen Bewertung solcher Assets nach ihrer Wiederbeschaffung oder ihrem Wiederauffinden. Diese Anforderung zielt auf die Risikominimierung bei der Wiederintegration potenziell kompromittierter Assets ab, da während der unkontrollierten Abwesenheit Manipulationen, unautorisierten Zugriffe oder Datenabflüsse aufgetreten sein könnten. Ohne strukturierte Rückkehrprozesse kann die unkontrollierte Wiederverwendung zurückgekehrter Assets zu Sicherheitslücken, Malware-Infektionen oder Datenschutzverletzungen führen. Umsetzungen können bei der Asset-Rückkehr (1) eine vollständige Identitätsprüfung anhand eindeutiger Kennzeichnungen wie Seriennummern oder Asset-Tags, (2) eine technische Integritätsprüfung durch Malware-Scans, Firmware-Vergleiche und Hardwareanalysen sowie (3) eine Datenintegrität-Bewertung mittels kryptografischer Prüfsummen oder forensischer Analysen umfassen. Als Alternative zur tiefergehenden Analyse von Systemen und Daten bietet sich auch die Löschung oder Entsorgung an. Prozessual kann die Einrichtung einer zentralen Asset-Return-Stelle mit definierten Eskalationswegen bei Auffälligkeiten, die Dokumentation aller Rückkehrfälle in einem Asset-Management-System und die Implementierung von Quarantäne-Verfahren für verdächtige Assets erfolgen.</p></td></tr><tr valign="top"><td>ASST.6.3: Konformitätsprüfung</td><td><p>Informationen und Assets für IT-Systeme KANN eine Konformitätsprüfung bei Rücknahme ausführen.</p></td><td><p>Assets sind nicht konform, wenn Sie die für sie geltenden Anforderungen nicht oder nicht mehr erfüllen, z.B. weil die Hardware manipuliert wurde oder keine Sicherheitsupdates mehr bereitgestellt werden. Die Prüfung kann durch automatische Prüfsysteme oder mit manuellen Verfahren, z.B. Sichtkontrolle von Siegeln, gewährleistet werden. Auch die Nutzung von Stichprobenkontrollen ist möglich. Zur Behandlung kann entweder die Ursache der Nichtkonformität beseitigt werden, oder alternative Lösungen können angewendet werden, z.B. kann das Gerät auf Werkszustand zurückgesetzt und neu installiert werden. Ist dies nicht möglich so bleibt keine andere Behandlungsmöglichkeit als das Assets nicht weiter zu verwenden.</p></td></tr><tr valign="top"><td>ASST.6.4: Zurücksetzen auf Ausgangszustand</td><td><p>Informationen und Assets für IT-Systeme SOLLTE bei Rücknahme das Zurücksetzen auf Ausgangszustand ausführen.</p></td><td><p>Dies kann in vielen Fällen am einfachsten durch vollständige Löschung oder Vernichtung der Speichermedien oder das Zurücksetzen auf Werkseinstellungen erfolgen. Zur Umsetzung einer Vernichtung siehe DIN 66399. Alternativ kann auch ein vordefiniertes Systemimage installiert werden, wodurch das System für die erneute Ausgabe vorbereitet wird, wenn das Systemimage alle vorher auf dem System vorhandenen Daten überschreibt oder diese vollständig verschlüsselt waren.</p></td></tr></table><h2>ASST.7: Löschen und Vernichten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>ASST.7.1: Nicht mehr benötigte Anwendungen</td><td><p>Informationen und Assets für Anwendungen SOLLTE eine Deinstallation nicht mehr benötigter Anwendungen ausführen.</p></td><td><p>Nicht mehr benötigte Anwendungen können Sicherheitslücken oder noch gültige Zugangsdaten enthalten und stellen ein unnötiges Sicherheitsrisiko dar. Kann durch Systeme automatisiert werden, die bei der Zuordnung von Anwendungen zu Personen eine automatische Installation oder Deinstallation erledigt. Wenn Anwendungen nicht länger benötigt werden, dann sind auch die für die Anwendung erforderlichen Berechtigungen nicht länger erforderlich. Hierzu gehören sowohl lokale als auch Cloud-Zugänge. Kann auch durch die Löschung der Zugangsdaten umgesetzt werden.</p></td></tr><tr valign="top"><td>ASST.7.2: Aufbewahrungs- und Löschfristen</td><td><p>Informationen und Assets für Daten SOLLTE die Aufbewahrung für <i>eine bestimmte Frist</i> verankern.</p></td><td><p>Klar festgelegte und in Prozessen verankerte Löschfristen helfen Sicherheits- und Compliancerisiken zu minimieren, indem Informationen entsorgt werden, wenn sie nicht mehr benötigt werden. Dies gilt sowohl für Originaldaten als auch für Kopien und archivierte Aufzeichnungen, einschließlich Protokolldateien. Hier besteht ein enger Bezug zu Compliance-Verpflichtungen, sowohl zur Aufbewahrung (z.B. für Nachweispflichten aus dem Steuerrecht) als auch zur Löschung (z.B. aus dem Datenschutzrecht). Die Auswahl der Methode zum Löschen hängt von der Vertraulichkeit der Daten, verwendeten Anwendungen oder Speichermedien und ggf. bestehenden Compliance-Verpflichtungen ab. Eine Herausforderung stellt dabei der Umgang mit Datenkopien in Datensicherungen dar. Da das nachträgliche Herausfiltern bestimmter Daten aus Datensicherungen häufig sehr aufwändig ist, ist es empfehlenswert die Versionierung der Datensicherungen so zu gestalten, dass die Daten zum Ablauf der Löschfrist ohnehin mit neueren Datensicherungen überschrieben wurden oder ältere Kopien der Datensicherung insgesamt gelöscht sind. Für kurzlebige Daten bietet es sich an diese nicht in eine einzige zentrale Datensicherung aufzunehmen, sondern je nach Schutzbedarf an Integrität und Verfügbarkeit dieser Daten gar keine oder eine Datensicherung für kurzlebige Daten, z.B. Diagnosedaten mit Personenbezug, vorzuhalten.</p></td></tr><tr valign="top"><td>ASST.7.2.1: Langfristige Archivierung</td><td><p>Informationen und Assets für Daten KANN die langfristige Archivierung mindestens für <i>eine bestimmte Frist</i> verankern.</p></td><td><p>Archivierung meint hier die langfristige Aufbewahrung derjenigen Daten, die über längere Zeit benötigt werden, z.B. über mehr als 10 Jahre. Hierbei kann es sich beispielsweise um Nachweise der Einhaltung rechtlicher Verpflichtungen, Daten zur Nachvollziehbarkeit von Angriffen (Audit Log), oder zur Geltendmachung von Ansprüchen handeln. Dabei kann es sich sowohl um analoge Dokumente als auch um digitale Daten handeln. Die meisten Institutionen verarbeiten Daten, die aufgrund von Compliance-Verpflichtungen langfristig gespeichert werden, z.B. handels- und steuerrechtlich relevante Dokumente oder Eigentumsurkunden.</p></td></tr><tr valign="top"><td>ASST.7.3: Geregeltes Löschen oder Vernichten</td><td><p>Informationen und Assets für Daten SOLLTE diese bei Erreichen der Aufbewahrungs- und Löschfrist löschen.</p></td><td><p>Ereignisse können z.B. der Ablauf der festgelegten Löschfrist, die Veräußerung von Assets oder deren Weitergabe an einen Dienstleister sein. Relevant sind hierbei neben physischen und virtuellen Medien auch die Datenträger in IT-Systemen wie Notebooks und Fahrzeugen. Sicheres Löschen bedeutet, Daten so zu entfernen, dass sie mit vertretbarem Aufwand (auch forensisch) nicht mehr rekonstruierbar sind. Je nach Medium geschieht das z. B. durch verifizierbares Überschreiben, kryptografisches Löschen (Schlüsselvernichtung) oder physische Zerstörung (inklusive zugehöriger Metadaten, Caches und Datensicherungen. Die Anforderung ist auch erfüllt, wenn sie durch einen Dienstleister durchgeführt wird, der hierzu verpflichtet ist.</p></td></tr><tr valign="top"><td>ASST.7.3.1: Standardisierte Vernichtung</td><td><p>Informationen und Assets für Daten SOLLTE ein standardisiertes Verfahren zur Vernichtung bei Veräußerung nach <i>einem anerkannten Standard</i> verankern.</p></td><td><p>Anerkannte Standards für die Vernichtung sind DIN 66399 oder ISO/IEC 21964. Die Sicherheitsstufe beschreibt die Intensität der Vernichtung - kleinteilige Vernichtung verringert die Wahrscheinlichkeit, dass Datenfragmente aus den Einzelteilen wiederhergestellt werden könnten. Die konkrete Vorgehensweise richtet sich dabei auch nach der Art des Speichermediums, z.B.  - die Vernichtung von Papier nach Sicherheitsstufe P-3 entsprechend der ISO/IEC 21964-2, - die Vernichtung optischer Speichermedien nach Sicherheitsstufe O-3 entsprechend der ISO/IEC 21964-2, - die Vernichtung sonstiger Speichermedien nach Sicherheitsstufe E-3 bzw. H-3 entsprechend der ISO/IEC 21964- 2. Für Speichermedien, die vor Nutzung vollständig verschlüsselt waren und deren Schlüssel gelöscht wurde, ist die Vernichtung nicht erforderlich.</p></td></tr><tr valign="top"><td>ASST.7.3.2: Löschverfahren</td><td><p>Informationen und Assets für Daten SOLLTE Löschverfahren verankern.</p></td><td><p>Unter „Löschverfahren“ ist hier ein nachvollziehbarer, dokumentierter technischer und prozessualer Ablauf zur endgültigen Entfernung oder Unkenntlichmachung von Informationen zu verstehen; „Endgültig“ bedeutet, dass Daten mit vertretbarem Aufwand nicht wiederhergestellt werden können. Ohne klare Verfahren könnte Alt- oder Schattendatenbestand bei Geräteweitergabe, in Backups oder Cloud-Objektspeichern verbleiben, was zu Datenschutzverletzungen, Erpressungsversuchen oder regulatorischen Sanktionen führen könnte. Hierzu gehören sowohl Nutzdaten von Systemen und Anwendungen, als auch Konfigurationsdateien oder Daten, die in begleitenden Dokumenten wie Betriebshandbüchern oder Informationswikis abgelegt sind.</p></td></tr><tr valign="top"><td>ASST.7.3.3: Zugelassene Löschanwendungen</td><td><p>Informationen und Assets für Daten KANN die Daten durch eine zugelassene Löschanwendung löschen.</p></td><td><p>Für eine aktuelle Liste der zugelassenen Löschanwendungen siehe BSI-Schrift 7164: Liste der zugelassenen IT-Sicherheitsprodukte und -systeme. Sicheres Löschen bedeutet, Daten so zu entfernen, dass sie mit vertretbarem Aufwand (auch forensisch) nicht mehr rekonstruierbar sind. Je nach Medium geschieht das z. B. durch verifizierbares Überschreiben, kryptografisches Löschen (Schlüsselvernichtung) oder physische Zerstörung (inklusive zugehöriger Metadaten, Caches und Datensicherungen.</p></td></tr><tr valign="top"><td>ASST.7.4: Wiederherstelltest</td><td><p>Informationen und Assets für Daten KANN einen Wiederherstelltest ausführen.</p></td><td><p>Der Test kann mit Software oder Hardware, die vermeintlich gelöschte Daten von Speichermedien wiederherstellen kann, durchgeführt werden. Bei vernichteten Speichermedien ist der Test entbehrlich.</p></td></tr><tr valign="top"><td>ASST.7.5: Vernichtungseinrichtungen</td><td><p>Informationen und Assets für Standorte KANN Vernichtungseinrichtungen installieren.</p></td><td><p>Die Installation von Vernichtungseinrichtungen dient dem Schutz sensibler Daten vor unbefugtem Zugriff, Missbrauch oder unkontrollierter Weitergabe. Ziel ist es, die Vertraulichkeit, Integrität und Verfügbarkeit von Informationen auch über ihren gesamten Lebenszyklus hinweg sicherzustellen – einschließlich der ordnungsgemäßen Entsorgung. Unter Vernichtungseinrichtungen versteht man mechanische oder elektronische Geräte, die Dokumente so zerkleinern oder unlesbar machen, dass eine Rekonstruktion unmöglich ist; typische Beispiele sind Aktenvernichter mit Schutzklasse P-4 oder höher oder Entsorgungsbehälter mit gesichertem Zugriff (z.B. abschließbare Sicherheitsbehälter). Dies kann auch so realisiert werden, dass Datenträger gesammelt und zentral gelöscht oder vernichtet werden. Kann durch die Institution selbst oder Dienstleister für die Aktenvernichtung umgesetzt werden. Bei der Verwendung von Dienstleistern ist es sinnvoll, deren Professionalität zu verifzieren, z.B. durch ein Zertifikat. Bei der Umsetzung ist es sinnvoll darauf zu achten, dass solche Einrichtungen nicht nur ausreichend dimensioniert und technisch geeignet sind, sondern auch physisch gegen unbefugten Zugriff geschützt werden – etwa durch Aufstellung in abgeschlossenen Räumen oder durch Zugangskontrolle.</p></td></tr><tr valign="top"><td>ASST.7.6: Autorisierung von Veräußerungen</td><td><p>Informationen und Assets SOLLTE Veräußerungen von Assets durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Veräußerung bezeichnet in diesem Kontext jede endgültige Abgabe oder Eigentumsübertragung (Verkauf, Spende, Rückgabe an Leasing, Recycling) eines Assets. Die Autorisierung kann verhindern, dass schutzbedürftige Informationen unkontrolliert den Besitz wechseln, Compliance-Vorgaben übersehen werden und Verantwortlichkeiten verwischen. Ohne geregelte Freigabe könnte ein ausgemusterter Laptop mit Restdaten verkauft, ein Speicherarray mit verbleibenden Schlüsseln weitergegeben oder eine nicht übertragbare Softwarelizenz abgegeben werden, was zu Datenabfluss, Vertragsverletzungen und Reputationsschäden führen könnte. Zur Umsetzung kann die Institution einen schlanken, nachvollziehbaren Freigabe-Workflow etablieren: Ein Veräußerungsantrag kann Asset-ID/Inventarnummer, Asset-Owner, Schutzbedarf/Klassifizierung, Datenträgerart, vorgesehenes Verwertungsverfahren, gewählte Datenlösch-/Vernichtungsmethode, Lizenz-/Vertragsrestriktionen, Übergabedatum und Empfänger erfassen; die Freigabe kann vor Übergabe erfolgen und revisionssicher protokolliert werden. Eine Entscheidungsmatrix kann die Genehmigungstiefe nach Schutzbedarf steuern, z. B. (1) „öffentlich“: fachliche Freigabe, (2) „intern“: Asset Owner + IT-Freigabe, (3) „vertraulich/streng“: Vier-Augen-Prinzip aus zuständige Person oder Rolle und Informationssicherheitsbeauftragte/r.</p></td></tr><tr valign="top"><td>ASST.7.7: Beschriftungen entfernen</td><td><p>Informationen und Assets SOLLTE alle der Institution zuzuordnenden Beschriftungen vor der Veräußerung von Assets löschen.</p></td><td><p>Die „Beschriftung“ eines Assets ist jede physische oder digitale Kennzeichnung, die eine eindeutige Zuordnung des Gegenstands oder Datenträgers zu Werten der Institution ermöglicht. Darunter fallen unter anderem Eigentumskennzeichnungen (engl. asset tags), Seriennummern, Barcodes, Gravuren, Aufkleber mit Logo, aber auch digitale Metadaten wie Gerätebezeichnungen, E-Mail-Konten, Hostnamen oder eingebettete Wasserzeichen. Das Löschen dieser Beschriftungen vor der Veräußerung stellt sicher, dass Dritte nicht unmittelbar auf den ursprünglichen Eigentümer schließen oder unautorisierte Rückschlüsse auf interne Strukturen, Sicherheitsarchitekturen oder Verantwortlichkeiten ziehen. Ohne diese Bereinigung könnte ein weiterveräußertes Gerät durch verbleibende Markierungen auf die Institution hinweisen und so gezielt für Social-Engineering-Angriffe oder Reputationsschäden genutzt werden. Eine solche Zuordnung könnte zudem dazu führen, dass vertrauliche Informationen über Inventar, Sicherheitsstandards oder IT-Bestände unbeabsichtigt offengelegt werden. Zudem könnte eine verbleibende Beschriftung zu Missverständnissen über Eigentumsverhältnisse oder Haftung führen, falls das Asset in einen Vorfall verwickelt wird. Konkret können unter den zu entfernenden Beschriftungen beispielsweise Eigentumsaufkleber mit der Inventarnummer, Etiketten mit Standort- oder Abteilungsbezeichnungen, Markierungen für interne Verwendungszwecke (z.B. <b>„Testgerät“</b>, <b>„intern“</b>), aber auch digital eingebettete Informationen wie institutionelle Metadaten in Office-Dokumenten oder gespeicherte WLAN-Profile auf mobilen Geräten verstanden werden. Auch optische Hinweise wie eingravierte Logos auf Gehäusen oder institutionelle Startbildschirme bei Laptops können darunterfallen. Zur Umsetzung kann es hilfreich sein, vor der Veräußerung eine Sichtprüfung durchzuführen und standardisierte Checklisten zu nutzen, um typische Beschriftungen systematisch zu identifizieren. Je nach Beschaffenheit des Assets kann der Einsatz von Reinigungsmitteln, Etikettenentfernern oder speziellen Werkzeugen in Betracht gezogen werden. Auch softwaregestützte Verfahren, etwa das Zurücksetzen auf Werkseinstellungen und das Prüfen auf verbleibende Metadaten, sind relevant. Nicht zuletzt kann die Einbindung von ISB oder des Datenschutzbeauftragten in Zweifelsfällen Klarheit darüber schaffen, ob eine bestimmte Kennzeichnung potenziell sicherheitsrelevant ist.</p></td></tr></table><h1>TEST: Änderungen und Tests</h1><p>Die Praktik <b>„Änderungen und Tests“</b> stellt sicher, dass alle geplanten Veränderungen an Informationssystemen systematisch und kontrolliert ablaufen, um ungewollte Störungen, Sicherheitsrisiken oder Compliance-Verstöße zu vermeiden (Change Management). Sie umfasst die Vorbereitung, Planung und Durchführung von Tests, die Freigabe und den Rollout von Änderunge, sowie die begleitende Dokumentation.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>TEST.1: Grundlagen</td><td align="right">6</td></tr><tr valign="top"><td>TEST.2: Vorbereitung</td><td align="right">5</td></tr><tr valign="top"><td>TEST.3: Tests</td><td align="right">12</td></tr><tr valign="top"><td>TEST.4: Freigabe</td><td align="right">7</td></tr><tr valign="top"><td>TEST.5: Bereitstellung</td><td align="right">5</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>35</b></td></tr></table><h2>TEST.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>TEST.1.1: Verfahren und Regelungen</td><td><p>Änderungen und Tests MUSS Verfahren und Regelungen zum Management von Neueinführungen, Änderungen oder der Entfernung von Komponenten <i>für den Informationsverbund, pro Geschäftsprozess oder pro IT-System</i> verankern.</p></td><td><p>Verfahren und Regelungen beschreiben die formalisierten Abläufe, nach denen Änderungen an informationstechnischen Komponenten – also Hardware, Software oder Konfigurationen – geplant, bewertet, genehmigt und umgesetzt werden; im Englischen ist hier oft von Change Management Procedures die Rede. Weil moderne Infrastrukturen komplexe Abhängigkeiten haben, könnten Änderungen an Systemen und Anwendungen sonst zu unbeabsichtigten Ausfällen oder Sicherheitslücken führen. Dies betrifft auch die Neueinführung von Systemen oder Anwendungen in den Informationsverbund, oder deren Entfernung. Das Ziel der Änderung können Sicherheitsaktualisierungen ebenso wie funktionelle Änderungen sein, da sich auch vermeintlich rein funktionelle Änderungen häufig auf die Sicherheit auswirken. KPI zur Leistungsmessung können z.B. die Fehlerquote bei Änderungen (CFR), die mittlere Wiederherstellungszeit (MTTR) und die Vorlaufzeit für Änderungen (Lead Time) sein. Die Verfahren und Regelungen können dabei entweder einheitlich für den gesamten Informationverbund, oder alternativ pro Geschäftsprozess oder (Kategorie von) IT-System festgelegt werden, um spezifischen Risiken oder Kontexten gerecht zu werden. Die Umsetzung kann in einem eigenen Prozess, oder integriert in andere Prozesse und Aufgaben, erfolgen. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>TEST.1.1.1: Dokumentation</td><td><p>Änderungen und Tests MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>TEST.1.1.2: Zuweisung der Aufgaben</td><td><p>Änderungen und Tests MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>TEST.1.1.3: Bekanntgabe</td><td><p>Änderungen und Tests MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>TEST.1.2: Regelmäßige Überprüfung</td><td><p>Änderungen und Tests MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr><tr valign="top"><td>TEST.1.3: Einschränkung von Änderungen</td><td><p>Änderungen und Tests SOLLTE die Durchführung von Änderungen auf Administrierende einschränken.</p></td><td><p>Ziel ist es, zu verhindern, dass unautorisierte Personen Eingriffe in produktive Systeme vornehmen. Ohne diese Einschränkung könnte Schadcode eingeschleust werden, Konfigurationen unbeabsichtigt verändert oder sensible Daten offengelegt werden. Die klare Zuweisung an Administrierende kann gleichzeitig sicherstellen, dass Änderungen nachvollziehbar und fachgerecht durchgeführt werden, wodurch die Stabilität und Verfügbarkeit von Systemen geschützt werden kann. Eine Institution kann die Anforderung beispielsweise durch folgende Maßnahmen umsetzen: (1) Verwendung von Rollenkonzepten, bei denen nur Administrierende Schreibrechte in produktiven Systemen besitzen, während anderen Rollen lediglich Leserechte eingeräumt werden können, (2) Einsatz von Testumgebungen oder Sandbox-Systemen, in denen auch Nicht-Administrierende Änderungen gefahrlos vorbereiten und dokumentieren können, (3) Einführung von Change-Management-Workflows mit Genehmigungsschritten, so dass Administrierende Änderungen erst nach dokumentierter Prüfung umsetzen können, und (4) Einsatz von technischen Kontrollmechanismen wie „Just-in-Time“-Privilegien oder Protokollierung von administrativen Sitzungen, wodurch die Nachvollziehbarkeit und Integrität der Änderungen verbessert werden kann.</p></td></tr></table><h2>TEST.2: Vorbereitung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>TEST.2.1: Versionshistorie</td><td><p>Änderungen und Tests SOLLTE eine Versionshistorie wesentlicher Änderungen protokollieren.</p></td><td><p>Wesentlich sind Änderungen, wenn sie Auswirkungen auf die Informationssicherheit von Produktivsystemen und -anwendungen haben können, die über eine geringe Anzahl von Nutzenden hinausgeht.</p></td></tr><tr valign="top"><td>TEST.2.2: Folgenabschätzung</td><td><p>Änderungen und Tests für Administrierende SOLLTE zu einer strukturierten Folgenabschätzung vor wesentlichen Änderungen anweisen.</p></td><td><p>Sinnvoll ist es die Ausführlichkeit der Folgenabschätzung an Umfang und Reichweite der Änderungen, sowie dem Risikoprofil betroffener Assets zu orientieren: Empfehlenswert ist es die Änderungen je nach Abschätzung der Folgen in Klassen einzusortieren (z.B. Geringe Auswirkungen, Mittlere Auswirkungen, Hohe Auswirkungen) und die weitere Prüftiefe nach dieser Einstufung auszurichten.</p></td></tr><tr valign="top"><td>TEST.2.2.1: Kategorisierung von Änderungen</td><td><p>Änderungen und Tests SOLLTE Änderungsvorhaben einer Kategorie zuweisen.</p></td><td><p>Dabei werden Änderungen je nach Abschätzung der Folgen in Kategorien einsortiert, die im Verhältnis zu den möglichen Auswirkungen stehen (z.B. Geringe Auswirkungen, Mittlere Auswirkungen, Hohe Auswirkungen). Umfang und Tiefe der weiterer Prüfungen kann dann nach dieser Einstufung ausgerichtet werden.</p></td></tr><tr valign="top"><td>TEST.2.2.2: Anpassung der Dokumentation</td><td><p>Änderungen und Tests SOLLTE die geplanten Änderungen dokumentieren.</p></td><td><p>Je nach Inhalt der Änderung können hierzu Konfigurationsdateien, Sicherheitsrichtlinien, oder begleitende Dokumente wie ein IT-Betriebshandbuch oder für Nutzende gedachte Anwenderhandbücher oder Wikis gehören.</p></td></tr><tr valign="top"><td>TEST.2.2.3: Dokumentation der Abhängigkeiten</td><td><p>Änderungen und Tests SOLLTE von der Änderung betroffene Abhängigkeiten dokumentieren.</p></td><td><p>Betroffene Abhängigkeiten sind sowohl alle Systeme und Anwendungen, die durch die geplanten Änderungen beeinflusst werden könnten, als auch die Abhängigkeiten der zu ändernden Systeme oder Anwendungen selbst (Up- and Downstream Dependency Management). Hierzu können z.B. Programmquellbibliotheken, angebundene Systeme, Netzanbindungen oder Anwendungen zählen.</p></td></tr></table><h2>TEST.3: Tests</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>TEST.3.1: Sicherheitstest</td><td><p>Änderungen und Tests SOLLTE vor wesentlichen Änderungen die Einhaltung der Sicherheitsanforderungen testen.</p></td><td><p>Änderungen sind wesentlich, wenn sie die Informationssicherheit von Produktivsystemen und -anwendungen betreffen und über eine geringe Anzahl von Nutzenden hinaus Auswirkungen haben können. Dabei sind sowohl die Sicherheitsanforderungen relevant, die direkt durch IT-Produkte umgesetzt werden (technische Anforderungen), als auch die prozessualen Anforderungen, die von der Änderung betroffen sind, etwa zur Überwachung von Ereignissen oder zur Sensibilisierung des Personals. Die Sicherheitsanforderungen ergeben sich aus den für das jeweilige Zielobjekt geltenden Vorgaben aus allen Praktiken. Sowohl die Funktionalität einzelner Module als auch das Zusammenspiel von Schnittstellen ist wichtig, um Sicherheitslücken frühzeitig zu erkennen.</p></td></tr><tr valign="top"><td>TEST.3.1.1: Dokumentation von Testergebnissen</td><td><p>Änderungen und Tests SOLLTE Tests einschließlich Prüfschritte, Ergebnissen und ggf. vorgenommenen Korrekturen dokumentieren.</p></td><td><p>Die Dokumentation von Tests zielt primär darauf ab, Transparenz und Nachvollziehbarkeit bei Änderungen zu gewährleisten, was das Risiko unbeabsichtigter Sicherheitslücken, Systemausfälle oder Datenverluste erheblich reduzieren kann. Ohne strukturierte Testdokumentation könnten beispielsweise fehlerhafte Konfigurationsänderungen unbemerkt in Produktivsysteme gelangen, was potenziell zu Verfügbarkeitsstörungen, verfälschten Daten oder kompromittierten Anwendungen führen könnte. Ein dokumentierter Testprozess ermöglicht zudem eine effektive Ursachenanalyse bei auftretenden Störungen, da alle durchgeführten Änderungen mit ihren beabsichtigten Wirkungen transparent nachvollzogen werden können. Eine nachvollziehbare und digital strukturierte Verknüpfung von Anforderung zu Prüfschritt und Prüfergebnissen kann durch OSCAL-Dokumente als strukturierte Daten erstellt werden. Gezielte Tests vor wesentlichen Änderungen tragen dazu bei, unbeabsichtigte Schwachstellen zu vermeiden, die zu unbefugtem Datenzugriff, Verlust von Geschäftsinformationen oder Ausfällen kritischer Systeme führen könnten. Je nach Art und Umfang der Änderungen lassen sich beispielsweise physische Zustände oder die Ausführung von Systemfunktionen verifizieren. Dabei werden sowohl die gewünschten Sicherheitsfunktionen als auch unerwünschte Zustände getestet, zum Beispiel, dass keine unautorisierten Funktionen aktiviert sind oder Apps ungewollt mit unbekannten Internetservern kommunizieren. Anwendbare Testarten umfassen statische und dynamische Tests, Unit- und Integrationstests sowie Regressionstests. Relevant ist dabei sowohl das Testen von manuellen Eingaben über die Benutzerschnittstelle als auch der Zugriffe über das Netzwerk, etwa über eine API. Die Tests können automatisiert (z. B. Unit-Tests, CI/CD-Tests, Schwachstellenscanner) oder manuell unterstützt (z. B. Click-Tests oder die Auswertung von LLM-Zusammenfassungen) durchgeführt werden. Sinnvoll ist es, automatische Tests für alle Funktionen und Codepfade einzusetzen, ergänzt durch manuelle Tests der wichtigsten Funktionen, wie Authentifizierung und Verschlüsselung, sowie durch Stichproben der übrigen Funktionen.</p></td></tr><tr valign="top"><td>TEST.3.1.2: Integritätstest</td><td><p>Änderungen und Tests SOLLTE die Integrität von Installationsdateien testen.</p></td><td><p>Dies kann z.B. durch Vergleich von Prüfsummen geschehen. Wenn möglich ist der Einsatz automatisierter Prüfungen empfehlenswert, es kann aber auch ein manueller Abgleich z.B. mit der Herstellerwebseite erfolgen.</p></td></tr><tr valign="top"><td>TEST.3.1.3: Testdaten</td><td><p>Änderungen und Tests SOLLTE die Testfälle abdeckende, aber unkritische Testdaten verankern.</p></td><td><p>Testdaten (engl. test data) sind in diesem Kontext synthetisch erstellte oder abstrahierte Daten, die zur Durchführung von Testfällen genutzt werden, ohne dass es sich dabei um operative oder besonders schützenswerte Informationen handelt. „Unkritisch“ bedeutet hier, dass die Daten keinen schützenswerten Daten wie Geschäftsgeheimnisse oder sicherheitsrelevanten Konfigurationsdetails enthalten, deren Missbrauch Schaden anrichten könnte. Testfälle (engl. test cases) sind vorab definierte Szenarien oder Abläufe, die das Verhalten einer Anwendung oder eines Systems gezielt prüfen sollen. Der Zweck der Anforderung liegt darin, sicherzustellen, dass Testaktivitäten einerseits realistische Bedingungen nachbilden, andererseits aber keine Risiken durch unbeabsichtigte Preisgabe oder Manipulation produktiver Daten entstehen. Ein Vorfall könnte beispielsweise darin bestehen, dass versehentlich echte Kundendaten in einer Testumgebung landen und durch unzureichende Sicherung Dritten zugänglich werden; durch den Einsatz unkritischer Testdaten kann dieses Risiko vermieden und dennoch die Qualität der Tests gewährleistet werden. Eine Institution kann die Anforderung praktisch umsetzen, indem sie Testdatensätze automatisiert generieren lässt, etwa durch Anonymisierung oder Pseudonymisierung produktiver Daten oder durch die Nutzung von Zufallswerten, die für Testlogik realistisch wirken. Zusätzlich kann es hilfreich sein, Regeln für Entwickler und Tester festzulegen, die dokumentieren, welche Arten von Daten zulässig sind. Auch Tools zur data masking oder synthetic data generation können verwendet werden, um komplexe Datenstrukturen ohne reale Inhalte nachzubilden.</p></td></tr><tr valign="top"><td>TEST.3.1.4: Testumgebung</td><td><p>Änderungen und Tests SOLLTE eine dedizierte Testumgebung installieren.</p></td><td><p>Eine dedizierte Testumgebung (auch Entwicklungsumgebung oder Laborumgebung genannt) ist hier eine von der Produktionsumgebung unabhängige Infrastruktur, die speziell für die Durchführung von Änderungen, Prüfungen und Qualitätssicherungsmaßnahmen vorgesehen ist. Sie dient dazu, geplante Anpassungen, Updates oder Neuentwicklungen realistisch nachzustellen, ohne die Verfügbarkeit oder Integrität der produktiven Systeme und Daten zu gefährden. Zur Produktivumgebung zählen dabei auch Betriebssysteme, verwendete Datenbanken und Netzschnittstellen. Dediziert bedeutet in diesem Zusammenhang, dass Ressourcen – beispielsweise Server, Datenbanken, Netzsegmente oder virtuelle Umgebungen – ausschließlich für Testzwecke bereitgestellt werden und nicht gleichzeitig produktiven Aufgaben dienen. Der Zweck dieser Vorgabe liegt darin, unbeabsichtigte Auswirkungen von Änderungen auf laufende Systeme zu vermeiden. Ohne eine solche Testumgebung könnte ein fehlerhaftes Update unmittelbar zu Produktionsausfällen führen oder sensible Daten unbeabsichtigt preisgeben. Eine Trennung kann dagegen sicherstellen, dass Schwachstellen oder Inkompatibilitäten frühzeitig erkannt werden, wodurch die Stabilität und Sicherheit der produktiven Systeme erhalten bleiben. Zur Umsetzung kann eine Institution verschiedene Maßnahmen einsetzen: (1) Sie kann separate physische oder virtuelle Serverlandschaften bereitstellen, die die Produktionsumgebung realitätsnah abbilden. (2) Sie kann Testdatenbanken mit anonymisierten oder synthetisch generierten Daten nutzen, um Datenschutzrisiken zu vermeiden. (3) Sie kann durch ein definiertes Deployment-Verfahren sicherstellen, dass Änderungen zunächst automatisiert in die Testumgebung ausgerollt und dort validiert werden, bevor eine Freigabe für die Produktion erfolgt.</p></td></tr><tr valign="top"><td>TEST.3.1.5: Kontinuierliche Tests</td><td><p>Änderungen und Tests KANN die Auswirkungen bei jeder Änderung automatisch testen.</p></td><td><p>„Automatisch testen“ meint den Einsatz technischer Verfahren oder Werkzeuge („continuous testing“), um bei Änderungen an Systemen oder Anwendungen unmittelbar und ohne manuelles Eingreifen Prüfungen auszuführen. Gemeint sind hier vordefinierte Testszenarien, die mit jedem Update, Patch oder Konfigurationswechsel ablaufen und systematisch überprüfen, ob die vorgesehenen Funktionen erhalten bleiben und ob unerwünschte Nebenwirkungen auftreten. Der Zweck liegt darin, dass Änderungen zwar notwendig sind, diese aber unbeabsichtigte Sicherheitslücken oder Funktionsstörungen mit sich bringen könnten – ein fehlerhaftes Update könnte beispielsweise Authentifizierungsprozesse umgehen lassen oder kritische Daten unzugänglich machen. Durch automatisierte Tests kann die Institution dagegen frühzeitig erkennen, ob eine Änderung die Vertraulichkeit, Integrität oder Verfügbarkeit gefährden könnte, und die Fehlerquote im Betrieb insgesamt senken. Umsetzungsmöglichkeiten können unterschiedlich gestaltet werden: Eine Institution kann (1) Continuous-Integration/Continuous-Delivery-Pipelines (CI/CD) einrichten, in die automatisierte Unit- und Integrationstests integriert sind, (2) produktionsnahe Szenarien in Testumgebungen abbilden und in denen Sicherheitstests automatisch mitlaufen, oder (3) Skripte einsetzen, die nach Konfigurationsänderungen direkt auf bekannte Schwachstellen oder das Vorhandensein von Sicherheitsfunktionen prüfen. Auch die Verwendung von Regressionstests, die kritische Kernfunktionen gezielt wiederholt prüfen, kann ein bewährtes Mittel sein, um sicherzustellen, dass durch eine Änderung keine unbeabsichtigten Seiteneffekte ausgelöst werden. Automatische Test ermöglichen es auch die Dokumentation der Testergebnisse automatisiert zu erstellen, sodass Verantwortliche sofort eine Übersicht über den Status erhalten.</p></td></tr><tr valign="top"><td>TEST.3.1.6: Chaos Engineering</td><td><p>Änderungen und Tests KANN die Fähigkeit zur Wiederherstellung durch Simulation verschiedenartiger Störungen testen.</p></td><td><p>Chaos Engineering kann helfen, die Zuverlässigkeit von Systemen oder Anwendungen zu erhöhen, indem es die Fähigkeit zur Wiederherstellung nach einem Fehler durch simulierte Ausfälle oder Störungen testet. Dabei ist jedoch zu beachten, dass dabei keine geschäftskritischen, im Betrieb befindlichen Dienste gestört werden. Daher ist der Ansatz nur nach einer Analyse und Abwägung der Risiken sinnvoll. Zweckmäßig ist es dabei, geschäftskritische Systeme und Anwendungen mit hohen Auswirkungen zu priorisieren, häufige Ausfallmodi zu testen, kritische Abhängigkeiten unter Stress zu setzen, vergangene Vorfälle nachzubilden und Systemannahmen durch methodische Prozesse zu hinterfragen. Hierzu kann eine Karte der Abhängigkeiten verwendet werden oder eine Analyse kritischer Pfade. Wertvolle Experimente können Netzwerkbeeinträchtigungen, Dienstausfälle, Abhängigkeitsunterbrechungen, Ressourcenerschöpfung, Multiregionsausfälle und Zeitsynchronisationsprobleme umfassen. Geschäftskritische Dienste können dabei z.B. durch eine Begrenzung auf bestimmte Systeme, oder Durchführung solcher Tests nur außerhalb der Betriebszeiten geschützt werden.</p></td></tr><tr valign="top"><td>TEST.3.1.7: Analyse der Zusammensetzung</td><td><p>Änderungen und Tests KANN die Zusammensetzung der Änderungen testen.</p></td><td><p>Eine Analyse der Zusammensetzung (Composition Analysis) ist die systematische Untersuchung und Bewertung der Bestandteile einer Software oder eines Systems – insbesondere in Bezug auf deren Herkunft, Eigenschaften und potenzielle Schwachstellen.  Hierzu können auch (teil-)automatisierte Lösungen eingesetzt werden, z.B. können SBOMs in eine Plattform zur Verwaltung von Schwachstellen importiert werden, die eine Bereitstellung blockiert, wenn eine CVSS ≥ 9.0-Schwachstelle keine kompensierende Maßnahme hat.</p></td></tr><tr valign="top"><td>TEST.3.1.8: Fuzzing</td><td><p>Änderungen und Tests KANN die Stabilität gegen Fehlerzustände oder Abstürze bei der Eingabe großer Mengen an Zufallsdaten testen.</p></td><td><p>Fuzzing ist eine automatisierte Softwaretestmethode, mit der unerwartete Schwachstellen und Fehler in Anwendungen durch Eingabe zufälliger, unerwarteter oder ungültiger Daten aufgedeckt werden können. Der Hauptzweck besteht darin, Grenzbedingungen zu prüfen und Programmabstürze, Speicherlecks oder sicherheitskritische Fehler wie Buffer Overflows zu identifizieren, bevor Angreifer diese ausnutzen können. Kann durch spezialisierte Tools oder kontinuierliches Fuzzing in der CI/CD-Pipeline umgesetzt werden. Für einen effektiven Einsatz empfiehlt es sich, mit strukturiertem Fuzzing zu beginnen, das auf bekannten Protokollspezifikationen oder Datenformaten basiert, Fuzzing-Tests in die frühen Phasen des Entwicklungszyklus zu integrieren, alle gefundenen Fehler systematisch zu dokumentieren und zu beheben, sowie regelmäßig neue Testfälle auf Basis entdeckter Schwachstellen zu entwickeln, um die Testabdeckung kontinuierlich zu verbessern.</p></td></tr><tr valign="top"><td>TEST.3.1.9: Lasttest</td><td><p>Änderungen und Tests KANN die Belastbarkeit bei hoher Auslastung testen.</p></td><td><p>Ziel ist es, die Dimensionierung der Ressourcen zu verifizieren und Fehler zu entdecken, die nur bei höherer Last auftreten. Hierzu können z.B. eine hohe Zahl gleichzeitiger Verbindungen, große Datenmengen oder eine hohe Zahl paralleler Interaktionen genutzt werden. Die Höhe der Auslastung kann sich dabei z.B. nach der maximalen Anzahl erwarteter gleichzeitiger Nutzungen richten.</p></td></tr><tr valign="top"><td>TEST.3.1.10: Penetrationstest bei Änderungen</td><td><p>Änderungen und Tests KANN bekannte Schwachstellen bei kritischen Änderungen testen.</p></td><td><p>Bei einem Penetrationstest führen qualifizierte Sicherheitsexperten kontrollierte Angriffe auf Systeme, Anwendungen oder Netzwerke durch. Der primäre Zweck besteht darin, die tatsächliche Angriffsfläche aus der Perspektive eines potenziellen Angreifers zu bewerten, reale Ausnutzungsmöglichkeiten zu demonstrieren und die Wirksamkeit implementierter Sicherheitsmaßnahmen unter realistischen Bedingungen zu verifizieren. Praktische Umsetzungsbeispiele umfassen Black-Box-Tests ohne Vorkenntnisse des Systems, Grey-Box-Tests mit begrenztem Zugang und Wissen sowie White-Box-Tests mit vollständigem Quellcode-Zugriff, wobei Tools zur Automatisierung und Strukturierung der Tests eingesetzt werden können. Für ein effektives Pentesting empfiehlt es sich, den Testumfang klar zu definieren und zu dokumentieren, realistische Angriffsziele und Erfolgsmetriken festzulegen, ausreichend Zeit für die Behebung identifizierter Schwachstellen im Release-Plan einzuplanen, ein erfahrenes, unabhängiges Testteam einzusetzen, das nicht an der Entwicklung beteiligt war, sowie Re-Tests nach der Behebung von Schwachstellen durchzuführen, um sicherzustellen, dass alle identifizierten Risiken vor dem Produktivgang angemessen adressiert wurden.</p></td></tr><tr valign="top"><td>TEST.3.2: Testabdeckung</td><td><p>Änderungen und Tests SOLLTE die Testabdeckung regelmäßig überprüfen.</p></td><td><p>Ein ungenügendes Testverfahren könnte beispielsweise dazu führen, dass Schwachstellen in kritischen Anwendungen unentdeckt bleiben, was wiederum zu Datenverlust, unbefugtem Zugriff oder Systemausfällen führen könnte. Ein Beispiel hierfür ist der Fall einer industriellen Steuerungsanlage, bei der eine nicht ausreichend getestete Firmware-Aktualisierung zu einem Sicherheitsversagen und anschließendem Produktionsausfall führt. Der Begriff <b>„Testabdeckung“</b> (engl. <b>„test coverage“</b>) bezeichnet hierbei den Umfang, in dem Komponenten, Funktionen und Schnittstellen eines Systems durch strukturierte Tests überprüft werden. Zur Umsetzung kann eine Institution verschiedene Maßnahmen implementieren: Für Software kann ein Code-Coverage-Monitoring etabliert werden, während für Hardware systematische Testmatrizen entwickelt werden können, die alle relevanten Betriebsparameter und Umgebungsbedingungen abdecken. Test-Dashboards können sowohl Software- als auch Hardware-Metriken visualisieren und in Entwicklungs- bzw. Implementierungsprozesse integriert werden. Für Hardware können FMEA-Analysen (Failure Mode and Effects Analysis) die kritischen zu testenden Komponenten identifizieren, während Software durch automatisierte CI/CD-Tests abgesichert werden kann. Bei der Implementierung empfiehlt es sich, einen risikobasierten Ansatz zu verfolgen, bei dem zuerst sicherheitskritische Komponenten umfassend getestet werden. Zudem kann eine systematische Dokumentation aller Testfälle und -ergebnisse, sowohl für Hardware- als auch für Software-Komponenten, die Nachvollziehbarkeit und kontinuierliche Verbesserung der Testabdeckung unterstützen. Zudem kann eine Kombination aus verschiedenen Testebenen (z.B. Stichproben, automatisierte und manuelle Verfahren, Unit-, Integrations- und Systemtests) eine umfassendere Abdeckung gewährleisten.</p></td></tr></table><h2>TEST.4: Freigabe</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>TEST.4.1: Autorisierung von Änderungen</td><td><p>Änderungen und Tests SOLLTE kritische Änderungen anhand von Kriterien einschließlich der Sicherheitsanforderungen autorisieren.</p></td><td><p>Änderungen sind kritisch, wenn Sie breite Auswirkungen auf Geschäftsprozesse haben (z.B. Aktivierung Zwei-Faktor-Authentifizierung am zentralen Verzeichnisdienst). Die Kritikalität ergibt sich außerdem aus Art und Umfang der Änderungen, z.B. umfangreiche Migration oder Bugfix. Kritische Änderungen können z.B. die Bereitstellung für eine größere Zahl interner oder externer Nutzender oder Änderungen an hochverfügbaren Systemen sein. Zu Kriterien können hier z.B. das Durchführen bestimmter Tests ohne Fehler, eine bestimmte Nutzerakzeptanz in eimem Beta-Test oder das Bestehen von Penetration Tests sein.  Zweckmäßig ist eine Implementierung mehrstufiger Autorisierung, bei der Änderungen anhand ihrer abgeschätzten Auswirkungen (niedrig, mittel, hoch) mit entsprechenden Genehmigungsanforderungen kategorisiert werden. Während es bei geringfügigen Änderungen an unkritischen Systemen ausreichen kann, die wichtigsten Sicherheitsanforderungen im Blick zu behalten - insbesondere hinsichtlich Authentifizierung, Verschlüsselung und Härtung - sind bei umfangreichen Änderungen an vielen Systemen mit eher hohem Risikoprofil die Auswirkungen meist nur durch automatisierte Prüfverfahren plus Checklisten für händische Tätigkeiten noch überschaubar.</p></td></tr><tr valign="top"><td>TEST.4.1.1: Unabhängigkeit der Autorisierung</td><td><p>Änderungen und Tests KANN kritische Änderungen auch durch eine von der Implementierung unabhängige Person autorisieren.</p></td><td><p>Eine Freigabe durch eine unabhängige Person ist die nachweisliche Bestätigung der Testergebnisse durch eine fachlich qualifizierte, aber nicht an der Entwicklung, Durchführung oder unmittelbaren Implementierung der getesteten Änderung beteiligte Person. Ziel ist es, Objektivität und Unvoreingenommenheit sicherzustellen und das Vier-Augen-Prinzip für kritische Änderungen zu wahren. Hierbei genügt es, wenn neben beteiligten Personen auch eine unabhängige Person die Änderung autorisiert hat, wie z.B. bei einem Change Advisory Board, an dem mehrere Personen beteiligt sind. Die geltenden Anforderungen sind alle für das Zielobjekt ausgewählten Sicherheitsanforderungen, z.B. Verifikation korrekter TLS-Konfiguration oder Fertigstellung einer Datensicherung mit korrektem Umfang zu geforderter Zeit gemäß Konzept. Empfehlenswert ist es den Prozess in einem Versionkontrollsystem abzubilden, sodass die Dokumention der Änderungen und der Freigabe weitestgehend automatisiert stattfindet.</p></td></tr><tr valign="top"><td>TEST.4.1.1.1: Staging</td><td><p>Änderungen und Tests SOLLTE eine Staging-Umgebung installieren.</p></td><td><p>Eine Staging-Umgebung ist von der Produktivumgebung getrennt, wenn sie keine Systeme, Anwendungen oder Datenquellen der Produktivumgebung verwendet. Sie entspricht so weit wie möglich der Produktivumgebung, damit zwischen Freigabe und Produktivbetrieb möglichst wenige Abweichungen vorkommen, z.B. hinsichtlich der Schwachstellen eingesetzter Softwareversionen oder der Verfügbarkeit von Ressourcen in verschiedenen Rechenzentren.</p></td></tr><tr valign="top"><td>TEST.4.1.2: Dokumentation der Freigabe</td><td><p>Änderungen und Tests SOLLTE die Freigabe einschließlich Zeitpunkt, Vorhaben, Freigabekriterien und freigebender Personen dokumentieren.</p></td><td><p>Je nach Organisationstruktur kann es sinnvoll sein, weitere Angaben aufzuführen, z.B. in der Freigabe durchgeführte Prüfschritte oder weitere beteiligte Personen. Allerdings kann sich die Freigabe auch auf eine Dokumentation der zuvor durchgeführten Tests stützen. In jedem Fall handelt es sich nur dann um eine Freigabe, wenn die entscheidenden Personen oder Rollen eine eigenständige Entscheidung getroffen haben, die auf einer eigenen Untersuchung des Änderungsvorhabens basiert.</p></td></tr><tr valign="top"><td>TEST.4.2: Signatur</td><td><p>Änderungen und Tests KANN eine Signatur der Freigabeerklärung ausführen.</p></td><td><p>Die Signatur der Freigabeerklärung ist hier als eine digitale oder handschriftliche Unterschrift zu verstehen, die dokumentiert, dass eine geplante Änderung oder ein Test geprüft, bewertet und zur Umsetzung freigegeben wurde. Die Signatur kann damit sowohl eine elektronische Signatur nach gängigen Standards (z. B. qualifizierte elektronische Signatur im Ticketsystem) als auch eine händische Unterschrift sein. Sie stellt nicht nur eine rechtliche, sondern vor allem eine technische und organisatorische Nachvollziehbarkeit sicher, indem eindeutig erkennbar wird, wer eine Entscheidung zur Durchführung von Änderungen verantwortet hat. Die Freigabe durch eine Signatur kann dazu beitragen, dass unbeabsichtigte oder fehlerhafte Änderungen nicht unkontrolliert in den Betrieb gelangen. Ein fehlender Nachweis könnte im Vorfallfall zu Streitigkeiten über Verantwortlichkeiten führen oder die forensische Nachvollziehbarkeit erschweren. Ebenso könnte ohne dokumentierte Freigabe eine ungetestete Änderung produktive Systeme beeinträchtigen und Ausfälle oder Datenverlust verursachen. Durch eine dokumentierte Signatur kann hingegen nachvollziehbar gemacht werden, dass fachliche, technische und sicherheitsrelevante Prüfungen stattgefunden haben und die Entscheidung zur Umsetzung bewusst und überprüfbar getroffen wurde.</p></td></tr><tr valign="top"><td>TEST.4.3: Rückfallösung</td><td><p>Änderungen und Tests SOLLTE eine Rückfallösung verankern.</p></td><td><p>Kritisch sind administrative Änderungen an geschäftskritischen Systemen, da ihr Ausfall gravierende Folgen haben könnte. Die Kritikalität ergibt sich außerdem aus Art und Umfang der Änderungen, z.B. umfangreiche Migration oder Bugfix. Maßnahmen können z.B. die Wiederherstellung aus einer vorher erstellten aktuellen Datensicherung, einer Versionsverwaltung oder Blue-Green-Deployment sein.</p></td></tr><tr valign="top"><td>TEST.4.4: Geregelte Notfalländerungen</td><td><p>Änderungen und Tests SOLLTE Regelungen für Notfalländerungen einschließlich Vorgehensweise, Zuständigkeiten, erforderlicher Ressourcen und minimaler Prüfschritte verankern.</p></td><td><p>Ein Notfall-Deployment-Prozess ermöglicht eine schnelle Reaktion auf akute Bedrohungen. Als Notfall-Ereignisse kommen z.B. Zero-Day-Exploits, kritische Sicherheitslücken mit aktiver Ausnutzung, schwerwiegende Produktionsfehler mit Geschäftsauswirkungen oder koordinierte Cyberangriffe in Frage. Zu einer strukturierten Vorgehensweise können z.B. gehören: (1) Ein Eskalationsverfahren mit definierten Kommunikationswegen, z.B. zum ISB und Administrierenden, welche über Rufbereitschaftspläne und automatisierte Alarmierungssysteme erreichbar sind und Zugriffsrechte auf isolierte Notfall-Deployment-Umgebungen, vorkonfigurierte Rollback-Mechanismen sowie dedizierte Notfall-Builds mit minimalen Abhängigkeiten besitzen.  (2) Minimale Prüfschritte können z.B. eine beschleunigte Sicherheitsvalidierung kritischer Codeänderungen, automatisierte Sicherheitsscans zur Identifikation offensichtlicher Schwachstellen, die Verifizierung der Code-Integrität durch mindestens zwei autorisierte Personen nach dem Vier-Augen-Prinzip sowie ein dokumentierter Genehmigungsprozess mit expliziter Abzeichnung durch den CISO oder einen designierten Stellvertreter sein.  (3) Eine Nachbereitung mit Post-Incident-Analyse zur Dokumentation der getroffenen Maßnahmen, identifizierten Verbesserungspotenzialen und notwendigen Nacharbeiten.</p></td></tr></table><h2>TEST.5: Bereitstellung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>TEST.5.1: Information betroffener Kreise</td><td><p>Änderungen und Tests SOLLTE von der Änderung betroffene Kreise informieren.</p></td><td><p>Betroffene Kreise können je nach Vorhaben z.B. interne oder externe Nutzende, IT-Betrieb, das Monitoring-Team, die Öffentlichkeitsarbeit oder ISB sein. Erforderliche Informationen können z.B. zu erwartende Ausfallzeiten oder Beginn und Ende des Wartungsfensters, die Vorgehensweise zum Bezug von Sicherheitsupdates oder anzupassende Sicherheitseinstellungen sein, die Nutzende selbst vornehmen können.</p></td></tr><tr valign="top"><td>TEST.5.2: Verschlüsselte Bereitstellung</td><td><p>Änderungen und Tests SOLLTE die Bereitstellung verschlüsseln.</p></td><td><p>Das Konzept der Bereitstellung (engl. Deployment oder Provisioning) bezieht sich hier auf den Vorgang des Übertragens, Installierens oder Aktivierens von Software-Artefakten, Konfigurationen, Skripten oder anderen digitalen Gütern von einer gesicherten Umgebung (z.B. Test- oder Staging-Umgebung) in die Ziel- oder Produktionsumgebung. Die Verschlüsselung dieser Bereitstellung meint dabei die kryptografische Sicherung des Datenstroms oder der übertragenen Daten während des Transports, sodass diese für unbefugte Dritte unlesbar sind. Diese Vorschrift dient primär dem Schutz vor der Offenlegung sensibler Daten oder der Manipulation der ausgelieferten Artefakte: Ein Angreifer, der den Übertragungsweg abhört, könnte ohne Verschlüsselung leicht auf vertrauliche Informationen zugreifen, etwa proprietären Quellcode oder sensible Konfigurationsparameter (wie Passwörter oder API-Schlüssel), was zur Geheimhaltung (Confidentiality) in der Institution im Widerspruch stünde. Außerdem könnte ein Man-in-the-Middle-Angriff die übertragenen Daten manipulieren und so bösartigen Code in die Produktionsumgebung einschleusen, bevor die Integrity-Checks greifen, was die Integrität der bereitgestellten Lösungen gefährden könnte. Technisch kann die Institution dies gewährleisten, indem alle Deployment-Pipelines ausschließlich gesicherte Kommunikationsprotokolle nutzen. Zusätzlich ist es sinnvoll die Bereitstellungs-Artefakte digital zu signieren und diese Signatur erst nach erfolgreicher End-zu-End-Integritätsprüfung (z.B. durch Prüfsummen wie SHA-256) auf dem Zielsystem zur Installation freigeben, was einen Manipulationsversuch im Transit erschwert.</p></td></tr><tr valign="top"><td>TEST.5.3: Schrittweiser Rollout</td><td><p>Änderungen und Tests KANN die Inbetriebnahme stufenweise ausführen.</p></td><td><p>Ein schrittweiser Rollout (Staged Rollout) ist eine stufenweise Betriebsaufnahme, um Probleme frühzeitig zu erkennen und zu verhindern, dass durch sie die gesamte Infrastruktur betroffen ist. Die Umsetzung kann z.B. durch Blue-Green-Deployment oder nach dem One-Some-All-Prinzip geschehen. Hierdurch soll verhindert werden, dass sich Probleme auf alle betroffenen Systeme oder Anwendungen gleichzeitig auswirken.</p></td></tr><tr valign="top"><td>TEST.5.4: Persistenz</td><td><p>Änderungen und Tests SOLLTE die Persistenz nach wesentlichen Änderungen testen.</p></td><td><p>Persistenz bedeutet hier, dass eine wesentliche Änderung nach ihrer Einführung dauerhaft wirksam bleibt, also auch nach einem Neustart, einem System-Update oder einem Rückspielen von Konfigurations-Backups nicht unbeabsichtigt verloren geht. Dies könnte beispielsweise dazu führen, dass eine sicherheitsrelevante Konfiguration nach einem Reboot verschwindet oder eine Migration zu einem neuen Anbieter scheitert, weil Daten oder Regeln nicht portabel waren. Eine Institution kann die Anforderung praktisch umsetzen, indem Änderungen nach Abschluss nicht nur funktional, sondern auch über System- und Lebenszyklusereignisse hinweg überprüft werden. Dazu kann es hilfreich sein, Änderungen gezielt mit simulierten Neustarts, Failover-Tests oder dem erneuten Einspielen von Standard-Backups zu validieren. Um den laufenden Betrieb hierdurch nicht zu beeinträchtigen können Systeme oder Anwendungsinstanzen nacheinander oder zu unkritischen Zeiten neu gestartet werden.</p></td></tr><tr valign="top"><td>TEST.5.5: Rückblick</td><td><p>Änderungen und Tests SOLLTE die Erreichung der Bereitstellungsziele <i>regelmäßig</i> überprüfen.</p></td><td><p>Ein effektiver Änderungsmanagementprozess kann von systematischen Überprüfungen nach der Implementierung profitieren. Institutionen können Bewertungen darüber einbeziehen, ob die Änderungen ihre beabsichtigten Ziele erreicht haben, Überprüfungen, dass Sicherheitsmechanismen weiterhin wirksam sind, Dokumentation der gewonnenen Erkenntnisse und Identifizierung notwendiger Anpassungen oder zusätzlicher Kontrollmechanismen. Diese Überprüfungen können wertvolle Einblicke für zukünftige Verbesserungen des Änderungsmanagementprozesses liefern.</p></td></tr></table><h1>PERS: Personal</h1><p>Die Praktik Personal fokussiert sich auf die Integration von Sicherheitsanforderungen über den gesamten Beschäftigungs- oder Vertragszyklus von Mitarbeitenden sowie externen Partnern hinweg. Ziel ist es, einen sicheren Umgang mit Informationen während der gesamten Dauer der Beschäftigung oder Zusammenarbeit zu gewährleisten.  Diese Praktik fokussiert auf den sicheren Umgang mit Personen, während Praktiken, wie Berechtigungen, den systemseitigen Zugriff regeln.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>PERS.1: Grundlagen</td><td align="right">5</td></tr><tr valign="top"><td>PERS.2: Aufgaben, Rollen, Zuständigkeiten</td><td align="right">8</td></tr><tr valign="top"><td>PERS.3: Personalzugang</td><td align="right">8</td></tr><tr valign="top"><td>PERS.4: Personalentwicklung</td><td align="right">3</td></tr><tr valign="top"><td>PERS.5: Personalbetreuung</td><td align="right">3</td></tr><tr valign="top"><td>PERS.6: Weggang von Mitarbeitenden</td><td align="right">3</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>30</b></td></tr></table><h2>PERS.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERS.1.1: Verfahren und Regelungen</td><td><p>Personal MUSS Verfahren und Regelungen zum Personalmanagement verankern.</p></td><td><p>Der Prozess stellt sicher, dass qualifiziertes und zuverlässiges Personal für alle Aufgaben zur Verfügung steht und allen Beteiligten ihre Aufgaben und Zuständigkeiten bekannt sind. Hierbei sind Einstellung, Einarbeitung, Weiterbildung und Austritt von Mitarbeitenden zu berücksichtigen. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>PERS.1.1.1: Dokumentation</td><td><p>Personal MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>PERS.1.1.2: Zuweisung der Aufgaben</td><td><p>Personal MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>PERS.1.1.3: Bekanntgabe</td><td><p>Personal MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>PERS.1.2: Regelmäßige Überprüfung</td><td><p>Personal MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr></table><h2>PERS.2: Aufgaben, Rollen, Zuständigkeiten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERS.2.1: Aufgaben</td><td><p>Personal SOLLTE für alle Tätigkeiten im Geltungsbereich Aufgaben mit Abgrenzungen und Schnittstellen verankern.</p></td><td><p>Aufgaben sind die konkreten Tätigkeiten, die für die Errichtung und Aufrechterhaltung des ISMS erforderlich sind, z.B. Netz überwachen, Pentest durchführen, Administration einer bestimmten Fachanwendung. Definieren Sie die Aufgaben so, dass Abgrenzung und Schnittstellen untereinander klar sind. Hierzu kann auf die Praktiken, Zielobjekte und deren Anforderungen zurückgegriffen werden.</p></td></tr><tr valign="top"><td>PERS.2.2: Rollen</td><td><p>Personal SOLLTE für alle Tätigkeiten im Geltungsbereich Rollen mit Zielen, Aufgaben, erforderlichen Kompetenzen und Qualifikationen verankern.</p></td><td><p>Eine Rolle beschreibt eine Stelle oder Personalposition innerhalb des ISMS. Sie benennt die Aufgaben der Position und die dazu erforderlichen Qualifikationsvoraussetzungen. Beispiele: Teamleiter, Entwickler, Admin, Sicherheitsanalyst, Fachaufgabenverantwortlicher.</p></td></tr><tr valign="top"><td>PERS.2.3: Rollentrennung</td><td><p>Personal SOLLTE für unvereinbare Aufgaben eine Rollentrennung verankern.</p></td><td><p>Bei einer Aufgabentrennung (Separation of Duties) werden miteinander in Konflikt stehende Aufgaben und Verantwortlichkeitsbereiche getrennt, um die Möglichkeiten zu unbefugter oder unbeabsichtigter Änderung oder zum Missbrauch zu reduzieren. Unvereinbar sind zwei Aufgaben insbesondere, wenn zwischen ihnen (1.) ein Interessenkonflikt oder (2.) ein erhöhtes Risiko für Datenmissbrauch vorliegt. (1.) Interessenkonflikte können z.B. die Auditierung der eigenen Aufgaben oder der Ergebnisse von Vorgesetzten sein. (2.) Ein erhöhtes Risiko für Datenmissbrauch liegt z.B. vor, wenn sowohl Rechnungsstellung als auch -genehmigung in einer Hand liegen.</p></td></tr><tr valign="top"><td>PERS.2.3.1: Rollentrennung - Verzeichnisdienst</td><td><p>Personal SOLLTE zwischen Administration von Verzeichnisdiensten und Pflege der verwalteten Daten eine Rollentrennung verankern.</p></td><td><p>Administrierende von Verzeichnisdiensten haben sehr weitreichende Rechte, einschließlich der Möglichkeit, Zugangskontrollen zu ändern. Durch eine Rollentrennung wird verhindert, dass eine Person die vollständige Kontrolle über die angebundene Infrastruktur und die Dateninhalte übernimmt. Dies reduziert das Risiko vorsätzlicher und fahrlässiger Schäden an zentraler Stelle.</p></td></tr><tr valign="top"><td>PERS.2.3.2: Rollentrennung - Virtualisierung</td><td><p>Personal SOLLTE zwischen Administration von virtuellen Systemen und VM-Hosts eine Rollentrennung verankern.</p></td><td><p>Liegen Gast- und Hostadministration in derselben Hand, so können Fehladministrationen oder Insiderangriffe sich auf alle betriebenen Server auswirken, ohne dass Administrierende hiervon Kenntnis erlangen können.</p></td></tr><tr valign="top"><td>PERS.2.3.3: Rollentrennung - Audits</td><td><p>Personal SOLLTE zwischen Implementierung von Sicherheitsanforderungen und deren Überprüfung eine Rollentrennung verankern.</p></td><td><p>Fehlt eine Rollentrennung zwischen Umsetzung und Überprüfung von Sicherheitsmaßnahmen, so besteht ein Interessenkonflikt zwischen der Aufgabe korrekter Implementierung und dem Finden von weiterem Verbesserungspotenzial oder Mängeln bei einer Überprüfung.</p></td></tr><tr valign="top"><td>PERS.2.3.4: Rollentrennung - Änderungen und Tests</td><td><p>Personal SOLLTE zwischen Implementierung und Test eine Rollentrennung verankern.</p></td><td><p>Liegen Implementierung von Funktionen und Änderungen, sowie deren Test in derselben Hand, so werden Probleme durch Nachlässigkeit oder Versehen leicht übersehen.</p></td></tr><tr valign="top"><td>PERS.2.4: Zuständigkeiten</td><td><p>Personal SOLLTE Zuständigkeiten für die Rollen zuweisen.</p></td><td><p>Damit die mit jeder Rolle verbundenen Aufgaben auch tatsächlich bearbeitet werden ist es erforderlich, jeder Rolle eine oder mehrere Personen oder Organisationseinheiten zuzuweisen, die für die mit der Rolle verbundenen Aufgaben zuständig sind. Hierbei ist es wichtig darauf zu achten, dass alle Rollen von ausreichenden Personalressourcen abgedeckt werden. Je nach Rolle können dafür auch Vertretungsregelungen erforderlich sein.</p></td></tr></table><h2>PERS.3: Personalzugang</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERS.3.1: Dienst- oder Arbeitsvertrag</td><td><p>Personal für Mitarbeitende SOLLTE die vertrauliche Behandlung von Betriebs- und Geschäftsgeheimnissen im Dienst- oder Arbeitsvertrag vereinbaren.</p></td><td><p>Ergänzend zu den gesetzlichen Verpflichtungen zur Wahrung von Betriebs- und Geschäftsgeheimnissen (z.B. aus dem GeschGehG) ist eine explizite Vertraulichkeitsvereinbarung (Non-disclosure Agreement, NDA) mit allen Externen und Mitarbeitenden sinnvoll, die Zugriff auf schützenswerte Informationen erhalten.</p></td></tr><tr valign="top"><td>PERS.3.2: Verfahrensanweisungen</td><td><p>Personal für Mitarbeitende SOLLTE explizit zur Einhaltung von Verfahrensanweisungen bei Neuzugang anweisen.</p></td><td><p>Wenn neue Mitarbeitende keine explizite Anweisung erhalten, dass Sicherheitsanweisungen existieren und einzuhalten sind, könnte es zu verspäteter Kenntnisnahme der Regelungen und dadurch zu Mängeln in der Einhaltung kommen. Das ist insbesondere bei Mitarbeitenden der Fall, die in manche Informationsverarbeitungsprozesse eingebunden sind, aber keinen Zugang zu Plattformen wie dem Intranet erhalten: Werden Verfahrensanweisungen nur im Intranet abgelegt, aber nicht bei Neuzugang explizit bekannt gegeben, so können diese Personen keine Kenntnis davon nehmen. Die Menge der Verfahrensanweisungen ergibt sich aus den für die jeweilige Tätigkeit relevanten gesetzlichen Anforderungen, sowie den Anforderungen zu den Handlungsworten „anweisen“ und „verbieten“.</p></td></tr><tr valign="top"><td>PERS.3.3: Betriebs- und Geschäftsgeheimnisse</td><td><p>Personal für Mitarbeitende SOLLTE zum Umgang mit definierten Betriebs- und Geschäftsgeheimnissen bei Neuzugang anweisen.</p></td><td><p>Eine Dienst- oder Arbeitsanweisung, die zu wahrende Betriebs- und Geschäftsgeheimnisse klar definiert, stellt sicher, dass Mitarbeitende ihre Pflichten genau kennen. Hierbei geht es insbesondere darum, klar zu definieren welche Informationen als Betriebs- und Geschäftsgeheimnisse zu behandeln sind, z.B. Kundendaten, Patente, alle nicht zur Veröffentlichung bestimmten oder mit bestimmten Schutzklassifizierungen versehene Dokumente. Außerdem relevant ist, dass diese Geheimnisse auch über das Ende des Vertragsverhältnisses hinaus zu wahren sind. Hier besteht ein enger Zusammenhang zum Informationsmanagement, wo z.B. auch geregelt wird, welche Anweisungen zum Schutz im Einzelnen einzuhalten sind (z.B. Markierung, Verwahrung). Damit die dort festgelegten Regelungen den Mitarbeitenden auch bekannt sind wird eine entsprechende Anweisung bei Neuzugang benötigt.</p></td></tr><tr valign="top"><td>PERS.3.4: Stellenbeschreibungen</td><td><p>Personal SOLLTE Stellenbeschreibungen vor Ausschreibung zu besetzender Stellen dokumentieren.</p></td><td><p>Eine Stellenbeschreibung ist hier ein Dokument, das die zentralen Aufgaben, Verantwortlichkeiten, Befugnisse und fachlichen sowie sicherheitsrelevanten Kriterien einer Position vor deren Ausschreibung festhält. Der Zweck dieser Anforderung liegt darin, klare Rollen und Verantwortlichkeiten zu definieren, um sowohl Fehlbesetzungen als auch unklare Zuständigkeiten zu vermeiden. Ohne eine dokumentierte Stellenbeschreibung könnte eine Institution Personen einstellen, deren Qualifikation oder Vertrauenswürdigkeit nicht den tatsächlichen sicherheitsrelevanten Kriterien entsprechen, was zu erhöhtem Missbrauchsrisiko oder unzureichender Aufgabenerfüllung führen könnte. Eine sauber ausgearbeitete Stellenbeschreibung kann dagegen Transparenz schaffen, spätere Konflikte reduzieren und die Sicherheit erhöhen, indem bereits im Auswahlprozess klar wird, welche Fachkenntnisse und Integritätsanforderungen benötigt werden. Beachten Sie dabei auch rechtliche Anforderungen wie das AGG. Zur Umsetzung kann eine Institution zunächst ein standardisiertes Format für Stellenbeschreibungen verwenden, in dem u.a. Aufgabenbereiche, Verantwortlichkeiten, sowie erforderliche fachliche und sicherheitsrelevante Qualifikationen erfasst werden. Eine abgestufte Vorlage kann bei unterschiedlichen Rollenarten (z.B. operative Mitarbeitende, Teamleitungen, Fachspezialisten) helfen, die Konsistenz zu wahren. Prozessual kann eine interne Prüfschleife eingerichtet werden, in der HR und die jeweilige Fachabteilung die Beschreibung autorisieren, bevor eine Stelle öffentlich ausgeschrieben wird. Außerdem kann es hilfreich sein, regelmäßig zu prüfen, ob bestehende Stellenbeschreibungen noch zu aktuellen Prozessen und eingesetzten Technologien passen, sodass keine veralteten oder unvollständigen Kriterien in die Rekrutierung einfließen.</p></td></tr><tr valign="top"><td>PERS.3.5: Prüfung der Bewerbungsunterlagen</td><td><p>Personal SOLLTE die Qualifikation von Bewerbenden anhand der Bewerbungsunterlagen vor der Besetzung von Stellen testen.</p></td><td><p>Die Prüfung von Unterlagen zur Qualifikation ist essenziell, um sicherzustellen, dass nur fachlich geeignete Personen Zugang zu sensiblen IT-Systemen und Daten erhalten. Fehlende Qualifikationen erhöhen das Risiko für Bedienfehler oder mangelndes Sicherheitsbewusstsein, was Schwachstellen und Angriffsflächen für Bedrohungen eröffnet. Zudem wird so das Risiko von gezielter Einschleusung von Angreifern verringert. Berücksichtigen Sie dabei die Persönlichkeitsrechte der Bewerbenden.</p></td></tr><tr valign="top"><td>PERS.3.6: Vertrauenswürdigkeit von Bewerbenden</td><td><p>Personal SOLLTE die Vertrauenswürdigkeit von Bewerbenden vor der Besetzung von Stellen testen.</p></td><td><p>Hierbei sind sowohl die Identität der Person, als auch ihre Qualifikation anhand von Nachweisen zu verifizieren. Insbesondere ist zu prüfen, ob der vorgelegte Lebenslauf korrekt, plausibel und vollständig ist. Bei Unklarheiten oder Widersprüchen können die Angaben durch Rückfragen bei der Quelle der Qualifikationsnachweise verifiziert werden.</p></td></tr><tr valign="top"><td>PERS.3.6.1: Sicherheitsüberprüfung</td><td><p>Personal KANN eine Sicherheitsüberprüfung vor der Besetzung von Stellen ausführen.</p></td><td><p>Bei einer Sicherheitsüberprüfung kann je nach Art der Tätigkeit ein Polizeiliches Führungszeugnis, eine finanzielle Hintergrundprüfung, ein Sicherheitsinterview, eine psychologische Eignungsprüfung, sowie eine Überprüfung von sozialen Beziehungen und Netzwerken sinnvoll sein.</p></td></tr><tr valign="top"><td>PERS.3.7: Einarbeitung</td><td><p>Personal für Mitarbeitende SOLLTE eine Einarbeitung bei Neuzugang ausführen.</p></td><td><p>Eine Einarbeitung ist eine strukturierte Vorgehensweise, bei der neue Mitarbeitende mit den relevanten Aufgaben, Zuständigkeiten, Systemen und Sicherheitsanforderungen ihrer Tätigkeit vertraut gemacht werden. Ziel ist es, ihnen nicht nur fachliche Grundlagen, sondern auch die spezifischen Abläufe und Schutzmaßnahmen der Institution zu vermitteln, sodass sie von Beginn an korrekt und sicher arbeiten können. Ohne eine solche Einarbeitung könnte es zu Fehlbedienungen von IT-Systemen kommen, die Sicherheitsvorfälle begünstigen, oder zu Verzögerungen bei der Umsetzung von Aufgaben, die die Verfügbarkeit kritischer Prozesse beeinträchtigen. Eine sorgfältige Einführung kann dagegen das Verständnis für Sicherheitsregeln fördern, den verantwortungsvollen Umgang mit sensiblen Informationen stärken und die Bindung der Mitarbeitenden an die Institution erhöhen. Um die Anforderung umzusetzen, kann die Institution verschiedene Maßnahmen kombinieren: (1) ein strukturiertes Onboarding-Dokument, das die wichtigsten Systeme, Zugriffsrechte und Sicherheitsrichtlinien erklärt, (2) eine begleitende Einführung durch erfahrene Kolleginnen und Kollegen, die praxisnahes Wissen vermitteln, (3) die direkte Integration sicherheitsrelevanter Hinweise in den Arbeitsalltag, etwa durch kurze Erläuterungen beim erstmaligen Zugriff auf sensible Anwendungen oder beim Anlegen von Berechtigungen. Ergänzend kann eine Checkliste genutzt werden, um sicherzustellen, dass alle relevanten Schritte nachvollziehbar abgeschlossen werden. Auch ein „Paten-System“ kann eingesetzt werden, bei dem neue Mitarbeitende für die ersten Wochen eine feste Ansprechperson haben, die Fragen klärt und auf mögliche sicherheitsrelevante Stolperfallen hinweist.</p></td></tr></table><h2>PERS.4: Personalentwicklung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERS.4.1: Qualifikationsbedarf</td><td><p>Personal für Mitarbeitende SOLLTE den Bedarf an Qualifikationsmaßnahmen anhand der Aufgaben <i>regelmäßig</i> überprüfen.</p></td><td><p>Qualifikationsmaßnahmen sind z.B. Zertifizierte Weiterbildungen, interne Schulungen oder universitäre Kurse. Prüfen Sie den Bedarf anhand der Aufgaben der Mitarbeitenden und berücksichtigen Sie dabei die in den Geschäftsprozessen verwendeten IT-Produkte. Zweckmäßig ist es hierzu in jedem Team einen Jahresplan zur Teilnahme an Qualifikationsmaßnahmen zu erstellen.</p></td></tr><tr valign="top"><td>PERS.4.2: Rollenspezifische Schulungen und Sensibilisierungen</td><td><p>Personal für Nutzende SOLLTE rollenspezifische Schulungen und Sensibilisierungen im Einklang mit den Anforderungen der Praktik Sensibilisierung bei Neuzugang und <i>regelmäßig</i> ausführen.</p></td><td><p>Neue Mitarbeitende könnten ohne gezielte Einführung unbewusst vertrauliche Informationen preisgeben, unsichere Passwörter wählen oder Phishing-Mails öffnen, da ihnen relevante Schutzprinzipien oder Gefährdungen im Kontext ihrer Tätigkeit nicht bekannt sind. Ebenso könnte es bei länger Beschäftigten zu einer „Routineblindheit“ kommen, sodass beispielsweise ungewöhnliche Systemmeldungen nicht mehr ernst genommen oder sensible Daten versehentlich an unberechtigte Personen weitergegeben werden. „Rollenspezifisch“ bedeutet in diesem Zusammenhang, dass die Inhalte der Schulung auf die jeweilige Tätigkeit zugeschnitten werden – eine Person im IT-Bereich benötigt z. B. andere Sicherheitskenntnisse als jemand im Vertrieb oder in der Verwaltung. Beispiele für rollenspezifische Schulungen sind Kurse zum sicheren IT-Betrieb für Administrierende, OWASP® Top 10 Training für Webentwickler und Social Engineering Abwehrtraining für die Institutionsleitung. Eine Institution kann diese Anforderung etwa umsetzen, indem sie standardisierte E-Learning-Module bereitstellt, die durch kurze Praxisszenarien ergänzt werden. Hilfreich ist, die Dauer der Formate überschaubar zu halten, um die Akzeptanz hoch zu halten, und die Wirksamkeit regelmäßig durch Feedback oder kleine Tests zu prüfen. Ebenso kann es sinnvoll sein, Fachbereiche in die Ausgestaltung einzubinden, damit Beispiele und Szenarien aus dem tatsächlichen Arbeitsalltag stammen. Mitarbeitende, die bereits eine passende Qualifikation erworben haben, können von der Schulung ausgenommen werden.</p></td></tr><tr valign="top"><td>PERS.4.2.1: Produktspezifische Schulungen und Sensibilisierungen</td><td><p>Personal für Administrierende SOLLTE produktspezifische Schulungen zum Umgang mit administrativen Werkzeugen bei Neuzugang und dem Einsatz neuer IT-Produkte ausführen.</p></td><td><p>Ziel ist es, den sicheren Umgang mit den in der Institution genutzten administrativen Werkzeugen zu erlernen (z.B. dem genutzten Verzeichnisdienst, Kommandozeilenbefehlen der genutzten Betriebssysteme, Wireshark oder Netzmanagement-Software). Hierzu gehört die Bedienung der jeweiligen Werkzeuge, Aspekte der sicheren Nutzung wie Verschlüsselung und Authentifizierung, die Vermeidung typischer Fehler, sowie der Umgang mit typischen Problemstellungen (Bugfixing). Verfügt die jeweilige Person bereits nachweislich über die Kenntnisse (z.B. passendes Zertifikat) so ist die Schulung für diese Person entbehrlich.</p></td></tr></table><h2>PERS.5: Personalbetreuung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERS.5.1: Maßregelung</td><td><p>Personal SOLLTE ein Verfahren zur Maßregelung verankern.</p></td><td><p>Legen Sie fest unter welchen Voraussetzungen (z.B. Benennung konkreter Pflicht, Nachweis des Verstoßes) welche Maßregelungsmaßnahmen zu ergreifen sind, wenn Mitarbeitende gegen Anweisungen zur Informationssicherheit verstoßen. Maßnahmen können von Mitarbeitergesprächen über der Entzug der Berechtigung zum Zugriff auf vertrauliche Daten bis hin zu Abmahnungen oder Kündigungen reichen. Für arbeitsrechtliche Maßnahmen gilt der Grundsatz der Verhältnismäßigkeit und das Verbot der Maßregelung bei zulässiger Rechtsausübung. Aufgrund des engen Bezugs zum Arbeitsrecht ist im Zweifel eine Rechtsberatung empfehlenswert.</p></td></tr><tr valign="top"><td>PERS.5.2: Innentäter</td><td><p>Personal SOLLTE ein interdisziplinäres Verfahren zum Umgang mit potenziellen Innentätern verankern.</p></td><td><p>Ein interdisziplinäres Verfahren zum Umgang mit potenziellen Innentätern integriert technische Aspekte und organisatorische Aspekte um zielgerichtete Verstöße durch Innentäter so früh wie möglich aufzuspüren und umfassend zu behandeln. Hierzu können beispielsweise die Analyse von Protokollen sowie der Einsatz technischer Detektionssysteme zur Identifikation unerlaubter Nutzung herangezogen werden. Ergänzend dazu dienen organisatorische Meldewege dazu, frühzeitig auf Anzeichen einer länger andauernden systemischen Unzufriedenheit bei Mitarbeitenden reagieren zu können. Maßnahmen bei Aufdeckung können von Mitarbeitergesprächen über den Entzug der Berechtigung zum Zugriff auf vertrauliche Daten bis hin zu Abmahnungen oder Kündigungen reichen. Berücksichtigen Sie bei der Festlegung die Persönlichkeitsrechte der Mitarbeitenden, insbesondere hinsichtlich Arbeitsüberwachung. Aufgrund des engen Bezugs zum Arbeitsrecht ist im Zweifel eine Rechtsberatung empfehlenswert.</p></td></tr><tr valign="top"><td>PERS.5.3: Vertrauens-Check sicherheitskritischer Rollen</td><td><p>Personal SOLLTE die Vertrauenswürdigkeit für <i>definierte sicherheitskritische Rollen</i> <i>regelmäßig</i> und anlassbezogen überprüfen.</p></td><td><p>Die Vertrauenswürdigkeit bezeichnet im hier relevanten Kontext die Eignung und persönliche Integrität von Personen, die in besonders sicherheitskritischen Rollen tätig sind – also Funktionen mit erweiterten Zugriffsrechten, administrativen Befugnissen oder Zugang zu sensiblen Informationen und Systemen. Sicherheitskritische Rollen können beispielsweise Systemadministratoren, Personal mit privilegierten Rechten in Cloud-Diensten oder Mitarbeitende im Finanz- und Abrechnungswesen sein. Regelmäßig bedeutet in diesem Zusammenhang, dass eine Überprüfung nicht nur einmalig bei Einstellung, sondern in sinnvollen zeitlichen Abständen erfolgen kann – etwa alle zwei bis drei Jahre oder anlassbezogen, zum Beispiel bei Beförderungen oder einem Wechsel in eine sicherheitsrelevante Funktion. Der Sinn dieser Anforderung liegt darin, Risiken wie Insider-Bedrohungen, Manipulationen oder unbefugte Informationsweitergabe frühzeitig zu reduzieren. So könnte ein Mitarbeiter mit verschuldeten privaten Verhältnissen erpressbar werden und vertrauliche Daten weitergeben, wohingegen eine erneute Vertrauensprüfung kann frühzeitig auffällige Entwicklungen sichtbar machen und das Sicherheitsniveau stabilisieren. Eine Umsetzung kann durch verschiedene Maßnahmen erfolgen, die sowohl technische als auch prozessuale Ansätze kombinieren. Institutionen können beispielsweise (1) Selbstauskünfte oder aktuelle Führungszeugnisse anfordern, (2) regelmäßige Abgleiche mit internen HR-Daten wie Abmahnungen oder Compliance-Verstößen durchführen und (3) strukturierte Interviews oder Fragebögen einsetzen, die Veränderungen in der Lebenssituation mit Relevanz für die Vertrauenswürdigkeit adressieren. Ergänzend kann eine technische Unterstützung durch revisionssichere Dokumentation in HR-Systemen erfolgen, sodass jede Überprüfung nachvollziehbar bleibt. Ein pragmatischer Tipp ist es, Überprüfungen an ohnehin bestehende HR-Prozesse – etwa jährliche Mitarbeitergespräche oder Rezertifizierungen von Zugriffsrechten – anzubinden, um sie effizient und konsistent in den Betriebsablauf zu integrieren. Auf diese Weise kann die Institution die Anforderung praxisnah erfüllen und gleichzeitig den administrativen Aufwand geringhalten.</p></td></tr></table><h2>PERS.6: Weggang von Mitarbeitenden</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>PERS.6.1: Weggang</td><td><p>Personal für Nutzende SOLLTE eine Vorgehensweise für den Weggang verankern.</p></td><td><p>Wenn Nutzende ohne gesteuertes Vorgehen aus dem Informationsverbund ausscheiden, könnten Zugänge oder Aufgaben unkontrolliert zurückgelassen werden, oder Informationen ungewollt an Dritte abfließen. Hierzu gehört z.B. Mitarbeitende an die Wahrung von Betriebs- und Geschäftsgeheimnissen zu erinnern. Außerdem sind von ausscheidenden Mitarbeitenden alle im Rahmen ihrer Tätigkeit erhaltenen Unterlagen, Schlüssel und Geräte sowie Ausweise und Zutrittsberechtigungen einzuziehen. Hierbei besteht ein enger Zusammenhang zum Berechtigungsmanagement.</p></td></tr><tr valign="top"><td>PERS.6.1.1: Entzug von Berechtigungen</td><td><p>Personal für Nutzende SOLLTE bei Weggang den unverzüglichen Entzug aller Zugriffsrechte im Einklang mit den Regelungen und Verfahren zum Berechtigungs- und Identitätsmanagement verankern.</p></td><td><p>Der unverzügliche Entzug bedeutet in diesem Kontext die sofortige und vollständige Deaktivierung aller Zugriffsrechte, sowohl auf physische Ressourcen (z. B. Gebäude, Serverräume, Schränke mit vertraulichen Unterlagen) als auch auf logische Systeme (z. B. Benutzerkonten in E-Mail-Diensten, ERP-Systemen, Cloud-Speichern). Physische Zugriffsrechte umfassen Schlüssel, Zugangskarten oder Codes, die eine Person nutzen kann, um in geschützte Bereiche zu gelangen. Logische Zugriffsrechte beziehen sich auf digitale Berechtigungen wie Passwörter, Tokens, VPN-Profile oder Single-Sign-On-Zugänge. Der Sinn dieser Vorgabe liegt darin, das Risiko unbefugter Zugriffe nach dem Ausscheiden von Mitarbeitenden oder externen Nutzenden zu minimieren. Ein entlassener Mitarbeitender könnte ansonsten noch Daten aus einer Cloud-Anwendung kopieren oder mit einer Zutrittskarte ein Rechenzentrum betreten. Werden die Rechte dagegen sofort entzogen, kann die Institution die Vertraulichkeit und Integrität sensibler Informationen sichern und zugleich Haftungsrisiken reduzieren. Eine Institution kann diese Anforderung durch abgestimmte technische und prozessuale Maßnahmen umsetzen. Dazu kann ein standardisierter Offboarding-Prozess etabliert werden, der mit der Personalabteilung synchronisiert ist und automatisch IT und Facility-Management informiert.</p></td></tr><tr valign="top"><td>PERS.6.1.2: Neubesetzung</td><td><p>Personal für Mitarbeitende SOLLTE bei Weggang frei gewordene Zuständigkeiten zuweisen.</p></td><td><p>Stellen Sie sicher, dass durch den Weggang von Mitarbeitenden keine Aufgaben des ISMS verwaisen – auch nicht bis zu einer geplanten Neueinstellung. Ordnen Sie stattdessen die Zuständigkeit für die Aufgaben/Rollenunverzüglich bestehendem Personal zu. Achten Sie dabei auch darauf, dass die festgelegten Rollentrennungen dabei nicht aufgehoben, bzw. durchbrochen werden. Um eine kontinuierliche Bearbeitung von Aufgaben sicherzustellen, ist eine Übergabe sinnvoll.</p></td></tr></table><h1>BES: Beschaffungsmanagement</h1><p>Die Praktik Beschaffungsmanagement sorgt für die frühzeitige Integration von Informationssicherheit in fachliche Anforderungs-, Planungs- und Beschaffungsverfahren, einschließlich angehender Projekte.  Dabei erfolgt keine Unterscheidung zwischen den Bereichen Organisation, Personal, Dienstleister, IT-Infrastruktur, Komponenten oder Gebäuden. Ziel ist es, Sicherheitsanforderungen frühzeitig in die strategische Planung einzubinden – von der <b>„Make-or-Buy“</b>-Entscheidung bis hin zur konkreten Beschaffung.  Während die Praktik Compliance sich explizit auf Anforderungen auf die Informationssicherheit konzentriert, umfasst das Beschaffungsmanagement alle fachlichen, regulatorischen und technischen Anforderungen, die in die Organisation, Personal-, Dienstleisterverträge, IT-Infrastruktur, Komponenten und Gebäude integriert werden müssen.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>BES.1: Grundlagen</td><td align="right">12</td></tr><tr valign="top"><td>BES.2: Bedarfserfassung</td><td align="right">12</td></tr><tr valign="top"><td>BES.3: Auswahl von Lieferanten</td><td align="right">5</td></tr><tr valign="top"><td>BES.4: Auswahl von Produkten und Dienstleistungen</td><td align="right">18</td></tr><tr valign="top"><td>BES.5: Auswahl von Produkten und Dienstleistungen - Zusammenarbeit</td><td align="right">27</td></tr><tr valign="top"><td>BES.6: Auswahl von Produkten und Dienstleistungen - Kündigung</td><td align="right">7</td></tr><tr valign="top"><td>BES.7: Abnahme</td><td align="right">19</td></tr><tr valign="top"><td>BES.8: Kompensierende Kontrollmechanismen</td><td align="right">5</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>105</b></td></tr></table><h2>BES.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.1.1: Verfahren und Regelungen</td><td><p>Beschaffungsmanagement MUSS Verfahren und Regelungen zur Beschaffung von IT-Produkten und Dienstleistungen verankern.</p></td><td><p>Relevant sind hierbei sowohl Beschaffungen von Produkten und Dienstleistungen für den internen Betrieb als auch Verträge bei denen Informationen für die Instiution extern verarbeitet werden, z.B. Cloud-Dienstleistungen. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>BES.1.1.1: Dokumentation</td><td><p>Beschaffungsmanagement MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>BES.1.1.2: Zuweisung der Aufgaben</td><td><p>Beschaffungsmanagement MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>BES.1.1.3: Bekanntgabe</td><td><p>Beschaffungsmanagement MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>BES.1.2: Regelmäßige Überprüfung</td><td><p>Beschaffungsmanagement MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr><tr valign="top"><td>BES.1.3: Lieferanten- und Dienstleisterverzeichnis</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE alle direkten Zulieferer und Dienstleister inklusive der jeweiligen Kontaktdaten und den bezogenen Lieferungen dokumentieren.</p></td><td><p>Direkte Zulieferer sind hier alle Vertragspartner, von denen IT-Produkte bezogen werden. Dienstleister sind alle Vertragspartner, die schützenswerte Informationen des Informationsverbundes verarbeiten.</p></td></tr><tr valign="top"><td>BES.1.3.1: Gesamte Lieferkette</td><td><p>Beschaffungsmanagement für Einkäufe KANN die gesamte Lieferkette inklusive der jeweiligen Unterauftragnehmer und deren Kontaktdaten dokumentieren.</p></td><td><p>Sicherheitsvorfälle können nicht nur auf direkter Ebene entstehen, sondern werden häufig durch nachgelagerte Dienstleister oder Unterlieferanten verursacht – etwa wenn ein Unterauftragnehmer unzureichende Sicherheitsmaßnahmen umsetzt, kritische Softwarekomponenten fehlerhaft bezieht oder sensible Daten bei einem Subdienstleister unkontrolliert verarbeitet werden. Ein solches Ereignis könnte sich durch Lieferausfälle, den Einschleusung kompromittierter Hard- oder Software oder auch durch den Verlust von Betriebsgeheimnissen bemerkbar machen. Nur wenn eine Institution die gesamte Kette kennt, kann sie Schwachstellen lückenlos erkennen, Abhängigkeiten bewerten und im Bedarfsfall schneller reagieren, etwa indem bei Störungen alternative Bezugsquellen aktiviert werden. Die (ja fortlaufend zu gewährleistende) Dokumentation der gesamten Lieferkette ist allerdings auch mit großem Aufwand verbunden und setzt auch die Bereitschaft zur Mitwirkung in der gesamten Lieferkette voraus.</p></td></tr><tr valign="top"><td>BES.1.4: Outsourcing-Strategie</td><td><p>Beschaffungsmanagement für Outsourcing KANN eine Strategie mit Zielen, Chancen und Risiken des Outsourcings verankern.</p></td><td><p>Outsourcing-Strategie bezeichnet hierbei die von der Institution festgelegten Grundsätze, Entscheidungskriterien und Grenzen für die Auslagerung von Leistungen. Die Strategie beinhaltet z.B. die Entscheidung über die Art und den Scope des Outsourcings und welche Arten von Anwendungen/Daten oder Prozessen ausgelagert werden. Bei einem Outsourcing in die Cloud wäre hier z.B. über <b>„cloud only, cloud first, some cloud, no cloud“</b> und bei der Bereitstellungsart über <b>„Saas, PaaS, IaaS“</b> etc. zu entscheiden. Typische Risiken sind versteckte Kosten, unklare Zuständigkeiten (<b>„Verantwortungsdiffusion“</b>) durch gemeinsame Verantwortlichkeit mit dem Dienstleister für die Informationssicherheit (Shared Responsibility), Verlust von eigenem Knowhow, Abhängigkeit vom Anbietenden von Outsourcing, Verlust von Kontroll- und Steuerungsmöglichkeiten, Einblicke Dritter in interne Betriebsabläufe und Daten. Ziele beinhalten unter anderem auch die angestrebten Sicherheitsziele, z.B. <b>„bei Bearbeitung von VS-NfD Inhalten die Einhaltung der VSA“</b>. Chancen können z.B. in einer schnelleren Einführung neuer Technologien, einer höheren Flexibilität bei Lastspitzen, einer verbesserten Verfügbarkeit durch die Infrastruktur des Dienstleisters oder in Kostenersparnissen durch Skaleneffekte liegen. Im Cloud-Kontext ergeben sich zudem Möglichkeiten wie eine weltweite Standortunabhängigkeit, einfachere Anbindung verteilter Teams oder die Nutzung spezialisierter Sicherheits- und Compliance-Services, die intern nur mit erheblichem Aufwand aufgebaut werden könnten.</p></td></tr><tr valign="top"><td>BES.1.4.1: Freigabe der Strategie</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE die Strategie durch die Institutionsleitung autorisieren.</p></td><td><p>Ziel ist es sicherzustellen, dass Auslagerungen dem Risikoverständnis, den gesetzlichen Rahmenbedingungen und den geschäftlichen Zielen entsprechen und Verantwortlichkeiten eindeutig verankert sind. Fehlende oder uneinheitliche Leitentscheidungen könnten zu Schattenbeschaffungen, regulatorischen Beanstandungen, Konzentrationsrisiken oder unkontrollierten Datenabflüssen führen; etwa könnte ein Fachbereich ohne strategischen Rahmen einen Dienst in einer problematischen Jurisdiktion beauftragen oder mehrere kritische Leistungen bei einem einzigen Anbieter bündeln, was bei dessen Ausfall zu erheblichen Betriebsunterbrechungen führen könnte.</p></td></tr><tr valign="top"><td>BES.1.5: Autorisierung des Bereitstellungsmodells</td><td><p>Beschaffungsmanagement für Cloud-Dienste SOLLTE für jeden Cloud-Dienst das Bereitstellungsmodell durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Hiermit ist die bewusste Entscheidung für ein Modell und die konzeptionelle Umsetzung (<b>„Shared Responsibility“</b>) dieser Entscheidung gemeint. Bereitstellungsmodelle sind z.B.: Public Cloud, Private Cloud, Community Cloud, Hybrid Cloud. Es kann in der Praxis aber zu dadurch nicht abgedeckten Varianten, wie z. B. <b>„Virtual Private Cloud“</b> kommen. Die Anforderung ist erst dann umgesetzt, wenn auch zwischen den Vertragspartnern das Bereitstellungsmodell explizit vereinbart ist, so dass die Verteilung der Verantwortlichkeiten (Shared Responsibility) für Schutzmaßnahmen zwischen Institution und Dienstleister klar geregelt ist.</p></td></tr><tr valign="top"><td>BES.1.6: Dokumentation des Bereitstellungsmodells</td><td><p>Beschaffungsmanagement für Cloud-Dienste SOLLTE für jeden Cloud-Dienst das gewünschte Bereitstellungsmodell mit Ausführung der geteilten Verantwortlichkeiten dokumentieren.</p></td><td><p>Hiermit ist die bewusste Entscheidung für ein Modell und die konzeptionelle Umsetzung (<b>„Shared Responsibility“</b>) dieser Entscheidung gemeint. Bereitstellungsmodelle sind z.B.: Public Cloud, Private Cloud, Community Cloud, Hybrid Cloud. Es kann in der Praxis aber zu dadurch nicht abgedeckten Varianten, wie z. B. <b>„Virtual Private Cloud“</b> kommen.</p></td></tr><tr valign="top"><td>BES.1.7: Vereinbarung der geteilten Verantwortung</td><td><p>Beschaffungsmanagement für Cloud-Dienste SOLLTE für jeden Cloud-Dienst mit dem Anbieter die geteilte Verantwortung vereinbaren.</p></td><td><p>Die Anforderung ist erst dann umgesetzt, wenn auch zwischen den Vertragspartnern das Bereitstellungsmodell explizit vereinbart ist, so dass die Verteilung der Verantwortlichkeiten (Shared Responsibility) für Schutzmaßnahmen zwischen Institution und Dienstleister klar geregelt ist.</p></td></tr></table><h2>BES.2: Bedarfserfassung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.2.1: Erfassung des Bedarfes</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE den Bedarf anhand einer Leistungsbeschreibung oder einer Umsetzungsstrategie dokumentieren.</p></td><td><p>Dies umfasst sowohl Bedürfnisse für eine sichere Funktionalität als auch nicht-funktionalen Bedarf wie Datensicherung und Einbindung in das Monitoring.</p></td></tr><tr valign="top"><td>BES.2.1.1: Verwendungszweck</td><td><p>Beschaffungsmanagement für IT-Produkte SOLLTE den Verwendungszweck dokumentieren.</p></td><td><p>Relevant kann hierbei beispielsweise sein, ob es verschiedene Einsatzszenarien (z.B. Innen- und Außendienst) gibt.</p></td></tr><tr valign="top"><td>BES.2.1.2: Geschäftsprozessprofile</td><td><p>Beschaffungsmanagement für Outsourcing KANN Geschäftsprozessprofile für (Teil-)Prozesse, die ausgelagert werden, mit Funktion, verarbeiteten Informationen, einzuhaltenden rechtlichen und organisatorischen Rahmenbedingungen, prozessualen Schnittstellen, Abhängigkeiten zwischen Prozessen, sowie ihren Schutzbedarfen und Kritikalitäten dokumentieren.</p></td><td><p>Ist bereits eine Business-Impact-Analyse (BIA) vorhanden, welche die Angaben enthält, so kann die Anforderung durch die BIA erfüllt werden. Kritikalität bezeichnet die Bedeutung eines Prozesses für den Geschäftsbetrieb der Institution. Die Umsetzung kann auch  durch eine Tabelle von Geschäftsprozessprofilen geschehen.</p></td></tr><tr valign="top"><td>BES.2.1.3: Systemvoraussetzungen</td><td><p>Beschaffungsmanagement für Anwendungen SOLLTE Systemvoraussetzungen dokumentieren.</p></td><td><p>Hierzu können sowohl Hardwareparameter gehören (z.B. 8 GB RAM, TPM 2.0), als auch Voraussetzungen an Betriebssysteme (z.B. Lauffähigkeit nur auf bestimmten Betriebssystemen oder bei Unterstützung bestimmter Funktionen), auf denen der Einsatz geplant ist.</p></td></tr><tr valign="top"><td>BES.2.1.4: Kompatibilität</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE den Bedarf für die Kompatibilität mit der bestehenden Infrastruktur im Hinblick auf die Schnittstellen, die Netzanbindung, das Administrationsmodell und das Datenmanagementmodell dokumentieren.</p></td><td><p>Werden Beschaffungen ohne Betrachtung der Kompatibilität zur angebundenen Infrastruktur vorgenommen, kann es zu unvorhergesehenen Wechselwirkungen zwischen Komponenten kommen. Durch die steigende Komplexität von Infrastrukturen wächst auch das Risiko solcher Inkompatibilitäten oder Fehlerbilder. Zur relevanten Infrastruktur können je nach Einsatzzweck z.B. der Verzeichnisdienst, die Protokollierung von Ereignissen, das Monitoring oder der Datenspeicher gehören. Soweit möglich, ist es sinnvoll, zur Anbindung anerkannte Standards zu nutzen, z.B. REST-API und HTTPS für die Schnittstellen, TCP/IP und Ethernet (IEEE 802.3) für die Netzanbindung, SSH für die Administration sowie SQL oder JSON für das Datenmanagement.</p></td></tr><tr valign="top"><td>BES.2.1.5: Lizenzierung</td><td><p>Beschaffungsmanagement für Anwendungen SOLLTE für den geplanten Einsatzzeitraum erforderliche Lizenzen dokumentieren.</p></td><td><p>Lizenzen sind erforderlich, wenn sie für den Einsatz der geplanten Anwendung benötigt werden. Hierbei können sowohl Softwarelizenzen für die Anwendung selbst als auch begleitende Lizenzen, z.B. für Protokollierungssysteme oder Cloud-Schnittstellen gehören. Die Lizenzierung ist ausreichend, wenn voraussichtlich für alle anfallenden Arbeiten genug Zugänge und IT-Systeme über den geplanten Einsatzzeittraum verfügbar sind. Denken Sie auch daran, welche Funktionen unter welcher Lizenz vom Anbieter freigeschaltet und erlaubt sind.</p></td></tr><tr valign="top"><td>BES.2.1.6: Support- und Wartungsverträge</td><td><p>Beschaffungsmanagement für IT-Produkte SOLLTE den Bedarf an Support- und Wartungsverträgen basierend auf dem Schutzbedarf für Verfügbarkeit dokumentieren.</p></td><td><p>Dies zielt auf den Abschluss von Support- und Wartungsverträgen für alle IT-Produkte ab, deren Verfügbarkeit nicht durch die Institution allein sichergestellt werden kann. Zur Ermittlung des Bedarfes können die Empfehlungen des jeweiligen Anbieters zu Wartungsintervallen herangezogen werden. Dabei kann es vorkommen, dass unterschiedliche Komponenten durchaus unterschiedliche Wartungsintervalle benötigen.</p></td></tr><tr valign="top"><td>BES.2.2: Dokumentation des Rechtsraums und der Datenlokation</td><td><p>Beschaffungsmanagement für Cloud-Dienste SOLLTE Rechtsraum und Datenlokation dokumentieren.</p></td><td><p>Beispielsweise könnte die Datenlokation auf europäische Standorte eingeschränkt sein, während der Anbieter seinen Hauptsitz im außereuropäischen Rechtsraum hat und daher nicht der DSGVO unterliegt. Werden keine Daten aus dem Informationsverbund verarbeitet, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>BES.2.3: Vereinbarung des Rechtsraums und der Datenlokation</td><td><p>Beschaffungsmanagement für Cloud-Dienste KANN Rechtsraum und Datenlokation mit dem Anbieter vereinbaren.</p></td><td><p>Beispielsweise könnte die Datenlokation auf europäische Standorte eingeschränkt sein, während der Anbieter seinen Hauptsitz im außereuropäischen Rechtsraum hat und daher nicht der DSGVO unterliegt. Werden keine Daten aus dem Informationsverbund verarbeitet, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>BES.2.4: Anhörung Nutzender</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Nutzende bei der Bedarfserfassung anhören.</p></td><td><p>Werden IT-Produkte oder Dienstleistungen für eine Zielgruppe beschafft, so ist es zweckmäßig, Vertreter dieser Zielgruppe in die Erhebung der Beschaffungskriterien mit einzubeziehen. Dies kann durch die Anhörung aller potenziellen Nutzer, z.B. durch eine Umfrage, oder durch die Anhörung bestimmter Personen oder Rollen aus dem Kreis der Nutzenden (z.B. Fachverantwortliche, Testgruppen oder Stichproben) erfolgen.</p></td></tr><tr valign="top"><td>BES.2.5: Anhörung Adminstrierender</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Administrierende bei der Bedarfserfassung anhören.</p></td><td><p>Ohne diese Einbindung könnte etwa eine Fachabteilung Systeme einkaufen, die keine sicheren Schnittstellen bieten, nicht mit bestehenden Sicherheitsrichtlinien kompatibel sind oder schwer zu administrieren sind, was später zu kostspieligen Nacharbeiten oder Sicherheitslücken führen könnte. Eine rechtzeitige Beteiligung kann hingegen gewährleisten, dass Produkte aus administrativer Sicht wartbar, updatefähig und kompatibel mit etablierten Sicherheitsmechanismen sind. Die Anforderung kann durch verschiedene Maßnahmen praktisch umgesetzt werden: (1) Ein definiertes Beschaffungsformular kann Eingabefelder enthalten, in denen die fachliche Einschätzung von Administrierenden dokumentiert werden kann. (2) Eine Checkliste mit Mindestkriterien wie Updatefähigkeit, Protokollierungsoptionen oder Berechtigungssteuerung kann bei jeder Bedarfserfassung hinzugezogen werden. (3) Ein kurzer, standardisierter Freigabeprozess über ein Ticket- oder Workflow-System kann sicherstellen, dass vor der endgültigen Beschaffung eine Rückmeldung aus administrativer Sicht eingeholt wird. (4) Zur Effizienzsteigerung kann eine Wissensdatenbank mit Erfahrungswerten zu bereits genutzten Produkten gepflegt werden, sodass Administrierende wiederkehrende Anforderungen schneller einschätzen können.</p></td></tr><tr valign="top"><td>BES.2.6: Outsourcing auf Grundlage der Geschäftsprozessprofile</td><td><p>Beschaffungsmanagement für Outsourcing KANN Outsourcingverträge auf Grundlage der Geschäftsprozessprofile durch die Leitung autorisieren.</p></td><td><p>Das Outsourcing eigener (Teil-)Prozesse ist eine bewusste und häufig folgenreiche Entscheidung - auch für die die eigene Kontrolle der Informationssicherheit. Die Entscheidung kann sich am festgestellten Schutzbedarf oder Risikoprofil der Institution und der betroffenen Geschäftsprozesse orientieren. Die Entscheidung durch die Leitung bezieht sich hier auf die Frage, ob Outsourcing von der Institution grundsätzlich gewollt ist und welche (Teil-)Prozesse ausgelagert werden können oder in der Institution verbleiben. Diese kann konkrete Geschäftsprozesse benennen, aber auch anhand allgemeiner Kriterien getroffen werden (z.B. Keine Auslagerung von Geschäftsprozessen mit hohem Schutzbedarf).</p></td></tr></table><h2>BES.3: Auswahl von Lieferanten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.3.1: Klassifizierung von Lieferantenbeziehungen</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Lieferantenbeziehungen einer Klasse zuweisen.</p></td><td><p>Klasse meint hier eine Einstufung der Lieferantenbeziehung aus dem Blickwinkel der Informationssicherheit. Dies ermöglicht den Mitarbeitern der Institution eine schnelle und korrekte Abschätzung, welche Informationen dem Lieferanten gegenüber preisgegeben werden dürfen. Die Klassen können sowohl anhand einer Einstufung der Daten (z.B. Preisgabe von Verschlussachen oder nicht), als auch anhand der Funktion aus Sicht der Institution (z.B. Finanzdienstleister, Versorgungseinrichtungen, Cloud, Logistik, Lieferant von IT-Produkten) gewählt werden. Es empfiehlt sich auch das Herkunftsland oder nachrichtendienstliche Erkenntnisse über den Lieferanten mit in die Bewertung einfließen zu lassen.</p></td></tr><tr valign="top"><td>BES.3.2: Auswahlkriterien</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE die Auswahl von Lieferanten anhand von Kriterien zu ihrer Verlässlichkeit verankern.</p></td><td><p>Beispielsweise durch Marktanalysen, Kundenreferenzen, Zertifizierungen, Begutachtungen oder Audits. Hierzu können z.B. Entwicklungsprozesse, Verschlüsselung oder Anonymisierung vertraulicher Daten, Schlüsselmanagement, Authentifizierung von Zugriffen, Wiederherstellung nach Vorfällen oder die Evaluation der sicheren Verarbeitung gehören. Auch die Prüfung auf finanzielle Stabilität des Lieferanten ist zu empfehlen. Ein finanziell instabiler Lieferant stellt ein erhebliches Risiko für die Geschäftskontinuität dar, da er möglicherweise den Betrieb einstellt, Supportleistungen nicht mehr erbringen kann oder von einem Unternehmen mit unklaren Sicherheitsstandards übernommen wird.</p></td></tr><tr valign="top"><td>BES.3.2.1: Zertifizierte Lieferanten</td><td><p>Beschaffungsmanagement für Einkäufe KANN die Auswahl von Lieferanten anhand von Zertifikaten, Testaten oder Vergleichbarem verankern.</p></td><td><p>Ein „Zertifikat“ ist in diesem Kontext ein formaler Nachweis durch eine akkreditierte, unabhängige Stelle, dass bestimmte Anforderungen oder Standards erfüllt werden (z. B. ISO/IEC-Normen). Ein „Testat“ kann die schriftliche Bestätigung einer fachkundigen Prüfstelle darstellen, dass ein Prozess oder System in definierten Punkten geprüft und als konform bewertet wurde. Vergleichbare Nachweise können Berichte von Audits, externe Gutachten oder auch dokumentierte Ergebnisse standardisierter Sicherheitstests sein. Eine Institution kann die Anforderung konkret umsetzen, indem sie in Ausschreibungen eine Liste akzeptierter Zertifikate (z. B. ISO 27001, ISO 9001, SOC 2), Testate (z. B. C5 für Cloud-Dienste) oder vergleichbarer Nachweise (z. B. Penetrationstest-Reports durch Dritte) benennt. Hilfreich kann es sein, Mindestgültigkeitszeiträume für Nachweise zu definieren, stichprobenartige Plausibilitätsprüfungen der Dokumente vorzunehmen oder in Bewertungsmatrizen höhere Gewichtungspunkte für aktuelle und unabhängige Nachweise zu vergeben. Zusätzlich kann ein einfacher Maßnahmenkatalog etabliert werden, der (1) überprüft, ob Nachweise aktuell und gültig sind, (2) die Relevanz für den konkreten Leistungsumfang bewertet und (3) die Ergebnisse nachvollziehbar dokumentiert, um Entscheidungen transparent und revisionssicher zu halten.</p></td></tr><tr valign="top"><td>BES.3.2.2: Quellendiversifikation</td><td><p>Beschaffungsmanagement für Einkäufe KANN die Auswahl von Lieferanten anhand ihrer Fähigkeit, ihre Bezugsquellen zu diversifizieren und die Bindung an bestimmte Lieferanten zu begrenzen, verankern.</p></td><td><p>Die Fähigkeit zur Diversifizierung von Bezugsquellen bedeutet in diesem Kontext, dass ein Lieferant nicht ausschließlich auf einzelne Hersteller, Produzenten oder Märkte angewiesen ist, sondern alternative Beschaffungswege vorweisen kann. Die Bindung an bestimmte Lieferanten beschreibt eine Abhängigkeit, bei der zentrale Produkte oder Dienstleistungen faktisch nur von wenigen oder gar einem Anbieter bezogen werden können. Der Sinn dieser Anforderung liegt darin, die Risiken eines Vendor lock-in auf Seiten des Lieferanten zu begrenzen: Könnte ein Lieferant aufgrund geopolitischer Spannungen, wirtschaftlicher Probleme oder technischer Abkündigungen sich nicht mehr auf seine Zulieferer verlassen, so könnt er möglicherweise seine Leistungen nicht mehr erbringen, wodurch die Institution ohne Alternativen möglicherweise gravierende Ausfälle erleiden würde. Eine bewusste Auswahl nach Diversifizierungsfähigkeit kann die Versorgungssicherheit erhöhen und kritische Engpässe vermeiden.</p></td></tr><tr valign="top"><td>BES.3.3: Unzuverlässige Lieferanten</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE die Beschaffung aus einer unbekannten oder unzuverlässigen Quelle untersagen.</p></td><td><p>Eine Quelle (z.B. ein Softwarelieferant) ist unzuverlässig, wenn zukünftig mit Verstößen gegen die Schutzziele Vertraulichkeit, Verfügbarkeit oder Integrität durch ihn zu rechnen ist (d.h. eine Prognose der Vertrauenswürdigkeit). Dies ist insbesondere der Fall, wenn erhebliche Verstöße gegen die Schutzziele durch ihn begangen worden sind oder Anzeichen dafür vorliegen, dass bei einer Verwendung mit solchen Verstößen zu rechnen ist.</p></td></tr></table><h2>BES.4: Auswahl von Produkten und Dienstleistungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.4.1: Klassifizierung von Beschaffungsvorhaben</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE dem Beschaffungsvorhaben eine Klasse zuweisen.</p></td><td><p>Hierzu kann auf die Klassifizierung von Informationen zurückgegriffen werden, die vom zu beschaffenden Vertrag betroffen sind.  Oft verfügen Lieferanten über eigene Klassifizierungsschemata, die sie wiederum mit bestimmten Sicherheitsregelungen und -mechanismen verknüpft haben. In diesem Fall bietet sich ein Mapping zwischen den institutionseigenen Klassen und denen des Lieferanten an.  Weitere Informationen zur Festlegung möglicher Kriterien, inklusive einer Risikobeurteilung, können der ISO/IEC 27036-3 entnommen werden.</p></td></tr><tr valign="top"><td>BES.4.2: Dokumentation der Beschaffungskriterien</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE <i>Kriterien</i> für die Beschaffung dokumentieren.</p></td><td><p>Beschaffungskriterien sind nachvollziehbare Bewertungsmaßstäbe, die bei der Anschaffung von IT-Produkten und Dienstleistungen berücksichtigt werden, um sicherzustellen, dass diese den Sicherheitsanforderungen der Institution entsprechen. Sie ergeben sich aus dem erfassten Bedarf (z.B. einer Beschreibung der Funktionen von IT-Produkten oder zu leistenden Diensten), sowie den Sicherheitsanforderungen an das zu beschaffende Produkt oder die Dienstleistung, die über das jeweilige Zielobjekt im Kompendium gefiltert werden können.   Beispiele für Beschaffungskriterien sind die Erfüllung definierter Sicherheitsstandards, Verschlüsselungsfähigkeiten, Authentifizierungsmechanismen, Autorisierungskonzepte, die Stärke der geforderten Mechanismen (z.B. Mehr-Faktor-Authentifizierung), Verfügbarkeitsgarantien (SLAs), Umfang und Qualität der Dokumentation, Regelungen zur Prüfung oder Überwachung der Sicherheitskontrollen, sowie Einsatzbedingungen wie Temperatur oder mobile Konnektivität. Relevant ist dabei der gesamte Lebenszyklus von Vertragsschluss über Entwicklung von Lösungen bis hin zu Regelungen für Kündigungen. Zu den Kriterien können auch Negativkriterien gehören, die eine Beschaffung verhindern würden (z.B. <b>„Keine Komponenten von der unmittelbaren Konkurrenz oder aus Staaten von denen bekannt ist, dass sie Spionage gegen den Sektor der Institution betreiben“</b>). Je nach Beschaffung kann dafür eine Beschreibung von Informationen und Methoden zur Bereitstellung oder zum Abruf der Informationen relevant sein, sowie eine Beschreibung bestimmter technischer Eigenschaften eines Systems oder einer Anwendung.  Zur Umsetzung bietet es sich an, standardisierte Vertragsvorlagen für neue Verträge zu verwenden. Bei individuellen Verträgen, die einzelne Sicherheitskontrollmechanismen festlegen, bietet sich ein Austausch von Beschreibungen der Mechanismen über strukturierte Datenformate wie OSCAL an.  Weitere Informationen zur Festlegung möglicher Kriterien, inklusive einer Risikobeurteilung, können der ISO/IEC 27036-3 entnommen werden.</p></td></tr><tr valign="top"><td>BES.4.3: Beschaffung anhand der Kriterien</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE die Beschaffung anhand der festgelegten Kriterien verankern.</p></td><td><p>Werden Waren, Systeme oder Dienstleistungen ohne überprüfbare Kriterien beschafft, kann dies zu Sicherheitslücken, finanziellen Schäden oder Abhängigkeiten führen. Beispielsweise könnte eine Institution Hardware von einem unbekannten Anbieter erwerben, deren Firmware Schadcode enthält, oder Cloud-Dienste nutzen, die ihre Datenhaltung in unsicheren Rechtsräumen vornehmen. Ebenso könnte ein IT-Dienstleister beauftragt werden, ohne dass geprüft wurde, ob er über angemessene Qualifikationen oder Referenzen verfügt, was im Ernstfall zu Ausfällen oder Datenverlust führen könnte.</p></td></tr><tr valign="top"><td>BES.4.4: Vertragsvorlage für Outsourcing</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE Kriterien für Outsourcing-Dienstleistungen in einer standardisierten Richtlinie für Verträge dokumentieren.</p></td><td><p>Eine standardisierte Richtlinie für Verträge enthält klare grundlegende Kriterien für Verträge mit Anbietenden von Outsourcing , etwa zu Datenlokationen, Test- und Freigabeverfahren, Compliance-Risiken bei Anbietenden von Outsourcing sowie bei Sub-Dienstleistenden, sowie weiteren Aspekte der Informationssicherheit für Outsourcing-Vorhaben. Der besondere Fokus auf Outsourcing ergibt sich daraus, dass hierbei nicht nur Werk- oder Dienstleistungen zugekauft werden, sondern sensible Prozesse oder Daten langfristig aus der direkten Kontrolle der Institution herausgegeben werden. Ohne standardisierte Kriterien könnte ein eigenhändisch formulierter Vertrag z. B. unpräzise Datenschutzregelungen enthalten, was im Vorfallfall dazu führen könnte, dass vertrauliche Daten in ein unsicheres Drittland gelangen oder dass bei Ausfällen keine klaren Eskalationswege bestehen.</p></td></tr><tr valign="top"><td>BES.4.5: Security by Design</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Security by Design vereinbaren.</p></td><td><p>Security by Design gilt als vereinbart, wenn eine Vorgehensweise nach diesem Prinzip oder eine bestimmte Sicherheitsarchitektur Vertragsbestandteil geworden sind,unabhängig von der Frage, von welchem Vertragspartner dies in den Vertrag eingebracht wurde. Zu einer Sicherheitsarchitektur gehören beispielsweise eine Beschreibung der bereitgestellten Schnittstellen und deren Sicherheitsmechanismen, ein Architekturdiagramm, sowie Schemata zum Aufbau von Komponenten oder von Quellcode.</p></td></tr><tr valign="top"><td>BES.4.5.1: Entwicklung nach einem Sicherheitslebenszyklus</td><td><p>Beschaffungsmanagement für IT-Produkte KANN Nachweise zur Entwicklung nach einem Sicherheitslebenszyklus vereinbaren.</p></td><td><p>Nachweis kann z.B. eine Zertifizierung oder vom Lieferanten unabhängige Auditierung sein.</p></td></tr><tr valign="top"><td>BES.4.5.2: Mandantentrennung</td><td><p>Beschaffungsmanagement für Outsourcing KANN eine festgelegte Mandantentrennung vereinbaren.</p></td><td><p>Eine Mandantentrennung bezeichnet die Trennung schützenswerter Daten und Verarbeitungskontexte zwischen verschiedenen Mandanten, also den Kunden des Anbieters. Eine festgelegte Mandatentrennung meint hier, dass der Anbieter Informationen über die von ihm zur Mandantentrennung getroffenen Maßnahmen bereitstellt. Hierzu gehören insbesondere Informationen darüber, welche Daten oder Funktionen als mandantenabhängige oder mandantenübergreifende Daten behandelt werden.</p></td></tr><tr valign="top"><td>BES.4.6: Security by Default</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Security by Default vereinbaren.</p></td><td><p>Der Detaillierungsgrad der Kriterien kann sich hierbei nach Umfang und Klassifizierung der Beschaffung richten. Bei einfachen Beschaffungen von geringer Bedeutung kann es ausreichend sein grundlegende Sicherheitsmechanismen wie Verschlüsselung und  Authentifizierung zu vereinbaren, während bei umfangreichen oder anderweitig risikobehafteten Beschaffungen eine Vereinbarung einzelner Sicherheitsmechanismen sinnvoll ist.</p></td></tr><tr valign="top"><td>BES.4.6.1: Authentifizierung des Kunden</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE eine Authentifizierung vor dem Zugriff auf schützenswerte Informationen oder Dienste vereinbaren.</p></td><td><p>Sinnvoll ist es sich hierbei sich auf konkrete Authentifizierungsmethoden (z.B. Kundenkennwort, OTP oder Passkeys) zu einigen, mit denen authentifiziert wird, bevor der Lieferant jemandem Zugriff auf Daten oder Prozesse wie den Versand einer neuen SIM-Karte gibt, um Angriffe wie SIM Swapping zu verhindern.</p></td></tr><tr valign="top"><td>BES.4.6.2: Verschlüsselung</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE die Verschlüsselung schützenswerter Informationen durch den Anbieter vereinbaren.</p></td><td><p>Hiermit ist die Ablageverschlüsselung (at rest) und die Transportverschlüsselung (in transit) gemeint. Die Transportverschlüsselung ist dabei sowohl für die Verbindung zum Outsourcing-Dienstleister, als auch bei der Übertragung innerhalb des Dienstleisternetzes vorzunehmen.</p></td></tr><tr valign="top"><td>BES.4.6.3: Manipulationsschutz</td><td><p>Beschaffungsmanagement für IT-Produkte KANN Schutzmechanismen gegen Manipulationen auf dem Lieferweg vereinbaren.</p></td><td><p>Bei physischen Produkten können hierfür Siegel oder schwer fälschbare Kennzeichnungen verwendet werden, während bei Software und Daten kryptographische Prüfsummen oder digitale Signaturen eingesetzt werden können.</p></td></tr><tr valign="top"><td>BES.4.7: ISMS beim Dienstleister</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE ein Managementsystem für Informationssicherheit (ISMS) vereinbaren.</p></td><td><p>Ohne klare Vorgaben zum Managementsystem könnte ein Anbieter vertrauliche Daten unverschlüsselt übertragen, Sicherheitslücken in seiner Infrastruktur nicht rechtzeitig schließen oder sicherheitsrelevante Vorfälle nicht transparent melden. Durch abgestimmte Sicherheitsstandards kann dagegen die Vertraulichkeit von Daten gewahrt, die Integrität von Prozessen gesichert und die Nachvollziehbarkeit bei Vorfällen verbessert werden. Das Vorhandensein lässt sich durch ein Zertifikat nachweisen, z.B. nach ISO/IEC 27001:2022 oder BSI IT-Grundschutz.</p></td></tr><tr valign="top"><td>BES.4.8: Konformitätsnachweise</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Nachweise des Lieferanten zur Erfüllung der Sicherheitskriterien vereinbaren.</p></td><td><p>Nachweise können z.B. durch eine passende Zertifizierung (etwa nach IT-Grundschutz bei Dienstleistern oder CCRA bei IT-Produkten), ein Testat (z.B. C5-Testat für Cloud-Anbieter), oder durch die Vorlage von Sicherheitskonzepten, Risikoanalysen und Pentesting-Ergebnissen erbracht werden.</p></td></tr><tr valign="top"><td>BES.4.8.1: Zertifizierung</td><td><p>Beschaffungsmanagement für Einkäufe KANN ein Zertifikat oder Testat nach <i>einem passenden Sicherheitsstandard</i> vereinbaren.</p></td><td><p>Ein Zertifikat ist eine unabhängige Bestätigung der Konformität, die von einer akkreditierten Konformitätsbewertungsstelle (wie z.B. einer Zertifizierungsstelle) ausgestellt wird, nachdem diese die Konformität eines Produkts, einer Dienstleistung, eines Prozesses oder eines Managementsystems mit bestimmten Normen oder Anforderungen bestätigt hat. Die Art des Zertifikates richtet sich dabei nach der Art der geplanten Beschaffung. IT-Produkte können z.B. nach Common Criteria zertifiziert werden. Bei Dienstleistungen kann ein zertifiziertes Managementsystem für Informationssicherheit (nach IT-Grundschutz oder ISO/IEC 27001) vereinbart werden. Ein Testat wäre z.B. C5.</p></td></tr><tr valign="top"><td>BES.4.8.2: Cloud-Konformität</td><td><p>Beschaffungsmanagement für Cloud-Dienste SOLLTE einen Konformitätsnachweis durch Dritte vereinbaren.</p></td><td><p>Beispielsweise durch ein C5 Testat. Hierbei ist zu prüfen, ob der Geltungsbereich und der Schutzbedarf die genutzten Clouddienste erfasst (Auswertung des Nachweises). Dies gilt auch für Subdienstleister.</p></td></tr><tr valign="top"><td>BES.4.8.3: IT-Grundschutz-Analyse der Infrastruktur</td><td><p>Beschaffungsmanagement für Outsourcing KANN eine IT-Grundschutz-Analyse der potenziell zu nutzenden Infrastruktur des Dienstleisters vereinbaren.</p></td><td><p>Bei einer IT-Grundschutz-Analyse im Rahmen des Outsourcings wird an der potenziell zu nutzenden Infrastruktur des Dienstleisters eine IT-Grundschutz-Analyse (Strukturanalyse, Schutzbedarfsfeststellung, …) durchgeführt. Anschließend werden die sich daraus ergebenden Sicherheitsanforderungen als Beschaffungskriterien an den Dienstleister gestellt. Dies bietet sich an, wenn entweder ein besonders hohes Sicherheitsniveau angestrebt wird, oder der Dienstleister bislang über kein ISMS verfügt, obwohl die Institution umfangreiche Prozesse auslagern möchte.</p></td></tr><tr valign="top"><td>BES.4.8.4: Offenlegung der Risikoanalyse</td><td><p>Beschaffungsmanagement für Outsourcing KANN eine Offenlegung der Risikoanalyse aus dem ISMS des Dienstleisters, soweit eine Risikoanalyse nach IT-Grundschutz-Vorgehensweise notwendig ist, vereinbaren.</p></td><td><p>Eine Offenlegung ist hierzu nur erforderlich, soweit die Informationen für die Risikoanalyse des Auftraggebers erforderlich sind.</p></td></tr><tr valign="top"><td>BES.4.9: Sicherheitsüberprüfung</td><td><p>Beschaffungsmanagement für Einkäufe KANN Sicherheitsüberprüfungen für Personen, die vom Lieferanten mit der Vertragsdurchführung beauftragt werden, vereinbaren.</p></td><td><p>Eine Sicherheitsüberprüfung meint die Verifikation von Personen, beruflicher Qualifikation und Verlässlichkeit von allen Mitarbeitenden mit Zugriff auf schützenswerte Informationen. Die Sicherheitsüberprüfung kann je nach Vereinbarung vom Lieferanten oder dem Auftraggeber ausgeführt werden. Die Verlässlichkeit kann z.B. anhand eines polizeilichen Führungszeugnisses und einer OSINT-Recherche verifiziert werden.</p></td></tr></table><h2>BES.5: Auswahl von Produkten und Dienstleistungen - Zusammenarbeit</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.5.1: Kompetenzen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE Kompetenzen in Informationssicherheit, die von den Mitarbeitern des Lieferanten verlangt werden, vereinbaren.</p></td><td><p>Dient dem Ziel, Risiken durch unzureichend geschultes Personal zu minimieren. Ohne solche Vorgaben könnte es dazu kommen, dass Dienstleister vertrauliche Daten versehentlich preisgeben, schwache Passwörter verwenden oder Phishing-Angriffe nicht erkennen. Durch die Vereinbarung von Mindestkompetenzen kann erreicht werden, dass Dienstleister Sicherheitsrichtlinien verstehen, Bedrohungen frühzeitig identifizieren und im Einklang mit den Schutzinteressen der Institution handeln. Im Kontext bedeutet Kompetenzen in Informationssicherheit, dass Mitarbeiter des Lieferanten über Wissen, Fähigkeiten und Verhalten verfügen, die erforderlich sind, um mit vertraulichen Informationen und IT-Systemen angemessen sicher umzugehen. Dies kann grundlegendes Verständnis für sichere Passwörter und mobile Geräte umfassen, aber auch Kenntnisse zu branchenspezifischen Sicherheitsverfahren oder zum Umgang mit sensiblen Kundendaten. Eine sinnvolle Umsetzung kann zum Beispiel beinhalten, dass die Institution in den Verträgen mit Lieferanten konkrete Mindestanforderungen an Schulungen und Zertifikate definiert, etwa: (1) Einführungsschulungen zu IT-Sicherheitsgrundlagen, (2) regelmäßige Auffrischungen zu Themen wie Social Engineering oder sichere Datennutzung, (3) Nachweise über spezielle Fachkenntnisse, wenn besonders sensible Daten verarbeitet werden. Praktisch kann eine Institution durch standardisierte Schulungsprogramme, die Überprüfung von Zertifikaten (z. B. ISO/IEC- oder BSI-bezogene Qualifikationen) oder durch kurze Wissens-Checks im Rahmen der Dienstleister-Onboarding-Prozesse sicherstellen, dass vereinbarte Kompetenzen tatsächlich vorhanden sind.</p></td></tr><tr valign="top"><td>BES.5.2: Service Level Agreement</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE die Einhaltung einer bestimmten Dienstgüte anhand von <i>Kriterien</i> vereinbaren.</p></td><td><p>Dienstgüte (engl. Service Quality oder Service Level) beschreibt das messbare Leistungsniveau, das ein externer Anbieter dauerhaft erbringen soll. Sie wird üblicherweise in Service Level Agreements (SLA) festgelegt und kann Aspekte wie Reaktionszeiten, Verfügbarkeiten, Fehlerraten oder Sicherheitsstandards betreffen. Die Kriterien können z. B. Verfügbarkeit (in %), maximale Wiederherstellungszeiten (Recovery Time Objective, RTO), Datensicherheitsmaßnahmen, Supportzeiten oder Nachweisintervalle für Penetrationstests sein. Der Zweck dieser Vorgabe liegt darin, Risiken unklarer Leistungs- oder Sicherheitsverantwortung zu vermeiden, die im Falle unpräziser oder fehlender Dienstgütezusagen zu Ausfällen, Datenverlusten oder unzureichenden Sicherheitsreaktionen führen könnten. Eine klar definierte und überprüfbare Dienstgüte kann dagegen Transparenz schaffen, die Vergleichbarkeit von Anbietern erleichtern und die Resilienz ausgelagerter Prozesse erhöhen. Dabei sind möglichst objektivierte, quantitative Kriterien deutlich nachvollziehbarer und eindeutiger als einfache Beschreibungen wie <b>„gut“</b>. Ein Beipiel ist eine Mindestverfügbarkeit von 99% für einen Server, auf dem hochverfügbare Daten gespeichert werden. Neben einzuhaltenden Mindestkriterien bietet es sich hier auch an optionale Qualitätskriterien festzulegen, bei deren Erfüllung höhere Preise akzeptiert werden, um ein <b>„Race to the bottom“</b> im Wettbewerb der Anbieter um die Institution zu vermeiden, da ein rein preisorientierter Wettlauf auf Kosten der Sicherheit gehen könnte.</p></td></tr><tr valign="top"><td>BES.5.3: Compliance-Verpflichtungen</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE die Übereinstimmung mit Compliance-Verpflichtungen vereinbaren.</p></td><td><p>Hierzu gehören beispielsweise der Schutz personenbezogener Daten, geistige Eigentumsrechte von interessierten Parteien oder Dritten. Aufgrund unterschiedlicher Rechtssetzung und -durchsetzung sind dabei insbesondere Verarbeitungsstandorte zwischen Inland, EU und außereuropäischem Ausland zu unterscheiden.</p></td></tr><tr valign="top"><td>BES.5.4: Informationssicherheitskontrollmechanismen</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Informationssicherheitskontrollmechanismen vereinbaren.</p></td><td><p>Genaue und vollständige Beschreibung der Mechanismen, insbesondere zur Zugriffskontrolle durch Mehr-Faktor-Authentifizierung, Verschlüsselung von Daten beim Transport und bei der Speicherung, Härtung von Systemen, Überwachung sicherheitsrelevanter Ereignisse oder zum Schwachstellenmanagement.</p></td></tr><tr valign="top"><td>BES.5.5: Nutzungsregelungen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE Regelungen zur Nutzung der Daten und damit verbundenen Assets vereinbaren.</p></td><td><p>Hierzu zählen z.B. Zugriffsregelungen und Regelungen darüber unter welchen Bedingungen (Ort, Zeit, etc.) Daten genutzt werden dürfen. Darüber hinaus gehören auch Regelungen dazu, wann eine Nutzung aus Sicht der Institution explizit nicht akzeptabel ist.</p></td></tr><tr valign="top"><td>BES.5.5.1: Datenlokationen</td><td><p>Beschaffungsmanagement für Dienstleistungen KANN die Verarbeitung von Daten ausschließlich an von der Institution erlaubten Datenlokationen vereinbaren.</p></td><td><p>Ziel ist es zu verhindern, dass vertrauliche Informationen in Staaten mit schwachem Datenschutz oder unter fremder Rechtsaufsicht verarbeitet werden. Ohne diese Festlegung könnte ein Dienstleister Daten an Subunternehmer in Drittländern weitergeben, wo staatliche Zugriffe oder unzureichende Sicherheitsmaßnahmen die Vertraulichkeit und Integrität der Daten gefährden könnten. Durch eine konsequente Beschränkung der Datenlokationen kann die Institution hingegen nachvollziehbare Sicherheits- und Rechtsrahmen schaffen, die Transparenz gegenüber Betroffenen erhöhen und das Risiko unkontrollierter Datenabflüsse verringern. Unter „Datenlokation“ ist in diesem Kontext der physische oder virtuelle Standort gemeint, an dem Daten gespeichert, verarbeitet oder übertragen werden – also Rechenzentren, Cloud-Regionen oder spezifische Länderzonen. Eine „erlaubte Datenlokation“ kann eine innerhalb der EU liegende Cloud-Region, ein zertifiziertes Rechenzentrum im eigenen Land oder ein dedizierter Bereich innerhalb eines Cloud-Anbieters sein. Die Institution kann dies umsetzen, indem sie (1) in Dienstleistungsverträgen präzise Angaben zu zulässigen Ländern oder Regionen vereinbart, (2) von Dienstleistern Nachweise wie technische Standortkontrollen oder Auditberichte einfordert und (3) bei Cloud-Diensten gezielt Konfigurationen wie „Data Residency“-Optionen, Geofencing oder restriktive Auswahl von Regionen einsetzt.</p></td></tr><tr valign="top"><td>BES.5.5.2: Autorisierung der Zugriffsberechtigung</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE Regelungen zur Autorisierung der Zugriffsberechtigung für Personal des Lieferanten anhand von <i>Kriterien</i> vereinbaren.</p></td><td><p>Dies kann beispielsweise durch eine explizite Liste der Personen oder Rollen des Zulieferers, welche berechtigt sind, die Informationen der Institution und andere zugehörige Vermögenswerte zu nutzen, umgesetzt werden.</p></td></tr><tr valign="top"><td>BES.5.6: Vergabe von Unteraufträgen</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Regelungen für die Vergabe von Unteraufträgen vereinbaren.</p></td><td><p>Unter einem „Unterauftrag“ versteht man in diesem Kontext die vollständige oder teilweise Weitergabe vertraglich geschuldeter Leistungen an Dritte, z.B. einem Subunternehmer (Subcontractor). Relevant ist, dass die Institution nicht nur mit dem direkten Vertragspartner in einer vertraglichen Beziehung steht, sondern durch Unteraufträge auch indirekt Abhängigkeiten und Risiken entstehen könnten. Ohne klare Vereinbarungen könnte es dazu kommen, dass Unterauftragnehmer geringere Sicherheitsstandards einhalten, vertrauliche Informationen unzureichend schützen oder den vereinbarten Leistungsumfang nicht vollständig erfüllen. Beispielsweise könnte ein IT-Dienstleister einen Teil der Softwareentwicklung an ein externes Team in einem Land mit niedrigeren Datenschutzstandards auslagern, was zu Datenabfluss, Urheberrechtsverletzungen oder unkontrollierten Zugriffswegen führt. Auch Lieferkettenmanipulationen, etwa durch den Austausch von Hardware-Komponenten gegen kompromittierte Bauteile, können so unbemerkt ihren Weg in kritische Systeme finden. Umgesetzt werden kann die Anforderung beispielsweise dadurch, dass (1) die Institution in Verträgen festhält, ob und in welchem Rahmen Unteraufaufträge zulässig sind. Eine weitere praxisnahe Maßnahme kann sein, (2) Subunternehmer nur nach vorheriger schriftlicher Zustimmung der Institution zuzulassen und dabei (3) bestimmte Kategorien wie kritische IT-Dienstleistungen oder Datenverarbeitung ausdrücklich zu kennzeichnen. Technisch kann vertraglich vereinbart werden, dass Subunternehmer mindestens gleichwertige Sicherheitsstandards nachweislich erfüllen und dies regelmäßig auditiert werden kann.</p></td></tr><tr valign="top"><td>BES.5.6.1: Weitergabe der Beschaffungskriterien</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE die Weitergabe der Beschaffungskriterien an Unterauftragnehmer vereinbaren.</p></td><td><p>Dient dazu, sicherzustellen, dass die bei der Auswahl von Produkten, Dienstleistungen oder Lieferanten berücksichtigten Anforderungen entlang der gesamten Lieferkette eingehalten werden. Werden diese Kriterien nicht weitergegeben, kann es dazu kommen, dass sicherheitsrelevante Eigenschaften verloren gehen, etwa wenn ein Unterauftragnehmer günstigere, aber unsichere oder nicht konforme Komponenten beschafft. So könnte beispielsweise ein IT-Dienstleister ohne Kenntnis der geforderten Verschlüsselungsstandards Speichermedien einsetzen, die keine wirksame Datenverschlüsselung bieten, oder ein Bauunternehmen minderwertige Zutrittskontrollsysteme verbauen, weil die eigentlichen Sicherheitsvorgaben nicht bekannt waren. Auch Lieferverzögerungen, rechtliche Probleme durch fehlende Zertifizierungen oder das Einschleusen von Schadsoftware über ungesicherte Lieferungen können die Folge sein. Um die Weitergabe zu vereinfachen, können die Kriterien in einem maschinell verarbeitbaren Format (z.B. OSCAL Catalog oder Profile) ausgetauscht werden.</p></td></tr><tr valign="top"><td>BES.5.6.2: Autorisierung von Unterauftragnehmern</td><td><p>Beschaffungsmanagement für Einkäufe KANN die Autorisierung von Unterauftragnehmern durch den Auftraggeber vereinbaren.</p></td><td><p>Unterauftragnehmer sind in diesem Zusammenhang Dritte, die vom beauftragten Hauptdienstleister zur Erfüllung vertraglicher Leistungen hinzugezogen werden. Die Autorisierung von Unterauftragnehmern durch den Auftraggeber kann sicherstellen, dass keine unkontrollierten oder ungeprüften Dritten in die Leistungserbringung eingebunden werden. Ohne eine solche Regelung könnte ein Hauptauftragnehmer eigenmächtig Subunternehmen einsetzen, die unzureichende Sicherheitsstandards einhalten, intransparent agieren oder in kritische Abhängigkeiten geraten. Durch die vorherige Zustimmung des Auftraggebers kann das Risiko unzureichender Qualifikation oder fehlender Vertrauenswürdigkeit reduziert werden und es kann eine gezielte Steuerung erfolgen, wer Zugang zu vertraulichen Informationen oder kritischen Prozessen erhält.</p></td></tr><tr valign="top"><td>BES.5.6.3: Nachverfolgbarkeit der Lieferkette</td><td><p>Beschaffungsmanagement für IT-Produkte KANN die Nachverfolgbarkeit der gesamten Lieferkette bis zum Hersteller für <i>kritische Komponenten</i> vereinbaren.</p></td><td><p>Kritische Komponenten sind in diesem Kontext Bauteile oder Softwareelemente, deren Kompromittierung erhebliche Auswirkungen auf Sicherheit, Verfügbarkeit oder Integrität der eingesetzten Systeme haben könnte, z. B. kryptographische Module, Firmware von Netzwerkgeräten oder sicherheitsrelevante Steuerungseinheiten. Ohne nachvollziehbare Herkunft könnten Komponenten aus unsicheren Produktionsumgebungen stammen, in denen Hintertüren eingebaut oder Schadcode eingeschleust wurde; ebenso könnten gefälschte Ersatzteile eingesetzt werden, deren Qualität und Funktionssicherheit unzureichend ist. „Nachverfolgbarkeit“ (Traceability) bedeutet in diesem Zusammenhang die Möglichkeit, Herkunft, Transport- und Verarbeitungsschritte einer Komponente lückenlos und verifizierbar zu dokumentieren. Geeignete Maßnahmen können z. B. die Anforderung eines „Chain of Custody“-Protokolls, die Nutzung digital signierter Herkunftszertifikate oder die Einbindung seriöser, auditierter Distributoren sein. Auch der Einsatz von Datenbanken anerkannter Prüfinstanzen, in denen verifizierte Hersteller gelistet sind, kann eine Möglichkeit sein, die Nachverfolgbarkeit zu unterstützen.</p></td></tr><tr valign="top"><td>BES.5.7: Schulung</td><td><p>Beschaffungsmanagement für Einkäufe KANN eine Schulung zur Nutzung gelieferter Sicherheitsmechanismen vereinbaren.</p></td><td><p>Sicherheitsmechanismen sind in diesem Kontext technische oder organisatorische Schutzfunktionen, die in gelieferten Produkten, Systemen oder Diensten bereits vorgesehen sind, beispielsweise Verschlüsselungsfunktionen, Zugriffskontrollen oder Protokollierungsfunktionen. Ziel der Anforderung ist es, dass diese Schutzfunktionen von den Mitarbeitenden der Institution auch tatsächlich verstanden und korrekt angewandt werden. Ohne entsprechende Schulung könnte es passieren, dass vorhandene Sicherheitsfunktionen ungenutzt bleiben oder falsch bedient werden, wodurch Daten kompromittiert oder unbefugt zugänglich werden könnten. Durch gezielte Unterweisungen kann das Potenzial solcher Mechanismen ausgeschöpft und die Widerstandsfähigkeit gegenüber Angriffen oder Fehlbedienungen erhöht werden. Die Umsetzung kann pragmatisch gestaltet werden: (1) Eine Institution kann bei der Lieferung von IT-Systemen mit dem Hersteller oder Dienstleister eine kurze Einweisung in die sicherheitsrelevanten Funktionen vereinbaren, beispielsweise zur richtigen Konfiguration einer Multifaktor-Authentisierung. (2) Bei komplexeren Produkten kann die Institution Trainingsmaterialien wie Handbücher, Videos oder interaktive Tutorials anfordern, die auf den Einsatz der bereitgestellten Sicherheitsfunktionen zugeschnitten sind. (3) Zusätzlich kann es hilfreich sein, eine kurze Praxisübung im Rahmen der Abnahme durchzuführen, in der Schlüsselmechanismen wie sichere Passwortänderung oder Rechtevergabe ausprobiert werden. Die Schulung kann je nach Bedarf als Vor-Ort-Einweisung, Remote-Sitzung oder durch strukturierte E-Learning-Module erfolgen.</p></td></tr><tr valign="top"><td>BES.5.8: Rechte für geistges Eigentum</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE für geistiges Eigentum, das während der Vertragslaufzeit entwickelt wird,  die Eigentumsrechte vereinbaren.</p></td><td><p>Geistiges Eigentum meint hier alle während der Vertragslaufzeit entstehenden immateriellen Schutzgüter wie Softwarecode, Datenmodelle, Konzepte, technische Dokumentationen oder urheberrechtlich geschützte Inhalte, die im Rahmen der Dienstleistungserbringung entwickelt oder verbessert werden. Der Sinn und Zweck einer vertraglichen Regelung der Eigentumsrechte liegt darin, sicherzustellen, dass die Institution dauerhaft Kontrolle und Nutzungsrechte über Ergebnisse behält, die für ihren Betrieb oder ihre Weiterentwicklung relevant sind. Ohne klare Festlegung könnte es zu Konflikten kommen, wenn ein Dienstleister etwa nach Projektende die weitere Nutzung einer entwickelten Lösung untersagt oder hohe Lizenzgebühren verlangt; eine vertragliche Klarheit kann dagegen rechtliche Auseinandersetzungen und Abhängigkeiten verhindern. Eine Umsetzung kann über konkrete Vertragsklauseln erfolgen, die präzise definieren, welche Partei Eigentum oder Nutzungsrechte an entwickelten Ergebnissen erhält und ob bestimmte Elemente (z. B. Standardbibliotheken des Dienstleisters) ausgenommen sind. Dazu kann die Institution (1) standardisierte Vertragsvorlagen mit abgestuften Rechtemodellen nutzen, (2) ein internes Prüfschema für alle externen Verträge etablieren, das die Einbindung der Rechtsabteilung vorsieht, und (3) bei komplexen Entwicklungsleistungen technische Dokumentationspflichten verankern, damit Eigentums- und Nutzungsrechte nachvollziehbar abgesichert sind. Praktisch kann es helfen, im Vertrag eine Übergabepflicht sämtlicher Quelltexte, Dokumentationen oder Zugangsdaten vorzusehen und diese an definierte Projektmeilensteine zu koppeln.</p></td></tr><tr valign="top"><td>BES.5.9: Umgang mit Änderungen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE Regelungen für den Umgang mit Änderungen vereinbaren.</p></td><td><p>Unkontrollierte oder unklare Änderungen bringen Risiken für die Verfügbarkeit, Integrität oder Vertraulichkeit von Informationen mit sich – etwa wenn ein Dienstleister plötzlich eine neue Softwareversion einführt, ohne die Auswirkungen auf Schnittstellen zu prüfen. Vereinbarte Prozesse für den Umgang mit Änderungen können dagegen sicherstellen, dass Abhängigkeiten transparent bleiben und Risiken im Vorfeld bewertet werden. Zur Umsetzung kann eine Institution mit Dienstleistern definieren, dass Änderungen vorab angekündigt und dokumentiert werden, z. B. durch ein Ticket- oder Freigabe-System, das beide Seiten einsehen können. Es kann hilfreich sein, verschiedene Kategorien von Änderungen (z. B. Standardänderungen, Notfalländerungen, größere Releases) zu vereinbaren und abhängig von der Kritikalität unterschiedliche Prüf- und Genehmigungsschritte festzulegen. Transparenz kann durch regelmäßige Änderungsberichte oder Dashboards erreicht werden, die auch historische Änderungen nachvollziehbar machen. Praktische Maßnahmen können sein: (1) Einführung eines Test- und Abnahmefensters vor produktiven Änderungen, (2) Einsatz von Versionskontrolle oder Änderungsprotokollen, um Auswirkungen gezielt zurückverfolgen zu können, (3) Einrichtung klarer Kommunikationswege, damit die Institution rechtzeitig von geplanten Änderungen erfährt und eigene Schutzmaßnahmen – etwa zusätzliche Backups – vorbereiten kann.</p></td></tr><tr valign="top"><td>BES.5.9.1: Autorisierung von Änderungen</td><td><p>Beschaffungsmanagement für Dienstleistungen KANN die Autorisierung von Änderungen durch den Auftraggeber vereinbaren.</p></td><td><p>Die Autorisierung von Änderungen bedeutet in diesem Kontext, dass die Institution mit einem Dienstleister vereinbart, dass geplante Anpassungen – etwa an Prozessen, Konfigurationen, Infrastruktur oder Vertragsbedingungen die zur Vertragserfüllung verwendet werden– vor ihrer Umsetzung explizit durch den Auftraggeber bestätigt werden. Damit ist nicht nur die formale Vertragsänderung gemeint, sondern auch technische oder organisatorische Änderungen, die mittelbar Auswirkungen auf Sicherheit, Verfügbarkeit oder Integrität von Daten und Diensten haben können. Der Zweck dieser Regelung liegt darin, die Kontrolle über den Einflussbereich des Dienstleisters zu behalten: Ohne solche Vereinbarungen könnte ein Dienstleister eigenmächtig Anpassungen vornehmen, die unerwartete Schwachstellen einführen oder die Datenlokation verändern könnten. Zur Umsetzung kann die Institution mit dem Dienstleister praktikable Verfahren zur Änderungsfreigabe vereinbaren. Dies kann z. B. durch (1) die Einführung eines Freigabe-Workflows in einem Ticket- oder Change-Management-System erfolgen, (2) die Verpflichtung zu einer schriftlichen Änderungsmitteilung mit klaren Auswirkungen auf Sicherheit und Betrieb, sowie (3) die Festlegung, dass kritische Änderungen erst nach einer formellen Zustimmung des Auftraggebers in einem definierten Zeitfenster umgesetzt werden können. Ergänzend kann der Dienstleister angehalten werden, geplante Änderungen in einer Änderungsübersicht mit Versionsstand und Rückfalloptionen zu dokumentieren, sodass die Institution bewerten kann, ob Risiken oder Abhängigkeiten entstehen.</p></td></tr><tr valign="top"><td>BES.5.10: Behandlung von Vorfällen</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Regelungen für die Behandlung von Vorfällen vereinbaren.</p></td><td><p>Ein Vorfall bezeichnet in diesem Zusammenhang jedes sicherheitsrelevante Ereignis, das zu einer Beeinträchtigung der Vertraulichkeit, Integrität oder Verfügbarkeit von Informationen oder IT-Diensten führen kann, etwa Datenabflüsse, unbefugte Zugriffe oder längerfristige Systemausfälle. Der Sinn und Zweck der Regelung liegt darin, mit Vertragspartnern abgestimmte Verfahren zu haben, um im Ernstfall schnell und koordiniert reagieren zu können. Ohne klare Vereinbarungen könnte wertvolle Zeit verloren gehen, es könnten unklare Zuständigkeiten entstehen oder Meldungen verzögert erfolgen. Mit abgestimmten Prozessen kann dagegen die Schadensbegrenzung beschleunigt, Transparenz über den Vorfall geschaffen und eine wirksame Ursachenanalyse ermöglicht werden. Hierzu gehört insbesondere die Benachrichtigung des Vertragspartners und die Zusammenarbeit zur Behebung von Vorfällen.</p></td></tr><tr valign="top"><td>BES.5.10.1: Meldewege</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE die Erreichbarkeit des Lieferanten über bestimmte Meldewege vereinbaren.</p></td><td><p>Die Meldewege bezeichnen in diesem Zusammenhang klar definierte Kommunikationskanäle, über die ein Lieferant zuverlässig erreichbar ist. Das kann beispielsweise eine dedizierte E-Mail-Adresse für Sicherheitsvorfälle, ein 24/7-Telefonkontakt, ein Ticket-System oder ein abgesicherter Webzugang sein. Der Sinn dieser Vereinbarung liegt darin, dass kritische Ereignisse, wie etwa ein entdeckter Datenabfluss oder technische Störungen in ausgelagerten Systemen, nicht ins Leere laufen. Ohne abgestimmte Erreichbarkeit könnte eine Meldung verzögert oder gar nicht ankommen, wodurch Schaden an vertraulichen Informationen unbemerkt bleiben könnte. Mit verbindlich vereinbarten Kanälen kann die Institution hingegen sicherstellen, dass relevante Informationen zeitnah und nachweisbar beim Lieferanten ankommen und bearbeitet werden. Die Umsetzung dieser Anforderung kann durch mehrere Maßnahmen unterstützt werden: (1) Eine Institution kann im Vertrag mit dem Lieferanten eine feste Ansprechstelle und Eskalationsstufen für bestimmte Ereignisse benennen lassen. (2) Es kann ein technischer Meldeweg wie ein verschlüsseltes E-Mail-Postfach oder ein Ticketportal vorgesehen werden, das eindeutig den Zweck <b>„Sicherheitsvorfälle“</b> trägt und regelmäßig überwacht wird.</p></td></tr><tr valign="top"><td>BES.5.10.2: Melden von Vorfällen</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE eine Verpflichtung zur unverzüglichen Information des Auftraggebers über ihn betreffende Vorfälle vereinbaren.</p></td><td><p>Der Sinn dieser Regelung liegt darin, dass der Auftraggeber seine Handlungsfähigkeit behält und Risiken frühzeitig einschätzen kann. Ein verzögerter Informationsfluss könnte dazu führen, dass Schäden sich unbemerkt ausweiten oder notwendige Reaktionen, wie etwa die Unterbindung von Angriffspfaden, verspätet erfolgen. Eine rechtzeitige Mitteilung kann hingegen Transparenz schaffen und es ermöglichen, dass Gegenmaßnahmen in Koordination mit dem Auftraggeber wirksam eingeleitet werden. Die praktische Umsetzung kann durch klare vertragliche Regelungen erfolgen, in denen Eskalationswege und Fristen für Meldungen definiert werden. Dazu kann ein gemeinsames Kontakt- und Kommunikationsverfahren etabliert werden, etwa ein 24/7 erreichbarer Ansprechpartner oder eine dedizierte Notfalladresse für sicherheitsrelevante Meldungen. Technisch kann eine Schnittstelle (z. B. ein abgesicherter Meldekanal oder Ticket-System) eingerichtet werden, über die Vorfälle dokumentiert und weitergeleitet werden können.</p></td></tr><tr valign="top"><td>BES.5.10.3: Schwachstellenbehebung</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE eine Verpflichtung für Lieferanten, die den Auftraggeber betreffende Schwachstelle zeitnah zu beheben, vereinbaren.</p></td><td><p>Die Verpflichtung bezieht sich hierbei auf die gesamte Lebensdauer der Dienstleistungen oder Produkte. Je nach Vertrag kann die Behebung von Schwachstellen z.B. durch Sicherheitsupdates oder den Austausch von Komponenten gewährleistet werden.</p></td></tr><tr valign="top"><td>BES.5.10.3.1: Schwachstellenmeldeprozess</td><td><p>Beschaffungsmanagement für IT-Produkte KANN einen Schwachstellenmeldeprozess nach <i>einem anerkannten Standard</i> vereinbaren.</p></td><td><p>Die Anforderung ist erfüllt, wenn der Prozess zur Meldung und Behandlung von Schwachstellen für das zu beschaffende Produkt vertraglich zugesichert ist, unabhängig von der Frage durch wen die Klausel in den Vertrag eingebracht wurde. Der Schwachstellenmeldeprozess kann direkt durch den Lieferanten oder durch Weitergabe der Verpflichtung an den Hersteller gewährleistet sein. Für Details siehe BSI TR-03183-3.</p></td></tr><tr valign="top"><td>BES.5.10.4: Konfliktlösungsprozesse</td><td><p>Beschaffungsmanagement für Einkäufe KANN Prozesse zur Lösung von Konflikten zwischen den Vertragsparteien vereinbaren.</p></td><td><p>Ein „Konflikt zwischen den Vertragsparteien“ bedeutet hier jede Form von Uneinigkeit, die im Zuge eines Vertragsverhältnisses auftreten kann – etwa über die Auslegung von Leistungszusagen, den Umgang mit Verzögerungen, Qualitätsabweichungen oder Verantwortlichkeiten bei Sicherheitsvorfällen. Solche Konfliktlösungsprozesse können helfen, Missverständnisse strukturiert zu klären und Rechtsstreitigkeiten vorzubeugen. Das Ziel der Anforderung ist es, Risiken durch unklare Verantwortlichkeiten und eskalierende Streitigkeiten zu verringern: Ein ungelöster Konflikt könnte dazu führen, dass sicherheitsrelevante Leistungen nicht rechtzeitig erbracht werden, Vertragsinhalte unterschiedlich interpretiert werden oder sensible Daten im Streitfall unkontrolliert preisgegeben werden. Umgekehrt kann eine klar geregelte Konfliktlösungsroutine Transparenz schaffen, die Handlungsfähigkeit der Institution sichern und einen fairen Interessenausgleich fördern. Praktisch umgesetzt werden kann dies durch verschiedene Maßnahmen: (1) In Verträgen kann eine Schlichtungsklausel vorgesehen werden, die definiert, dass bei Meinungsverschiedenheiten zunächst ein moderiertes Gespräch oder ein Mediationsverfahren durchgeführt werden kann. (2) Es kann hilfreich sein, feste Eskalationspfade zu vereinbaren, zum Beispiel mit einer dreistufigen Struktur aus Projektleitung, Management-Ebene und unabhängiger Stelle. (3) Die Institution kann Checklisten nutzen, um im Konfliktfall die relevanten Dokumentationen – etwa Leistungsnachweise oder Kommunikationsprotokolle – geordnet vorzulegen. (4) Technische Hilfen wie gemeinsame Ticket- oder Kollaborationssysteme können Transparenz schaffen und verhindern, dass Konflikte durch unklare Informationslagen eskalieren.</p></td></tr><tr valign="top"><td>BES.5.10.5: Konsequenzen bei Verstößen</td><td><p>Beschaffungsmanagement für Einkäufe KANN Abhilfemaßnahmen für den Fall von Verstößen durch den Lieferanten vereinbaren.</p></td><td><p>Hierzu können Abhilfemaßnahmen wie die Abschaltung angreifbarer Systeme, die Information betroffener Personen sowie Entschädigungen für die betroffene Institution oder betroffene Dritte in einer festgelegten Höhe gehören.</p></td></tr><tr valign="top"><td>BES.5.11: Recht auf Audit</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE ein Recht des Auftraggebers zur Überprüfung der Sicherheitsprozesse und -maßnahmen, die im Zusammenhang mit dem Vertrag stehen, vereinbaren.</p></td><td><p>Je nach Vereinbarung kann die Umsetzung durch ein vom Auftraggeber durchgeführtes Audit, eine Revision (Second Party Audit) oder eine Auditierung durch Dritte (Third Party Audit), z.B. im Rahmen einer Zertifizierung, erfolgen.</p></td></tr><tr valign="top"><td>BES.5.12: Informationspflichten</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE eine Pflicht des Lieferanten, den Auftraggeber regelmäßig über die Wirksamkeit der Sicherheitsmaßnahmen zu informieren, vereinbaren.</p></td><td><p>Im konkreten Kontext bedeutet Wirksamkeit, dass die vereinbarten Sicherheitsmaßnahmen des Lieferanten nicht nur formal existieren, sondern nachweislich den angestrebten Schutzzweck erfüllen – beispielsweise durch messbare Ergebnisse, dokumentierte Prüfberichte oder Nachweise aus internen Kontrollen. Der Auftraggeber ist hierbei die Institution, die eine Dienstleistung einkauft und deren Informationswerte geschützt werden sollen, während der Lieferant der erbringende externe Dienstleister ist, dessen Sicherheitspraktiken Einfluss auf diese Informationswerte haben. Regelmäßige Informationen können etwa Statusberichte, Prüfprotokolle oder Kennzahlen zu Sicherheitsvorfällen und deren Behandlung umfassen.</p></td></tr><tr valign="top"><td>BES.5.13: Bereitstellung von Datensicherungen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE eine Verpflichtung des Lieferanten, Sicherungskopien regelmäßig bereitzustellen, vereinbaren.</p></td><td><p>Der Zweck dieser Anforderung liegt in der Absicherung gegen Datenverlust durch technische Defekte, menschliche Fehler oder Schadsoftware. Ein fehlendes Backup könnte dazu führen, dass wichtige Kundendaten, Vertragsunterlagen oder Konfigurationsstände dauerhaft verloren gehen. Durch die vertragliche Verpflichtung zur Bereitstellung von Sicherungskopien kann die Institution ihre Datenhoheit behalten und Ausfälle oder Manipulationen deutlich schneller abfangen. Die Umsetzung kann beispielsweise so erfolgen, dass der Lieferant verpflichtet wird, Backups auf einem separaten, verschlüsselten Speichermedium bereitzustellen, welches der Institution in vereinbarten Intervallen übergeben wird. Zur Umsetzung kann ein Lieferant beispielsweise quartalsweise Berichte zu durchgeführten Penetrationstests, Schwachstellen-Scans oder Notfallübungen bereitstellen. Ebenso kann er standardisierte Dashboards mit Kennzahlen zu Sicherheitsvorfällen, Patchständen oder Awareness-Maßnahmen freigeben. Hilfreich kann auch sein, dass der Lieferant auf Anfrage gezielt Audit-Reports oder Zertifikate (z. B. SOC-2-Berichte, ISO 27001-Auditberichte) zur Verfügung stellt.</p></td></tr><tr valign="top"><td>BES.5.13.1: Datenbereitstellung</td><td><p>Beschaffungsmanagement für Outsourcing KANN die Bereitstellung der beim Dienstleister verarbeiteten Daten in einem standardisierten Format vereinbaren.</p></td><td><p>Kann das Risiko verringern, dass im Falle eines Anbieterwechsels, einer Vertragsbeendigung oder einer Notfallwiederherstellung Daten nur in proprietären oder unvollständig dokumentierten Formaten vorliegen. Ohne ein solches Format könnte eine Institution vor dem Problem stehen, dass bei einem unerwarteten Ausfall des Dienstleisters die Daten erst zeitaufwendig konvertiert werden müssen, was den Geschäftsbetrieb verzögert oder kritische Prozesse unterbricht.</p></td></tr><tr valign="top"><td>BES.5.14: Löschregeln</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE die Löschung von Daten während der Vertragslaufzeit im Einklang mit den Compliance-Verpflichtungen der Institution vereinbaren.</p></td><td><p>Compliance-Verpflichtungen werden in der Praktik GC ermittelt. Die Umsetzung kann z.B. durch individuelle vertragliche Festlegung oder durch die Auswahl eines Dienstleisters, dessen Löschregelungen im Einklang mit den Compliance-Verpflichtungen stehen, erfolgen.</p></td></tr></table><h2>BES.6: Auswahl von Produkten und Dienstleistungen - Kündigung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.6.1: Entziehung der Zugangsberechtigungen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE die Entziehung der für den Vertrag relevanten Zugangsberechtigungen für den Fall einer Kündigung vereinbaren.</p></td><td><p>„Zugangsberechtigungen“ meint hier die Gesamtheit aller physischen, logischen und administrativen Rechte, die externen Dienstleistern den Zugriff auf Systeme, Daten, Gebäude oder digitale Ressourcen der Institution ermöglichen. Dazu gehören sowohl Benutzerkonten und technische Schnittstellen als auch Zutrittskarten oder Remote-Zugänge über VPN. Der Sinn und Zweck der Vorschrift liegt darin, dass unautorisierte Zugriffe nach einer Vertragsbeendigung verhindert werden können. Ein ehemaliger Dienstleister könnte ansonsten weiterhin über aktive Accounts sensible Daten einsehen oder Systeme manipulieren, was zu Datenabfluss, Sabotage oder unbemerkten Veränderungen führen könnte.</p></td></tr><tr valign="top"><td>BES.6.2: Löschung von Daten</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE die Löschung aller beim Dienstleister vorhandenen Daten für den Fall einer Kündigung vereinbaren.</p></td><td><p>Kündigung meint hier sowohl ordentliche als auch außerordentliche Kündigungen. Hierzu können z.B. die Rückgabe von Authentifizierungstoken oder Löschung aller Auftraggeberdaten nach Ablauf der gesetzlichen Aufbewahrungsfristen gehören. Relevant sind dabei neben Inhaltsdaten auch Metadaten, Lizenzen und weitere Zugriffsrechte.</p></td></tr><tr valign="top"><td>BES.6.2.1: Löschverfahren</td><td><p>Beschaffungsmanagement für Dienstleistungen KANN ein Verfahren zur nicht wiederherstellbaren Löschung für den Fall einer Kündigung vereinbaren.</p></td><td><p>Ein Verfahren zur nicht wiederherstellbaren Löschung bedeutet in diesem Kontext, dass Daten nach Beendigung einer Dienstleistungsbeziehung so entfernt werden, dass auch mit spezialisierten forensischen Methoden keine Rekonstruktion mehr möglich ist. Typische Verfahren reichen von mehrfachen Überschreibungen mit Zufallswerten über kryptographisches Löschen (Zerstörung der Schlüssel, die zur Entschlüsselung notwendig wären) bis hin zur physikalischen Zerstörung der Speichermedien. Die Regelung zielt darauf ab, das Risiko zu mindern, dass vertrauliche Daten nach einer Vertragskündigung bei einem Dienstleister verbleiben und unbefugt genutzt oder versehentlich offengelegt werden könnten. Ein Datenleck nach einem Providerwechsel könnte beispielsweise zu Identitätsdiebstahl, Industriespionage oder Reputationsschäden führen. Die Vereinbarung einer sicheren, nicht wiederherstellbaren Löschung kann sicherstellen, dass Informationen tatsächlich entfernt sind und keine Restkopien unkontrolliert in Umlauf geraten.</p></td></tr><tr valign="top"><td>BES.6.3: Übertragbarkeit von Daten</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE die Übertragbarkeit von Daten, Konfigurationen und der Funktionalität für den Fall einer Kündigung vereinbaren.</p></td><td><p>Ohne eine solche Regelung kann es zu erheblichen Betriebsstörungen kommen, etwa wenn ein Dienstleister im Streitfall Daten nur in proprietären Formaten bereitstellt oder deren Übergabe verzögert. Dies könnte dazu führen, dass eine Institution den Betrieb nicht nahtlos mit einem neuen Anbieter fortsetzen kann, etwa bei Cloud-Diensten, Hosting oder SaaS-Lösungen. Auch kann der Verlust von Metadaten, Zugriffshistorien oder Konfigurationsdateien eintreten, was die Nachvollziehbarkeit und Funktionsfähigkeit stark einschränken könnte. Unter „Übertragbarkeit von Daten“ (Data Portability) versteht man in diesem Kontext die technische und organisatorische Fähigkeit, alle relevanten Daten in einem vollständigen, strukturierten und maschinenlesbaren Format an die Institution oder einen Nachfolger zu übertragen. Es geht dabei nicht nur um die Rohdaten, sondern auch um begleitende Informationen, die für die Wiederaufnahme des Betriebs an anderer Stelle erforderlich sind (Metadaten). Die Angemessenheit dieser Maßnahme bemisst sich daran, wie stark die Tätigkeit der Institution von den ausgelagerten Prozessen abhängt und wie groß die Auswirkungen einer verzögerten oder unvollständigen Rückgabe wären.</p></td></tr><tr valign="top"><td>BES.6.4: Übertragung von Supportdienstleistungen</td><td><p>Beschaffungsmanagement für Dienstleistungen KANN die Übergabe der Supportdienstleistungen für den Fall einer Kündigung vereinbaren.</p></td><td><p>Die Übergabe der Supportdienstleistungen beschreibt in diesem Kontext die geordnete und dokumentierte Weitergabe von relevanten Informationen, Ressourcen und Zugängen durch einen externen Dienstleister an die Institution oder einen neuen Dienstleister, wenn ein Vertrag endet. Dazu gehören z. B. Dokumentationen zu Konfigurationen, Wartungsprotokolle, Zugangsdaten, Lizenzinformationen oder Ansprechpartnerketten. Ziel ist es, dass der Betrieb der unterstützten Systeme nach Vertragsende ohne Unterbrechung oder Informationsverlust fortgesetzt werden kann. Die Anforderung dient dazu, Risiken abzufedern, die entstehen, wenn bei einer Kündigung der Dienstleister abrupt ausscheidet. Ohne geregelte Übergabe könnte es passieren, dass wichtige Betriebsinformationen verloren gehen, der Zugriff auf Systeme blockiert wird oder die Institution abhängig von individuellem Wissen einzelner Personen bleibt. Die Übergabe kann entweder an die Institution selbst oder an einen von der Institution gewählten neuen Vertragspartner erfolgen. Um die Anforderung praktisch umzusetzen, kann eine Institution in Verträgen explizit eine Exit- oder Übergabeklausel verankern, die Inhalte, Formate und Fristen der Übergabe beschreibt. Diese Klausel kann beispielsweise definieren, dass (1) aktuelle System- und Betriebsdokumentationen vollständig zu übergeben sind, (2) Zugangsdaten in einem abgestimmten Verfahren gesichert bereitgestellt werden und (3) technische Ansprechpartner für eine Übergangsphase verfügbar bleiben.</p></td></tr><tr valign="top"><td>BES.6.5: Behandlung aufzubewahrender Aufzeichnungen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE Kontrollmechanismen zur Behandlung aufzubewahrender Aufzeichnungen für den Fall einer Kündigung vereinbaren.</p></td><td><p>Der Begriff Kontrollmechanismen kann in diesem Kontext verstanden werden als vertraglich vereinbarte Verfahren, technische Maßnahmen oder organisatorische Vorkehrungen, die es der Institution ermöglichen, die Vollständigkeit, Integrität und Vertraulichkeit der betreffenden Aufzeichnungen sicherzustellen. Aufzubewahrende Aufzeichnungen bezeichnet hierbei jede Form von Daten oder Dokumenten – in physischer oder digitaler Form – die aufgrund gesetzlicher, vertraglicher oder interner Vorgaben über das Vertragsende hinaus (zumindest für einen bestimmten Zeitraum) vom Dienstleister aufbewahrt werden. Dabei kann es sich beispielsweise um Vertragsunterlagen, Protokolldateien oder Gesprächsprotokolle handeln, die etwa aus steuerlichen Gründen aufzubewahren sind.</p></td></tr><tr valign="top"><td>BES.6.6: Rückgewähr von Assets</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE die Rückgewähr von Assets für den Fall einer Kündigung vereinbaren.</p></td><td><p>Rückgewähr bedeutet hier, dass sämtliche von der Institution bereitgestellte Werte – wie etwa IT-Systeme, Datenträger oder Papierkopien – bei Beendigung des Vertragsverhältnisses an die Institution zurückgegeben werden. Der Zweck liegt darin, unkontrollierten Weitergebrauch oder Missbrauch von Informationen und Ressourcen zu verhindern. So könnte etwa ein externer Dienstleister nach einer Kündigung weiterhin Zugriff auf sensible Daten behalten oder unbeabsichtigt alte Backup-Medien in seinem Besitz behalten, was zu Datenabflüssen oder unautorisierten Offenlegungen führen könnte. Eine klare Regelung kann dagegen sicherstellen, dass sämtliche Ressourcen nachvollziehbar wieder unter die alleinige Kontrolle der Institution gelangen und Vertraulichkeit sowie Integrität gewahrt bleiben. Für die Umsetzung kann es hilfreich sein, die Rückgabepflicht vertraglich zu konkretisieren und präzise Abläufe zu definieren. So kann die Institution (1) Inventarlisten führen, in denen alle übergebenen physischen Geräte, Datenträger oder Zutrittsmedien eindeutig aufgeführt werden, (2) Checklisten für die geordnete Rückführung bei Vertragsende einsetzen und (3) eine Rückgabequittung oder Übergabebestätigung durch den Dienstleister einfordern, die den ordnungsgemäßen Erhalt dokumentiert. Ergänzend kann die Institution Rückgabefristen und Verantwortlichkeiten im Vertrag festlegen sowie technische Maßnahmen wie die Sperrung von verlorenen oder nicht zurückgegebenen Zutrittskarten einplanen. Auch kann eine Abnahmeprüfung der zurückgegebenen Assets durch die Institution erfolgen, um sicherzustellen, dass diese vollständig und funktionsfähig übergeben wurden.</p></td></tr></table><h2>BES.7: Abnahme</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.7.1: Eingangskontrolle</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE erbrachte oder gelieferte Leistungen anhand von <i>Kriterien zur Akzeptanz</i> vor der ersten Verwendung testen.</p></td><td><p>Durch eine Prüfung anhand von Akzeptanzkriterien wird sichergestellt, dass die erbrachten IKT-Dienstleistungen oder IKT-Produkte den geforderten Beschaffungskriterien entsprechen. Die Akzeptanzkriterien können also den Beschaffungskriterien entsprechen oder deren Prüfung konkretisieren. Hierzu können verschiedene Methoden eingesetzt werden, etwa Stichproben, Sicherheitstests oder die Nachverfolgung der Lieferkette anhand von Seriennummern.  Dabei besteht ein enger Zusammenhang zu den Praktiken Dienstleistersteuerung, sowie Änderungen und Tests.</p></td></tr><tr valign="top"><td>BES.7.1.1: Test der Kompatibilität</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE die Kompatibilität des Dienstes mit dem Informationsverbund im Hinblick auf die Schnittstellen, die Netzanbindung, das Administrationsmodell und das Datenmanagementmodell testen.</p></td><td><p>Die Regelung dient dazu, ungewollte Brüche oder Inkompatibilitäten zu vermeiden, die im Betrieb zu Sicherheits- oder Funktionsproblemen führen können. Ohne eine solche Überprüfung könnte z. B. eine unklare Rechtevergabe dazu führen, dass ein Dienstleister umfassendere Zugriffe erhält als notwendig, oder eine fehlerhafte Schnittstellenintegration könnte den Ausfall wichtiger Anwendungen nach sich ziehen. Umgekehrt kann eine saubere Prüfung sicherstellen, dass Outsourcing-Dienste nahtlos integriert, technisch handhabbar und im Betrieb kontrollierbar bleiben. Für die Bewertung der Kompatibilität sind dabei vier Aspekte besonders kritisch: Schnittstellen sind die technischen Übergabepunkte, an denen Systeme Daten austauschen oder Funktionen ansprechen; Netzanbindung bezeichnet die physische oder logische Verbindung zwischen dem Dienstleister und dem Informationsverbund der Institution; das Administrationsmodell beschreibt, wer welche Rechte zur Einrichtung, Änderung und Überwachung von Systemkomponenten hat; und das Datenmanagementmodell legt fest, wie Daten gespeichert, strukturiert, repliziert und gelöscht werden.</p></td></tr><tr valign="top"><td>BES.7.1.2: Netzcheck</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE die Umsetzung der geforderten Beschaffungskriterien für die Netzanbindung vor der Netzanbindung testen.</p></td><td><p>Netzanbindung meint hier jede Form der logischen oder physischen Kopplung von Netzwerken – etwa über VPN, MPLS, dedizierte Leitungen oder Cloud-Interconnects. Der Sinn dieser Vorschrift liegt darin, Risiken aus unsicheren oder ungetesteten Dienstleisterverbindungen zu minimieren. So könnte ein ungeprüfter Zugang über eine unsauber konfigurierte VPN-Schnittstelle Schadsoftware einschleusen oder interne Systeme unautorisiert zugänglich machen. Umgekehrt kann die vorgelagerte Prüfung sicherstellen, dass Verschlüsselung, Bandbreite, Trennung sensibler Netze oder auch Logging-Vorgaben wie vorgesehen funktionieren und dadurch ein sicherer, nachvollziehbarer Betrieb gewährleistet wird. Die Umsetzung kann durch mehrere Maßnahmen erfolgen: (1) Vor der Inbetriebnahme kann ein technischer Funktionstest durchgeführt werden, bei dem Firewalls, Routing und VPN-Tunnel anhand von Testaccounts überprüft werden. (2) Ein Abnahmetest durch die Institution kann beinhalten, dass simulierte Angriffe oder Fehlkonfigurationen (z. B. offene Ports) nachgestellt werden, um die Widerstandsfähigkeit des Dienstleisters zu prüfen. (3) Prozessual kann eine Checkliste genutzt werden, die verbindlich vorgibt, dass Sicherheitsanforderungen wie Verschlüsselungsstandards, Protokollierung, Redundanz oder die Einhaltung von Latenzgrenzen dokumentiert und validiert sind, bevor der „Go-Live“ erfolgt. Zusätzlich kann es hilfreich sein, die Ergebnisse der Tests nachvollziehbar in einem Freigabeprotokoll festzuhalten, das sowohl die Institution als auch der Dienstleister unterzeichnen. Auf diese Weise kann die Institution sicherstellen, dass die Netzanbindung nicht nur formell, sondern auch praktisch den definierten Kriterien entspricht.</p></td></tr><tr valign="top"><td>BES.7.2: Prozesse vor Netzanbindung</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE vor Anbindung des Datennetzes der Nutzenden an das Datennetz der Anbietenden alle sicherheitsrelevanten Maßnahmen im Einklang mit den Regelungen und Verfahren des Managementsystems verankern.</p></td><td><p>Der Sinn der Vorschrift liegt darin, Risiken durch unkontrollierte Netzwerkanbindungen zu minimieren, die bei Outsourcing deutlich höher sind als bei Standard-Dienstleistungsverträgen. Ohne vorherige Verankerung von Prozessen und technischen Lösungen, die für die sichere Anbindung zum Outsourcing-Dienstleiser erforderlich sind, könnte etwa Schadsoftware aus dem Anbietenden-Netz ungehindert in das Netz der Institution gelangen oder unbefugte Zugriffe könnten entstehen, wenn Authentifizierungsverfahren nicht abgestimmt sind. Umgekehrt kann eine klare Festlegung vorab bewirken, dass nur geprüfte, verschlüsselte und überwachte Schnittstellen genutzt werden, was eine vertrauenswürdige Zusammenarbeit ermöglicht. Da Outsourcing regelmäßig mit tiefen technischen Integrationen verbunden ist, unterscheidet es sich von herkömmlichen Lieferantenbeziehungen, bei denen keine direkte Netzwerkkopplung erfolgt. Eine Institution kann diese Anforderung praktisch umsetzen, indem sie vor der Anbindung (1) eine technische Schnittstellenbeschreibung einfordert, die Protokolle, Ports und Authentifizierungsmechanismen dokumentiert, (2) die Kommunikation auf gesicherte Kanäle wie VPN oder verschlüsselte Direktleitungen beschränkt, und (3) Verfahren zur Netzsegmentierung etabliert, sodass der Zugriff nur auf explizit freigegebene Systeme möglich ist. Ergänzend kann eine Checkliste für Dienstleisterprüfung genutzt werden, in der Sicherheitszertifikate, Protokolle zur Patch-Pflege oder geplante Monitoring-Mechanismen abgefragt werden. Ein prozessualer Tipp kann darin bestehen, die Netzfreigabe erst nach einem gemeinsamen Test der Sicherheitsmechanismen freizuschalten und dies in einem Freigabeprotokoll zu dokumentieren. So kann eine Institution sicherstellen, dass Outsourcing-Verbindungen kontrolliert, nachvollziehbar und mit einem definierten Sicherheitsniveau umgesetzt werden.</p></td></tr><tr valign="top"><td>BES.7.3: Anhörung Prozessbeteiligter</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE alle am ausgelagerten Prozess beteiligten Mitarbeiter oder Rollen anhören.</p></td><td><p>Je nach Prozess können hierzu z.B. IT-Betriebspersonal oder Cybersicherheitsexperten der Institution oder von weiteren Dienstleistern, oder die Rechtsabteilung gehören.</p></td></tr><tr valign="top"><td>BES.7.4: Vollständigkeit der Unterlagen</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE Informationen, die für eine bestimmungsgemäße Verwendung im Informationsverbund erforderlich sind, dokumentieren.</p></td><td><p>Dient in erster Linie dazu, sicherheitsrelevante Eigenschaften, Abhängigkeiten und Einsatzbedingungen nachvollziehbar festzuhalten. Ohne diese Informationen könnte es zu Fehlkonfigurationen, unsachgemäßem Betrieb oder unentdeckten Schwachstellen kommen, etwa wenn sicherheitskritische Firmware-Updates, empfohlene Hardening-Anleitungen oder Hinweise zu bekannten Sicherheitslücken nicht beachtet werden. So könnte beispielsweise ein Netzwerkgerät ohne die dokumentierten Herstellerhinweise zu sicheren Standardpasswörtern betrieben werden, wodurch Angreifer einfachen Zugriff erlangen könnten. Für diesen Kontext bedeutet „Informationen, die für eine bestimmungsgemäße Verwendung der Beschaffung im Informationsverbund erforderlich sind“ sämtliche sicherheitsrelevanten Dokumente, Konfigurationshinweise, Updateanweisungen und Supportinformationen, die erforderlich sind, damit beschaffte Produkte und Dienste so verwendet werden können, wie in den Beschaffungskriterien vorgesehen.  Am einfachsten kann diese Anforderung erfüllt werden, indem die erforderlichen Informationen vom Lieferanten oder Hersteller mitgeliefert werden. Alternativ ist es auch möglich, dass die Institution die Dokumentation selbst vornimmt, z.B. in Zusammenarbeit mit dem Lieferanten, durch Untersuchung der Lieferung oder durch Ablage von Informationen, welche der Hersteller auf seiner Webseite bereitgestellt hat. Eine praktische Umsetzung kann darin bestehen, dass die Institution im Rahmen des Beschaffungsprozesses gezielt nach sicherheitsrelevanten Unterlagen fragt und diese zentral ablegt, etwa in einem internen Dokumentationssystem, auf das die zuständigen Administratoren und IT-Sicherheitsverantwortlichen zugreifen können. Hierbei kann es hilfreich sein, Checklisten einzusetzen, die beim Wareneingang oder der Inbetriebnahme prüfen, ob etwa Handbücher mit sicherheitsrelevanten Konfigurationsempfehlungen, Updatepläne, Zertifikate oder Kompatibilitätslisten vorliegen. Auch kann die Institution eine eindeutige Referenzierung der Unterlagen vornehmen, damit später nachvollziehbar ist, welche Version der Herstellerinformationen bei Inbetriebnahme zugrunde lag. Um die Nutzbarkeit zu erhöhen, kann eine Kurzfassung der relevanten Sicherheitspunkte in die interne Betriebsdokumentation übernommen werden, während die Originalunterlagen für Detailfragen hinterlegt bleiben. Bei wiederkehrenden Beschaffungen ähnlicher Komponenten kann zudem eine Vorlagenstruktur helfen, in der die typischen Unterlagenarten und deren Ablageorte definiert sind. So wird sichergestellt, dass die sicherheitsrelevanten Informationen nicht nur vorhanden, sondern auch im Bedarfsfall schnell auffindbar und anwendbar sind.</p></td></tr><tr valign="top"><td>BES.7.4.1: Beschreibung der Sicherheitsarchitektur</td><td><p>Beschaffungsmanagement für IT-Produkte SOLLTE eine Beschreibung der Sicherheitsarchitektur dokumentieren.</p></td><td><p>Die technische Sicherheitsarchitektur bezeichnet in diesem Kontext die strukturierte Darstellung der sicherheitsrelevanten Komponenten und Mechanismen eines IT-Produkts. Dazu gehören z. B. die eingesetzten kryptografischen Verfahren, die Segmentierung von Netzwerken, Schnittstellen zu anderen Systemen, Rollen- und Berechtigungskonzepte sowie Schutzmechanismen gegen Schadsoftware oder Manipulation. Sie bildet somit eine nachvollziehbare Übersicht, wie die Sicherheit im Produkt technisch verankert ist und wie diese in die bestehende IT-Landschaft integriert werden kann. Die Dokumentation kann verhindern, dass eine Institution Systeme übernimmt, deren Schutzmechanismen unklar oder unzureichend sind. Ohne eine solche Transparenz könnte es passieren, dass kritische Schwachstellen verborgen bleiben oder Sicherheitsmechanismen aufgrund mangelnden Verständnisses nicht korrekt konfiguriert werden. Eine sinnvolle Umsetzung kann beispielsweise so erfolgen: (1) Ein Anbieter kann verpflichtet werden, vor Abnahme ein Architekturdiagramm mit hervorgehobenen Sicherheitskomponenten bereitzustellen. (2) Die Institution kann bei Pilotinstallationen Checklisten verwenden, um die dokumentierten Sicherheitsmaßnahmen mit der realisierten Konfiguration abzugleichen. (3) Ergänzend kann ein standardisiertes Template genutzt werden, das Mindestangaben wie eingesetzte Protokolle, Verschlüsselungsmechanismen, Rollenmodelle und Logging-Kapazitäten abfragt, sodass einheitliche und vergleichbare Unterlagen entstehen. Auch ein Abgleich mit bewährten Referenzarchitekturen kann helfen, die Vollständigkeit und Plausibilität der Angaben zu prüfen.</p></td></tr><tr valign="top"><td>BES.7.4.2: Beschreibung von Sicherheitsmechanismen</td><td><p>Beschaffungsmanagement für IT-Produkte SOLLTE eine Beschreibung der gelieferten Sicherheitsmechanismen dokumentieren.</p></td><td><p>Hierzu zählt z.B. eine Information des Herstellers, dass die Verschlüsselung nach BSI TR-02102 erfolgt.</p></td></tr><tr valign="top"><td>BES.7.4.3: Empfohlene Konfiguration</td><td><p>Beschaffungsmanagement für IT-Produkte SOLLTE eine vom Hersteller oder Lieferanten für den sicheren Betrieb empfohlene Konfiguration dokumentieren.</p></td><td><p>Eine vom Hersteller oder Lieferanten empfohlene Konfiguration ist eine dokumentierte Vorgabe, welche Einstellungen, Dienste und Sicherheitsparameter für den sicheren Betrieb vorgesehen sind. Diese Empfehlung ist im Fachkontext oft als Secure Baseline Configuration bekannt und kann z. B. Angaben zu Benutzerrechten, Netzwerkschnittstellen oder Update-Mechanismen enthalten. Der Sinn und Zweck dieser Anforderung liegt darin, dass IT-Produkte nicht im unsicheren Auslieferungszustand betrieben werden, sondern in einer geprüften und abgestimmten Form. Ohne solche Empfehlungen könnte ein System mit unnötig offenen Ports betrieben werden oder ein Administratorkonto ohne Passwortschutz bestehen, was Angreifern leichtes Spiel böte. Eine dokumentierte und nachvollziehbar empfohlene Konfiguration kann hingegen dafür sorgen, dass Schwachstellen von Beginn an reduziert werden und ein sicherer Ausgangszustand für den weiteren Betrieb geschaffen wird. Konkret kann dies durch (1) die Ablage der Herstellerempfehlungen in einer zentralen Wissensdatenbank, (2) die Überführung dieser Vorgaben in technische Checklisten für Systemadministratoren oder (3) die Nutzung von Skripten oder Vorlagen zur automatischen Einrichtung von Betriebssystemen, Netzwerkgeräten oder Anwendungen erfolgen. Zusätzlich kann es hilfreich sein, Abweichungen zur Empfehlung zu dokumentieren, um spätere Prüfungen oder Audits nachvollziehbar zu gestalten.</p></td></tr><tr valign="top"><td>BES.7.4.4: Dokumentation der Komponenten</td><td><p>Beschaffungsmanagement für Einkäufe SOLLTE eine Beschreibung der verwendeten Hardware- und Softwarekomponenten dokumentieren.</p></td><td><p>Hierzu zählen Angaben zum Hersteller und der Leistungsfähigkeit und Zusammensetzung der verbauten Hardware- und Softwarekomponenten. Für die Softwarekomponenten kann die Beschreibung standardisiert nach BSI TR-03183-2 erfolgen.</p></td></tr><tr valign="top"><td>BES.7.4.4.1: Software Bill of Materials (SBOM)</td><td><p>Beschaffungsmanagement für IT-Produkte KANN für jede gelieferte Software die entsprechende Software Bill of Materials (SBOM) nach <i>einem anerkannten Standard</i> dokumentieren.</p></td><td><p>Je nach Produkt können hierzu auch die Firmware, das Betriebssystem oder mehrere Softwarebestandteile einer Anwendung gehören. Ein anerkannter Standard für SBOM ist die BSI TR-03183-2.</p></td></tr><tr valign="top"><td>BES.7.4.5: Netzverbindungen ab Werk</td><td><p>Beschaffungsmanagement für IT-Produkte SOLLTE eine Liste der Internetserver, mit denen das IT-Produkt von sich aus Verbindung aufnimmt, mit Zweck der Verbindung, Zieladresse(n), Port-Nummern dokumentieren.</p></td><td><p>Geräte und Software verbinden sich oft schon im Auslieferungszustand oder bei der normalen Nutzung über das Internet mit Diensten, z.B. zur Übermittlung von Telemetrie- und Diagnosedaten oder zur Bereitstellung von Cloud-Funktionen. Eine Liste der Verbindungen hilft, die Übersicht zu behalten, welche Kommunikationsbeziehungen zu welchem Zweck das IT-Produkt aufnimmt. Die Liste kann vom Lieferanten gestellt werden oder durch Untersuchung des Produktes selbst ermittelt werden. Eine eigene Untersuchung ist jedoch deutlich aufwändiger, da sichergestellt werden muss, dass auch Verbindungen erfasst werden, die z.B. nur bei einem Absturz der Anwendung aufgebaut werden.</p></td></tr><tr valign="top"><td>BES.7.4.6: Shared Responsibility</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE die Verteilung der Zuständigkeiten und deren Abgrenzung dokumentieren.</p></td><td><p>Beim Outsourcing gibt es verteilte Zuständigkeiten zwischen Dienstleister und Institution (sog. Shared Responsibility). Hierbei ist z.B. relevant, welche Verarbeitungen in der Zuständigkeit des Dienstleisters liegen und welche weiterhin bei der Institution vorgenommen werden, z.B. Infrastructure-as-a-Service vs. Software-as-a-Service.</p></td></tr><tr valign="top"><td>BES.7.4.7: Organisatorische Schnittstellen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE die organisatorischen Schnittstellen des Dienstleisters dokumentieren.</p></td><td><p>Beispielsweise Meldewege für Notfälle, Sicherheitsvorfälle, Eskalationsstufen.</p></td></tr><tr valign="top"><td>BES.7.4.8: Technische Schnittstellen</td><td><p>Beschaffungsmanagement für Dienstleistungen SOLLTE die vom Dienstleister bereitgestellten technischen Schnittstellen und deren Sicherheitsfunktionalität dokumentieren.</p></td><td><p>Die Dokumentation der vom Dienstleister bereitgestellten technischen Schnittstellen und deren Sicherheitsfunktionalität dient in erster Linie dazu, Transparenz über potenzielle Angriffspunkte und Integrationsrisiken zu schaffen. Fehlende oder unzureichend beschriebene Schnittstellen können zu gravierenden Vorfällen führen: So könnte etwa eine unsauber dokumentierte API unbemerkt unverschlüsselte Daten übertragen oder unautorisierte Zugriffe ermöglichen.</p></td></tr><tr valign="top"><td>BES.7.4.9: Auslagerungsregister</td><td><p>Beschaffungsmanagement für Outsourcing SOLLTE Informationen über den Dienstleister, die Kritikalität des Prozesses, abgeschlossene Verträge und Vereinbarungen sowie Zeitpunkt und Inhalt von Änderungen an den Vereinbarungen nach Vertragsschluss dokumentieren.</p></td><td><p>Hierzu genügt ein zentrales Auslagerungsregister, welches zu allen ausgelagerten Prozessen die geforderten Informationen enthält. Als Angaben zum Dienstleister gehören dessen Unternehmensbezeichnung und Erreichbarkeiten.</p></td></tr><tr valign="top"><td>BES.7.4.10: Serviceprofil</td><td><p>Beschaffungsmanagement für Cloud-Dienste SOLLTE für jeden geplanten oder genutzten Cloud-Dienst ein Serviceprofil mit dem Namen des Services und des Anbieters dokumentieren.</p></td><td><p>Mögliche Inhalte um zuvor identifizierte Anforderungen ergänzen : Bezeichnung, Kurzbeschreibung, Kategorie, Sub- bzw. Sekundärservices, Varianten, technische Parameter, Service-Parameter/SLA, SLA-Messung, Gültigkeit des Services (Zeitraum), Service-Übergabe, Methoden der Kostenermittlung, Preis/Verrechnung, Ansprechpartner für den Service, Berechtigte und Anforderer sowie Voraussetzungen und Abhängigkeiten zu anderen Diensten.</p></td></tr><tr valign="top"><td>BES.7.4.11: Mandantentrennung</td><td><p>Beschaffungsmanagement für Outsourcing KANN die beim Dienstleister implementierten Maßnahmen zur Mandantentrennung nach Vertragsschluss dokumentieren.</p></td><td><p>Die Dokumentation der beim Dienstleister implementierten Maßnahmen zur Mandantentrennung kann dazu beitragen, die Risiken unzureichender Abgrenzung zwischen verschiedenen Kundeninstanzen transparent zu bewerten und im Bedarfsfall nachzuweisen. Ohne eine solche Transparenz könnte es zu Datenabflüssen oder unbefugtem Zugriff durch andere Mandanten kommen, etwa wenn virtuelle Maschinen auf derselben Hardware betrieben werden und Schwachstellen in der Virtualisierung ausgenutzt werden könnten. Eine dokumentierte Trennungskontrolle kann nachweisen, dass Speicher, Rechenleistung oder Netzwerksegmente isoliert sind und dadurch die Vertraulichkeit und Integrität der eigenen Daten erhalten bleibt. Im Kontext bedeutet Mandantentrennung die technische und/oder organisatorische Gewährleistung, dass Daten, Prozesse und Ressourcen verschiedener Kunden innerhalb einer geteilten Infrastruktur so voneinander abgegrenzt sind, dass unbeabsichtigte oder absichtliche Zugriffe ausgeschlossen werden können. Damit ist nicht nur die physische, sondern auch die logische Separation gemeint. Die Umsetzung kann sinnvoll erfolgen, indem eine Institution nach Vertragsschluss gezielt vom Dienstleister beschriebene Schutzmechanismen abfragt und dokumentiert, beispielsweise Isolierungsverfahren auf Hypervisor-Ebene, Verschlüsselung pro Mandant oder die Vergabe getrennter Schlüsselmaterialien. Praktisch kann es hilfreich sein, in Service-Reports nachvollziehbare Testnachweise zu verlangen, etwa Ergebnisse von Penetrationstests, die speziell auf Mandantengrenzen zielen.</p></td></tr><tr valign="top"><td>BES.7.4.12: Software Bill of Materials (SBOM) - Cloud</td><td><p>Beschaffungsmanagement für Cloud-Dienste KANN für jede gelieferte Software-as-a-Service (SaaS) die entsprechende Software Bill of Materials (SBOM) nach <i>einem anerkannten Standard</i> dokumentieren.</p></td><td><p>Ein anerkannter Standard für SBOM ist die BSI TR-03183-2.</p></td></tr></table><h2>BES.8: Kompensierende Kontrollmechanismen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BES.8.1: Bereithaltung alternativer Lieferanten</td><td><p>Beschaffungsmanagement für Einkäufe KANN die Bereithaltung alternativer Lieferanten verankern.</p></td><td><p>Das Bereithalten alternativer Lieferanten kann dazu beitragen, Abhängigkeiten zu reduzieren und die Resilienz der Liefer- und Beschaffungskette zu erhöhen. Das ist insbesondere dann von großer Bedeutung, wenn ein einzelner, wichtiger Lieferant kurzfristig ausfällt – etwa durch Produktionsstörungen, Insolvenzen, Lieferengpässe, politische Sanktionen oder Cyberangriffe auf dessen Systeme. In solchen Fällen könnte die institutionseigene Versorgung mit kritischen Gütern oder Dienstleistungen gefährdet sein, was wiederum Ausfälle, Qualitätsmängel oder Vertragsstrafen nach sich ziehen könnte. Gerade bei sicherheitskritischen Komponenten, Spezialsoftware oder Ersatzteilen mit langen Vorlaufzeiten könnte das Fehlen einer zweiten Bezugsquelle zu erheblichen Betriebsunterbrechungen führen. Der Begriff „alternative Lieferanten“ meint in diesem Kontext qualifizierte Drittanbieter, die vergleichbare Produkte oder Leistungen in einer wirtschaftlich und technisch angemessenen Qualität und Menge wirksam bereitstellen können. „Angemessenheit“ bezieht sich hier auf den Grad, in dem ein alternativer Lieferant die Mindestanforderungen der Institution hinsichtlich Qualität, Sicherheit, Verfügbarkeit und Kompatibilität erfüllt, während „Wirksamkeit“ bedeutet, dass dieser im Bedarfsfall tatsächlich kurzfristig und ohne erhebliche Zusatzrisiken einspringen kann.  Zur praktischen Umsetzung kann eine Institution zunächst identifizieren, für welche Materialien, Systeme oder Services ein Ausfall besonders kritisch wäre, und für diese gezielt alternative Bezugsquellen evaluieren. Dazu kann gehören, eine Lieferantenliste mit geprüften Zweitanbietern zu pflegen, Rahmenverträge vorzubereiten oder vereinbarte Notfallmengen zu definieren, die im Bedarfsfall abgerufen werden können. Eine Möglichkeit ist es, Testbestellungen bei alternativen Anbietern durchzuführen, um Qualität, Liefergeschwindigkeit und Kommunikationswege zu erproben. Ebenso kann es hilfreich sein, technische Spezifikationen so zu gestalten, dass mehrere Anbieter kompatible Produkte liefern können, um Lock-in-Effekte zu vermeiden.</p></td></tr><tr valign="top"><td>BES.8.2: Verfahren zur Übertragung von Geschäftsprozessen</td><td><p>Beschaffungsmanagement für Outsourcing KANN Verfahren zur Übertragung von Geschäftsprozessen für den Fall einer geplanten oder ungeplanten Beendigung des Vertrages verankern.</p></td><td><p>Es empfiehlt sich diese Alternativen in einem Maßnahmenkatalog zu dokumentieren. Darin können z.B. alternative Dienstleister festgehalten werden, welche über das notwendige Niveau an Informationssicherheit verfügen, um den Prozess, welcher an den bisherigen Dienstleister ausgelagert wird, in gleichem Maße umzusetzen.</p></td></tr><tr valign="top"><td>BES.8.3: Ressourcensouveränität</td><td><p>Beschaffungsmanagement für Outsourcing KANN ausreichende interne Ressourcen für den Fall einer geplanten oder ungeplanten Beendigung des Vertrages zuweisen.</p></td><td><p>Die Bereithaltung ausreichender interner Ressourcen zielt hier darauf ab, für den Fall einer plötzlichen Einstellung der beschafften Dienste ausreichend ausgestattet zu sein, um einer übermäßigen Abhängigkeit gegenüber den Anbietenden von Outsourcing vorzubeugen. Zu den notwendigen Ressourcen gehört sowohl Personal, welches für die bei einem Ausfall des Dienstleisters erforderlichen Aufgaben qualifiziert ist, als auch die für diese Aufgaben erforderliche Infrastruktur (z.B. IT-Systeme, Anwendungslizenzen, Zugänge und Berechtigungen).</p></td></tr><tr valign="top"><td>BES.8.4: Individuelle Implementierung kritischer Komponenten</td><td><p>Beschaffungsmanagement für IT-Produkte KANN eine eigens für die Institution entwickelte Implementierung kritischer Komponenten vereinbaren.</p></td><td><p>Dient dazu das Risiko zu mindern, dass sicherheitsrelevante Funktionen oder Integrationspunkte ungeeignet, unvollständig oder von Drittanbietern unzureichend abgesichert bereitgestellt werden. Kritische Komponenten sind dabei jene Hardware- oder Software-Bestandteile, deren Ausfall, Kompromittierung oder Fehlfunktion wesentliche Geschäftsprozesse beeinträchtigen oder sensible Daten gefährden könnte – etwa Kryptomodule, Authentifizierungsmechanismen, Schnittstellen zur Anbindung an interne Systeme oder sicherheitsrelevante Konfigurationsbausteine. Ohne gezielte Einflussnahme bei der Beschaffung könnte es beispielsweise vorkommen, dass ein Standardprodukt mit unsicheren Voreinstellungen geliefert wird, ein Modul nicht die für den Einsatzzweck erforderliche Verschlüsselung unterstützt oder herstellerseitige Updates nicht zeitnah bereitgestellt werden. Andererseits bergen selbst entwickelte Komponenten gegenüber Standardbeschaffungen das Risiko, dass die Eigenentwicklungen unzureichend getestet oder im Einsatz erprobt wurden. Daher ist vor einer Eigenentwicklung eine Risikoabschätzung sinvoll. Typischerweise lohnt eine Eigenentwicklung sich nur wenn erhebliche Ressourcen für deren Absicherungs vorhanden sind und der Vertraulichkeit oder Integrität eine stark erhöhte Bedeutung im Vergleich zu Standardprodukten zukommt.  Eine Institution kann bei der Umsetzung dieser Anforderung gezielt in den Beschaffungsvertrag aufnehmen, dass bestimmte Komponenten nach definierten Vorgaben angepasst, gehärtet oder erweitert werden – beispielsweise eine erweiterte Protokollierungsfunktion in einer Verwaltungssoftware, eine abgesicherte Firmware-Konfiguration bei Netzwerkgeräten oder die Integration zusätzlicher Prüfmechanismen in eine Schnittstellen-API.</p></td></tr><tr valign="top"><td>BES.8.5: Treuhand</td><td><p>Beschaffungsmanagement für Dienstleistungen KANN ESCROW- bzw. Treuhandverträge vereinbaren.</p></td><td><p>ESCROW- bzw. Treuhandverträge regeln die Verwertungs- und Bearbeitungsrechte (z.B. für eine Software sowie Herausgabefälle des Quellcodes) für den Fall, dass es zu Streitigkeiten oder Ausfällen der Dienstleister kommt. Hierzu gehören auch ggf. zur Nutzung erforderliche Begleitunterlagen oder Zugangsmittel wie Schlüssel oder Passwörter. Außerdem ist es zweckmäßig, vertraglich festzulegen, wie häufig Daten (z.B. Quellcode) hinterlegt und dokumentiert werden. Auch eine Regelung bzgl. der Geheimhaltungspflichten im Vertrag ist zu empfehlen.</p></td></tr></table><h1>DEV: Entwicklung</h1><p>Die Praktik Entwicklung stellt sicher, dass Sicherheitsanforderungen bereits von Beginn an in die Planungs- und Entwicklungsphase von IT-Systemen und Anwendungen integriert werden. Auf diese Weise können potenzielle Schwachstellen frühzeitig erkannt und vermieden werden, wodurch die Sicherheit über den gesamten Lebenszyklus der IT-Systeme und Anwendungen hinweg gewährleistet ist.  Entwicklung berücksichtigt die Software- und Systementwicklung, also die Erzeugung und Integration neuer IT-Komponenten in die IT-Infrastruktur der Institution.  Durch die enge Zusammenarbeit mit anderen Praktiken wie IT-Betrieb, Asset Management und Konfiguration wird gewährleistet, dass die entwickelten IT-Komponenten nicht nur sicher entwickelt werden, sondern auch sicher betrieben, verwaltet und gepflegt werden können. Diese enge Verzahnung sorgt dafür, dass Sicherheitsanforderungen durchgängig und über alle Phasen hinweg eingehalten werden.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>DEV.1: Grundlagen</td><td align="right">5</td></tr><tr valign="top"><td>DEV.2: Softwareentwicklung - Security by Design</td><td align="right">8</td></tr><tr valign="top"><td>DEV.3: Softwareentwicklung - Härtung</td><td align="right">4</td></tr><tr valign="top"><td>DEV.4: Softwareentwicklung - Code</td><td align="right">11</td></tr><tr valign="top"><td>DEV.5: Softwareentwicklung - Updates</td><td align="right">3</td></tr><tr valign="top"><td>DEV.6: Freigabe</td><td align="right">1</td></tr><tr valign="top"><td>DEV.7: Bereitstellung und Betrieb</td><td align="right">2</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>34</b></td></tr></table><h2>DEV.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DEV.1.1: Verfahren und Regelungen</td><td><p>Entwicklung MUSS Verfahren und Regelungen zur Entwicklung von IT-Produkten verankern.</p></td><td><p>Für ein Verfahren zur Softwareentwicklung siehe BSI TR-03185. Entwickelt die Institution im Informationsverbund keine IT-Produkte, so sind diese und alle anderen Anforderungen der Praktik entbehrlich. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>DEV.1.1.1: Dokumentation</td><td><p>Entwicklung MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>DEV.1.1.2: Zuweisung der Aufgaben</td><td><p>Entwicklung MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>DEV.1.1.3: Bekanntgabe</td><td><p>Entwicklung MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>DEV.1.2: Regelmäßige Überprüfung</td><td><p>Entwicklung MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr></table><h2>DEV.2: Softwareentwicklung - Security by Design</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DEV.2.1: Architektur nach dem Prinzip Security by Design</td><td><p>Entwicklung SOLLTE die Architektur nach dem Prinzip <b>„Security by Design“</b> verankern.</p></td><td><p>Unter <b>„Security by Design“</b> ist zu verstehen, dass Sicherheitsprinzipien und -mechanismen integrale Bestandteile der Architektur sind, anstatt nur nachträglich <b>„angeflanscht“</b> zu werden. Hierzu gehören Sicherheitsprinzipien wie Modularisierung, Verschlüsselung und Authentifizierung beim Entwurf der Architektur. Die Umsetzung kann durch Threat Modeling realisiert werden. Für Details siehe BSI TR-03185. Bei der Umsetzung von Security by Design empfiehlt sich auch ein Blick in die Praktik Konfiguration, spezifisch die Anforderungen zu Verschlüsselung, Authentifizierung, etc.</p></td></tr><tr valign="top"><td>DEV.2.2: Dokumentation der (Software-)Architektur</td><td><p>Entwicklung für Anwendungen SOLLTE die Architektur dokumentieren.</p></td><td><p>Die Architektur bezeichnet im konkreten Kontext die strukturierte Beschreibung der grundlegenden Komponenten einer Software sowie deren Schnittstellen, Abhängigkeiten und das Datenmodell. Sie stellt dar, wie Module, Datenflüsse und externe Systeme ineinandergreifen, und bildet damit das Gerüst für Wartung, Weiterentwicklung und Sicherheitsbewertungen. Ohne dokumentierte Architektur könnte eine Institution nach Jahren vor der Situation stehen, dass nur einzelne Entwickler den Aufbau verstehen, was den Wissenstransfer erschwert und bei Personalwechseln erhebliche Risiken birgt. Eine unklare oder fehlende Dokumentation könnte zudem dazu führen, dass Abhängigkeiten von proprietären Technologien übersehen werden, wodurch sich ein Vendor Lock-in entwickelt, der die Institution langfristig bindet. Umgekehrt kann eine nachvollziehbare Architektur Dokumentation sicherstellen, dass Schwachstellenanalysen effizient durchgeführt werden, dass Sicherheitslücken frühzeitig erkannt werden und dass neue Entwickler schneller eingearbeitet werden können. Zur Umsetzung der Anforderung kann eine Institution standardisierte Diagrammtypen wie UML oder C4 einsetzen, um Abhängigkeiten und Schnittstellen verständlich abzubilden. Hilfreich kann es sein, die Architektur in mehreren Sichten zu dokumentieren, etwa eine logische Sicht (Funktionen und Module), eine technologische Sicht (Server, Container, Frameworks) und eine sicherheitsrelevante Sicht (z. B. Trust Boundaries). Die Dokumentation kann in Versionskontrollsystemen wie Git gepflegt werden, sodass Änderungen an Architekturentscheidungen nachvollziehbar bleiben. Ergänzend kann es praktikabel sein, automatisierte Werkzeuge einzusetzen, die Code-Strukturen analysieren und Diagramme generieren, wodurch Konsistenz zwischen Dokumentation und Implementierung unterstützt werden kann.</p></td></tr><tr valign="top"><td>DEV.2.3: Ausführbarkeit mit minimalen Rechten</td><td><p>Entwicklung für Anwendungen SOLLTE die fehlerfreie Ausführung mit den geringst möglichen Berechtigungen verankern.</p></td><td><p>Die Anwendung ermöglicht die Ausführung mit den geringst möglichen Berechtigungen, wenn sie nur die Berechtigungen benötigt, die für die gerade intendierte Funktionalität erforderlich sind (also z.B. auch ohne Kamerazugriff funktioniert, wenn Nutzende nur vorhandene Bilder betrachten möchten). Sind einzelne Berechtigungen nicht vorhanden, so funktioniert die Anwendung mit entsprechenden Einschränkungen weiterhin (Graceful Degradation).</p></td></tr><tr valign="top"><td>DEV.2.4: Einschränkung Zugriffs auf Quellcode</td><td><p>Entwicklung SOLLTE den schreibenden Zugriff auf Quellcode einschränken.</p></td><td><p>Eine Einschränkung des schreibenden Zugriffes auf den Quellcode auf die zur Aufgabenerfüllung erforderlichen Personen oder IT-Systeme hilft, unbefugte Änderungen am Quellcode zu verhindern. Nach dem Grundsatz der geringstmöglichen Berechtigung benötigen schreibenden Zugriff nur Personen wie Entwickler oder Maintainer, zu deren Aufgaben die Arbeit am Code gehört.</p></td></tr><tr valign="top"><td>DEV.2.5: Einschränkung des Zugriffs auf Zugangsdaten</td><td><p>Entwicklung für Anwendungen SOLLTE den lesenden und schreibenden Zugriff auf Zugangsdaten einschränken.</p></td><td><p>Von der Anwendung verwendete Zugangsdaten können z.B. API-Schlüssel oder Datenbankanmeldeinformationen sein. Statt diese im Quellcode zu hinterlegen ist es besser, sie in Umgebungsvariablen oder sogenannten Vaults zu speichern. Hierbei hilft es auch, solche Daten mit .gitignore-Regeln aus der Versionskontrolle auszuschließen.</p></td></tr><tr valign="top"><td>DEV.2.6: Widerstandsfähigkeit gegen gängige Angriffsmuster</td><td><p>Entwicklung für Anwendungen SOLLTE Schutzfunktionen gegen gängige Angriffsmuster installieren.</p></td><td><p>Gängige Angriffsmuster sind wiederkehrende Vorgehensweisen von Angreifenden, die in der Praxis häufig auftreten, z. B. SQL-Injection, Cross-Site-Scripting (XSS) oder Pufferüberläufe. Welche Angriffsmuster für die konkrete Anwendung gängig sind, hängt von Funktionalität und Architektur der Anwendung ab, z.B. Prompt Injection bei generativer KI. Die Vorschrift zielt darauf ab, dass Produkte bereits in der Entstehung so gestaltet werden, dass typische Schwachstellen systematisch erschwert werden. Ohne entsprechende Vorkehrungen könnte ein Angreifer etwa durch manipulierte Eingaben vertrauliche Daten auslesen oder unautorisiert Funktionen steuern. Werden Schutzfunktionen frühzeitig eingebaut, kann die Stabilität des Produkts erhöht, die Angriffsfläche reduziert und das Vertrauen der Nutzenden gestärkt werden. Zur Umsetzung können etablierte Programmierpraktiken wie das Verwenden sicherer Standardbibliotheken, das Einschränken von Nutzerrechten im Code oder das Einführen von Fallback-Mechanismen bei fehlerhaften Eingaben verwendet werden. Ergänzend kann die Institution Secure Coding Guidelines nutzen, die häufige Angriffsmuster adressieren und Entwickelnden praxisnahe Hilfen bieten.</p></td></tr><tr valign="top"><td>DEV.2.6.1: Eingabevalidierung</td><td><p>Entwicklung für Anwendungen SOLLTE Eingabedaten auf eingeschleuste Befehle testen.</p></td><td><p>Bei der Eingabevalidierung (Input Validation) wird getestet, ob die Eingabedaten eingeschleuste Befehle enthalten, z.B. SQL-Injection, Kommandozeilenbefehle oder Prompt Injection bei generativer KI.   Welche Eingaben betroffen sein könnten, kann durch eine Taint Analyse herausgefunden werden. Alternativ können auch alle Eingabedaten validiert werden (Server Side Validation).</p></td></tr><tr valign="top"><td>DEV.2.6.2: Ausgabekodierung</td><td><p>Entwicklung für Anwendungen SOLLTE eine Ausgabekodierung ausführen.</p></td><td><p>Ausgabekodierung (Output Encoding) ist wichtig, da sie spezielle Zeichen neutralisiert und so Angriffe wie Cross-Site Scripting (XSS) oder HTML-Injektionen verhindert, die ansonsten Schadcode ausführen könnten. Empfehlenswert ist kontextabhängiges Encoding und Escaping, basierend auf standardisierten Frameworks wie OWASP ESAPI.</p></td></tr></table><h2>DEV.3: Softwareentwicklung - Härtung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DEV.3.1: Replay-Angriffe</td><td><p>Entwicklung für Anwendungen SOLLTE Replay-Angriffe blockieren.</p></td><td><p>Wenn die Anwendung Anfragen von anderen Anwendungen oder IT-Systemen entgegennimmt (z.B. per API), dann besteht die Gefahr, dass Angreifer eine vorherige Anfrage erneut verwenden um unbefugt Zugang zu erhalten. Maßnahmen können sein: (1) Identifikatoren, die nur einmal gültig sind (Nonce, Sequenznummern), (2) kryptographische Mechanismen wie MAC und Digitale Signaturen, Challenge-Response-Authentifizierung, OTP.</p></td></tr><tr valign="top"><td>DEV.3.2: Routinen zur Fehlerbehandlung</td><td><p>Entwicklung für Anwendungen SOLLTE spezifische und allgemeine Routinen zur Fehlerbehandlung ausführen.</p></td><td><p>Behandeln Sie Fehler (Exceptions) möglichst nahe an der Quelle (z.B. Buffer Overflows, fehlende Dateien) und sehen sie eine Routine vor, die unerwartete Fehler abfängt. Geben Sie passende Fehlermeldungen aus und protokollieren Sie Fehler.</p></td></tr><tr valign="top"><td>DEV.3.3: Deaktivierung der Ausgabe schützenswerter Daten durch Fehlermeldungen</td><td><p>Entwicklung für Anwendungen SOLLTE die Ausgabe schützenswerter Daten durch Fehlermeldungen deaktivieren.</p></td><td><p>Werden sensible Daten in Fehlermeldungen oder Log-Einträgen verwendet, kommt es leicht zur Offenlegung dieser Informationen gegenüber Unbefugten. Hierzu gehören auch Hinweise auf das Vorhandensein oder Nicht-Vorhandensein eines Nutzendenkontos.</p></td></tr><tr valign="top"><td>DEV.3.4: Passwort-Hashing</td><td><p>Entwicklung für Anwendungen SOLLTE das Hashing von Passwörtern, die zur Authentifizierung an der Anwendung verwendet werden vor der Verarbeitung oder Speicherung aktivieren.</p></td><td><p>Ziel ist der Schutz vor Angriffen, welche Passwörter beim Transport oder aus dem Speicher auslesen und sich hiermit anmelden. Dies kann durch Hash und Salt gemäß BSI TR-02102 vermieden werden.</p></td></tr></table><h2>DEV.4: Softwareentwicklung - Code</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DEV.4.1: Nutzerinformation bei kritischen Ereignissen</td><td><p>Entwicklung für Anwendungen SOLLTE bei sicherheitskritischen Ereignissen die betroffenen Nutzenden informieren.</p></td><td><p>Z.B. bei Anmeldung von neuen Geräten, Zurücksetzen des Passwortes, ungewöhnlichen Standorten oder der Änderung von Stammdaten.</p></td></tr><tr valign="top"><td>DEV.4.2: Bibliotheksquellen</td><td><p>Entwicklung für Anwendungen SOLLTE die Einbindung externer Softwarebibliotheken und -Schnittstellen aus unzuverlässigen oder unbekannten Quellen untersagen.</p></td><td><p>Eine Quelle ist unzuverlässig, wenn zukünftig mit Verstößen gegen die Schutzziele Vertraulichkeit, Verfügbarkeit oder Integrität durch sie zu rechnen ist (d.h. eine Prognose der Vertrauenswürdigkeit). Dies ist insbesondere der Fall, wenn erhebliche Verstöße gegen die Schutzziele durch sie begangen worden sind oder Anzeichen dafür vorliegen, dass bei einer Verwendung mit solchen Verstößen zu rechnen ist.</p></td></tr><tr valign="top"><td>DEV.4.3: SBOM</td><td><p>Entwicklung für Anwendungen SOLLTE die Bestandteile mit Hilfe einer Software Bill of Materials (SBOM) vor dem Release dokumentieren.</p></td><td><p>Details siehe BSI TR-03183-2. Anwendungen zur Modulverwaltung und Software Composition Analysis (SCA) können dabei unterstützen SBOMs als Teil eines CI/CD Prozesses automatisiert zu sammeln.</p></td></tr><tr valign="top"><td>DEV.4.4: Integrität externer Softwarebibliotheken</td><td><p>Entwicklung für Anwendungen SOLLTE die Integrität externer Softwarebibliotheken vor dem Release testen.</p></td><td><p>Gemeint ist damit sowohl die technische Unversehrtheit (z. B. durch kryptografische Prüfungen wie Hash- oder Signaturvalidierung) als auch die inhaltliche Zuverlässigkeit (z. B. keine eingeschleusten Schadfunktionen oder versteckte Abhängigkeiten). Der Sinn und Zweck dieser Anforderung liegt darin, die Risiken durch unsichere oder manipulierte Fremdkomponenten zu reduzieren. So könnte ein Angreifer Schadcode in eine weit verbreitete Bibliothek einschleusen, die dann unbemerkt in der Anwendung landet, oder eine Abhängigkeit könnte im Hintergrund auf nicht mehr gepflegte Versionen verweisen. Eine wirksame Integritätsprüfung kann verhindern, dass fehlerhafte oder kompromittierte Bausteine in produktive Anwendungen gelangen und kann damit auch die Abhängigkeit von nicht vertrauenswürdigen Quellen abmildern. Zur Umsetzung können (1) Hashwerte oder digitale Signaturen von Bibliotheken mit den Referenzwerten der Hersteller verglichen werden, (2) der Bezug externer Pakete über offizielle, verifizierte Repositories statt über inoffizielle Quellen stattfinden, und (3) in der Build-Pipeline eine automatisierte Integritätsprüfung eingerichtet sein, die verdächtige oder unvollständige Bibliotheken blockieret. Ergänzend kann eine institutionseigene Allowlist gepflegt werden, die geprüfte Versionen von Bibliotheken enthält, sodass Entwickler nicht unkontrolliert beliebige Abhängigkeiten einbinden. Ein praktischer Tipp kann sein, die Prüfmechanismen möglichst früh im Entwicklungsprozess zu automatisieren, um spätere manuelle Nacharbeiten oder Verzögerungen vor einem Release zu vermeiden.</p></td></tr><tr valign="top"><td>DEV.4.5: Updates externer Softwarebibliotheken</td><td><p>Entwicklung für Anwendungen SOLLTE externe Softwarebibliotheken auf Sicherheitsupdates vor dem Release testen.</p></td><td><p>Werden veraltete Softwarebibliotheken in eine veröffentlichte Software eingebunden, so können diese Sicherheitslücken oder Fehler enthalten, die in den aktuellen Versionen bereits behoben sind. Prüfen Sie daher vor einer Freigabe der Software ob eingebundene Bibliotheken aktualisiert wurden.</p></td></tr><tr valign="top"><td>DEV.4.6: Compileroptionen</td><td><p>Entwicklung für Anwendungen SOLLTE Compileroptionen für Sicherheitsfunktionen vor dem Release aktivieren.</p></td><td><p>Compileroptionen wie Stack Canaries, PIE, PIE, CFI können automatisch Schutzmechanismen in Programme einbauen. Bewährte Praxis ist es, diese Compileroptionen zu aktivieren, sofern es keine entgegenstehenden besonderen Gründe gibt, darauf im Einzelfall zu verzichten. Werden interpretierte Programmiersprachen verwendet, so ist die Anforderung analog auf die Interpreter-Optionen anzuwenden.</p></td></tr><tr valign="top"><td>DEV.4.7: Deterministischer Binärcode</td><td><p>Entwicklung für Anwendungen KANN eine reproduzierbare Vorgehensweise zur Erstellung eines bestimmten Binärcodes aus dem Quellcode dokumentieren.</p></td><td><p>Ein bestimmter Binärcode meint hier eine reproduzierbare Anwendung (Reproducible builds). Das bedeutet, dass jeder, der denselben Quellcode und dieselbe Build-Umgebung verwendet, bitweise identische Binärdateien erstellt, was die Integrität der Software gegen Manipulationen oder Malware sichert. Dies geschieht durch die genaue Beschreibung der Build-Umgebung und die Vermeidung von zufälligen Faktoren wie Zeitstempeln, die sich auf die erzeugten Artefakte auswirken könnten.</p></td></tr><tr valign="top"><td>DEV.4.8: Default-Zugangsdaten</td><td><p>Entwicklung für Anwendungen SOLLTE Default-Zugangsdaten vor dem Release dokumentieren.</p></td><td><p>Falls die Software Default-Zugangsdaten wie Passwörter oder Zertifikate enthält, so ist eine sichere Nutzung der Software nur möglich, wenn Nutzende hiervon Kenntnis erhalten um die Zugangsdaten ändern zu können. Sind keine Default-Zugangsdaten erforderlich, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>DEV.4.9: Voreinstellungen nach dem Prinzip Security by Default</td><td><p>Entwicklung für Anwendungen SOLLTE Voreinstellungen nach dem Prinzip <b>„Security by Default“</b> aktivieren.</p></td><td><p>Voreinstellungen sind die Parameter der Anwendung, mit denen diese im Auslieferungszustand (oder bei Cloud-Anwendungen beim Anlegen eines neuen Zugangskontos) ausgeführt wird. Welche Parameter hier konkret sicher sind ergibt sich aus der Praktik Konfiguration für die jeweilige Art von Zielobjekten.</p></td></tr><tr valign="top"><td>DEV.4.10: Protokollierung von Codeänderungen</td><td><p>Entwicklung für Anwendungen SOLLTE Änderungen am Quellcode einschließlich Zeitpunkt, Inhalt der Änderung, ändernder Person und der Begründung der Änderung protokollieren.</p></td><td><p>Im Kontext dieser Anforderung bezeichnet Quellcode den in einer Programmiersprache geschriebenen, von Menschen lesbaren Anteil einer Anwendung, während eine Änderung jede Anpassung, Ergänzung oder Entfernung dieses Codes umfasst. Unter Begründung ist die dokumentierte fachliche oder technische Motivation zu verstehen, die erläutert, warum eine Änderung notwendig war, beispielsweise zur Fehlerbehebung, Funktionserweiterung oder Verbesserung der Sicherheit. Der Zeitpunkt entspricht dabei einem präzisen Zeitstempel, der eine eindeutige zeitliche Nachvollziehbarkeit erlaubt, und die ändernde Person ist diejenige, die die Modifikation fachlich veranlasst oder technisch durchgeführt hat – nicht zwingend dieselbe Rolle wie ein Freigebender oder Reviewer. Die Protokollierung kann verhindern, dass unautorisierte oder fehlerhafte Anpassungen unentdeckt bleiben, und sie kann im Streitfall eine klare Nachvollziehbarkeit bieten. Ohne diese Nachweise könnte es zu unklaren Verantwortlichkeiten, erhöhtem Manipulationsrisiko oder schwer nachvollziehbaren Fehlfunktionen kommen. Eine Institution kann diese Anforderung durch Nutzung von Versionsverwaltungssystemen wie Git oder Subversion umsetzen, indem sie für jede Änderung standardisierte Commit-Meldungen mit Zeitstempel, Autor und Begründung erzwingt. Ergänzend kann ein Workflow etabliert werden, bei dem Änderungen erst nach einem Merge- oder Pull-Request mit dokumentierter Beschreibung in den Hauptzweig gelangen. Sinnvoll ist es zudem, einfache Vorlagen oder Textbausteine für Begründungen bereitzustellen, sodass Änderungen einheitlich und vollständig erklärt werden können. Für Transparenz kann zusätzlich ein automatisches Änderungsprotokoll generiert werden, das regelmäßig exportiert oder archiviert wird, um auch ohne Zugriff auf das Versionsverwaltungssystem auswertbar zu bleiben.</p></td></tr><tr valign="top"><td>DEV.4.11: Test bei Änderungen am Quellcode</td><td><p>Entwicklung für Anwendungen SOLLTE Änderungen am Quellcode im Einklang mit den Verfahren und Regelungen für Änderungen und Tests testen.</p></td><td><p>„Änderungen am Quellcode“ (engl. source code changes) bezeichnet im gegebenen Kontext sämtliche Modifikationen, die an den Programmbestandteilen einer Anwendung vorgenommen werden, also etwa neue Funktionen, Fehlerkorrekturen oder Anpassungen an Schnittstellen. Fehlerhafte oder ungetestete Anpassungen könnten etwa zu Sicherheitslücken, Datenverlust oder Instabilitäten im Betrieb führen, wohingegen eine strukturierte Prüfung verhindern kann, dass bekannte Schwachstellen erneut auftreten oder unbeabsichtigte Seiteneffekte entstehen. Solche Änderungen sind daher als Teil des Change Managements zu betrachten, dessen Anforderungen im Einzelnen in der Praktik Änderungen und Tests zu finden sind. Zur praktischen Umsetzung kann eine Institution jede Änderung automatisiert durch Static Application Security Testing (SAST) prüfen, wodurch potenzielle Schwachstellen direkt im Quellcode erkannt werden können. Ergänzend ist es sinnvoll Dynamic Application Security Testing (DAST) einzusetzen, um die lauffähige Anwendung in einer Testumgebung gegen typische Angriffe wie SQL-Injection oder Cross-Site-Scripting zu überprüfen. Sinnvolle Maßnahmen können dabei sein: (1) Aufbau einer Continuous-Integration-Pipeline, die automatisierte Unit-, Integrations- und Sicherheitstests einbindet und Ergebnisse konsolidiert darstellt, (2) Durchführung von manuellen explorativen Tests in einer isolierten Testumgebung, um auch unerwartete Nutzungsmuster zu prüfen, (3) Einsatz von Regressionstests, die sicherstellen können, dass neue Änderungen keine bestehenden Funktionen beeinträchtigen. Eine Institution kann damit die Qualitätssicherung stärken und gleichzeitig Angriffsflächen durch fehlerhafte Änderungen reduzieren.</p></td></tr></table><h2>DEV.5: Softwareentwicklung - Updates</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DEV.5.1: Verankerung des Zeitraums für Updates</td><td><p>Entwicklung für Anwendungen SOLLTE einen Zeitraum der Bereitstellung von Sicherheitsupdates verankern.</p></td><td><p>Hierbei wird festgelegt, für welchen Zeitraum Sicherheitsaktualisierungen (Patches) für das Produkt bereitgestellt werden. Denken Sie dabei daran, ob ggf. Compliance-Verpflichtungen einzuhalten sind, z.B. § 475b Abs. 3 Nr. 2 BGB für Verbraucherverträge.</p></td></tr><tr valign="top"><td>DEV.5.2: Information über Zeitraum für Updates</td><td><p>Entwicklung für Anwendungen SOLLTE Auftraggeber über den festgelegten Zeitraum für Sicherheitsupdates informieren.</p></td><td><p>Stellen Sie den Empfängern der Software Informationen darüber bereit, wie lange Sicherheitsaktualisierungen gewährleistet werden und wie diese bezogen werden können.</p></td></tr><tr valign="top"><td>DEV.5.3: Integritätsprüfung</td><td><p>Entwicklung für Anwendungen SOLLTE Nutzende über Möglichkeiten zur Verifikation der Integrität von Installations-, Update- und Patchdateien informieren.</p></td><td><p>Dies kann z.B. durch die Veröffentlichung von Prüfsummen über einen authentifizierten Kanal wie eine Webseite mit X.509-Zertifikat erfolgen.</p></td></tr></table><h2>DEV.6: Freigabe</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DEV.6.1: Freigabe nach Änderungen und Tests</td><td><p>Entwicklung SOLLTE die Freigabe zur Nutzung im Einklang mit den entsprechenden Verfahren und Regelungen für Änderungen und Tests autorisieren.</p></td><td><p>Eine Freigabe zur Nutzung (Release) meint hier die formelle und autorisierte Überführung einer entwickelten oder geänderten IT-Komponente (wie Software, Systemkonfiguration, Dienstleistung) von einer Test- oder Entwicklungsumgebung in eine Produktions- oder Betriebsumgebung, um den Endbenutzern zur Verfügung zu stehen. Die Vorschrift zielt darauf ab, sicherzustellen, dass nur getestete und abgestimmte Änderungen in den Betrieb gelangen. Ohne diese Autorisierung könnte ungetesteter Code oder eine nicht genehmigte Systemänderung zu schwerwiegenden Betriebsunterbrechungen, Datenverlust oder Sicherheitslücken führen. Eine formalisierte Freigabe kann die Integrität und Verfügbarkeit von Systemen schützen, indem sie die Einhaltung der etablierten Verfahren und Regelungen für Änderungen und Tests sicherstellt.</p></td></tr></table><h2>DEV.7: Bereitstellung und Betrieb</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DEV.7.1: Sichere Bereitstellung</td><td><p>Entwicklung SOLLTE die Bereitstellung im Einklang mit den entsprechenden Verfahren und Regelungen für Änderungen und Tests verankern.</p></td><td><p>Die Bereitstellung ist der Prozessschritt, durch den eine neu entwickelte oder geänderte Softwareversion, ein Dienst oder ein System in die Produktionsumgebung überführt und dort aktiv für die Endnutzer oder Geschäftsprozesse zugänglich gemacht wird. Die Anforderungen aus der Praktik Änderungen und Tests (also zum Change Management) betreffen auch die Bereitstellung. Eine geordnete Bereitstellung minimiert das Risiko, dass ungetestete oder nicht genehmigte Änderungen in Betrieb gehen, was sonst zu Dienstunterbrechungen, Datenverlust oder der Ausnutzung von Sicherheitslücken führen könnte.</p></td></tr><tr valign="top"><td>DEV.7.2: Zertifikatsmonitoring</td><td><p>Entwicklung für Anwendungen SOLLTE die Ausstellung neuer Zertifikate für die von der Anwendung verwendeten Domains überwachen.</p></td><td><p>Anwendungen die über das Netz kommunizieren nutzen typischerweise X.509-Zertifikate zur Authentifizierung (z.B. per TLS). Die Ausstellung neuer Zertifikate bei Zertifizierungsstellen kann ein Angriffsversuch Dritter sein, die vorgeben wollen die Anwendung zu betreiben. Dies kann mittels Certificate Transparency automatisiert werden.</p></td></tr></table><h1>KONF: Konfiguration</h1><p>Die Praktik Konfiguration stellt sicher, dass IT-Komponenten – wie Anwendungen und IT-Systeme – gemäß den festgelegten Informationssicherheitsrichtlinien eingerichtet und kontinuierlich gepflegt werden, um Sicherheitslücken durch fehlerhafte oder unsichere Einstellungen zu vermeiden. Dies umfasst auch die nachvollziehbare Erstellung und Fortführung der Dokumentation.  Konfiguration beinhaltet die Realisierung einer sicheren Konfiguration von Anwendungen und IT-Systemen. Sie fokussiert auf die Sicherstellung eines sicheren Zustands (z.B. Maßnahmen zur Systemhärtung). Hingegen beinhaltet die Praktik IT-Betrieb alle Vorgehensweisen zur Wartung und Pflege der Anwendungen und IT-Systeme im Rahmen eines strukturierten IT-Betriebs.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>KONF.1: Grundlagen</td><td align="right">8</td></tr><tr valign="top"><td>KONF.2: Konfiguration von Systemen</td><td align="right">13</td></tr><tr valign="top"><td>KONF.3: Physischer Schutz</td><td align="right">9</td></tr><tr valign="top"><td>KONF.4: Vertrauenswürdige Basisdienste</td><td align="right">7</td></tr><tr valign="top"><td>KONF.5: Authentifizierung</td><td align="right">4</td></tr><tr valign="top"><td>KONF.6: Rollen und Berechtigungen</td><td align="right">21</td></tr><tr valign="top"><td>KONF.7: Schutz vor Schadcode</td><td align="right">17</td></tr><tr valign="top"><td>KONF.8: Sicherheitsupdates</td><td align="right">3</td></tr><tr valign="top"><td>KONF.9: Verfügbarkeit von Ressourcen</td><td align="right">3</td></tr><tr valign="top"><td>KONF.10: Konfiguration von Anwendungen</td><td align="right">7</td></tr><tr valign="top"><td>KONF.11: Vertrauensbeziehungen</td><td align="right">14</td></tr><tr valign="top"><td>KONF.12: Kontrollierte Datenverarbeitung</td><td align="right">25</td></tr><tr valign="top"><td>KONF.13: Senden und Empfangen von Nachrichten</td><td align="right">16</td></tr><tr valign="top"><td>KONF.14: Verteilte Anwendungen</td><td align="right">7</td></tr><tr valign="top"><td>KONF.15: Ressourcenauslastung</td><td align="right">4</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>158</b></td></tr></table><h2>KONF.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.1.1: Verfahren und Regelungen</td><td><p>Konfiguration MUSS Verfahren und Regelungen zum Konfigurationsmanagement verankern.</p></td><td><p>Die Umsetzung kann in einem eigenen Prozess, oder integriert in andere Prozesse und Aufgaben erfolgen. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>KONF.1.1.1: Dokumentation</td><td><p>Konfiguration MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>KONF.1.1.2: Zuweisung der Aufgaben</td><td><p>Konfiguration MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>KONF.1.1.3: Bekanntgabe</td><td><p>Konfiguration MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>KONF.1.2: Regelmäßige Überprüfung</td><td><p>Konfiguration MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr><tr valign="top"><td>KONF.1.3: Management von Werkzeugen</td><td><p>Konfiguration SOLLTE verwendete Konfigurationswerkzeuge einschließlich Verwendungszweck und Herkunft dokumentieren.</p></td><td><p>Der Begriff Konfigurationswerkzeuge bezeichnet in diesem Zusammenhang alle technischen Hilfsmittel, mit denen Systemeinstellungen erstellt, verändert oder verwaltet werden – beispielsweise Skriptsprachen, Automatisierungs-Frameworks, Versionsverwaltungswerkzeuge oder grafische Konfigurationsoberflächen. Unter Verwendungszweck wird verstanden, welche Funktion das jeweilige Werkzeug innerhalb des Betriebs erfüllt, etwa für automatisierte Serverbereitstellung, Netzwerkkonfiguration oder Datenbankparametersteuerung. Mit Herkunft ist die Herkunft des Werkzeugs gemeint, d. h. ob es sich um Eigenentwicklungen, quelloffene Software oder kommerzielle Produkte handelt und aus welchen Quellen diese bezogen werden. Die Dokumentation dieser Punkte kann Transparenz schaffen und Nachvollziehbarkeit erhöhen, wodurch Fehlkonfigurationen oder Manipulationen schneller erkannt werden können. Ohne klare Übersicht könnte unklar bleiben, mit welchen Mitteln kritische Systeme verändert wurden, was die Ursachenanalyse im Störungsfall erheblich erschweren könnte. Eine saubere Dokumentation kann verhindern, dass nicht vertrauenswürdige oder nicht mehr gepflegte Werkzeuge unbemerkt im Betrieb verbleiben und so potenzielle Angriffsvektoren entstehen. Für die Umsetzung kann die Institution eine strukturierte Werkzeugliste führen, in der pro Eintrag neben Name, Version und Hersteller auch Zweck und Beschaffungsquelle vermerkt werden. Diese Liste kann in einem Konfigurations- oder Inventarsystem gepflegt werden, sodass Aktualisierungen automatisiert oder zumindest standardisiert erfolgen können. Praktisch kann es helfen, jedes neue Werkzeug vor Einsatz über ein Freigabeverfahren einzutragen und zu kennzeichnen, ob es intern geprüft wurde. Eine einfache Möglichkeit besteht darin, bestehende Versionskontrollsysteme oder zentrale Wiki-Seiten zu nutzen, die alle relevanten Informationen versioniert und nachvollziehbar speichern können. Dies kann auch durch eine Markierung der administrativen Werkzeuge im Inventar der Anwendungen umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.1.4: Einschränkung des Zugriffs auf Dokumentation</td><td><p>Konfiguration SOLLTE den Zugriff auf dokumentierte Konfigurationen einschränken.</p></td><td><p>„Dokumentierte Konfigurationen“ sind hierbei festgehaltene Einstellungen von IT-Systemen, Anwendungen, Netzwerken oder Sicherheitskomponenten, die in schriftlicher oder elektronischer Form vorliegen und den Sollzustand einer IT-Umgebung definieren. Der Zweck der Vorschrift liegt darin, die Integrität und Vertraulichkeit solcher Konfigurationsinformationen zu schützen. Ein unkontrollierter Zugriff könnte beispielsweise dazu führen, dass ein Unbefugter Passworteinstellungen oder Firewall-Regeln manipuliert. Aus der Konfiguration von IT-Systemen könnte ein Angreifer zudem wichtige Informationen zu möglichen Schwachstellen ablesen (z.B. bei technisch notwendiger Verwendung schwacher Verschlüsselungsalgorithmen oder unsicherer Authentisierungsprotokolle wie NTLM). Ein strikter Zugriffsschutz (z.B. durch restriktive Berechtigungen oder Verschlüsselung) verhindert den unberechtigten Zugriff zu diesen sensiblen Informationen. Praktisch hilfreich kann auch sein, Konfigurationen verschlüsselt abzulegen und bei elektronischen Repositories sogenannte „Branch Protection“-Mechanismen einzusetzen, sodass Änderungen nur über geprüfte Freigabeprozesse übernommen werden können. Auf Papier vorliegende Konfigurationen kann die Institution in verschlossenen Schränken oder Archiven mit eingeschränktem Personenkreis verwahren.</p></td></tr><tr valign="top"><td>KONF.1.5: Verschlüsselung von Konfigurationsgeheimnissen</td><td><p>Konfiguration SOLLTE Konfigurationsgeheimnisse verschlüsseln.</p></td><td><p>Konfigurationsgeheimnissen sind sensitive, nicht-öffentliche Daten, die von Systemen, Applikationen oder Diensten zur Laufzeit benötigt werden, um auf andere Ressourcen zuzugreifen oder ihre eigene Funktionalität sicherzustellen. Bekannte Beispiele sind Anmeldeinformationen wie Passwörter, Datenbank-Verbindungszeichenfolgen (Connection Strings), API-Schlüssel oder private Schlüssel von Zertifikaten; im Englischen wird hierfür übergreifend der Fachbegriff Secrets verwendet. Der Zweck dieser Vorschrift ist die Sicherstellung der Vertraulichkeit dieser hochsensiblen Informationen. Ungeschützt im Klartext hinterlegt, könnte ein Angreifer bei einem unautorisierten Zugriff auf Konfigurationsdateien, Quellcode-Verzeichnisse oder Backups diese Geheimnisse direkt auslesen und damit weitreichenden Zugriff auf angebundene Systeme oder Daten erlangen.</p></td></tr></table><h2>KONF.2: Konfiguration von Systemen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.2.1: Grundkonfiguration für Systeme</td><td><p>Konfiguration für IT-Systeme SOLLTE eine Grundkonfiguration dokumentieren.</p></td><td><p>Eine Grundkonfiguration (engl. baseline configuration) bezeichnet hier einen dokumentierten Ausgangszustand, der alle sicherheitsrelevanten Einstellungen, Dienste und Komponenten umfasst und als verbindlicher Referenzpunkt für den Betrieb und die Härtung dient. Sie stellt damit eine Art „Zielzustand“ dar, anhand dessen spätere Änderungen überprüft oder Abweichungen erkannt werden können. Ohne eine solche Referenz könnte es bei Installationen, Updates oder Wiederherstellungen zu unsicheren Abweichungen kommen, etwa wenn unnötige Dienste aktiv bleiben, Standardkonten nicht deaktiviert sind oder Kommunikationsschnittstellen unkontrolliert offenstehen; umgekehrt kann eine saubere Grundkonfiguration sicherstellen, dass Systeme konsistent, nachvollziehbar und auf Basis etablierter Sicherheitsanforderungen betrieben werden. Hierzu gehört z.B. die Konfiguration der Uhrensychronisation, von DNS und Verzeichnisdiensten, die Änderung von Default-Zugangsdaten oder der automatische Abruf benötigter Lizenzen. Die Umsetzung einer Grundkonfiguration kann durch verschiedene Maßnahmen unterstützt werden: (1) Es ist sinnvoll, Herstellerdokumentationen zu sichten und empfohlene Härtungseinstellungen (z. B. Deaktivierung unsicherer Protokolle) als Ausgangspunkt zu übernehmen. (2) Ergänzend können Empfehlungen des BSI oder Benchmarks wie die CIS Benchmarks herangezogen werden, um systematisch sicherheitskritische Parameter zu prüfen und einzupflegen. (3) Für komplexe Umgebungen kann ein Konfigurationsskript oder ein Automatisierungs-Tool (z. B. Ansible, Puppet, Chef) genutzt werden, um eine reproduzierbare Baseline einzuspielen und Abhängigkeiten der Komponenten konsistent zu berücksichtigen. Auf diese Weise kann die Institution sicherstellen, dass jede Installation oder Wiederherstellung eines Systems auf einer überprüfbaren und einheitlichen Basis erfolgt.</p></td></tr><tr valign="top"><td>KONF.2.1.1: Versionierung</td><td><p>Konfiguration für IT-Systeme SOLLTE eine Versionierung vorheriger Konfigurationen verankern.</p></td><td><p>Die Versionierung bezeichnet hier die strukturierte Nachvollziehbarkeit von Änderungen an Konfigurationen, also das Speichern, Dokumentieren und bei Bedarf Wiederherstellen älterer Zustände eines IT-Systems. Sie unterscheidet sich von einem einfachen Backup dadurch, dass nicht nur eine Kopie vorliegt, sondern explizit eine fortlaufende Historie mit Vergleichen, Rücksetzpunkten (rollback points) und optional Kommentaren geführt wird. Der Zweck liegt darin, dass eine ungewollte oder fehlerhafte Anpassung an einer Konfiguration im Betrieb schnell erkannt und – wenn erforderlich – präzise auf einen definierten, funktionsfähigen Zustand zurückgesetzt werden kann. Ohne eine solche Versionierung könnte eine fehlerhafte Änderung unbemerkt bleiben oder nur schwer rückgängig gemacht werden. Praktisch umgesetzt kann dies z. B. durch den Einsatz von Konfigurationsmanagement-Tools erfolgen, die automatisch Änderungen versionieren und mit Prüfsummen sichern. Alternativ kann eine Institution auch Konfigurationsdateien regelmäßig in ein Versionsverwaltungssystem wie Git einspielen. Zusätzlich kann es hilfreich sein, Konfigurationsänderungen über standardisierte Änderungsprozesse einzupflegen, sodass jede Anpassung nachvollziehbar protokolliert wird. Eine weitere Möglichkeit kann die Einrichtung von Skripten sein, die Konfigurationsstände automatisch aus Geräten exportieren und revisionssicher ablegen. Zur Umsetzung können Anwendungen zur Geheimnisverwaltung, oft als Secrets-Manager oder Vault bezeichnet, eingesetzt werden. Solche Anwendungen speichern alle Geheimnisse zentral und hochverschlüsselt und stellen sie erst bei Bedarf zur Laufzeit über eine authentifizierte und gesicherte Schnittstelle (API) zur Verfügung. Eine weitere, weit verbreitete Praxis ist die Auslagerung von Secrets aus den Konfigurationsdateien in Umgebungsvariablen (Environment Variables) des ausführenden Systems, wodurch eine strikte Trennung von Code und Konfiguration erreicht wird. Alternativ kann auch die Konfigurationsdatei selbst oder zumindest die Abschnitte, die Geheimnisse enthalten, verschlüsselt werden, wobei dies erfordert, dass der zur Entschlüsselung notwendige Schlüssel seinerseits sicher an die Applikation übergeben wird.</p></td></tr><tr valign="top"><td>KONF.2.2: Kryptographische Verfahren und Protokolle</td><td><p>Konfiguration für IT-Systeme SOLLTE kryptographische Verfahren und Protokolle im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement aktivieren.</p></td><td><p>Kryptographie wird für die Authentifizierung, Verschlüsselung und Integritätprüfung in Systemen verwendet, z.B. bei der Verschlüsselung von Speichermedien, bei der Anmeldung am System, Transportverschlüsselung von Systemupdates oder Integritätsprüfung von Systemfunktionen. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Funktionen so zu konfigurieren sind, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>KONF.2.3: Änderung von Default-Zugangsdaten</td><td><p>Konfiguration für IT-Systeme SOLLTE die Änderung von Default-Zugangsdaten ausführen.</p></td><td><p><b>„Default-Zugangsdaten“</b> sind werkseitig voreingestellte Benutzername-Passwort-Kombinationen wie <b>„root“</b> oder <b>„administrator“</b>, sowie vergleichbare Authentifizierungsmerkmale, die bei der Erstinbetriebnahme von IT-Systemen unverändert vorhanden sind. Diese Daten sind in der Regel öffentlich dokumentiert oder leicht im Internet auffindbar. Ihr Fortbestehen im Produktivbetrieb könnte ein erhebliches Risiko darstellen, da ein Angreifer mit minimalem Aufwand Zugriff auf Systeme erlangen könnte. Ein klassischer Vorfall könnte sein, dass ein öffentlich erreichbarer Router mit unveränderten Standardzugängen übernommen wird. Die Änderung kann demgegenüber sicherstellen, dass nur berechtigte Personen Zugriff erlangen, und kann damit unbefugte Manipulationen oder Datendiebstahl wirksam erschweren. Eine Institution kann die Anforderung umsetzen, indem bei der Inbetriebnahme jedes Systems ein Prozess etabliert wird, der die Standardzugangsdaten unmittelbar ersetzt. Dies kann beispielsweise (1) durch verpflichtende Initial-Setup-Routinen erfolgen, die eine Passwortänderung erzwingen, oder (2) durch zentrale Checklisten oder automatisierte Inventarisierung, die offene Standardzugänge identifizieren und schließen. Die Anforderung ist auch dann erfüllt, wenn diese Zugänge deaktiviert oder durch Zugänge mit von der Institution verwalteten Zugangsdaten ersetzt werden.</p></td></tr><tr valign="top"><td>KONF.2.4: Deaktivierung nicht benötigter Systemfunktionen</td><td><p>Konfiguration für IT-Systeme SOLLTE nicht benötigte Systemfunktionen deaktivieren.</p></td><td><p>Die Deaktivierung von Funktionen, die für Betrieb oder aus Sicherheitssicht nicht benötigt werden, hilft, die Angriffsfläche und Fehlerkomplexität zu verringern, z.B. unnötige Identitäten, ggf. nicht benötigte Schnittstellen wie Bluetooth, nicht verwendete Netzprotokolle wie NTLMv1 Authentifizierung, schwache Verschlüsselungsalgorithmen wie TLS1.1, die Anzeige von Nachrichteninhalten auf dem Sperrbildschirm oder nicht benötigte System- oder Telemetriedienste. Relevant sind dabei sowohl Betriebssystem- als auch Firmwarefunktionen.</p></td></tr><tr valign="top"><td>KONF.2.4.1: Nicht benötigte Zertifikate</td><td><p>Konfiguration für IT-Systeme SOLLTE nicht benötigte Zertifikate deaktivieren.</p></td><td><p>Hierbei ist insbesondere an die vom Betriebssystem als vertrauenswürdig eingestuften Zertifizierungsstellen zu denken, wenn sie nicht länger benötigt werden. Verfügt das IT-System über keine Zertifikate, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.2.4.2: Externe Cloud-Anbindungen</td><td><p>Konfiguration für IT-Systeme SOLLTE nicht benötigte Cloud-Anbindungen deaktivieren.</p></td><td><p>Eine Cloud-Anbindung ist eine technische Schnittstelle, über die ein IT-System Daten oder Dienste mit einer externen Cloud-Plattform austauscht. Dazu können sowohl direkte API-Integrationen wie die Anmeldung an Cloud-Verzeichnisdienste, aber auch automatische Synchronisationsmechanismen, Hintergrund-Updates über Cloud-Server oder agentenbasierte Remote-Management-Funktionen zählen. Nicht benötigte Anbindungen können dadurch identifiziert werden, dass sie weder für den produktiven Betrieb noch für Wartung, Support oder Sicherheitsfunktionen erforderlich sind. Der Sinn und Zweck dieser Regelung liegt darin, die Angriffsfläche zu reduzieren und unkontrollierte Datenflüsse zu vermeiden. Ein nicht genutzter, aber weiterhin aktiver Cloud-Connector könnte etwa unbemerkt sensible Metadaten an Drittdienste übertragen oder als Einfallstor für Schadsoftware missbraucht werden; die gezielte Deaktivierung kann dagegen unnötige Risiken eliminieren und die Übersichtlichkeit der Systemarchitektur erhöhen.</p></td></tr><tr valign="top"><td>KONF.2.5: Überprüfung der Konfiguration</td><td><p>Konfiguration für IT-Systeme SOLLTE die Übereinstimmung der tatsächlichen Konfiguration mit dem Referenzzustand <i>regelmäßig</i> überprüfen.</p></td><td><p>Referenzzustand („baseline configuration“) bezeichnet hier die dokumentierte und freigegebene Konfiguration eines IT-Systems, also die gewünschte und autorisierte Einstellung von Parametern, Diensten und Komponenten. Die tatsächliche Konfiguration ist die aktuelle technische Umsetzung dieser Einstellungen auf dem System selbst. Der Abgleich beider Zustände dient vor allem der Vermeidung von Configuration Drift – d.h. dass Systeme schleichend von der definierten Soll-Konfiguration abweichen. Dies könnte auftreten, wenn Änderungen nicht zentral dokumentiert oder automatisierte Installationen nicht einheitlich umgesetzt werden. Ohne diese Kontrolle könnte es zu unbemerkten Fehlkonfigurationen kommen, die Sicherheitslücken öffnen oder Betriebsstörungen verursachen. Durch regelmäßige Vergleiche kann eine Institution sicherstellen, dass Systeme konsistent, vertrauenswürdig und wartbar bleiben. Eine praktische Umsetzung kann auf verschiedenen Ebenen erfolgen. Technisch kann eine Institution (1) Konfigurations-Management-Werkzeuge einsetzen, die Referenzzustand-Definitionen mit Systemzuständen automatisch abgleichen, (2) Skripte oder Policies nutzen, die regelmäßig Konfigurationsdateien oder Systemeinstellungen auslesen und protokollieren, oder (3) Hash- oder Signaturverfahren anwenden, um Veränderungen an Konfigurationsdateien nachzuweisen. Prozessual kann es hilfreich sein, Änderungen zentral zu dokumentieren und automatische Reports über Abweichungen an Verantwortliche weiterzuleiten, damit diese reagieren können. Zusätzlich kann eine Institution Pilotprüfungen an Stichproben-Systemen durchführen, um die Wirksamkeit automatischer Abgleiche zu validieren. Durch diese Maßnahmen kann eine Institution eine belastbare Routine etablieren, die Configuration Drift reduziert und nicht nur technische Abweichungen sichtbar macht, sondern auch menschliche Fehler oder unautorisierte Eingriffe frühzeitig erkennen kann.</p></td></tr><tr valign="top"><td>KONF.2.5.1: Automatische Konfigurationsverwaltung</td><td><p>Konfiguration für IT-Systeme KANN die Überprüfung der Konfiguration durch <i>einen automatisierten Mechanismus</i> aktivieren.</p></td><td><p>Eine automatische Konfigurationsverwaltung  ermöglicht eine einheitliche Konfiguration, z.B. für Passwortvorgaben, Verschlüsselung oder automatische Updates. Insbesondere bei der Verwaltung zahlreicher Endgeräte oder einer Bring Your Own Device Strategie (BYOD) bietet eine solche Verwaltung den einzig praktikablen Ansatz die Sicherheitsparameter der Geräte zu kontrollieren. Dies kann über selbst betriebenes zentrales Managementsystem (UEM oder MDM), Cloud-Dienste wie Intune oder Konfigurationsmanagement-Werkzeuge wie Ansible umgesetzt werden. Bei Abweichungen kann entweder ein automatisierter Mechanismus die erforderliche Konfiguration vornehmen, oder eine manuelle Entscheidung über die passende Behandlung erfolgen.</p></td></tr><tr valign="top"><td>KONF.2.5.1.1: Automatische Konfigurationsverwaltung</td><td><p>Konfiguration für Endgeräte SOLLTE die Verwaltung durch ein Mobile Device Management (MDM) verankern.</p></td><td><p>Die Konfigurationsanforderungen für Mobile Device Management (MDM) sind im BSI-Mindeststandard für MDM umfassend beschrieben. Es ist empfehlenswert, diese Mindestanforderungen heranzuziehen. Ergänzend wird empfohlen, sicherheitsrelevante Kriterien bereits bei der Produktauswahl zu berücksichtigen, vertrauenswürdige Apps durch Reputationsdienste zu prüfen, kompromittierte Geräte (z. B. durch Jailbreak oder Root) automatisiert zu erkennen und Geofencing zur kontextbezogenen Richtliniendurchsetzung einzusetzen.</p></td></tr><tr valign="top"><td>KONF.2.6: Souveräne Werkzeuge</td><td><p>Konfiguration für IT-Systeme KANN Souveräne Werkzeuge installieren.</p></td><td><p>„Souveräne Werkzeuge“ sind Anwendungen, Systeme und physische Werkzeuge, die technisch, rechtlich und organisatorisch unabhängig von externen Herstellern, Cloud-Anbietern oder staatlicher Einflussnahme betrieben werden können. Das umfasst vor allem Lösungen, die lokal kontrollierbar und ohne zwingende Abhängigkeit zu externen Plattformen nutzbar sind. Der Sinn der Vorschrift liegt darin, die Handlungsfähigkeit und Sicherheit der Institution zu stärken: Ein rein cloudbasierter Konfigurationsdienst könnte durch einen plötzlichen Ausfall, eine staatlich erzwungene Sperrung oder durch nachträglich geänderte Lizenzbedingungen die Betriebsfähigkeit gefährden. Die Nutzung souveräner Werkzeuge kann dagegen die Verfügbarkeit kritischer Systeme erhöhen, die Datenhoheit bewahren und Manipulationsmöglichkeiten von Dritten minimieren. Souveräne Konfigurationssysteme machen unabhängig vor Ausfällen, Datenschutzverletzungen oder einseitigen Änderungen der Nutzungsbedingungen durch externe Dienstleister. Eine Institution kann diese Anforderung beispielsweise so umsetzen: (1) Es kann auf quelloffene Konfigurations-Frameworks zurückgegriffen werden, die lokal installiert und betrieben werden. (2) Virtualisierte oder containerisierte Varianten dieser Werkzeuge werden in der eigenen Infrastruktur betrieben, sodass keine unkontrollierten externen Abhängigkeiten entstehen. (3) Ergänzend kann ein internes Repository für Konfigurationsmodule eingerichtet werden, um eine vertrauenswürdige, geprüfte und nachvollziehbare Quellenbasis sicherzustellen.</p></td></tr><tr valign="top"><td>KONF.2.7: Alternative Administrationszugänge</td><td><p>Konfiguration für IT-Systeme KANN alternative Administrationszugänge installieren.</p></td><td><p>Das ist zum Beispiel von Bedeutung bei zentralen Systemen wie Firewalls und Router, bei deren Ausfall eine Fernwartung nicht mehr möglich ist. Hierzu können alternative Werkzeuge, sowie alternative Protokolle, Schnittstellen und Zugangskonten verwendet werden. Alternative Werkzeuge sind z.B. Kommandozeilenwerkzeuge, API-Schnittstellen oder die Konsole virtualisierter oder physischer Server, statt der Grafischen Benutzeroberfläche. Bei Cloud-Diensten kann dies z.B. durch Vorhalten von sowohl Browser-Zugang als auch CLI-Zugang geschehen. Alternative Zugangskonten sind z.B Break-Glass-Accounts, deren Zugangsdaten nur bei Notfällen aus einem Safe entnommen werden.</p></td></tr><tr valign="top"><td>KONF.2.8: Abgesicherter und authentisierter Bootprozess</td><td><p>Konfiguration für IT-Systeme KANN einen abgesicherten und authentisierten Bootprozess aktivieren.</p></td><td><p>Dies empfiehlt sich für eingebettete Systeme (Embedded Systems), indem z.B. der Bootloader die Integrität des Betriebssystems überprüft und es nur dann lädt, wenn es als korrekt eingestuft wurde. Ebenso empfiehlt es sich ein mehrstufiges Boot-Konzept mit kryptographisch sicherer Überprüfung der Einzelschritte zu realisieren, sichere Hardware-Vertrauensanker zu verwenden, bei ARM & UEFI-basierten Systemem jeweils (ARM) Secure Boot zu nutzen.</p></td></tr></table><h2>KONF.3: Physischer Schutz</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.3.1: Kryptographischer Hardwarespeicher</td><td><p>Konfiguration für IT-Systeme SOLLTE einen kryptographischen Hardwarespeicher aktivieren.</p></td><td><p>Ein kryptographischer Hardwarespeicher bezeichnet in diesem Kontext eine gesicherte, hardwarebasierte Komponente, die kryptographische Schlüssel oder andere besonders sensible Geheimnisse in einer isolierten und manipulationsgeschützten Umgebung verwahrt. Der Einsatz solcher Speicher kann das Risiko deutlich reduzieren, dass kryptographische Schlüssel bei einem Softwareangriff kompromittiert werden, und kann gleichzeitig die Integrität sicherheitskritischer Prozesse wie Verschlüsselung, Signatur oder Authentifizierung erhöhen. Als Standards können hierzu etwa eine Trusted Execution Environment (TEE), Secure Elements (SE) or Dedicated Security Components (DSC) infrage kommen. Vgl. ISO/IEC 11889 (TPM 2.0), ISO/IEC 19790 / FIPS 140-3 oder ETSI EN 303 645 (für IoT).</p></td></tr><tr valign="top"><td>KONF.3.2: Speicherverschlüsselung</td><td><p>Konfiguration für IT-Systeme SOLLTE integrierte Festspeichermedien verschlüsseln.</p></td><td><p>Die Verschlüsselung von Datenträgern erschwert es Angreifern, Daten von verlorenen oder gestohlenen Geräten auszulesen. Die Verschlüsselung kann in Hard- oder Software (z.B. Windows BitLocker®, Apple FileVault®, Linux® dm-crypt) erfolgen. Für anerkannte kryptographische Algorithmen siehe BSI TR 02102.</p></td></tr><tr valign="top"><td>KONF.3.3: SIM-PIN</td><td><p>Konfiguration für IT-Systeme SOLLTE bei Mobilfunkanschluss eine SIM-PIN aktivieren.</p></td><td><p>Eine SIM-PIN ist eine persönliche Identifikationsnummer, die direkt auf der SIM-Karte gespeichert wird und beim Starten oder Einlegen der Karte abgefragt wird. Sie dient nicht der Benutzeranmeldung am Endgerät selbst, sondern schützt den Mobilfunkanschluss auf Netzebene. Ohne aktivierte SIM-PIN könnte ein Angreifer bei Verlust oder Diebstahl einer SIM-Karte unmittelbar den Mobilfunkanschluss verwenden, etwa für kostenpflichtige Anrufe oder zum Abfangen von SMS-TANs. Die Aktivierung einer SIM-PIN kann somit eine missbräuchliche Nutzung deutlich erschweren, indem ein zusätzliches Hindernis für den unbefugten Zugriff auf Mobilfunkdienste geschaffen wird. Gilt auch für stationäre Systeme mit SIM oder Systeme die eine eSIM verwenden, da eine PIN je nach Diensteanbieter SIM-Swapping vorbeugen kann. Falls das System keine SIM-Karte verwendet, ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.3.4: Physischer Diebstahlschutz</td><td><p>Konfiguration für Endgeräte KANN einen physischen Diebstahlschutz installieren.</p></td><td><p>Ein physischer Diebstahlschutz bezeichnet im vorliegenden Kontext sämtliche Vorrichtungen oder Maßnahmen, die ein Entwenden von Endgeräten wie Laptops, Tablets oder Arbeitsplatzrechnern erschweren. Hierzu gehören insbesondere physische Schlösser, die mithilfe eines Stahlkabels mit einer dafür vorgesehenen Öffnung am Endgerät verbunden werden können, sodass das Endgerät an einem festen Gegenstand fixiert bleibt. Der Sinn dieser Vorgabe liegt darin, das Risiko zu reduzieren, dass ein Gerät durch unbefugte Dritte entwendet und dadurch der Zugriff auf gespeicherte Informationen oder Zugangsdaten ermöglicht wird. Ein Vorfall könnte entstehen, wenn ein Angreifer ein ungesichertes Notebook während einer Konferenz oder in einem Büro mitnimmt und darüber unverschlüsselte Daten ausliest. Ein angemessen eingesetzter Diebstahlschutz kann die Gelegenheit zum Zugriff verringern, den Aufwand für einen Angreifer erhöhen und so die Wahrscheinlichkeit für den Verlust sensibler Informationen deutlich reduzieren. Zur praktischen Umsetzung kann eine Institution unterschiedliche Maßnahmen wählen. So kann ein Laptop-Kabelschloss genutzt werden, um mobile Geräte temporär an Arbeitsplätzen zu sichern, oder ein Schließfachschrank kann für Aufbewahrung außerhalb der Nutzungszeiten vorgesehen sein. Für stationäre Systeme kann eine feste Verschraubung mit dem Schreibtisch oder die Unterbringung in abschließbaren Möbeln erfolgen. Ergänzend kann eine Institution darauf achten, Geräte mit serienmäßig integrierten Vorrichtungen (z. B. Verriegelungsöffnungen für Kabelschlösser) zu beschaffen, um eine flexible Sicherung zu ermöglichen. Auch das Kennzeichnen von Geräten durch gravierte Inventarnummern oder gut sichtbare Eigentumsaufkleber kann eine zusätzliche Abschreckungswirkung entfalten.</p></td></tr><tr valign="top"><td>KONF.3.5: Standortbestimmung</td><td><p>Konfiguration für IT-Systeme KANN eine Funktion zur Bestimmung des Standortes aus der Ferne <i>durch einen automatisierten Mechanismus</i> aktivieren.</p></td><td><p>Der Begriff automatisierter Mechanismus bezeichnet im gegebenen Kontext ein technisches Verfahren, das ohne manuelle Eingriffe die Standortbestimmung eines IT-Systems ermöglicht. Dies kann etwa durch GALILEO- oder GPS-Sensoren, durch WLAN- oder Mobilfunkortung, sowie durch Auswertung netzwerktechnischer Parameter erfolgen. Der Rückgriff auf die Standortbestimmung mittels Mobilfunksignal oder WLANs in der Nähe ist nur empfehlenswert, wenn das System die Sattelitenbestimmung nicht unterstützt. Der Sinn dieser Vorschrift liegt darin, potenzielle Risiken durch unkontrollierte Standortänderungen oder verdeckte Verlagerungen von IT-Systemen zu reduzieren. Ein Vorfall könnte eintreten, wenn ein Server oder Endgerät unbemerkt aus einem gesicherten Bereich entfernt wird und dadurch sensible Daten oder Konfigurationen kompromittiert werden. Im positiven Fall kann die Standortbestimmung Transparenz über den Verbleib kritischer Systeme schaffen und so die Reaktionsfähigkeit bei Diebstahl oder Verlust erhöhen. Ein praktischer Ansatz kann sein, dass Systeme beim Start ihre Position automatisch protokollieren, sodass Abweichungen vom erwarteten Standort erkannt werden. Alternativ kann eine Softwarelösung eingesetzt werden, die Netzwerkverbindungen auf bestimmte Geozonen überprüft. Beachten Sie hierbei auch den Zusammenhang mit den Verfahren und Regelungen zum Informations- und Assetmanagement, sowie zur Detektion von Sicherheitsvorfällen, etwa dass Standortdaten regelmäßig in ein zentrales Monitoring-Tool eingespielt und mit erlaubten Standorten abgeglichen werden. Um technische Ressourcenauslastung und Datenschutz angemessen auszubalancieren ist es zweckmäßig dies nur für besonders schutzbedürftige Geräte vorzusehen und klar festzulegen, ob die Standortbestimmung kontinuierlich, ereignisbezogen oder stichprobenartig erfolgt.</p></td></tr><tr valign="top"><td>KONF.3.6: Fernlöschung oder -sperre</td><td><p>Konfiguration für Endgeräte KANN eine Funktion zur Fernlöschung oder -sperre aktivieren.</p></td><td><p>Eine automatische Fernlöschung meint hier die technische Möglichkeit, gespeicherte Daten eines Endgeräts über eine externe Steuerung dauerhaft zu entfernen, während eine Fernsperre das Gerät durch zentral initiierte Befehle unbenutzbar macht, ohne die Daten selbst zu löschen. Funktionen zur Fernlöschung (Remote Wiping) sind insbesondere relevant auf allen mobilen Endgeräten, damit bei Bedarf (z.B. wenn das Endgerät verloren geht oder gestohlen wird) alle Daten auf dem Gerät aus der Ferne gelöscht werden können. Ohne eine solche Funktion könnte ein verlorenes, vergessenes oder unzureichend zurückgesetztes Gerät Daten preisgeben oder unbefugt weiterverwendet werden. Für stationäre Endgeräte ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.3.6.1: Automatische Fernlöschung oder -sperre</td><td><p>Konfiguration für Endgeräte KANN eine automatische Fernlöschung oder -sperre bei Inaktivität nach <i>einer längeren Frist</i> aktivieren.</p></td><td><p>Beide Mechanismen können bei längerer Inaktivität ausgelöst werden, also wenn ein Endgerät über einen bestimmten Zeitraum hinweg nicht mehr mit den Systemen der Institution in Kontakt steht oder nicht genutzt wird. Als angemessene Frist für eine solche Inaktivität können z. B. 30 Tage, 60 Tage oder 90 Tage definiert werden, abhängig vom Sicherheitsbedarf und der Einsatzumgebung. Dies kann verhindern, dass ungenutzte Geräte mit sensiblen Daten in Umlauf bleiben oder in falsche Hände geraten. Ein automatisches Entfernen oder Sperren kann hier das Risiko eines Datenabflusses erheblich reduzieren und gleichzeitig eine Kontrolle über den Gerätelebenszyklus sichern. Zur Umsetzung kann die Institution beispielsweise Mobile-Device-Management-Lösungen einsetzen, die nach Ablauf der gewählten Frist automatisiert Fernlöschung oder Fernsperre auslösen. Alternativ kann eine Endpoint-Security-Lösung integriert werden, die periodisch prüft, ob das Gerät eine Verbindung zum Netz herstellt, und bei Überschreiten des Schwellenwerts eine definierte Aktion anstößt. Auch ein Prozess, bei dem Inaktivität zunächst mit einer Warnmeldung angekündigt wird, bevor tatsächlich gesperrt oder gelöscht wird, kann die Benutzerfreundlichkeit erhöhen.</p></td></tr><tr valign="top"><td>KONF.3.7: Einschränkung angeschlossener Peripherie</td><td><p>Konfiguration für IT-Systeme SOLLTE angeschlossene Peripherie einschränken.</p></td><td><p>Peripherie bezeichnet angeschlossene Geräte, die über Schnittstellen wie USB, Bluetooth oder andere Ports mit dem IT-System kommunizieren. Gemeint sind sowohl physische Peripheriegeräte wie Drucker, USB-Sticks oder Netzanbindungen, als auch die Installation virtueller Peripherie z.B. virtuelle Druckertreiber. Einschränkung bedeutet hierbei, dass die Nutzung von Peripheriegeräten verhindert wird, die nicht von der Institution autorisiert wurden, abhängig vom Einsatzzweck des Systems. Der Sinn und Zweck dieser Regelung liegt darin, Angriffsflächen zu verringern und das Einschleusen oder Abfließen von Daten zu erschweren. So könnte ein unkontrollierter Anschluss externer USB-Sticks Schadsoftware einschleusen oder sensible Daten unbemerkt kopieren, während eine restriktive Konfiguration unautorisierte Datenabflüsse wirksam verhindern kann.</p></td></tr><tr valign="top"><td>KONF.3.8: Einschränkung von Wechselmedien</td><td><p>Konfiguration für IT-Systeme SOLLTE das automatische Einbinden von Wechselmedien einschränken.</p></td><td><p>Funktionen, die Wechselmedien automatisch einbinden und Inhalte darauf öffnen oder ausführen könnten zur unkontrollierter Verbreitung von Schadcode beitragen. Betrifft z.B. CD/DVD-Laufwerke, Bandlaufwerke oder USB-Sticks. Dies Kann umgesetzt werden, indem die Einbindung in das Betriebssystem durch spezielle Managementanwendungen blockiert wird oder auch durch systemeigene Sicherheitsfunktionen, z.B. indem alle Dateien auf Wechselmedien als nicht ausführbar markiert sind (Mount-Option „noexec“).  Verfügt das IT-System über keine Anschlussmöglichkeit für Wechsellaufwerke, so ist die Anforderung entbehrlich.</p></td></tr></table><h2>KONF.4: Vertrauenswürdige Basisdienste</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.4.1: Anbindung an Verzeichnisdienst</td><td><p>Konfiguration für IT-Systeme SOLLTE die Anbindung an einen Verzeichnisdienst aktivieren.</p></td><td><p>Anbindung meint hier die Authentifizierung und Autorisierungsprüfung von Zugangskonten über einen Verzeichnisdient (häufig auch als Directory Service bezeichnet). Dies ermöglicht die zentrale Verwaltung von Identitäten und deren Berechtigungen. Dies bedeutet, dass Zugriffsrechte für alle angebundenen Systeme zentral verwaltet und bei Bedarf umgehend angepasst werden können, was die Einhaltung des Prinzips der geringsten Rechte (Principle of Least Privilege) unterstützt. Ein häufiger Ansatz zur technischen Umsetzung ist die Verwendung von Protokollen wie LDAP (Lightweight Directory Access Protocol) oder der Einsatz von Single Sign-On (SSO) Lösungen, die eine einmalige Authentifizierung des Nutzers für mehrere Systeme ermöglichen. Institutionen können dabei die Anbindung neuer Systeme durch Automatisierung im Rahmen des Provisioning-Prozesses sicherstellen, um menschliche Fehler zu reduzieren. Beispielsweise könnte ein Standard-Skript bei der Installation eines neuen Servers dessen automatische Anbindung an den Verzeichnisdient veranlassen. In Windows Betriebssystemen erfolgt die Konfiguration des Betriebssystem über entsprechende Gruppenrichtlinien (Group Policy Object) aus dem Active Directory.</p></td></tr><tr valign="top"><td>KONF.4.1.1: Weiterleitung von Anmeldeinformationen</td><td><p>Konfiguration für IT-Systeme SOLLTE die Weiterleitung mehrfach verwendbarer Anmeldeinformationen deaktivieren.</p></td><td><p>„Weiterleitung mehrfach verwendbarer Anmeldeinformationen“ (auch als Credential Forwarding oder Credential Delegation bekannt) meint technische Mechanismen, bei denen die Anmeldeinformationen eines Zugangskontos (z.B. Kennworthashes oder Kerberos-Tickets) an ein zweites System weitergereicht werden, um sich dort ebenfalls zu authentifizieren, ohne die Daten erneut eingeben zu müssen. Ziel der Deaktivierung ist hier die Unterbrechung von Angriffsketten, die auf dem Diebstahl von Zugangsdaten basieren. Ein Angreifer könnte sonst nach der Kompromittierung eines weniger kritischen Systems, wie einem Webserver, die dorthin weitergeleiteten Anmeldeinformationen eines Administrators aus dem Arbeitsspeicher auslesen und sich mit diesen Rechten unbemerkt im gesamten Netzwerk weiter ausbreiten (Laterale Bewegung). Das gezielte Deaktivieren des Credential Forwarding kann die Angriffsfläche erheblich reduzieren und solche „Pass-the-Hash“- oder „Pass-the-Ticket“-Angriffe effektiv eindämmen, da Anmeldeinformationen mit hohen Privilegien gar nicht erst auf unsichere Systeme gelangen. Stattdessen kann die Authentifizierung ausschließlich temporäre, eingeschränkte Tickets oder Tokens verwenden. Hierzu gehören z.B. Windows Remote Credential Guard oder RestrictedAdmin, sowie unter Linux SSH-Agent Forwarding oder GSSAPI. Eine Token-basierte Authentifizierung ist eine Strategie zur Verbesserung der Informationssicherheit. Nachdem Benutzende ihre Anmeldedaten eingegeben haben, werden diese überprüft und ein einmaliges verschlüsseltes Token generiert, mit dem sie anschließend auf Online-Ressourcen zugreifen können, ohne bei jeder Anfrage ihren Benutzernamen und ihr Passwort eingeben zu müssen. Bei SSH-Verbindungen kann die unsichere „Agent Forwarding“-Funktion serverseitig in der Konfigurationsdatei deaktiviert werden.</p></td></tr><tr valign="top"><td>KONF.4.2: DNS-Anbindung</td><td><p>Konfiguration für IT-Systeme SOLLTE die vom System verwendeten DNS-Server autorisieren.</p></td><td><p>Autorisierte DNS-Server sind hier Resolving-Server, die von der Institution autorisiert wurden. Dies können entweder DNS-Server der Institution selbst oder externe DNS-Server zuverlässiger Anbieter sein.</p></td></tr><tr valign="top"><td>KONF.4.2.1: DNS-Verschlüsselung</td><td><p>Konfiguration für IT-Systeme SOLLTE DNS-Verschlüsselung aktivieren.</p></td><td><p>DNS-Verschlüsselung, im Englischen oft als DNS over TLS (DoT) oder DNS over HTTPS (DoH) bezeichnet, ist ein Verfahren, bei dem Anfragen zur Namensauflösung im Internet kryptographisch geschützt werden, um deren Vertraulichkeit und Integrität sicherzustellen. Erfolgen diese Anfragen unverschlüsselt, könnte ein Angreifer im Netz die aufgerufenen Webseiten und Dienste eines Nutzers mitlesen und protokollieren. Schlimmer noch, ein Angreifer könnte die Antworten manipulieren, um den Nutzer unbemerkt auf gefälschte Webseiten umzuleiten, beispielsweise für Phishing-Angriffe. Die Aktivierung der DNS-Verschlüsselung kann einem solchen Ausspähen und Manipulieren der Namensauflösung effektiv entgegenwirken und stellt sicher, dass die Kommunikation zwischen dem Client und dem DNS-Server authentisch und nicht einsehbar ist. Nutzt das System kein DNS, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.4.3: Authentifizierung von Fernwartungsfunktionen</td><td><p>Konfiguration für IT-Systeme SOLLTE Fernwartungsfunktionen im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement authentifizieren.</p></td><td><p>Unter Fernwartungsfunktionen versteht man technische Zugänge, die es ermöglichen, IT-Systeme aus der Ferne zu administrieren oder Fehler zu beheben, etwa über Protokolle wie RDP, SSH oder proprietäre Remote-Support-Lösungen. Fernwartungsfunktionen könnten für eine Institution erhebliche Risiken bergen, wenn ihre Nutzung nicht eindeutig authentifiziert wird. Ohne verlässliche Identitäts- und Berechtigungsprüfung könnte ein Unbefugter über eine Remote-Schnittstelle auf Systeme zugreifen, Konfigurationen manipulieren oder Schadsoftware einschleusen. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>KONF.4.4: Einschränkung von Fernwartungsfunktionen</td><td><p>Konfiguration für IT-Systeme SOLLTE Fernwartungsfunktionen im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement einschränken.</p></td><td><p>Fernwartungszugänge, etwa über RDP, SNMP oder Anwendungen zur Fernsteuerung des Systems erlauben typischerweise eine Vielzahl von Eingriffen in Systemkonfiguration und Datenverarbeitungen. Beispiele sind die Remote-Zwischenablage und die automatische Einbindung von Peripheriegeräten, Wechseldatenträgern und Netzlaufwerken. Unautorisierte Fernwartungszugänge könnten für Angriffe missbraucht werden. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>KONF.4.5: Zeitquellen</td><td><p>Konfiguration für IT-Systeme SOLLTE Zeitquellen autorisieren.</p></td><td><p>Eine einheitliche Zeitquelle für die Systemuhr (meist über NTP oder PTP) ist essenziell für die einheitliche Auswertung von Logdateien, sowie für moderne kryptographische Verfahren. Es empfiehlt sich zu definieren, welche NTP-Server von welchen NTP-Clients genutzt werden sollen und ob NTP-Server im Broadcast-Modus oder im Client-Server-Modus arbeiten. Letzteres (Client-Server) ist hierbei Best Practice. In bestimmten Fällen empfiehlt es sich außerdem, dass sich NTP-Server bei der Kommunikation gegenüber Clients authentisieren und demnach NTP-Clients nur authentifizierte NTP-Daten akzeptieren.</p></td></tr></table><h2>KONF.5: Authentifizierung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.5.1: Authentifizierung am System</td><td><p>Konfiguration für IT-Systeme SOLLTE den Zugriff auf das System im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement authentifizieren.</p></td><td><p>Betrifft sowohl die lokale Anmeldung über eine Benutzeroberfläche als auch den Zugriff über Fernwartungsprotokolle oder -anwendungen wie RDP, SNMP, wenn diese vorhanden sind.  Die Umsetzung erfolgt im einfachsten Fall durch einen Login, bzw. eine Bildschirmsperre für das IT-System. Biometrische Daten wie Fingerabdrücke können gefälscht werden und sind nicht so leicht zu ändern wie Passwörter. Setzen Sie Biometrie daher nicht als einzigen Authentifizierungsfaktor ein, sondern wenn, dann nur zur Ergänzung (Mehr-Faktor-Authentifizierung). Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist. Die Anforderung ist entbehrlich, wenn das System keinen Zugriff auf schützenswerte Daten erlaubt, z.B. bei Nutzung als Kiosk.</p></td></tr><tr valign="top"><td>KONF.5.1.1: Authentifizierung an der Firmware</td><td><p>Konfiguration für IT-Systeme SOLLTE den Zugriff auf die Firmware im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement authentifizieren.</p></td><td><p>Durch unautorisierte Änderungen an Einstellungen der Firmware (UEFI oder Embedded System) könnten Fehlerzustände entstehen oder Sicherheitsfunktionen wie TPM deaktiviert werden. Dies kann je nach Firmware durch lokale Zugangspasswörter oder zentrale Berechtigung umgesetzt werden. Hierbei sind insbesondere Einstellungen von Sicherheitsfunktionen oder der Netzanbindung relevant. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>KONF.5.1.2: Pre-Boot-Authentifizierung</td><td><p>Konfiguration für Endgeräte KANN den Zugriff vor dem Start des Betriebssystems authentifizieren.</p></td><td><p>Diese Authentifizierung vor dem Start, oft als <b>„Pre-Boot Authentication“</b> (PBA) oder <b>„Hardware-based Authentication“</b> bezeichnet, verhindert, dass ein Gerät gestartet wird, bevor sich Nutzende mit Anmeldeinformationen, wie zum Beispiel einem Passwort oder einem biometrischen Merkmal, autorisiert haben. Ohne diese Authentifizierung könnte ein Angreifer versuchen, das Gerät direkt zu booten, die Festplatte zu kopieren oder zu manipulieren, um sensitive Daten zu extrahieren. Eine gängige Methode ist die Verwendung einer Festplattenverschlüsselung (Full Disk Encryption, FDE) mit einer Pre-Boot-Authentifizierung. Eine Institution könnte auch eine Mehr-Faktor-Authentifizierung (MFA) vor dem Start des Betriebssystems einsetzen, beispielsweise indem ein Hardware-Token oder ein biometrischer Scan zusätzlich zum Passwort erforderlich ist, was die Sicherheit weiter erhöht.</p></td></tr><tr valign="top"><td>KONF.5.2: Keine Mehrfachanmeldung</td><td><p>Konfiguration für IT-Systeme SOLLTE die gleichzeitige Anmeldung mehrerer Zugangskonten deaktivieren.</p></td><td><p>Wenn Nutzende mit verschiedenen Identitäten simultan im System angemeldet sind, erhöht sich das Risiko von versehentlichen Datenvermischungen oder Falscheingaben deutlich. Dies kann besonders in sensiblen Bereichen wie im Finanzwesen oder Gesundheitswesen schwerwiegende Folgen haben, wo vertrauliche Kundendaten oder Patienteninformationen unbeabsichtigt zwischen verschiedenen Kontexten übertragen werden könnten. Bei Vorfällen wird so auch erschwert herauszufinden, von welchem Zugangskonto bestimmte Ereignisse stammen.</p></td></tr></table><h2>KONF.6: Rollen und Berechtigungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.6.1: Minimal erforderliche Berechtigungen für Anwendungen</td><td><p>Konfiguration für IT-Systeme SOLLTE erforderliche Berechtigungen für Anwendungen einschränken.</p></td><td><p>Ziel ist es, Angriffsflächen zu minimieren und unerwünschte Seiteneffekte zu vermeiden. Durch restriktive Rechtevergabe pro App lässt sich das Risiko für Zugriffe auf sensible Bereiche stark senken. Gleichzeitig trägt dieses Prinzip dazu bei, eine klare Trennung zwischen den einzelnen Systemkomponenten zu bewahren und unkontrollierte Wechselwirkungen zu verhindern. Beispiele sind Lese- und Schreibrechte für Verzeichnisse, insbesondere für Systemverzeichnisse, Berechtigungen zum Zugriff auf Sensoren oder Peripheriegeräte, sowie der Netzzugriff. Um die Umsetzung zu erleichtern können Berechtigungsprofile erstellt werden, die je nach Anwendungsklasse (z. B. Office, Multimedia, Tools) eine Basislinie an Privilegien definieren. Diese Profile können in einer zentralen Verwaltungssoftware (z. B. über Gruppenrichtlinien oder ein Mobile‑Device‑Management) hinterlegt und automatisch auf neue Installationen angewendet werden. Vor der Freigabe einer Softwareinstallation kann ein Reviewprozess etabliert werden, bei dem anhand von Funktionsdokumentationen geprüft wird, welche minimalen Rechte erforderlich sind. Darüber hinaus kann der Einsatz von Sandboxing- oder Virtualisierungstechnologien unterstützen, indem Anwendungen in einer isolierten Umgebung mit genau festgelegten Schnittstellen betrieben werden können. Tools zur Rechteanalyse (etwa zur Ermittlung der tatsächlich genutzten APIs und Dateizugriffe) können helfen, überflüssige Freigaben im Nachgang weiter einzuschränken.</p></td></tr><tr valign="top"><td>KONF.6.1.1: Datenkapselung</td><td><p>Konfiguration für IT-Systeme KANN Datenkapselung aktivieren.</p></td><td><p>Bei der Datenkapselung, im Englischen als data encapsulation bekannt, handelt es sich um einen Schutzmechanismus, bei dem Daten logisch vor dem Zugriff des restlichen Systems verborgen werden. Hierdurch wird der direkte Zugriff unterbunden und ausschließlich über definierte, sichere Schnittstellen bereitgestellt. Zweck ist es, die Angriffsfläche auf sensible Daten zu verringern und deren Integrität sowie Vertraulichkeit zu wahren. Ohne eine solche Kapselung könnte beispielsweise eine Schadsoftware auf einem Server direkt auf Konfigurationsdateien oder im Arbeitsspeicher gehaltene Anmeldeinformationen anderer Anwendungen zugreifen und diese manipulieren oder ausleiten. Durch eine wirksame Datenkapselung kann die Institution sicherstellen, dass Zugriffe nur über vorab genehmigte und protokollierte Wege erfolgen, was eine unautorisierte Modifikation oder einen unbemerkten Abfluss von Daten erschwert. Technisch erfolgt dies zum Beispiel durch einen abgeschlossenen Speicherbereich auf einem mobilen Gerät für persönliche Informationen wie Kontakte oder Kalender (PIM-Container). Die Kapselung erfordert eine separate Authentisierung vor dem Zugriff auf die gekapstelten Daten und eine vom Betriebssystem unabhängige Daten- & Transportverschlüsselung innerhalb der Kapselung.</p></td></tr><tr valign="top"><td>KONF.6.1.2: Isolierung von Anwendungen</td><td><p>Konfiguration für IT-Systeme KANN Isolierung von Anwendungen aktivieren.</p></td><td><p>Die Isolation von Anwendungen (auch Kapselung oder Application Sandboxing genannt) dient dazu, die Angriffsfläche eines Systems zu reduzieren und die Vertraulichkeit, Integrität sowie Verfügbarkeit kritischer Komponenten besser zu schützen. Durch eine klare Trennung der Anwendungs- und Systemprozesse und von deren Ressourcenzugriffen (Netzwerk, Datei‑ oder Geräte‑I/O) kann eine kompromittierte Applikation nicht unbegrenzt auf weitere Systemressourcen zugreifen, sondern ist auf genau definierte Schnittstellen beschränkt. Dies ermöglicht es, Fehlfunktionen oder Angriffe einzudämmen, Schadsoftware leichter zu erkennen und Verantwortlichkeiten einzelner Module transparent zu halten. Dies kann z.B. durch Containerisierung oder eine Microservice-Architektur, in der jede Komponente nur über REST- oder Message-Queue-Schnittstellen kommuniziert umgesetzt werden. Auch klassische Virtualisierung (Gastsysteme mit Hypervisor) oder Betriebssystemfunktionen wie SELinux/AppArmor‑Profile und chroot‑Jails zählen dazu, weil sie Applikationen auf genau festgelegte Ressourcen beschränken. Im Kontext der Containerisierung empfiehlt es sich ebenfalls eine feste Zuordnung von Containern zu Container-Hosts vorzunehmen.</p></td></tr><tr valign="top"><td>KONF.6.1.3: Isolierte Arbeitsumgebungen</td><td><p>Konfiguration für Endgeräte KANN eine isolierte Arbeitsumgebungen aktivieren.</p></td><td><p>Verschiedene Verwendungen sind z.B. die berufliche und private Nutzung, oder die Nutzung als IT-System mit erhöhtem Schutzbedarf und das Surfen im Internet. Arbeitsumgebungen sind getrennt, wenn die zu schützenden Daten ausschließlich in der geschützten Umgebung verbleiben. Beispielimplementierungen sind Apple® Configuration Profile oder Android™ Work Profile. Je nach Aufbau des Systems können hierzu z.B. Trennung auf Betriebssystemebene, netzbasierte Trennung, Virtualisierung oder Container eingesetzt werden.</p></td></tr><tr valign="top"><td>KONF.6.2: Gemeinsam genutzte Verzeichnisse</td><td><p>Konfiguration für Endgeräte SOLLTE die Zugriffsrechte gemeinsam verwendeter Verzeichnisse einschränken.</p></td><td><p>Relevant sind hierbei sowohl speziell eingerichtete Verzeichnisse für die gemeinsame Bearbeitung von Dateien als auch Verzeichnisse, die vom System für gemeinsame Dateien verwendet werden, z.B. /tmp. Unter Linux kann das Sticky-Bit verwendet werden, um den Zugriff auf die Dateien in diesem Verzeichnis einzuschränken, so dass nur noch der Eigentümer einer Datei (oder der Eigentümer des Verzeichnisses) diese Datei löschen oder umbenennen darf.</p></td></tr><tr valign="top"><td>KONF.6.3: Kiosk-Modus</td><td><p>Konfiguration für Endgeräte KANN das automatische Zurücksetzen auf einen definierten Zustand nach der Nutzung aktivieren.</p></td><td><p>Ein Kiosk‑Modus (auch als Gast-Zugang bezeichnet) kann dazu dienen, die Integrität und den definierten Ausgangszustand eines Systems dauerhaft sicherzustellen, indem nach jeder Sitzung oder in regelmäßigen Abständen ein vollständiger Rücksetzvorgang angestoßen wird. Damit soll verhindert werden, dass ungewollte Änderungen – etwa durch Malware, böswillige Manipulation oder versehentlich abgelegte Nutzerdaten – dauerhaft auf dem System verbleiben. Gleichzeitig kann so gewährleistet werden, dass jede neue Nutzer­session in einer standardisierten, getesteten Umgebung beginnt, was sowohl den Support‑Aufwand reduziert als auch Datenschutzaspekte stärkt, da keine personenbezogenen Daten auf dem Gerät zurückbleiben können. Typische Anwendungsfälle können öffentliche Terminals in Bibliotheken oder Behörden, digitale Informations­stelen in Museen und Einkaufszentren sowie Schulungs‑ oder Präsentationsrechner in Unternehmen sein. In solchen Szenarien kann das System beim Ausloggen oder nach einer festgelegten Zeit (z. B. nachts) automatisch auf ein sauberes Basis-Image zurückgesetzt werden. Denkbar ist auch ein Einsatz in Fabrikumgebungen, um Versuchs‑ und Prüfsysteme immer wieder in einen definierten Ausgangszustand zu bringen, oder in Testlaboren für Software, wo nach jedem Testlauf eine reine Umgebung erforderlich ist.  Für die produktneutrale Umsetzung kann man beispielsweise mit Virtualisierungs­technologien arbeiten, die mittels Snapshot‑Rollback beim Neustart eine saubere VM‑Instanz bereitstellen. Alternativ kann ein Live‑Betriebssystem vollständig im Arbeitsspeicher laufen oder das Dateisystem über Overlay‑Techniken (z. B. OverlayFS, AUFS) nur virtuell überschrieben werden – alle Änderungen verwerfen sich beim Neustart automatisch. Auch der Einsatz von read‑only‑Partitionen kombiniert mit einem Schreibbereich in RAM kann eine einfache Lösung sein. Skript­basierte Cron‑Jobs oder Systemd‑Timer können den Rücksetz­prozess zu definierten Zeiten anstoßen. Externes Logging und Konfigurations­management (etwa über Ansible oder Puppet) kann dabei helfen, wichtige Ereignisse und Konfigurations­änderungen zu protokollieren, ohne den Kiosk‑Modus zu beeinträchtigen.</p></td></tr><tr valign="top"><td>KONF.6.4: Privilegierte Systemfunktionen</td><td><p>Konfiguration für IT-Systeme SOLLTE privilegierte Funktionen einschränken.</p></td><td><p>Sind privilegierte Funktionen nicht eingeschränkt, so könnten Innentäter oder Angreifer über das Netz unbefugte Manipulationen vornehmen, Fehlkonfigurationen ausgelöst werden oder sich Schadcode automatisch einnisten. Privilegierte Funktionen können z.B. ein lokales Berechtigungsmanagement, die Installation von Anwendungen, der Schreibzugriff auf Systemverzeichnisse oder die Änderung der Systemkonfiguration sein.</p></td></tr><tr valign="top"><td>KONF.6.4.1: Rollenbasierte Privilegierung</td><td><p>Konfiguration für IT-Systeme KANN rollenbasiertes Berechtigungsmanagement aktivieren.</p></td><td><p>Rollenbasierte Administration schränkt die Berechtigungen administrativer Zugangskonten anhand von Rollen so ein, dass nur die jeweils erforderlichen Funktionen freigeschaltet sind. Dies kann z.B. mit Windows PowerShell Just Enough Administration (JEA) oder SELinux, AppArmor oder Sudoers umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.6.5: Dynamische Zugriffskontrolle im System</td><td><p>Konfiguration für IT-Systeme KANN dynamische Zugriffskontrolle im System aktivieren.</p></td><td><p>Dynamische Zugriffssteuerung (Dynamic Access Control, DAC) erteilt Zugriff auf Dateien und andere Ressourcen basierend auf dynamischen Bedingungen. Beispiele sind Zugriffe von bestimmten Orten oder IP-Adressen, von Systemen auf denen nicht die aktuellsten Sicherheitsupdates oder bestimmte Identifikationszertifikat installiert sind, oder zu ungewöhnlichen Zeiten. Da DAC komplex sein kann ist es zweckmäßig auch auf Funktionen zur Auditierung und Protokollierung der DAC zu achten.</p></td></tr><tr valign="top"><td>KONF.6.6: Getrennte Datenhaltung</td><td><p>Konfiguration für Anwendungen SOLLTE Zugriffe eines Zugangskontos auf Daten anderer Zugangskonten einschränken.</p></td><td><p>Dies kann je nach Anwendung z.B. durch eine in der Anwendung integrierte Rollen- und Rechteverwaltung, Zugriffsrechte auf Dateisystemebene oder durch die Verwendung unterschiedlicher Systeme oder Netze pro Zugang realisiert werden.</p></td></tr><tr valign="top"><td>KONF.6.6.1: Mandantenfähigkeit</td><td><p>Konfiguration für Anwendungen SOLLTE wenn die Anwendung mehrere Mandaten bedient, für jeden Mandanten eine eigene Berechtigungskonfiguration aktivieren.</p></td><td><p>Der Ausdruck <b>„mehrere Mandanten“</b> (im Englischen auch multi-tenancy genannt) bezieht sich auf eine Softwarearchitektur, bei der eine einzige Instanz einer Anwendung gleichzeitig die Bedürfnisse mehrerer, voneinander unabhängiger Kundengruppen (Mandanten) bedient. Eine eigene Berechtigungskonfiguration bedeutet, dass jeder Mandant eine separate, von den anderen getrennte Sammlung von Zugriffsregeln und -rechten erhält. Dies dient dem Schutz vor Datenlecks, da ein Angreifer, der sich unrechtmäßig Zugang zu einem Mandanten verschafft, dadurch nicht automatisch die Berechtigungen für andere Mandanten übernimmt. Eine separate Konfiguration kann verhindern, dass ein Fehlverhalten oder eine Fehlkonfiguration bei einem Mandanten die Sicherheit aller anderen beeinträchtigt. Technische Möglichkeiten hierfür sind die Verwendung von mandantenspezifischen Datenbank-Schemata oder die logische Trennung von Daten innerhalb einer gemeinsamen Datenbank durch Mandanten-IDs. Darüber hinaus kann die Institution sicherstellen, dass die Authentifizierung und Autorisierung für jeden Mandanten streng getrennt sind, zum Beispiel durch die Nutzung unterschiedlicher API-Schlüssel oder Single-Sign-On-Konfigurationen pro Mandant.</p></td></tr><tr valign="top"><td>KONF.6.7: Privilegierte Funktionen der Anwendung</td><td><p>Konfiguration für Anwendungen SOLLTE privilegierte Funktionen einschränken.</p></td><td><p>Sind privilegierte Funktionen nicht eingeschränkt, so könnten Innentäter oder Angreifer über das Netz unbefugte Manipulationen vornehmen, Fehlkonfigurationen ausgelöst werden oder sich Schadcode automatisch einnisten. Privilegierte Funktionen können z.B. ein Berechtigungsmanagement der Anwendung, der Zugriff auf Daten mehrerer Zugangskonten, das Hinzufügen oder Entfernen akzeptierter X.509-Zertifikate, ein Moderationsrecht oder die Änderung der Sicherheitskonfiguration der Anwendung sein.</p></td></tr><tr valign="top"><td>KONF.6.8: Berechtigungen des Webserver-Prozesses</td><td><p>Konfiguration für Webserver SOLLTE die Berechtigungen des Webserver-Prozesses einschränken.</p></td><td><p>Wird der laufende Prozess über das Web kompromittiert, so verhindert eine Einschränkung der Rechte eine weitere Ausbreitung des Angriffs. Relevant sind dabei Zugriffsrechte für Dateisystem und Systemfunktionen. Zweckmäßig ist es hierzu, die Berechtigungen so einzuschränken, dass der Serverdienst a) keinen Zugriff auf Dateien außerhalb des WWW-Wurzelverzeichnisses hat, b) Schreibzugriffe innerhalb des WWW‑Wurzelverzeichnisses nur in explizit autorisierten Unter­verzeichnissen hat, c) keine Programme oder Shell‑Befehle außerhalb der vorgesehenen Interpreter ausführen kann, d) keine privilegierten Berechtigungen besitzt.  Unterverzeichnisse die Schreibrechte benötigen könnten sind etwa /uploads, /cache, /tmp.</p></td></tr><tr valign="top"><td>KONF.6.9: Zugriff auf Code</td><td><p>Konfiguration für Webserver SOLLTE den Zugriff auf Quelldateien einschränken.</p></td><td><p>Quelldateien sind in diesem Zusammenhang alle Dateien, die zur Funktionsweise einer Webanwendung benötigt werden, deren Auslieferung an den Browser von Nutzenden aber nicht erforderlich ist. Dazu gehören Programmier- oder Skriptcode, Konfigurationsdateien, Datenbankverbindungen und sensible Daten wie APIs oder Anmeldeinformationen. Das Verhindern des direkten Zugriffs auf diese Dateien dient der Prävention von Informationslecks und der Minderung des Risikos unautorisierter Offenlegung. Eine nicht restriktive Konfiguration könnte beispielsweise die Offenlegung von Code-Teilen, die Logik der Anwendung oder sogar hartkodierten Passwörtern ermöglichen, was zu einer weitreichenden Kompromittierung des Systems führen könnte. Die Umsetzung kann durch platzieren dieser Dateien außerhalb des WWW-Wurzelverzeichnisses erfolgen. Weiterhin kann der Zugriff auf bestimmte Dateitypen wie .php, .ini, .env oder .sql mittels Webserver-Regeln (z.B. in .htaccess für Apache oder location-Blöcke in Nginx) explizit verweigert werden, wodurch auch versehentlich im öffentlichen Verzeichnis abgelegte Quelldateien geschützt sind. Bei der Wahl eines Content-Management-Systems oder Frameworks kann eine sichere Standardkonfiguration die Umsetzung erleichtern. Zusätzlich können serverseitige Skripte so konfiguriert werden, dass sie nur aus vordefinierten, sicheren Verzeichnissen ausgeführt werden dürfen, was als Secure Execution Path bekannt ist.</p></td></tr><tr valign="top"><td>KONF.6.10: Auflistung von Verzeichnisinhalten</td><td><p>Konfiguration für Webserver SOLLTE die Auflistung von Verzeichnisinhalten einschränken.</p></td><td><p>Über das Auflisten von Verzeichnisinhalten erhalten Angreifer Einblick in die interne Struktur des Systems und potenziell sensibler Daten. Zur Umsetzung kann in der Konfiguration des Webservers (z.B. Apache, Nginx) die Directory-Listing-Funktion deaktiviert werden. Alternativ kann über Dateien wie .htaccess der Zugriff auf die notwendigen Verzeichnisse eingeschränkt werden.</p></td></tr><tr valign="top"><td>KONF.6.11: Einschränkung von Uploads</td><td><p>Konfiguration für Webserver SOLLTE Uploads einschränken.</p></td><td><p>Uploads sind Dateien, die von Nutzenden auf den Server übertragen werden. Diese könnten Schadprogramme enthalten oder den Speicher füllen. Sinnvolle Beschränkungen sind z.B. der Upload nur nach Anmeldung, eine maximale Dateigröße, erlaubte Dateitypen und deren Speicherorte.</p></td></tr><tr valign="top"><td>KONF.6.12: Konferenzmoderation</td><td><p>Konfiguration für VK-Anwendungen SOLLTE Konferenzmoderation aktivieren.</p></td><td><p>Bei Konferenzen kann es vorkommen, dass ungewollt Teilnehmende zu hören sind. Dies kann versehentlich geschehen oder im Rahmen eines Angriffes.</p></td></tr><tr valign="top"><td>KONF.6.13: Dynamische Zugriffskontrolle in der Anwendung</td><td><p>Konfiguration für Anwendungen KANN dynamische Zugriffskontrolle in der Anwendung aktivieren.</p></td><td><p>Beispiele sind Zugriffe von bestimmten Orten oder IP-Adressen, von Systemen auf denen nicht die aktuellsten Sicherheitsupdates oder bestimmte Identifikationszertifikat installiert sind, oder zu ungewöhnlichen Zeiten.</p></td></tr><tr valign="top"><td>KONF.6.14: Browser Sandboxing</td><td><p>Konfiguration für Webbrowser SOLLTE Browser Sandboxing aktivieren.</p></td><td><p>Sandboxing bedeutet, dass jede Instanz und jeder Verarbeitungsprozess nur auf die eigenen Ressourcen zugreifen kann. Die Isolation kann durch eigene Threads oder eigene Prozesse realisiert sein.</p></td></tr><tr valign="top"><td>KONF.6.15: Virtualisierte Browser-Umgebung</td><td><p>Konfiguration für Webbrowser KANN Virtualisierte Browser-Umgebung aktivieren.</p></td><td><p>Eine Browser-Umgebung ist virtualisiert, wenn der Code des Browser nicht im Betriebssystem des Clients, sondern in einem dediziert hierzu virtualisierten Betriebssystem ausgeführt wird, z.B. ReCoBS.</p></td></tr><tr valign="top"><td>KONF.6.16: Datenaustausch in der Virtualisierung</td><td><p>Konfiguration für Virtualisierungslösungen KANN den Datenaustausch zwischen virtualisierten Client einschränken.</p></td><td><p>Der Datenaustausch zwischen virtualisierten Anwendungen umfasst jegliche direkte oder indirekte Kommunikationswege wie virtuelle Netzwerke, geteilte Speicherbereiche oder Copy-and-Paste-Funktionen über die Virtualisierungsplattform. Der Sinn dieser Anforderung liegt darin, unbeabsichtigte oder böswillige Datenübertragungen zwischen isolierten Anwendungen einzuschränken. Ohne diese Einschränkungen könnte Schadsoftware von einer kompromittierten VM unbemerkt auf eine andere übergreifen oder sensible Informationen könnten durch Fehlkonfigurationen ungewollt in eine fremde VM gelangen. Eine klare Abgrenzung kann hingegen sicherstellen, dass selbst bei Kompromittierung einer Anwendung deren Wirkungskreis begrenzt bleibt und Vertraulichkeit, Integrität sowie Stabilität anderer Anwendungen erhalten bleiben. Die praktische Umsetzung kann durch mehrere Maßnahmen erfolgen, die sich technisch wie prozessual ergänzen. So kann eine Institution (1) virtuelle Netzwerke segmentieren, sodass VMs nur über explizit eingerichtete Firewalls miteinander kommunizieren können, (2) gemeinsame Speicherbereiche oder Zwischenablagen deaktivieren, sofern diese nicht zwingend benötigt werden, und (3) die Nutzung von Schnittstellen wie USB-Passthrough oder Drag-and-Drop bewusst unterbinden oder nur für klar definierte Administrations-VMs freigeben. Darüber hinaus kann es sinnvoll sein, die Konfiguration regelmäßig mit Härtungsleitfäden abzugleichen. Ein pragmatischer Tipp ist es, beim Aufsetzen neuer VMs die Standardkonfigurationen bewusst restriktiv zu wählen und nur jene Austauschfunktionen schrittweise zu aktivieren, die für den Geschäftsbetrieb wirklich erforderlich sind.</p></td></tr></table><h2>KONF.7: Schutz vor Schadcode</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.7.1: Echtzeitscanner</td><td><p>Konfiguration für IT-Systeme SOLLTE eine automatische Prüfung auf Schadcode bei Installation oder Öffnung von Dateien aktivieren.</p></td><td><p>Schadcode kann sich sowohl auf lokalen Speichermedien, als auch auf Netzlaufwerken oder Wechseldatenträgern befinden. Für Netzlaufwerke kann die Anforderung auch umgesetzt werden, indem Dateien bei der Speicherung auf dem zentralen System auf Schadcode geprüft werden. Die Anwendung zur Schadcodeprüfung kann z.B. auch als EDR, XDR oder IDS bezeichnet werden. Moderne Systeme zur Erkennung von Schadcode verwenden eine Kombination aus Virensignaturen, Heuristiken, als auch Anomalieerkennung. Falls das System die Installation von Anwendungen nicht unterstützt, so ist dieser Teilschritt entbehrlich.</p></td></tr><tr valign="top"><td>KONF.7.2: Regelmäßige Scans</td><td><p>Konfiguration für IT-Systeme SOLLTE einen regelmäßigen Scan von Dateien auf dem System nach potenziellem Schadcode aktivieren.</p></td><td><p>Schadcode kann sich sowohl auf lokalen Speichermedien, als auch auf Netzlaufwerken oder Wechseldatenträgern befinden. Für Netzlaufwerke kann die Anforderung auch umgesetzt werden, indem Dateien bei der Speicherung auf dem zentralen System auf Schadcode geprüft werden. Die Anwendung zur Schadcodeprüfung kann z.B. auch als EDR, XDR oder IDS bezeichnet werden. Moderne Systeme zur Erkennung von Schadcode verwenden eine Kombination aus Virensignaturen, Heuristiken, als auch Anomalieerkennung.  Falls das System die Installation von Anwendungen nicht unterstützt, so ist dieser Teilschritt entbehrlich.</p></td></tr><tr valign="top"><td>KONF.7.3: Host-basierte Angriffserkennung</td><td><p>Konfiguration für IT-Systeme SOLLTE Host-basierte Angriffserkennung aktivieren.</p></td><td><p>Host-basierte Angriffserkennung, im Englischen auch als Host-based Intrusion Detection (HID) oder Host-based Intrusion Prevention (HIP) bezeichnet, bezieht sich auf Mechanismen, die auf den einzelnen IT-Systemen, wie Servern oder Workstations, selbst operieren, um böswillige Aktivitäten zu erkennen und zu verhindern. Im Gegensatz zu netzwerkbasierten Systemen, die den Datenverkehr überwachen, fokussiert sich die Host-basierte Erkennung auf interne Systemereignisse, wie die Integrität von Dateisystemen, Änderungen an kritischen Konfigurationsdateien, oder die Erkennung von unbekannten Prozessen. Der Hauptzweck dieser Anforderung besteht darin, eine zusätzliche Sicherheitsebene zu schaffen, die direkt am Endpunkt (Host) agiert, was die Erkennung von Angriffen ermöglicht, die bereits die äußeren Schutzmechanismen überwunden haben könnten, beispielsweise wenn ein Angreifer eine bekannte Schwachstelle ausnutzt, um einen Prozess mit erhöhten Rechten auszuführen. Diese Maßnahmen können dabei helfen, interne Lateralbewegungen eines Angreifers zu erkennen und somit die Ausbreitung eines Vorfalls zu verlangsamen oder zu stoppen, bevor es zu einem größeren Schaden kommt.</p></td></tr><tr valign="top"><td>KONF.7.4: Angriffserkennung anhand von Netzverkehr</td><td><p>Konfiguration für IT-Systeme KANN Angriffserkennung anhand von Netzverkehr aktivieren.</p></td><td><p>Hierbei wird eine netzwerkbasierte Bedrohungsanalyse direkt auf dem IT-System durchgeführt. Dieser Ansatz, oft als Host-based Network Intrusion Detection System (H-NIDS) oder Endpoint Detection and Response (EDR) bezeichnet, ermöglicht eine tiefere Sicht in das Systemverhalten. Statt nur den Datenstrom am Perimeter zu überwachen, kann so die Institution verdächtige Aktivitäten wie das Scannen von Netzwerk-Ports, den Aufbau ungewöhnlicher Verbindungen zu Command-and-Control-Servern oder den Versuch der Datenexfiltration erkennen. Ohne diese Erkennung könnte sich ein Angreifer, der bereits in das Netzwerk eingedrungen ist, unentdeckt von System zu System bewegen oder sensible Daten unbemerkt nach außen senden. Die dezentrale Erkennung auf den Clients kann zudem dabei helfen, interne Lateral-Movement-Versuche zu identifizieren, da der Datenverkehr zwischen den Systemen überwacht wird, selbst wenn er das interne Netzwerk nicht verlässt. Um diese Anforderung umzusetzen, kann die Institution spezialisierte EDR- oder Endpoint-Security-Lösungen nutzen, die eine integrierte Funktion zur Netzwerküberwachung bieten. Es kann ebenfalls eine regelbasierte Erkennung über lokale Host-Firewalls oder Sicherheitsagenten aktiviert werden, die bestimmte Muster im Netzwerkverkehr blockieren oder protokollieren. Bei der Einführung solcher Maßnahmen ist es entscheidend, die Performance des Clients zu berücksichtigen. Daher kann die Konfiguration so optimiert werden, dass sie nur kritische Protokolle oder Ports überwacht, um die Systemressourcen zu schonen.</p></td></tr><tr valign="top"><td>KONF.7.5: Alarmierung</td><td><p>Konfiguration für IT-Systeme SOLLTE eine Benachrichtigung bei potenziellem Schadcode aktivieren.</p></td><td><p>Durch die Aktivierung einer Benachrichtigung kann eine Institution schnell auf verdächtige Aktivitäten reagieren, noch bevor sich der Schadcode vollständig im System etablieren und erheblichen Schaden anrichten könnte. Eine Möglichkeit zur Umsetzung ist der Einsatz von Endpoint Detection and Response (EDR)-Lösungen, die in der Lage sind, Verhaltensanomalien in Echtzeit zu erkennen und sofortige Benachrichtigungen auszulösen. Eine effektive Umsetzung erfordert, dass die Benachrichtigungen sowohl an die Endnutzer als auch an die zuständigen IT-Sicherheitsteams gesendet werden, um eine umfassende und koordinierte Reaktion zu ermöglichen. Dabei können Automatisierungsregeln im Security Information and Event Management (SIEM) die Benachrichtigungen an die richtigen Personen eskalieren und so die Reaktionszeit verkürzen.</p></td></tr><tr valign="top"><td>KONF.7.6: Automatische Updates</td><td><p>Konfiguration für IT-Systeme SOLLTE Automatische Updates der Mechanismen zur Schadcodeerkennung aktivieren.</p></td><td><p>Da Schadprogramme und Angriffsmethoden ständig abgeändert werden um bekannte Erkennungsmuster zu umgehen, sind aktuelle Erkennungsfunktionen entscheidend um laufende Angriffe erkennen zu können, z.B. Signatur-Update oder Aktualisierungen der Lernfunktion zur Anomalieerkennung. Dies kann durch automatische Aktualisierungen der Signaturen und Mechanismen zur Angriffserkennung umgesetzt werden, z.B. als tagesaktueller Download von Viren-Signaturen. Die Anforderung kann auch durch einen schrittweisen Rollout der Erkennungsfunktionen umgesetzt werden, um einen Test in der Institution zu ermöglichen.</p></td></tr><tr valign="top"><td>KONF.7.7: Regelmäßiger Funktionstest</td><td><p>Konfiguration für IT-Systeme KANN die Funktionsfähigkeit des Schadcodeschutzes <i>regelmäßig</i> überprüfen.</p></td><td><p>Die Funktionsfähigkeit des Schadcodeschutzes beschreibt den operativen Zustand der eingesetzten Schutzmechanismen (engl. Malware Protection, oft auch Antivirus oder Endpoint Detection and Response, kurz EDR), der über die reine Installation der Software hinausgeht. Sie umfasst die korrekte Ausführung der Schutzdienste, die Aktualität der Erkennungssignaturen und Verhaltensregeln sowie die Fähigkeit, auf Bedrohungen aktiv zu reagieren und diese zu protokollieren. Eine regelmäßige Überprüfung dieser Funktionsfähigkeit kann die Institution vor unbemerkten Sicherheitslücken schützen. Ein deaktivierter oder fehlerhafter Schutzmechanismus könnte beispielsweise dazu führen, dass Ransomware unbemerkt Daten verschlüsselt oder ein Trojaner Anmeldeinformationen abgreift, obwohl eine Schutzsoftware installiert ist. Durch die proaktive Verifikation kann hingegen sichergestellt werden, dass diese wesentliche Verteidigungslinie durchgehend intakt ist und auf Angriffsversuche reagieren kann. Zur konkreten Umsetzung kann die Institution auf verschiedene, sich ergänzende Maßnahmen zurückgreifen. Eine zentrale Verwaltungskonsole der eingesetzten Schutzlösung kann genutzt werden, um den Status aller angebundenen Systeme automatisiert zu überwachen und Alarme auszulösen, wenn Systeme sich nicht mehr melden, veraltete Signaturen aufweisen oder Dienste beendet wurden. Ergänzend kann die tatsächliche Erkennungsleistung proaktiv durch den Einsatz einer standardisierten Testdatei wie dem EICAR-Teststring verifiziert werden; dieser kann automatisiert auf den Systemen platziert werden, um zu prüfen, ob der Schadcodeschutz wie erwartet anschlägt und eine Meldung generiert. Auf Systemen ohne zentrale Anbindung kann die Funktionsfähigkeit mittels Skripten überprüft werden, die lokal den Dienststatus und das Alter der Signaturdateien auslesen und in einer überwachten Logdatei dokumentieren.</p></td></tr><tr valign="top"><td>KONF.7.8: Dual-Engine-Strategie</td><td><p>Konfiguration für IT-Systeme KANN für die Erkennung von Schadcode unterschiedliche Scan-Engines aktivieren.</p></td><td><p>Hiermit ist gemeint, dass die Angriffserkennung mittels (zwei oder mehr) verschiedenen Scan-Engines durchgeführt wird, um die Erkennungswahrscheinlichkeit zu erhöhen. Hierdurch kann es zu Performanceeinbußen oder einer höheren Fehlerkennungquote kommen.</p></td></tr><tr valign="top"><td>KONF.7.9: Einschränkung der Installation</td><td><p>Konfiguration für IT-Systeme SOLLTE die Installation von Anwendungen einschränken.</p></td><td><p>Es empfiehlt sich z.B. die zu installierende Software nicht unkontrolliert in das Wurzeldateisystem des Betriebssystems zu installieren. Wenn die zu installierende Software aus dem Quellcode kompiliert werden soll, dann empfiehlt es sich diese nur unter einem unprivilegierten Konto zu entpacken, zu konfigurieren und zu übersetzen.</p></td></tr><tr valign="top"><td>KONF.7.10: Einschränkung der Ausführung</td><td><p>Konfiguration für IT-Systeme SOLLTE die Ausführung nicht autorisierter Anwendungen einschränken.</p></td><td><p>Wenn Anwendungen an beliebigen Speicherorten installiert und ausgeführt werden, z.B. im Wurzeldateisystem des Betriebssystems oder an Speicherorten zusammen mit Daten der Nutzerumgebung, dann könnte dies zahlreiche Sicherheitsrisiken mit sich bringen. Unbefugte oder schadhafte Anwendungen könnten unbemerkt an unautorisierte Orte platziert werden, wo sie außerhalb etablierter Sicherheitskontrollen agieren und beispielsweise Privilege-Escalation-Angriffe durchführen können. Zudem wird das Risiko der Manipulation von Anwendungsdateien erhöht, da Angreifer gezielt nach nicht-geschützten Speicherorten suchen, um dort eigenen Code zu hinterlegen oder legitime Anwendungen zu modifizieren. Eine solche Situation kann zu <b>„Living-off-the-Land“</b>-Angriffen führen, bei denen Angreifer vorhandene legitime Programme missbrauchen, um Schadaktionen auszuführen, was die Erkennung erheblich erschwert. Die Beschränkung von Ausführungsspeicherorten (Execution Control) zielt darauf ab, die Angriffsfläche zu reduzieren und eine bessere Kontrolle über ausführbare Programme zu ermöglichen.  Zur technischen Umsetzung dieser Anforderung kann eine Institution verschiedene Maßnahmen implementieren. Application Allowlisting kann eingesetzt werden, um nur vertrauenswürdige Anwendungen aus definierten Verzeichnissen auszuführen, beispielsweise mittels AppLocker unter Windows oder SELinux unter Linux-Systemen. Zusätzlich können Software Restriction Policies (SRPs) konfiguriert werden, um Ausführungsrechte auf bestimmte Verzeichnispfade zu begrenzen, wobei eine Trennung zwischen Systemverzeichnissen und Nutzerverzeichnissen empfehlenswert ist. Weitere wirksame Techniken umfassen die Implementierung von Code Signing, wodurch nur digital signierte Anwendungen ausgeführt werden können, sowie die Nutzung von Container-Technologien wie Docker, die eine isolierte Ausführungsumgebung bieten. Dabei kann auf das Inventar der Anwendungen als Grundlage zurückgegriffen werden.</p></td></tr><tr valign="top"><td>KONF.7.11: Einschränkung von Softwarebibliotheken</td><td><p>Konfiguration für IT-Systeme KANN die Ausführung nicht autorisierter Softwarebibliotheken einschränken.</p></td><td><p>Softwarebibliotheken sind wiederverwendbare Codesammlungen, die Entwicklern fertige Funktionalitäten bieten, ohne diese selbst programmieren zu müssen. Unautorisierte Bibliotheken stellen Sicherheitsrisiken dar, weil sie absichtlich eingeschleusten Schadcode enthalten könnten, der Daten ausspioniert oder Systeme kompromittiert. Sie durchlaufen seltener reguläre Sicherheitsüberprüfungen und könnten für Supply-Chain-Angriffe genutzt werden, bei denen harmlos erscheinender Code mit versteckten Schadfunktionen in Paketmanager eingeschleust wird. Zudem erhalten unautorisierte Bibliotheken häufig keine regelmäßigen Sicherheitsupdates, sodass bekannte Schwachstellen unbehoben bleiben. Mangelnde Dokumentation und unklare Abhängigkeiten von anderen ungeprüften Quellen erhöhen das Risiko zusätzlich. Beispiele sind Dateien der Typen .dll, .ocx,  und .so. Die Umsetzung kann durch Sicherheitsfunktionen erfolgen, die nur das Laden autorisierter Bibliotheken in Systemprozessen erlaubt. Verfügt das IT-System über keine Möglichkeit zur Installation von Anwendungen, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.7.12: Einschränkung von Skripten</td><td><p>Konfiguration für IT-Systeme KANN die Ausführung nicht autorisierter Skripte einschränken.</p></td><td><p>Skripte könnten Schadcode enthalten oder zu Fehlerzuständen auf dem System führen. Die Auswirkungen schädlicher Skripte können eingeschränkt werden, indem nur bestimmte Systemfunktionen für Skripte erlaubt werden. Die Umsetzung ist mit Funktionen wie dem Windows PowerShell Constrained Language Mode oder Linux Secure Computing Mode möglich. Verfügt das System über keine Möglichkeit zur Ausführung von Skripten, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.7.13: Einschränkung von Systemaufrufen</td><td><p>Konfiguration für IT-Systeme KANN Systemaufrufe pro Anwendung einschränken.</p></td><td><p>Ein Systemaufruf (engl. system call) ist dabei die Methode, mit der eine Anwendung Zugriff auf die Ressourcen des Betriebssystems anfordert, z.B. um eine Datei zu öffnen, in das Netzwerk zu kommunizieren oder einen neuen Prozess zu starten. Diese feingranulare Einschränkung wird in der Branche auch als Capability-based Security oder Seccomp (Secure Computing Mode) bezeichnet. Der Zweck dieser Vorschrift ist die gezielte Reduzierung der Angriffsfläche, indem selbst eine vertrauenswürdige, aber kompromittierte Anwendung daran gehindert wird, schädliche Aktionen auszuführen. Ein Angreifer könnte beispielsweise die Prozess-ID (PID) einer Anwendung kapern und versuchen, über deren Kontext privilegierte Systemaufrufe durchzuführen, um sich im Netzwerk auszubreiten oder sensible Daten zu löschen. Die Einschränkung dieser Aufrufe kann die Folgen eines erfolgreichen Angriffs erheblich mildern und so die Ausbreitung von Malware oder die Manipulation von Systemprozessen verhindern.</p></td></tr><tr valign="top"><td>KONF.7.14: Code-Signierung im Betriebssystemkern</td><td><p>Konfiguration für IT-Systeme SOLLTE Code-Signierung im Betriebssystemkern aktivieren.</p></td><td><p>Laufende Kernprozesse des Systems können geschützt werden, indem nur signierter Code hierauf zugreifen darf. Beispiele sind unter Windows der der PPL-Schutz (Protected Process Light) des Local Credential Store (LSA-Schutz) oder unter Linux mit SELinux oder dem Secure Computing Mode.</p></td></tr><tr valign="top"><td>KONF.7.15: Lokale Firewall</td><td><p>Konfiguration für IT-Systeme SOLLTE ein- und ausgehende Netzverbindungen einschränken.</p></td><td><p>Eine lokale Firewall ist eine Anwendung, welche nur die zum Betrieb und zur Wartung des IT-Systems notwendigen ein- und ausgehenden Verbindungen zulässt. Bringt das Betriebssystem diese Funktionalität bereits vom Werkszustand her mit, so ist die Anforderung ebenfalls erfüllt, wenn sie entsprechend konfiguriert ist. Zweckmäßig ist hierbei ein Allowlist-Ansatz, der die gewünschte Verbindung möglichst genau beschreibt (z.B. anhand Server-IP und Port).</p></td></tr><tr valign="top"><td>KONF.7.16: Anti-Exploit</td><td><p>Konfiguration für IT-Systeme SOLLTE Systemfunktionen zum Schutz des Systems vor der Ausnutzung bekannter Sicherheitslücken aktivieren.</p></td><td><p>Angreifer versuchen häufig, bekannte Sicherheitslücken oder offene Systemfunktionen zur Verbreitung oder Einnistung von Schadcode zu missbrauchen. Funktionen zum Schutz vor der Ausnutzung von Sicherheitslücken (Anti-Exploit) können helfen dies zu verhindern. Beispiele sind Data Execution Prevention (DEP), Defender Exploit Guard (WDEG) oder System Integrity Protection (SIP).</p></td></tr><tr valign="top"><td>KONF.7.16.1: Anti-Exploit für den Arbeitsspeicher</td><td><p>Konfiguration für IT-Systeme SOLLTE den Schutz des Arbeitsspeichers vor der Ausnutzung bekannter Sicherheitslücken aktivieren.</p></td><td><p>Gelingt es Angreifern Code auf dem System auszuführen, so könnten sie versuchen, über den Arbeitsspeicher des Systems den Schadcode weiter zu verbreiten oder Zugriff auf Daten zu erlangen. Hierzu gehören Angriffe wie Buffer Overflows, Return-Oriented Programming, Heap Spraying, Use-After-Free, Memory Scraping oder Side-Channel-Angriffe wie Spectre und Meltdown. Schutzmaßnahmen hiergegen können durch Software oder durch Hardware umgesetzt sein. Softwarebasiert sind z.B. Address Space Layout Randomization (ASLR), Data Execution Prevention (DEP), Stack Canaries. Hardwarebasiert sind z.B. Trusted Execution Environments (TEE).</p></td></tr></table><h2>KONF.8: Sicherheitsupdates</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.8.1: Automatische Überprüfung</td><td><p>Konfiguration für IT-Systeme SOLLTE das Vorliegen von Sicherheitsupdates überwachen.</p></td><td><p>Eine Überwachung von Sicherheitsupdates bedeutet, dass die IT-Systeme selbsttätig nach neuen Aktualisierungen suchen, die Schwachstellen in der Software beheben. Technisch können Systeme so konfiguriert werden, dass sie über zentrale Update-Server regelmäßig auf neue Patches prüfen. Es ist ratsam, einen automatisierten Prozess einzurichten, der bei Vorliegen von Updates diese automatisiert ausrollt oder eine Meldung an die zuständigen IT-Administratoren und ggf. die betroffenen Nutzer sendet. Diese Benachrichtigung kann über E-Mail, ein internes Ticketsystem oder ein Dashboard erfolgen. Ein guter Tipp ist die priorisierte Behandlung von Updates, bei der kritische Sicherheits-Patches vor Routine-Updates installiert werden.</p></td></tr><tr valign="top"><td>KONF.8.1.1: Automatische Sicherheitsupdates</td><td><p>Konfiguration für IT-Systeme SOLLTE Sicherheitsupdates automatisch installieren.</p></td><td><p>Dies kann durch direkten Download vom Hersteller oder einen eigenen Verteilerserver umgesetzt werden, so lange dieser ebenfalls automatisch aktuell gehalten wird. Damit Sicherheitsupdates des Betriebssystems auch tatsächlich wirken und Fehlerzustände vermieden werden ist typischerweise ein Neustart erforderlich, damit die Betriebssystemfunktionen und damit verbundene Anwendungen aus dem installierten Update neu geladen und in einen definierten Zustand versetzt werden. Manche Systeme unterstützen alternativ auch Live-Patching des Betriebssystems im laufenden Betrieb.</p></td></tr><tr valign="top"><td>KONF.8.2: Automatische Updates der Anwendung</td><td><p>Konfiguration für Anwendungen SOLLTE die automatische Installation von Sicherheitsupdates aktivieren.</p></td><td><p>Dies kann durch direkten Download vom Hersteller oder einen eigenen Verteilerserver umgesetzt werden, so lange dieser aktuell gehalten wird.</p></td></tr></table><h2>KONF.9: Verfügbarkeit von Ressourcen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.9.1: Speicherplatzbegrenzung</td><td><p>Konfiguration für IT-Systeme SOLLTE den Speicherplatz für die Nutzerumgebung einschränken.</p></td><td><p>Nutzerumgebung meint hier alle Anwendungen und Dienste, die auf dem System betrieben werden, aber keine Systemdienste sind. Alternativ empfiehlt es sich Mechanismen des verwendeten Datei- oder Betriebssystems zu nutzen, die Benutzende bei einem bestimmten Füllstand der Festplatte warnen oder nur noch Administrierenden Schreibrechte einräumen.</p></td></tr><tr valign="top"><td>KONF.9.2: Begrenzung der Rechenleistung</td><td><p>Konfiguration für Hostsysteme KANN die zur Verfügung stehende Rechenleistung anhand von <i>Schwellwerten</i> einschränken.</p></td><td><p>Dies kann durch eine Beschränkung der Anzahl verwendeter Rechenkerne, der Rechenleistung pro Rechenkern oder durch eine indirekte Beschränkung (z.B. eine begrenzte Menge an Anfragen oder Eingabetoken in Anwendungen) umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.9.3: Alternative Komponenten für kritische Funktionen</td><td><p>Konfiguration für IT-Systeme KANN alternative Komponenten für <i>bestimmte kritische Funktionen</i> installieren.</p></td><td><p>Beispiele sind redundante Stromnetzteile, Ethernet-Anschlüsse oder eine Mobilfunkanbindung als Ausfallsicherheit für die kabelgebundene Netzanbindung.</p></td></tr></table><h2>KONF.10: Konfiguration von Anwendungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.10.1: Grundkonfiguration für Anwendungen</td><td><p>Konfiguration für Anwendungen SOLLTE eine Grundkonfiguration dokumentieren.</p></td><td><p>Eine Grundkonfiguration (engl. baseline configuration) bezeichnet in diesem Kontext einen dokumentierten Ausgangszustand einer Anwendung, der sowohl funktionale Anforderungen als auch sicherheitsrelevante Einstellungen berücksichtigt. Sie umfasst unter anderem Parameter wie Benutzerrechte, Logging-Einstellungen, Schnittstellenaktivierungen oder Verschlüsselungsoptionen und bildet damit die Referenz, auf die spätere Anpassungen zurückgeführt oder überprüft werden können. Fehlt eine nachvollziehbare Grundkonfiguration, könnte es bei Updates, Migrationen oder im Incident-Fall zu schwer erkennbaren Abweichungen kommen, die unerwünschte Sicherheitslücken hinterlassen. Eine klare Dokumentation kann dagegen die Nachvollziehbarkeit erhöhen, unerwünschte Änderungen sichtbar machen und den sicheren Betrieb der Anwendung unterstützen. Zur praktischen Umsetzung kann die Institution eine dokumentierte Konfigurationsvorlage entwickeln, die sowohl Herstellerempfehlungen als auch anerkannte Empfehlungen des BSI oder aus Benchmarks wie die des Center for Internet Security (CIS) berücksichtigt. Die Sicherheit von Anwendungen ist in besonderem Maße kontextbezogen: So könnten z.B. über E-Mail oder Messenger hoch vertrauliche Daten ausgetauscht werden oder auch öffentliche Informationen. Daher ist hier eine Vertiefung der Risikoanalyse empfehlenswert, die sich an der Verwendung der Anwendungen in Geschäftsprozessen orientiert. Dabei besteht ein enger Bezug zu Compliance-Anforderungen, zum Beispiel an finanzielle Transaktionen oder den Datenschutz, je nachdem welche Datenverarbeitungen mit der Anwendung vorgenommen werden.</p></td></tr><tr valign="top"><td>KONF.10.1.1: Versionierung</td><td><p>Konfiguration für Anwendungen SOLLTE eine Versionierung vorheriger Konfigurationen verankern.</p></td><td><p>Die Versionierung bezeichnet hier die strukturierte Nachvollziehbarkeit von Änderungen an Konfigurationen, also das Speichern, Dokumentieren und bei Bedarf Wiederherstellen älterer Zustände einer Anwendung. Sie unterscheidet sich von einem einfachen Backup dadurch, dass nicht nur eine Kopie vorliegt, sondern explizit eine fortlaufende Historie mit Vergleichen, Rücksetzpunkten (rollback points) und optional Kommentaren geführt wird. Der Zweck liegt darin, dass eine ungewollte oder fehlerhafte Anpassung an einer Anwendungskonfiguration im Betrieb schnell erkannt und – wenn erforderlich – präzise auf einen definierten, funktionsfähigen Zustand zurückgesetzt werden kann. Ohne diese Rückgriffsmöglichkeit könnte ein Konfigurationsfehler den gesamten Dienst außer Betrieb setzen, während eine Versionierung die Verfügbarkeit und Nachvollziehbarkeit stärken kann. Zur Umsetzung kann eine Institution technische Verfahren einsetzen, die eine automatische Ablage und Historisierung von Konfigurationsdateien unterstützen, beispielsweise durch (1) den Einsatz verteilter Versionskontrollsysteme wie Git oder Subversion (SVN) für textbasierte Konfigurationsdateien, (2) integrierte Konfigurationsarchivierung in gängigen Deployment- oder Container-Tools, oder (3) systemseitige Snapshot-Mechanismen, die gezielt für Konfigurationsverzeichnisse genutzt werden.</p></td></tr><tr valign="top"><td>KONF.10.2: Kryptographische Verfahren und Protokolle in Anwendungen</td><td><p>Konfiguration für Anwendungen SOLLTE kryptographische Verfahren und Protokolle im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement aktivieren.</p></td><td><p>Kryptographie wird für die Authentifizierung, Verschlüsselung und Integritätprüfung in Anwendungen verwendet, z.B. bei der Anmeldung an der Anwendung, Transportverschlüsselung zum Datenaustausch oder digitalen Signierung von Nachrichten. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>KONF.10.3: Änderung von Default-Zugangsdaten</td><td><p>Konfiguration für Anwendungen SOLLTE die Änderung von Default-Zugangsdaten ausführen.</p></td><td><p>Hiermit sind Default-Passwörter, als auch vertrauenswürdige Authentisierungs-Schlüssel oder Zertifikate fallen, die per Default zur Anmeldung akzeptiert werden, gemeint.</p></td></tr><tr valign="top"><td>KONF.10.4: Deaktivierung nicht benötigter Anwendungsfunktionen</td><td><p>Konfiguration für Anwendungen SOLLTE nicht benötigte Anwendungsfunktionen deaktivieren.</p></td><td><p>Funktionen die für den Betrieb nicht benötigt werden stellen ein unnötiges Sicherheitsrisiko dar, da sie von Angreifern ausgenutzt werden oder durch Wechselwirkungen zu unvorhergesehenen Fehlern führen könnten. Hierzu gehören z.B. ungenutzte Cloud-Anbindungen, Module, Leistungsmerkmale oder Einstellungen. Installationspakete enthalten häufig eine Vielzahl von ausführbaren Dateien und Erweiterungen. Für den Betrieb nicht benötigte Anwendungskomponenten können Schwachstellen enthalten und sind ein unnötiges Sicherheitsrisiko.</p></td></tr><tr valign="top"><td>KONF.10.5: Überprüfung der Konfiguration</td><td><p>Konfiguration für Anwendungen SOLLTE die Übereinstimmung der tatsächlichen Konfiguration mit dem Referenzzustand <i>regelmäßig</i> überprüfen.</p></td><td><p>Referenzzustand („baseline configuration“) bezeichnet hier die dokumentierte und freigegebene Konfiguration der Anwendung, also die gewünschte und autorisierte Einstellung von Parametern, Diensten und Komponenten. Die tatsächliche Konfiguration ist die aktuelle technische Umsetzung dieser Einstellungen der Anwendung selbst. Der Abgleich beider Zustände dient vor allem der Vermeidung von Configuration Drift – d.h. dass Anwendungen schleichend von der definierten Grundkonfiguration abweichen. Dies könnte auftreten, wenn Änderungen nicht zentral dokumentiert oder automatisierte Installationen nicht einheitlich umgesetzt werden. Ohne diese Kontrolle könnte es zu unbemerkten Fehlkonfigurationen kommen, die Sicherheitslücken öffnen oder Betriebsstörungen verursachen. Durch regelmäßige Vergleiche kann eine Institution sicherstellen, dass Anwendungen konsistent, vertrauenswürdig und wartbar bleiben. Die Umsetzung kann technisch etwa mit Skripten erfolgen, die automatisiert Konfigurationsparameter auslesen und vergleichen. Auch der Einsatz von „Configuration Management“- oder „Compliance Scanning“-Werkzeugen kann unterstützen, indem sie Differenzen visualisieren und Reports erzeugen. Prozessual kann es hilfreich sein, Prüfintervalle nach Kritikalitätsklassen zu staffeln (z. B. sicherheitskritische Anwendungen wöchentlich, weniger kritische vierteljährlich) und Ergebnisse in Change-Management-Prozesse zurückzuführen.</p></td></tr><tr valign="top"><td>KONF.10.5.1: Automatisierte Überprüfung der Konfiguration</td><td><p>Konfiguration für Anwendungen KANN die Überprüfung der Konfiguration durch <i>einen automatisierten Mechanismus</i> aktivieren.</p></td><td><p>Die automatische Auditierung der Systemkonfiguration ermöglicht eine kontinuierliche und effiziente Überprüfung, ob IT-Systeme sicher und regelkonform konfiguriert sind. Dabei wird die aktuelle Konfiguration automatisiert mit vordefinierten Soll-Vorgaben (etwa unternehmensinternen Richtlinien oder externen Benchmarks wie denen des Center for Internet Security (CIS)) abgeglichen. Dies ist besonders sinnvoll, da manuelle Prüfungen fehleranfällig, zeitaufwändig und in großen Infrastrukturen kaum durchführbar sind. Automatisierte Audits erhöhen die Transparenz, erkennen Abweichungen frühzeitig und erleichtern die Einhaltung von Compliance-Vorgaben. So wird die Angriffsfläche durch fehlerhafte oder unsichere Einstellungen erheblich reduziert.</p></td></tr></table><h2>KONF.11: Vertrauensbeziehungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.11.1: Authentifizierung vor dem Zugriff</td><td><p>Konfiguration für Anwendungen SOLLTE Zugriffe auf schützenswerte Daten im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement authentifizieren.</p></td><td><p>Ziel ist es, vertrauliche Daten vor dem Zugriff von Unbefugten zu schützen. Relevant sind hierbei sowohl Frontend-Zugänge wie Webportale, als auch Backend-Datenschnittstellen wie Datenbank-API. Dies kann durch eine anwendungsspezifische Authentifizierung, oder durch Nutzung eines zentralen Identity Providers (Single-Sign-On) erfüllt werden. Für die Authentifizierung kommen z.B. Passwörter, X.509-Zertifikate, OTP-Token in Frage. Zweckmäßig ist hierfür der Einsatz von Standardkomponenten wie OAuth 2.0 und die Verbindung mit einem zentralen Berechtigungsmanagement der Anwendung. Im Einklang mit den Anforderungen des Identitäts- und Berechtigungsmanagements bedeutet, dass für die Anwendung die Anforderungen aus der Praktik Identitäts- und Berechtigungsmanagement erfüllt sind, die dort festgelegt wurden. Hierzu gehört die Art der Authentifizierung (z.B. Passwort, Biometrie, Mehr-Faktor-Authentifizierung) ebenso wie die relevanten Parameter (Passwortkomplexität, etc.). Auf Daten die nicht vertraulich (z.B. öffentlich) sind kann auch ohne Authentifizierung Zugriff erlaubt sein. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist. Verarbeitet die Anwendung gar keine vertraulichen Daten, dann ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.11.1.1: Authentifizierung von geplanten Konversationen</td><td><p>Konfiguration für TK-Anwendungen SOLLTE den Zugriff auf geplante Konversationen im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement authentifizieren.</p></td><td><p>Viele TK-Anwendungen bieten geplante Konversationen, z.B. in virtuellen Meeting-Räumen oder über Telefonkonferenzen, die über eine Rufnummer erreichbar sind. Wird der Zugriff hierauf nicht authentifiziert, so könnten unbemerkt Unberechtigte teilnehmen und Informationen abhören oder auf Meta-Informationen wie Teilnehmer oder Uhrzeiten zugreifen. Der Schutz kann z.B. durch Passwörter/PINs oder über die Anmeldung per Zertifikat oder Single-Sign-On geschehen. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>KONF.11.1.2: Authentifizierung von Netzverbindungen - clientseitig</td><td><p>Konfiguration für Anwendungen SOLLTE die Gegenstelle vor dem Datenaustausch im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement authentifizieren.</p></td><td><p>Stellt eine Anwendung Anfragen über das Netz oder nimmt eine Anwendung Anfragen über das Netz entgegen, so gewährleistet eine Authentifizierung der Gegenstelle, dass diese autorisiert ist Anfragen zu stellen oder zu beantworten. Eine gängige Lösung ist die Prüfung von X.509-Zertifikaten beim Verbindungaufbau mit TLS. Für die Umsetzung ist es nicht unbedingt erforderlich, dass sich die Gegenstelle bei jeder Anfrage/Abruf erneut authentifiziert, wenn bei der Authentifizierung eine sichere Verbindung per TLS aufgebaut wird. Mit Anfragen sind alle Zugriffe gemeint, sei es über eine Web-URL oder eigene API. Die Formulierung <b>„im Einklang mit den zugehörigen Anforderungen zum Identitäts- und Berechtigungsmanagement“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik Berechtigung (BER) festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist. Für lesende Zugriffe auf unkritische, öffentliche Daten ist die Authentifizierung der lesenden Anwendung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.11.2: Warteraum</td><td><p>Konfiguration für VK-Anwendungen SOLLTE einen virtuellen Warteraum aktivieren.</p></td><td><p>Virtuelle Warteräume geben Konferenzmoderatoren die Möglichkeit, Teilnehmer vor Eintritt in einem virtuellen Warteraum persönlich zu authentifizieren.</p></td></tr><tr valign="top"><td>KONF.11.3: Alternative Authentifizierung</td><td><p>Konfiguration für Anwendungen KANN ein ebenso vertrauenswürdiges, alternatives Verfahren zur Authentifizierung aktivieren.</p></td><td><p>Wenn Nutzende ihren Primärzugang (z.B. Passwort, Smartphone mit Authentifizierungs-App) nicht mehr haben, wird eine alternative Möglichkeit zur Authentifizierung benötigt. Damit dieser Alternativzugang den Schutz der Primärmethode nicht aushebelt, ist eine vergleichbare Zuverlässigkeit der Authentifizierung erforderlich. Lösungsmöglichkeiten je nach Schutzbedarf sind z.B. (1) ein Einmalpasswort, dass an die hinterlegte E-Mailadresse versendet wird, (2) die persönliche Vorstellung mit Ausweis, (3) die Verifikation über bestehende Sitzungen, (4) Rückfallantworten wie Sicherheitsfragen oder PUK.</p></td></tr><tr valign="top"><td>KONF.11.4: Veröffentlichung von Domain-Infomationen</td><td><p>Konfiguration für DNS-Server SOLLTE die Veröffentlichung von Domain-Infomationen anhand von <i>Kriterien</i> einschränken.</p></td><td><p>Angreifer nutzen häufig DNS um das Netz zu erkunden (DNS-Reconnaissance). Veröffentlichen Sie Domain-Informationen nur, wenn diese zu einem Dienst gehören, der zur externen Nutzung gedacht ist. Nur intern benötigte DNS-Einträge dagegen bleiben intern.  Kriterien können z.B. Domains oder Subdomain sein (intern.domain.com vs www.domain.com).</p></td></tr><tr valign="top"><td>KONF.11.5: Erraten von Zugriffslinks</td><td><p>Konfiguration für Webanwendungen SOLLTE das Durchprobieren von Zugriffslinks durch <i>einen automatisierten Mechanismus</i> blockieren.</p></td><td><p>Ermöglichen Links den Zugriff auf vertrauliche Daten ohne Authentifizierung, so könnten Angreifer versuchen diese zu finden, z.B. mit Durchprobieren von Meeting-Links oder Ressourcen-URLs. Mögliche Maßnahmen sind Nicht-Sequentielle IDs mit hoher Entropie, Rate Limiting von Anfragen oder CAPTCHA. Hierbei bietet sich eine Kombination von Maßnahmen an, die Anzahl erwarteter Zugriffe, Verfügbarkeits- und Usability-Kriterien ebenso beachtet wie das Risikoprofil der Anwendung. Bietet die Webanwendung keinerlei Zugriff auf schützenswerte Informationen ohne Authentifizierung, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.11.6: Einschränkung unauthentifizierter Anschlüsse</td><td><p>Konfiguration für TK-Anwendungen SOLLTE von unauthentifizierten Anschlüssen erreichbare Gegenstellen einschränken.</p></td><td><p>Als unauthentifizierte Anschlüsse (engl. unauthenticated connections) sind hier alle Endpunkte zu verstehen, die eine Kommunikation ohne Anmeldung ermöglichen. Dies umfasst beispielsweise Notfalltelefone in Aufzügen, öffentlich zugängliche Telefone oder auch Faxgeräte in ungesicherten Bereichen. Aber auch an Konferenzraum-Systeme für Videokonferenzen oder den anonymen Gast-Zugang zu Online-Meetings ist zu denken. Die Anforderung zielt darauf ab, den Missbrauch dieser Kommunikationskanäle zu unterbinden, deren Nutzung nicht eindeutig einem authentifizierten Benutzer zugeordnet werden kann. Ohne eine Einschränkung der erreichbaren Gegenstellen – also der kontaktierbaren externen Domänen, Meeting-IDs oder Benutzerkonten – könnte ein Angreifer vertrauliche interne Besprechungen ausspähen oder ein unautorisierter Gast könnte von einem Konferenzraum aus sensible Daten per Bildschirmübertragung an externe Dritte weitergeben. Ohne eine solche Einschränkung könnte ein unberechtigter Nutzer auf Kosten der Institution kostenpflichtige Mehrwertdienste oder teure Auslandsnummern anwählen und so erheblichen finanziellen Schaden verursachen. Ebenso könnte eine missbräuchliche Nutzung zur Belästigung Dritter oder zur Absetzung von böswilligen Notrufen erfolgen, was die Verfügbarkeit kritischer Ressourcen beeinträchtigen könnte.</p></td></tr><tr valign="top"><td>KONF.11.7: Übersicht angemeldeter Verbindungen</td><td><p>Konfiguration für Anwendungen KANN eine Übersicht angemeldeter Verbindungen aktivieren.</p></td><td><p>Je nach Anwendung können dabei Informationen wie Gerätename, Betriebssystemtyp, Browser-Agent oder IP-Adresse angezeigt werden.</p></td></tr><tr valign="top"><td>KONF.11.8: Einschränkung von Schnittstellen</td><td><p>Konfiguration für Anwendungen SOLLTE aktivierte Schnittstellen einschließlich denen zu anderen Anwendungen, Cloud-Funktionen oder Erweiterungen einschränken.</p></td><td><p>Die Einschränkung von Schnittstellen hilft, ungewollte oder böswillige Zugriffe auf Anwendungen und Daten zu verhindern. Durch das Festlegen klarer Regeln welche Systeme oder Anwendungen über welche Schnittstellen auf welche Daten zugreifen können wir das <b>„Need to know“</b> Prinzip in der Kommunikation umgesetzt. Ferner kann ein solcher Ansatz dazu beitragen, die Integrität und Vertraulichkeit von Informationen zu wahren, indem nur autorisierte Kommunikationspartner berechtigt werden, Daten zu lesen, zu schreiben oder Funktionalitäten aufzurufen. Beispiele sind die Synchronisierung von Lesezeichen und Historie im Browser, die Anbindung von Cloud-Funktionen, etwa eine serverless Image-Processing-API, für die ein entsprechendes Rollenkonzept noch nicht hinterlegt und von der Sicherheitsverantwortlichen geprüft wurde, oder die Installation einer Browsererweiterungen. Erweiterungen (Plugins, AddOns), die nicht von der Institution für die Verwendung autorisiert wurden, können zu ungewollten Datenabflüssen führen und Schadcode enthalten. Zur Umsetzung kann es hilfreich sein, standardisierte Formulare oder digitale Workflows zu etablieren, in denen die Notwendigkeit, der Umfang und die Verantwortlichen für jede neue Schnittstelle dokumentiert werden. Die Einschränkung kann auch durch Komponenten außerhalb der Anwendung erfolgen, zum Beispiel durch API-Gateways, die nur auf Whitelists registrierter Endpunkte reagieren, oder durch Einsatz von Zertifikaten und OAuth-Scopes. Um unautorisierte Erweiterungen technisch zu unterbinden kann die Deinstallation oder Deaktivierung der Erweiterungen, sowie das Setzen von Berechtigungen zur Installation nur für Administrierende umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.11.8.1: Einschränkung von Zonentransfers</td><td><p>Konfiguration für DNS-Server SOLLTE Zonentransfers einschränken.</p></td><td><p>Zum Schutz vor DNS-Reconnaissance und DNS-Spoofing, da Zonendaten alle DNS-Einträger einer Domäne enthalten. Kann durch Einschränkung auf autorisierte IP-Adressen und TSIG umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.11.8.2: Einschränkung von TK-Verbindungen</td><td><p>Konfiguration für TK-Anwendungen SOLLTE unerwünschte TK-Verbindungen einschränken.</p></td><td><p>Kann durch Session Border Controller (SBC) oder Filterung innerhalb von Anwendungen umgesetzt werden. SBC filtern die Signalisierung und Mediastreams auf dem Kommunikationsweg, insbesondere beim Verbindungsaufbau mittels SIP, H.323 oder MGCP.</p></td></tr><tr valign="top"><td>KONF.11.8.2.1: Einschränkung der TK-Gegenstellen</td><td><p>Konfiguration für TK-Anwendungen SOLLTE Verbindungen mit externen Gegenstellen einschränken.</p></td><td><p>Telekommunikation mit externen Stellen ist essenziell für viele Geschäftsprozesse, aber auch beliebtes Ziel für Social Engineering und technische Angriffe. Kann z.B. durch eine Beschränkung auf europäische Rufnummernkreise oder den Ausschluss unerwünschter IP-Adressbereiche umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.11.9: Verschlüsselung schützenswerter Daten (at-rest)</td><td><p>Konfiguration für Anwendungen KANN schützenswerte Daten bei der Speicherung (at-rest) verschlüsseln.</p></td><td><p>Hierbei ist insbesondere an Zugangsdaten zu denken. Die Anforderung ist auch dann erfüllt, wenn Daten statt einer Verschlüsselung mit Hash und Salt versehen sind. Zur Umsetzung siehe BSI TR-02102.</p></td></tr></table><h2>KONF.12: Kontrollierte Datenverarbeitung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.12.1: Eingabevalidierung</td><td><p>Konfiguration für Anwendungen SOLLTE die Validierung von Eingabedaten durch <i>einen automatisierten Mechanismus</i> aktivieren.</p></td><td><p>Eingabevalidierung (engl. input validation) ist die technische und logische Überprüfung von Daten, die von Nutzenden, Schnittstellen oder externen Quellen an eine Anwendung übergeben werden. Ziel ist es, sicherzustellen, dass nur erwartete, syntaktisch und semantisch korrekte Eingaben verarbeitet werden – beispielsweise Zahlen in einem numerischen Feld, zulässige Dateiformate bei Uploads oder inhaltlich beschränkte Steuerzeichen in Formularen. Fehlende oder unzureichende Eingabevalidierung könnte es Angreifenden ermöglichen, schadhaften Code einzuschleusen (injection attacks wie SQL Injection oder Command Injection), Geschäftslogik zu manipulieren oder Systeme über Ressourcenmissbrauch lahmzulegen. Eine saubere Validierung kann dagegen die Angriffsfläche deutlich reduzieren und die Verlässlichkeit der Anwendung erhöhen. Dabei hängt die Ausgestaltung stark vom Einsatzzweck ab: Während etwa bei einer Textverarbeitung größere Freiheiten gewährt werden können, erfordern sensible Szenarien wie SQL-Injection bei Datenbankanfragen, die Abwehr von prompt injection bei Large Language Models (LLM) oder die Verarbeitung von Zahlungsdaten sehr strikte Prüfungen. Je nach Anwendung und Risikoprofil können Plausbilitätsprüfungen, die Beschränkung der Eingabedaten auf vordefinierte Werte, Verifikationen der Daten bei einer dritten Stelle (z.B. eines Zahlungsmittels beim Zahlungsanbieter), Regular Expression Entry Patterns, oder Data Escaping als Maßnahmen sinnvoll sein.</p></td></tr><tr valign="top"><td>KONF.12.1.1: Zertifikatsprüfung</td><td><p>Konfiguration für Webbrowser SOLLTE die automatische Validierung des Zertifikates einschließlich der vollständigen Zertifikatskette aktivieren.</p></td><td><p>Zertifikatsprüfung (Certificate Validation) ist eine Funktion, bei der ein Browser das digitale Zertifikat einer Webseite vor dem Verbindungsaufbau verifiziert. Dabei wird sichergestellt, dass das Zertifikat von einer vertrauenswürdigen Zertifizierungsstelle (CA - Certificate Authority) ausgestellt, gültig und nicht abgelaufen oder widerrufen ist. Dabei wird die vollständige Zertifikatskette, einschließlich des Root-Zertifikates verifiziert.  Ist das Zertifikat ungültig, so wird der Aufruf der Seite blockiert. Die korrekte Implementierung dieses Prozesses kann die Vertraulichkeit und Integrität der übertragenen Daten gewährleisten und schützt vor Man-in-the-Middle-Angriffen, bei denen Angreifer versuchen, den Datenverkehr abzufangen. Zur Umsetzung dieser Anforderung können Institutionen die zentrale Konfiguration von Browsern über Gruppenrichtlinien (Group Policies) oder Mobile Device Management (MDM)-Lösungen vornehmen.</p></td></tr><tr valign="top"><td>KONF.12.1.2: Content Security Policy (CSP)</td><td><p>Konfiguration für Webbrowser SOLLTE aufgerufene Inhalte anhand der von der Webseite bereitgestellten Content Security Policy einschränken.</p></td><td><p>Eine Content Security Policy (CSP) ist ein Sicherheitsmechanismus, der es einer Webseite erlaubt, dem Webbrowser mitzuteilen, von welchen Quellen er aktive Inhalte wie Skripte oder auch passive Inhalte wie Bilder laden darf. Durch diesen als Whitelist funktionierenden Ansatz kann die Institution die Angriffsfläche ihrer Webanwendungen erheblich reduzieren. Ohne eine wirksame CSP könnten Angreifer durch Cross-Site-Scripting-Angriffe (XSS) bösartige Skripte in eine Webseite einschleusen, die dann im Browser des Nutzers ausgeführt werden und beispielsweise sensible Daten auslesen oder Aktionen im Namen des Opfers durchführen könnten. Die Aktivierung einer CSP blockiert die Ausführung von nicht vertrauenswürdigen Skripten und das Laden unerwünschter Ressourcen und schützt somit die Integrität und Vertraulichkeit der Web-Sitzung.</p></td></tr><tr valign="top"><td>KONF.12.1.3: Same-Origin-Policy</td><td><p>Konfiguration für Webbrowser SOLLTE aufgerufene Inhalte anhand der von der Webseite bereitgestellten Same-Origin-Policy einschränken.</p></td><td><p>Die Same-Origin-Policy, oft auch als SOP bekannt, ist ein fundamentaler Sicherheitsmechanismus im Webbrowser, der sicherstellt, dass von einer Quelle (Origin) geladene Skripte oder Dokumente nicht mit Ressourcen einer anderen Quelle interagieren können, wobei eine Quelle durch die Kombination aus Protokoll, Hostname und Port definiert wird. Sinn und Zweck dieser strikten Trennung ist der Schutz vor Datenabfluss und unbefugten Interaktionen zwischen unterschiedlichen Webanwendungen innerhalb derselben Browsersitzung. Ohne diese Isolierung könnte eine schadhafte Webseite beispielsweise vertrauliche Informationen aus einer parallel geöffneten legitimen Anwendung, wie einem Online-Banking-Portal oder internen Firmentool, auslesen und an einen Angreifer senden. Die konsequente Durchsetzung der Same-Origin-Policy durch den Browser kann solche Cross-Site-Scripting-Angriffe (XSS) effektiv unterbinden und somit die Vertraulichkeit und Integrität der vom Nutzer verarbeiteten Daten gewährleisten.</p></td></tr><tr valign="top"><td>KONF.12.1.4: Subresource Integrity-Prüfung</td><td><p>Konfiguration für Webbrowser SOLLTE aufgerufene Inhalte anhand der von der Webseite bereitgestellten Subresource Integrity-Prüfung einschränken.</p></td><td><p>Unter Subresource Integrity (SRI), zu Deutsch etwa „Integrität von Unterressourcen“, versteht man einen Sicherheitsmechanismus von Webbrowsern, der sicherstellt, dass die vom Browser geladenen Ressourcen, wie z.B. JavaScript-Dateien oder CSS-Stylesheets, die von einem Drittanbieter (etwa einem Content Delivery Network, CDN) stammen, nicht unerwünscht manipuliert wurden. Technisch geschieht dies dadurch, dass die Webseite beim Einbinden der Ressource einen kryptografischen Hashwert (oder Digest) der erwarteten Datei als Attribut (z.B. integrity=<b>„...“</b>) mitsendet. Der Webbrowser kann dann nach dem Herunterladen der Ressource diesen Hashwert neu berechnen und mit dem bereitgestellten Wert vergleichen. Dies ist notwendig, da die Institution zwar die eigene Webseite kontrolliert, aber nicht die Server Dritter, von denen oft Bibliotheken geladen werden. Der Sinn und Zweck dieser Vorschrift liegt darin, die Sicherheit der Endnutzer zu erhöhen und Risiken durch manipulierte externe Inhalte zu minimieren. Ohne diese Prüfung könnte eine kompromittierte Drittanbieter-Ressource bösen Code in die Webseite der Institution einschleusen, was zu Vorfällen wie Datendiebstahl oder der Installation von Malware auf den Geräten der Nutzer führen könnte.</p></td></tr><tr valign="top"><td>KONF.12.1.5: HTTP Strict Transport Security (HSTS)</td><td><p>Konfiguration für Webbrowser SOLLTE aufgerufene Inhalte anhand der von der Webseite bereitgestellten  HTTP Strict Transport Security (HSTS) Richtlinie einschränken.</p></td><td><p>Die HTTP Strict Transport Security (HSTS) ist ein Web-Sicherheitsmechanismus – definiert in IETF RFC 6797 – der Webbrowser zwingt, eine ausschließlich verschlüsselte Verbindung (HTTPS) mit einem Webserver zu nutzen, selbst wenn der Nutzer oder eine Anwendung versucht, über das unsichere HTTP zuzugreifen. Konkret beinhaltet die HSTS-Richtlinie (oder Policy) einen speziellen HTTP-Antwort-Header, den der Webserver an den Browser sendet, der die Dauer (max-age) festlegt, für die der Browser die Verbindung nur über HTTPS herstellen soll. Die restriktive Konfiguration von Webbrowsern in Bezug auf diese Richtlinie kann die Schutzwirkung erhöhen, da so das Risiko eines Man-in-the-Middle (MITM)-Angriffs, bei dem ein Angreifer eine unverschlüsselte Verbindung abfangen oder den Nutzer auf eine unsichere Seite umleiten könnte, deutlich reduziert wird. Eine solche Konfiguration kann die Institution vor dem ungewollten Downgrade-Angriff (Downgrade Attack) schützen, bei dem die Verbindung von HTTPS auf das unsichere HTTP erzwungen wird.</p></td></tr><tr valign="top"><td>KONF.12.1.6: JavaScript</td><td><p>Konfiguration für Webbrowser KANN JavaScript einschränken.</p></td><td><p>Schadcode in JavaScript kann unbefugt auf sensible Daten zugreifen oder die angezeigte Webseite manipulieren. Da viele Webseiten JavaScript zur Ausführung benötigen, ist die Deaktivierung von JavaScript mit erheblichen funktionalen Einschränkungen verbunden. Ein möglicher Kompromiss ist, dass Administrierende oder Nutzende Ausnahmen für einzelne Seiten hinzufügen können.</p></td></tr><tr valign="top"><td>KONF.12.1.7: Filtern schädlicher Webinhalte</td><td><p>Konfiguration für Webanwendungen SOLLTE eine Filterung schädlicher Webinhalte aktivieren.</p></td><td><p>Anfragen an Webanwendungen könnten dazu führen, dass diese sich anders verhalten als gewollt. Mögliche Folgen sind die unzulässige Preisgabe von Informationen, die Manipulation oder der Verlust von Daten sowie Betriebsstörungen. Typische Auslöser sind SQL Injection oder Cross-Site-Scripting. Solche potenziell schädlich wirkenden Inhalte können durch eine Web Application Firewall oder durch geeignete Eingabevalidierung in der Webanwendung gefiltert werden.</p></td></tr><tr valign="top"><td>KONF.12.1.8: Duplikate im Verzeichnisbaum</td><td><p>Konfiguration für Verzeichnisdienste SOLLTE Duplikate im Verzeichnisbaum blockieren.</p></td><td><p>Da jedes Zugangskonto nur einmal benötigt wird können Duplikate von Attributen wie Name oder Organisationseinheit nur als Fehler oder Angriff vorkommen. In OpenLDAP kann dies beispielsweise durch Overlays realisiert werden. Dies gilt ausschließlich für Daten von Nutzenden.</p></td></tr><tr valign="top"><td>KONF.12.1.9: Journaling</td><td><p>Konfiguration für Dateiserver SOLLTE Journaling aktivieren.</p></td><td><p>Beim Journaling werden Änderungen an Dateien zunächst in einem speziellen Protokoll (Journal) aufgezeichnet, bevor sie tatsächlich geschrieben werden, um Datenintegrität und Konsistenz sicherzustellen. Auf einem Dateiserver ist dies besonders wichtig, da es das Risiko von Datenverlusten bei plötzlichen Abstürzen oder Stromausfällen minimiert und eine schnelle Wiederherstellung ermöglicht.</p></td></tr><tr valign="top"><td>KONF.12.1.10: HTTP-Response-Header</td><td><p>Konfiguration für Webanwendungen SOLLTE HTTP-Response-Header aktivieren.</p></td><td><p>Hierzu können z.B. Content-Security-Policy (CSP), X-Frame-Options, X-XSS-Protection, Referrer-Policy, Permissions-Policy, HSTS und X-Content-Type-Optionen gehören.</p></td></tr><tr valign="top"><td>KONF.12.1.11: Aktive Inhalte</td><td><p>Konfiguration für Office-Anwendungen SOLLTE Aktive Inhalte deaktivieren.</p></td><td><p>Aktive Inhalte (Makros) in Office-Dokumenten können Schadcode enthalten oder zu nicht nachvollziehbaren Datenfehlern führen. Viele Nutzende verwenden solche Funktionen jedoch für ihre Arbeit, so dass eine generelle Sperrung mit Einschränkungen verbunden ist. Autorisierte Ausnahmen bilden daher einen guten Kompromiss bei normalen Schutzbedarf. Dies kann durch den geschützten Modus (Protected View) umgesetzt werden. Werden bestimmte Makros dennoch häufig benötigt, so können Makros mit digitaler Signatur einer anerkannten Zertifizierungsstelle oder von vertrauenswürdigen Speicherorten zugelassen werden.</p></td></tr><tr valign="top"><td>KONF.12.2: Verschlüsselungsstatus der aktuellen Verbindung</td><td><p>Konfiguration für Webbrowser SOLLTE eine Anzeige der Verschlüsselung der aktuellen Verbindung aktivieren.</p></td><td><p>Die Anzeige der Verschlüsselung der aktuellen Verbindung im Webbrowser, auch bekannt als Connection Encryption Indicator oder oft durch ein 🔒-Symbol dargestellt, ist ein essenzielles Merkmal für die Wahrnehmung der Vertrauenswürdigkeit einer Online-Kommunikation. Sie visualisiert, ob die Datenübertragung zwischen dem Browser des Benutzers und dem Webserver mittels eines kryptografischen Protokolls, typischerweise Transport Layer Security (TLS) (früher Secure Sockets Layer (SSL)), abgesichert ist. Diese Vorschrift zielt darauf ab, das Risiko des Abhörens von Daten durch Dritte (Eavesdropping) zu minimieren; denn ohne diese Anzeige könnte ein Benutzer unbemerkt sensible Informationen über eine ungesicherte Verbindung eingeben, was beispielsweise zur Kompromittierung von Anmeldedaten oder vertraulichen Geschäftsinformationen führen könnte.</p></td></tr><tr valign="top"><td>KONF.12.3: Cookies</td><td><p>Konfiguration für Webbrowser SOLLTE Cookies einschränken.</p></td><td><p>Cookies sind Dateien, in denen Webseiten Daten auf dem System speichern. Sie können Authentifizierungstoken und andere personenbezogene Daten enthalten und durch Angriffe wie Cross-Site-Scripting (XSS) oder Session Hijacking kompromittiert werden. Die Speicherung von Cookies per Default auszuschalten könnte jedoch zu Funktionseinschränkungen führen. Nutzende oder Administrierende können Ausnahmen für bestimme Webseiten, z.B. im Intranet, hinzufügen.</p></td></tr><tr valign="top"><td>KONF.12.4: Speicherung von Zugangsdaten</td><td><p>Konfiguration für Webbrowser SOLLTE eine geschützte Speicherung von Zugangsdaten aktivieren.</p></td><td><p>Werden Zugangsdaten gespeichert, so könnten Angreifer diese auslesen und missbrauchen. Daher ist es wichtig, Vertraulichkeit und Integrität sensibler Anmeldedaten zu gewährleisten. Durch die Nutzung einer geprüften Browser‑Extension kann sichergestellt werden, dass Passwörter nur in einem verschlüsselten Vault abgelegt werden, der zentral verwaltet oder versioniert wird. Ein starkes Master‑Passwort kann als Schlüssel dienen, sodass selbst bei Verlust des Geräts oder unautorisiertem Zugriff auf die lokale Datenbank die Daten ohne Kenntnis dieses Passworts nicht lesbar sind. Wird die Funktion komplett deaktiviert, kann das Risiko unkontrollierter Speicherung oder unsicherer Autovervollständigung minimiert werden – der Anwender kann sich stattdessen etwa auf einen externen Manager oder eine Single‑Sign‑On‑Lösung verlassen. Konkret kann dies in der Praxis auf verschiedene Weisen aussehen: So kann eine Institution über Gruppenrichtlinien festlegen, dass nur eine offiziell freigegebene Extension (etwa einer Open‑Source‑Lösung oder eines kommerziellen Anbieters) installiert werden darf. Alternativ lassen sich browserinterne Passwort‑Speicher mit einem Master‑Passwort verschlüsseln – denkbar ist hier sowohl die Nutzung integrierter Funktionen von Browsern mit zuverlässiger Krypto‑Engine als auch externer Tools wie plattformübergreifende Passwort‑Manager, die eine Browser‑Anbindung per Plugin bieten. In Szenarien mit besonders hohen Sicherheitsanforderungen kann die Speicherung ganz deaktiviert werden, etwa indem das entsprechende Feature per Policy abgeschaltet wird und Nutzer gezielt mit einem eigenständigen, von der Institution kontrollierten Tool arbeiten. Für die Umsetzung bietet es sich an, zunächst eine klare Richtlinie zu formulieren, die alle Mitarbeitenden über die zugelassenen Speicherwege informiert und gleichzeitig erklärt, warum unautorisierte Methoden unerwünscht sein können. IT‑Administratoren können über zentrale Management‑Werkzeuge (GPOs, MDM‑Systeme) die Installation autorisierter Extensions automatisieren und unerwünschte Funktionen deaktivieren. Es kann hilfreich sein, standardisierte Vorlagen für sichere Master‑Passwörter zu kommunizieren und regelmäßige Schulungen anzubieten, in denen der Umgang mit dem Passwort‑Manager, das Prüfen der Passwortstärke und das Einspielen von Updates erklärt werden. Schließlich kann eine optionale Passwort‑Auditing‑Funktion im Manager eingesetzt werden, mit der Nutzer Schwachstellen in ihren Passwörtern erkennen und verbessern können – so bleibt die gesamte Passwortlandschaft im Unternehmen übersichtlich und sicher.</p></td></tr><tr valign="top"><td>KONF.12.5: Auto-Vervollständigung von Daten</td><td><p>Konfiguration für Webbrowser SOLLTE die Auto-Vervollständigung von Daten einschränken.</p></td><td><p>Webseiten können Eingaben auch auslesen, bevor diese abgesendet werden. Die Deaktivierung der Auto-Vervollständigung verhindert, dass der Browser diese Daten automatisch eingibt.</p></td></tr><tr valign="top"><td>KONF.12.6: Browser-Historie</td><td><p>Konfiguration für Webbrowser KANN die dauerhafte Browser-Historie deaktivieren.</p></td><td><p>Kann durch das Löschen der Historie beim Beenden oder durch Deaktivierung der Historie umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.12.7: Erweiterte Attribute</td><td><p>Konfiguration für Dateiserver SOLLTE Erweiterte Attribute aktivieren.</p></td><td><p>Erweiterte Attribute ermöglichen die Speicherung von Metadaten zu Dateien zur Speicherung von Zugriffsrechten und Statusindikatoren. Kann unter Linux durch Samba mit Extended Attributes und unter Windows durch Nutzung des NTFS-Dateisystems umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.12.8: Teilnahme per Default ohne Bild und Ton</td><td><p>Konfiguration für VK-Anwendungen SOLLTE Bild und Ton per Default deaktivieren.</p></td><td><p>Eine Konfiguration, bei der die Standardeinstellung (per default) für Bild und Ton deaktiviert ist, bedeutet, dass Nutzerinnen und Nutzer die Videokonferenz-Anwendungen (VK-Anwendungen) betreten, ohne dass ihre Kamera und ihr Mikrofon automatisch eingeschaltet sind.  Diese Voreinstellung minimiert das Risiko, dass sensible oder private Informationen unbeabsichtigt geteilt werden. Einem Vorfall, bei dem vertrauliche Gespräche im Hintergrund unfreiwillig übertragen werden, könnte so effektiv vorgebeugt werden. Die Institution kann dadurch das Risiko unbeabsichtigter Datenexposition minimieren, indem die Kontrolle über die Aktivierung von Bild und Ton explizit bei den Nutzenden bleibt. Um diese Anforderung umzusetzen, kann die Institution die technischen Einstellungen in der Verwaltungs- oder Admin-Konsole der jeweiligen Anwendung anpassen, um die Standardwerte für alle Teilnehmenden zu ändern. Ebenfalls kann eine technische Richtlinie implementiert werden, die sicherstellt, dass die Applikation vor dem Start eines Meetings eine Checkliste anzeigt, die die Nutzenden explizit auffordert, Kamera und Mikrofon bewusst zu aktivieren.</p></td></tr><tr valign="top"><td>KONF.12.9: Information über Aufzeichnung</td><td><p>Konfiguration für VK-Anwendungen SOLLTE eine Anzeige laufender Aufzeichnungen aktivieren.</p></td><td><p>Heimliche Aufzeichnungen verletzen die Vertraulichkeit der Kommunikation. Eine Aufzeichnung von Wort und Bild ohne den Willen der Aufgezeichneten kann zudem eine Persönlichkeitsrechtsverletzung bis hin zur Straftat (§ 201 StGB) darstellen. Dies gilt auch für Aufzeichnungen, die KI-gestützt ausgewertet werden.</p></td></tr><tr valign="top"><td>KONF.12.10: Cookie-Attribute</td><td><p>Konfiguration für Webanwendungen SOLLTE Cookie-Attribute aktivieren.</p></td><td><p><b>„Secure“</b> erzwingt die verschlüsselte HTTPS-Übertragung, wodurch Man-in-the-middle-Angriffe verhindert werden. <b>„Samesite“</b> sorgt dafür, dass Cookies nur zurückgesendet werden, wenn die Anfrage von der ursprünglichen Seite stammt. Hierdurch werden Cross-Site Request Forgery Angriffe erschwert. <b>„HttpOnly“</b> verbietet es Client-seitigen Skripten auf das Cookie zuzugreifen, wodurch Cross-Site Scripting (XSS) erschwert wird.</p></td></tr><tr valign="top"><td>KONF.12.11: Anonyme oder Pseudonyme Kommunikation</td><td><p>Konfiguration für TK-Anwendungen KANN Anonyme oder Pseudonyme Kommunikation aktivieren.</p></td><td><p>Wenn eine persönliche Identifikation von Kommunikationspartnern erforderlich ist, ist eine Verschleierung von Erreichbarkeiten sinnvoll. In der klassischen Telefonie kann hierfür die Rufnummerunterdrückung für ausgehende Anrufe (CLIR) oder eine Pseudonymisierung, z.B. durch Übermittlung der 0 statt der Nebenstelle, genutzt werden. Für die Verschleierung der Netzquelle können Proxy-Server oder Anonymisierungsgateways genutzt werden. Für weitere Details siehe <b>„Kompendium für organisationsinterne Telekommunikationssysteme mit erhöhtem Schutzbedarf“</b>.</p></td></tr><tr valign="top"><td>KONF.12.12: Verbindungsprotokoll</td><td><p>Konfiguration für TK-Anwendungen SOLLTE ein für Nutzende verfügbares Verbindungsprotokoll protokollieren.</p></td><td><p>Ein solches Protokoll, oft auch als Call Detail Record (CDR) oder Connection Log bezeichnet, dokumentiert für Nutzende nachvollziehbar die Kommunikationsverbindungen, die sie über die Anwendung herstellen. Das Protokoll könnte dabei erfassen, wann eine Verbindung aufgebaut wurde, wie lange sie bestand, mit wem sie stattfand (z.B. die Rufnummer oder der Benutzername der Gegenstelle) und aus welcher Richtung (ein- oder ausgehend) sie kam. In der klassischen Telefonie ist dies die Auflistung der zuletzt ein- oder ausgehenden Anrufe. Eine solche Protokollierung kann als wichtige Maßnahme der Rechenschaftspflicht oder Accountability dienen. Durch die lückenlose Protokollierung der Aktivitäten der Nutzenden kann transparent nachvollzogen werden, welche Verbindungen zu welchem Zeitpunkt hergestellt wurden. Dies kann dabei helfen, ungewöhnliche oder nicht autorisierte Kommunikationsversuche zu erkennen und die Integrität der genutzten Systeme zu wahren. Ohne ein solches Protokoll könnte eine unberechtigte Nutzung oder ein Datenabfluss aus dem internen Netzwerk unentdeckt bleiben. Hierbei besteht ein enger Zusammenhang mit Compliance-Verpflichtungen zur Aufbewahrung und Löschung von Telekommunikationsdaten.</p></td></tr><tr valign="top"><td>KONF.12.13: Sendebericht</td><td><p>Konfiguration für Faxe SOLLTE einen Sendebericht protokollieren.</p></td><td><p>Ein Sendebericht ermöglicht es bei der Verwendung von Faxen nachzuweisen, dass das Fax tatsächlich an die Gegenstelle versendet wurde. Für einen rechtssicheren Nachweis ist es sinnvoll, wenn der Sendebericht außerdem weitere Angaben wie die versendete Seitenzahl, eine Vorschau der ersten Seite odes des gesamten Inhaltes, sowie den Status mit dem die Verbindung beendet wurde (z.B. OK) beinhaltet.</p></td></tr><tr valign="top"><td>KONF.12.14: DNS-Falschinformationen</td><td><p>Konfiguration für DNS-Server SOLLTE DNS-Antworten, die falsche Domain-Informationen liefern, deaktivieren.</p></td><td><p>Falsch sind Domain-Informationen, wenn sie nicht der tatsächlichen Erreichbarkeit des Zieles entsprechen, sondern z.B. auf Werbeseiten umleiten. DNS-Server, die falsche Antworten liefern, können zu unerwarteten Fehlern in Anwendungen oder zum DNS-Hijacking führen. Sie sind an unerwarteten Websites, Zertifikatsfehlern oder mit DNS-Prüfsoftware zu erkennen. Gilt sowohl für die Konfiguration des eigenen Servers, als auch für die verwendeten DNS Upstream Server.</p></td></tr></table><h2>KONF.13: Senden und Empfangen von Nachrichten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.13.1: Filtern schädlicher Nachrichten</td><td><p>Konfiguration für Interpersonelle Kommunikation SOLLTE eine Filterung schädlicher Nachrichteninhalte aktivieren.</p></td><td><p>Unter Filterung schädlicher Nachrichteninhalte versteht man Verfahren, die Inhalte automatisch prüfen und unerwünschte, gefährliche oder manipulative Bestandteile erkennen, blockieren oder kennzeichnen können. Der Sinn dieser Vorgabe liegt darin, potenziell gefährliche Inhalte wie Phishing-Versuche, schadhaften Code oder gezielte Desinformation frühzeitig abzufangen. Ohne eine solche Filterung könnte Schadsoftware über Anhänge eingeschleust werden oder Mitarbeitende könnten durch manipulierte Links zu vertraulichen Datenabgaben verleitet werden. Mit einer wirksamen Filterung kann die Angriffsfläche reduziert, das Vertrauen in die Kommunikationskanäle erhöht und die Produktivität geschützt werden. Zur Umsetzung kann eine Institution technische Maßnahmen kombinieren: (1) E-Mail-Gateways oder Chat-Schnittstellen können mit Inhaltsfiltern ausgestattet werden, die bekannte Malware-Signaturen, verdächtige Links oder gefährliche Dateitypen erkennen. (2) Ergänzend kann heuristische Analyse und maschinelles Lernen eingesetzt werden, um Muster verdächtiger Inhalte zu identifizieren, auch wenn diese noch nicht in Signaturdatenbanken enthalten sind. (3) Regeln zur Blockierung bestimmter Dateianhänge (z. B. ausführbare Dateien) können eingerichtet werden, während sichere Alternativen für den Austausch bereitgestellt werden. (4) Schließlich kann ein klarer Prozess vorgesehen werden, um falsch-positive Erkennungen manuell zu prüfen und legitime Kommunikation wieder freizugeben.</p></td></tr><tr valign="top"><td>KONF.13.1.1: SPAM-Filter</td><td><p>Konfiguration für Interpersonelle Kommunikation SOLLTE die Zustellung unerwünschter Nachrichten blockieren.</p></td><td><p>Unter Zustellung unerwünschter Nachrichten ist das Blockieren oder Filtern von Spam, Phishing-Versuchen, Social-Engineering-Nachrichten oder belästigender Kommunikation zu verstehen. Diese Anforderung zielt darauf ab, die Integrität der Kommunikationskanäle zu wahren und das Risiko von Sicherheits- oder Vertrauensbrüchen zu reduzieren. Ohne geeignete Filtermechanismen könnte Schadsoftware per Anhang eingeschleust werden, sensible Informationen könnten durch täuschend echte Phishing-Nachrichten abgegriffen werden oder Mitarbeitende könnten durch gezielte Belästigungen in ihrer Arbeitsfähigkeit eingeschränkt werden. Zur Umsetzung kann eine Institution verschiedene Ansätze kombinieren: (1) Der Einsatz serverseitiger Filtermechanismen auf Mail-Gateways oder Collaboration-Plattformen kann zentral die meisten unerwünschten Nachrichten aussortieren. (2) Ergänzend können clientseitige Filterregeln aktiviert werden, die Benutzern zusätzliche Möglichkeiten zur Sortierung bieten, etwa über Whitelists und Blacklists. Praktisch kann es auch hilfreich sein, Quarantäneordner einzurichten, damit Anwender verdächtige Nachrichten selbständig einsehen und fälschlich blockierte Nachrichten zurückholen können.</p></td></tr><tr valign="top"><td>KONF.13.1.2: Interpretation aktiver Inhalte</td><td><p>Konfiguration für Interpersonelle Kommunikation SOLLTE die automatische Interpretation aktiver Inhalte deaktivieren.</p></td><td><p>Unter aktiven Inhalten sind hier Elemente zu verstehen, die beim Empfang automatisch ausgeführt oder interpretiert werden könnten, wie z. B. eingebettete Skripte in E-Mails, dynamische Makros in Dokumenten oder der automatische Download von externen Bildern in Chat-Nachrichten. Hintergrund ist, dass eine empfangene Nachricht nicht nur reinen Text oder statische Informationen enthalten könnte, sondern zusätzliche versteckte Anweisungen, die beim Anzeigen sofort wirken. Ein typischer Vorfall könnte etwa sein, dass eine Mitarbeiterin eine HTML-E-Mail öffnet, die ein eingebettetes JavaScript enthält und dadurch unbemerkt Zugangsdaten abgegriffen werden. Durch Deaktivieren solcher Inhalte wird verhindert, dass Schadcode automatisch ausgeführt wird. Betrifft sowohl Inhalte in Freitext-Datenfeldern, als auch an die Nachricht angehängt Dateien. Beispielsweise kann in Mail-Clients die Ausführung von Makros deaktiviert, die Darstellung externer Inhalte blockiert oder das Rendern von Skripten untersagt werden. Ebenso kann bei Messaging-Diensten die Anzeige von aktiven Inhalten durch Filter eingeschränkt werden, sodass nur reiner Text oder geprüfte Anhänge angezeigt werden. Ergänzend kann es hilfreich sein, benutzerseitige Tipps wie das standardmäßige Verwenden einer Nur-Text-Ansicht oder die klare Kennzeichnung von blockierten Inhalten zu etablieren. Institutionen können durch regelmäßige Konfigurationsprüfungen sicherstellen, dass Änderungen durch Updates oder neue Versionen die Deaktivierung nicht unbemerkt wieder aufheben.</p></td></tr><tr valign="top"><td>KONF.13.2: Authentizität von Nachrichten</td><td><p>Konfiguration für Interpersonelle Kommunikation SOLLTE eine automatische Verifikation der Authentizität von Nachrichten aktivieren.</p></td><td><p>Die Authentizität von Nachrichten bezeichnet in diesem Zusammenhang die nachweisbare Echtheit und Unverfälschtheit einer digitalen Mitteilung im Rahmen der interpersonellen Kommunikation, also die Sicherheit, dass eine Nachricht tatsächlich von der angegebenen Quelle stammt und auf dem Übertragungsweg nicht manipuliert wurde. Im Fachjargon wird hier häufig von Message Authenticity oder auch von Origin Authentication gesprochen, wobei beide Begriffe eng mit kryptographischen Verfahren wie Digital Signatures oder Message Authentication Codes (MACs) verbunden sind. Der Sinn dieser Anforderung liegt darin, sicherzustellen, dass Angreifer keine falschen Identitäten vortäuschen oder den Inhalt von Nachrichten unbemerkt verändern können. Andernfalls könnte etwa eine gefälschte Anweisung in einem Chat zu Fehlhandlungen führen oder ein manipuliertes Dokument im E-Mail-Verkehr falsche Entscheidungen auslösen; mit automatischer Verifikation kann hingegen das Vertrauen in die Integrität und Herkunft von Kommunikation gewährleistet werden. Zur Umsetzung kann eine Institution beispielsweise digitale Signaturen einsetzen, die durch etablierte Standards wie S/MIME oder OpenPGP realisiert werden können, sodass E-Mail-Programme die Echtheit automatisch überprüfen. Auch der Einsatz von Ende-zu-Ende-Verschlüsselung mit eingebauter Authentizitätsprüfung, etwa bei Protokollen wie Signal Protocol oder TLS mit Client-Zertifikaten, kann eine geeignete Maßnahme sein. Darüber hinaus kann die Integration einer zentralen Public Key Infrastructure (PKI) oder die Nutzung verteilter Vertrauensmodelle (z. B. Web of Trust) sicherstellen, dass Schlüsselpaare zuverlässig verwaltet werden und Anwender ohne manuelle Prüfungen von Zertifikaten auskommen.</p></td></tr><tr valign="top"><td>KONF.13.2.1: Verifikation der Sendeberechtigung</td><td><p>Konfiguration für E-Mail SOLLTE eine automatische Verifikation der Sendeberechtigung aktivieren.</p></td><td><p>Mit dem Sender Policy Framework (SPF) kann geprüft werden, ob der Sender zum Versand von E-Mails für diese Mailadresse berechtigt war. E-Mails ohne SPF-Header sind unzureichend authentifiziert, so dass sie leicht für Spoofing oder Phishing missbraucht werden können. Allerdings werden noch immer E-Mails ohne SPF verschickt, so dass eine Blockierung zu funktionalen Einschränkungen führen könnte. Kompromissmaßnahmen können z.B. die Markierung der E-Mail mit einem Warnhinweis , Allowlisting, Greylisting, Quarantäne oder eine Filterung durch Anomalieerkennung sein.</p></td></tr><tr valign="top"><td>KONF.13.2.2: Verifikation der Serversignatur</td><td><p>Konfiguration für E-Mail SOLLTE die Serversignatur eingehender E-Mails automatisch authentifizieren.</p></td><td><p>Die DKIM-Signatur ist zu unterscheiden von einer PGP-Signatur, die in der Regel nicht automatisch vergeben wird.  E-Mails ohne DKIM sind unzureichend authentifiziert, so dass sie leicht für Spoofing oder Phishing missbraucht werden können. Allerdings werden noch immer E-Mails ohne DKIM verschickt, so dass eine Blockierung zu funktionalen Einschränkungen führen könnte. Kompromissmaßnahmen können z.B. die Markierung der E-Mail mit einem Warnhinweis , Allowlisting, Greylisting, Quarantäne oder eine Filterung durch Anomalieerkennung sein. Die Formulierung <b>„im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik IDM festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>KONF.13.3: Kryptographische Signatur des Mailservers</td><td><p>Konfiguration für E-Mail SOLLTE die Kryptographische Signatur des Mailservers aktivieren.</p></td><td><p>Die kryptographischen Signatur des Mailservers ist ein digitaler Stempel des versendenden Mailservers selbst, mit dem die Authentizität des sendenden Mailservers belegt wird. Ein bekannter technischer Standard hierfür ist DomainKeys Identified Mail (DKIM). Diese Signatur wird durch den absendenden Mailserver (oder einen vorgeschalteten Dienst) unter Verwendung eines privaten kryptographischen Schlüssels erzeugt. Der Empfänger kann die Signatur mit einem öffentlich zugänglichen Schlüssel, der typischerweise im Domain Name System (DNS) der sendenden Domain hinterlegt ist, verifizieren. Diese Schutzmaßnahme kann die Glaubwürdigkeit der E-Mails erhöhen und trägt zur Prävention von Risiken bei, wie dem Spoofing des Absenders: Ein Angreifer könnte ohne eine solche Signatur die Identität der Institution vortäuschen, was zu Phishing-Vorfällen führen könnte.</p></td></tr><tr valign="top"><td>KONF.13.4: Kryptographische Signatur durch Nutzende</td><td><p>Konfiguration für E-Mail KANN die kryptographische Signatur durch Nutzende aktivieren.</p></td><td><p>Wird eine vom E-Mail vom Sendenden signiert, so können bei Empfang die Authentizität und Integrität der Nachricht verifiziert werden. Dies kann mit S/MIME oder PGP umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.13.5: Publikation der Sendeberechtigung</td><td><p>Konfiguration für E-Mail SOLLTE die Publikation der eigenen Sendeberechtigung im DNS aktivieren.</p></td><td><p>Dies wird typischerweise über spezielle DNS-Einträge wie den Sender Policy Framework (SPF) realisiert. Damit kann eine Institution im DNS festlegen, welche Mail-Server berechtigt sind, E-Mails im Namen ihrer Domäne zu versenden. Ein entsprechender DNS-Eintrag, der sogenannte SPF-Record, ermöglicht es empfangenden Mail-Servern, die Absender-Adresse einer eingehenden E-Mail zu überprüfen. Dies kann die Schutzwirkung gegen gängige Risiken wie E-Mail-Spoofing verbessern, bei dem sich ein Angreifer als legitimer Absender ausgibt, um die Empfänger zu täuschen. Ohne eine solche Konfiguration könnte ein Angreifer beispielsweise E-Mails mit gefälschter Absenderadresse verschicken, die scheinbar von der Geschäftsleitung stammen, um einen Nutzer zur Herausgabe von sensiblen Informationen zu verleiten (Phishing). Durch die Aktivierung von SPF kann das Risiko verringert werden, dass solche bösartigen Nachrichten die Postfächer von Nutzern erreichen. Es ist wichtig, den Eintrag sorgfältig zu erstellen, um alle legitimen Absender abzudecken, einschließlich Diensten von Drittanbietern. Ein häufiger Fehler ist, dass nicht alle autorisierten Mail-Server korrekt gelistet sind, was dazu führen könnte, dass legitime E-Mails fälschlicherweise als Spam markiert werden.</p></td></tr><tr valign="top"><td>KONF.13.5.1: Strenge Senderpolicy</td><td><p>Konfiguration für E-Mail SOLLTE eine strenge Senderpolicy aktivieren.</p></td><td><p>Ein strenger Senderpolicy-Eintrag, auch <b>„hard fail“</b> (-all) genannt, weist empfangende Mailserver an, E-Mails, die von nicht autorisierten Servern stammen, zurückzuweisen oder als Spam zu markieren. Dies kann das Risiko von Phishing-Angriffen erheblich reduzieren, bei denen Angreifer versuchen, sich als vertrauenswürdige Institutionen auszugeben. Eine solche Konfiguration kann auch Spoofing verhindern, bei dem die Absenderadresse gefälscht wird, was dazu führen könnte, dass Kunden oder Mitarbeiter betrügerischen Anweisungen folgen, die scheinbar von der Institution selbst stammen. Zur Umsetzung einer strengen Senderpolicy kann die Institution sicherstellen, dass sie einen SPF-Eintrag in ihren DNS-Einstellungen hinterlegt. Dieser Eintrag sollte alle autorisierten Server explizit auflisten und mit dem <b>„-all“</b> Mechanismus enden, um eine strikte Ablehnung nicht konformer E-Mails zu signalisieren.</p></td></tr><tr valign="top"><td>KONF.13.6: Publikation der Serversignatur</td><td><p>Konfiguration für E-Mail SOLLTE die Publikation der Serversignatur im DNS aktivieren.</p></td><td><p>Eine Serversignatur, auch bekannt als DKIM (DomainKeys Identified Mail), ist eine kryptografische Signatur, die der E-Mail-Dienst der Institution an jede ausgehende Nachricht anhängt. Sie stellt sicher, dass die E-Mail tatsächlich von der angegebenen Domain gesendet wurde und während der Übertragung nicht manipuliert wurde. Ohne diese Signatur könnte ein Angreifer E-Mails im Namen der Institution versenden (E-Mail-Spoofing), was zu Phishing-Angriffen, dem Diebstahl von Zugangsdaten oder der Verbreitung von Malware führen könnte. Das Aktivieren der Publikation im DNS bedeutet, den öffentlichen Teil dieses kryptografischen Schlüssels im Domain Name System (DNS) der Domain zu veröffentlichen. Empfangende E-Mail-Server können diesen öffentlichen Schlüssel verwenden, um die Signatur der E-Mail zu verifizieren und somit deren Echtheit zu bestätigen. Zur Umsetzung kann die Institution E-Mail-Server-Software so konfigurieren, dass sie DKIM-Signaturen automatisch zu ausgehenden Nachrichten hinzufügt. Dies kann oft durch die Installation und Konfiguration von speziellen DKIM-Filter-Plugins erreicht werden.</p></td></tr><tr valign="top"><td>KONF.13.7: TLS-Reports</td><td><p>Konfiguration für E-Mail KANN TLS-Reports <i>regelmäßig</i> überprüfen.</p></td><td><p>TLS-Reports, auch TLS-RPT (Transport Layer Security Reporting) genannt, sind Berichte, mit denen Betreiber von Mailservern einander Probleme beim E-Mail-Versand über TLS melden können. Sie können Informationen zu Verbindungsproblemen und möglichen Sicherheitsproblemen enthalten. Hierzu kann TLS-RPT (Transport Layer Security Reporting) genutzt werden.</p></td></tr><tr valign="top"><td>KONF.13.8: DMARC-Reports</td><td><p>Konfiguration für E-Mail KANN DMARC-Reports <i>regelmäßig oder bei Eingang</i> überprüfen.</p></td><td><p>Mit DMARC kann der Empfänger dem Sender einen automatischen Bericht über den DMARC-Status empfangener Mails zukommen lassen. Prüfen Sie diese Berichte automatisiert auf Fehlermeldungen und Zustellprobleme und ergreifen Sie bei Problemen Korrekturmaßnahmen.</p></td></tr><tr valign="top"><td>KONF.13.9: Publikation der DMARC-Richtlinie</td><td><p>Konfiguration für E-Mail SOLLTE die Publikation der DMARC-Richtlinie aktivieren.</p></td><td><p>Eine DMARC-Richtlinie legt fest, welchen Umgang sie sich von Empfängern wünschen, die E-Mails von ihrer Domain nicht authentifizieren können. Die Information der Empfänger kann über einen DMARC-Eintrag im DNS erfolgen.</p></td></tr><tr valign="top"><td>KONF.13.10: Authentifizierung der Server-Zertifikate über DNS</td><td><p>Konfiguration für E-Mail SOLLTE die Authentifizierung der Server-Zertifikate über das DNS aktivieren.</p></td><td><p>Die Authentifizierung der Server-Zertifikate über das DNS (Domain Name System) kann die Sicherheit der E-Mail-Kommunikation erheblich steigern. Dabei werden Zertifikatsinformationen in DNS-Einträgen genutzt, um die Echtheit der TLS/SSL-Zertifikate eines E-Mail-Servers zu überprüfen und sicherzustellen, dass man tatsächlich mit dem beabsichtigten Kommunikationspartner spricht. Techniken wie DANE (DNS-based Authentication of Named Entities) oder CAA (Certificate Authority Authorization) nutzen spezifische DNS-Resource Records (wie TLSA oder CAA Records), um entweder die verwendeten Zertifikate oder die autorisierten Zertifizierungsstellen im DNS zu hinterlegen. Dies kann verhindern, dass ein Angreifer eine gefälschte Identität vortäuschen oder eine Man-in-the-Middle-Attacke durchführen könnte, indem er ein nicht autorisiertes oder kompromittiertes Zertifikat präsentiert. Ohne diese zusätzliche Überprüfung könnte ein Angreifer beispielsweise den E-Mail-Verkehr der Institution abfangen und mitlesen, während er sich als der legitime Server ausgibt. Die Aktivierung dieser DNS-basierten Überprüfung kann also die Vertraulichkeit und Integrität der übertragenen E-Mails schützen. Zur Umsetzung werden Informationen über eigene Serverzertifikate im DNS hinterlegt und die Prüfung eingehender E-Mails auf hinterlegte Einträge der sendenden Servers aktiviert.</p></td></tr><tr valign="top"><td>KONF.13.11: MTA-STS</td><td><p>Konfiguration für E-Mail SOLLTE MTA-STS aktivieren.</p></td><td><p>Die Mail Transfer Agent Strict Transport Security (MTA-STS) ist ein wichtiger Standard zur Erhöhung der Sicherheit im E-Mail-Verkehr, der die verschlüsselte Zustellung von Nachrichten durch die Erzwingung von Transport Layer Security (TLS) auf der Übertragungsebene gewährleistet. MTA-STS stellt dabei sicher, dass versendende Mail Transfer Agents (MTA) nur verschlüsselte Verbindungen zum Ziel-MTA aufbauen, wodurch Downgrade-Angriffe oder die Umleitung auf unsichere Kanäle wirksam unterbunden werden können. Der Zweck dieser Vorschrift liegt darin, die Vertraulichkeit und Integrität von E-Mail-Inhalten während der Übertragung zu schützen. Ohne MTA-STS könnte ein Angreifer die Kommunikation abfangen und den unverschlüsselten E-Mail-Verkehr mitlesen (Eavesdropping) oder die Nachricht manipulieren, bevor sie den Empfänger erreicht. Die Aktivierung kann das Risiko minimieren, dass E-Mails über unsichere oder unauthentifizierte Verbindungen übertragen werden, selbst wenn die Ziel-Institution TLS unterstützt, was einen robusten Schutz gegen gängige Man-in-the-Middle-Angriffe bietet. Obwohl DNS-Based Authentication of Named Entities (DANE) eine stärkere kryptografische Authentifizierung des TLS-Zertifikats des Ziel-MTA bietet, sollte MTA-STS zusätzlich aktiviert werden, da es eine alternative oder ergänzende Schutzschicht darstellt, falls DANE beim Kommunikationspartner noch nicht implementiert ist oder dessen DNS-Sicherheit (DNSSEC) nicht vertrauenswürdig ist.</p></td></tr></table><h2>KONF.14: Verteilte Anwendungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.14.1: Verschlüsselung beim Transport</td><td><p>Konfiguration für Anwendungen SOLLTE Kommunikation beim Transport über Netze nach <i>einem anerkannten Standard</i> verschlüsseln.</p></td><td><p>Werden Daten unverschlüsselt übertragen, so könnten sie abgehört oder unbemerkt manipuliert werden. Relevant sind hierbei alle von der Anwendung übertragenen Daten, inklusive Authentifizierung an der Benutzerschnittstelle oder API, Abruf von Daten, Server-Server-Replikation oder zur Datensicherung. Das betrifft sowohl Inhalts- als auch Metadaten. Die Umsetzung kann mit Algorithmen zur Transportverschlüsselung wie Transport Layer Security (TLS) oder Ende-zu-Ende-Verschlüsselung erfolgen. Für aktuelle Verschlüsselungsverfahren siehe BSI TR-02102. Die Konfiguration der Verschlüsselung kann sich daran orientieren, wie lange die transportieren Daten, z.B. Transaktionen, vertraulich zu behandeln sind. Eine Herausforderung hierbei sind Anwendungen, die über allgemeine Anbindungen mit anderen Instiutionen kommunizieren, z.B. E-Mails oder Anrufe ins öffentliche Telefonnetz. Diese Anwendungen können nur ihren Teil der Verbindungsstrecke verschlüsseln, so dass der Rest der Strecke und damit die Verbindung an sich dennoch unverschlüsselt sein könnte. Überträgt die Anwendung keine schützenswerten Daten über das Netz, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>KONF.14.1.1: Obligatorische Verschlüsselung</td><td><p>Konfiguration für Anwendungen SOLLTE unverschlüsselte und anfällige Verbindungen über Netze deaktivieren.</p></td><td><p>Obligatorische Verschlüsselung bedeutet, dass die Anwendung ausschließlich nach dem Stand der Technik verschlüsselt kommuniziert. Unverschlüsselte oder mit bekannten Methoden angreifbare Verbindungsanfragen werden dagegen abgelehnt. Die Verwendung obligatorischer Verschlüsselung im Internet ist aktuell sehr uneinheitlich: Viele E-Mail-Server z.B. verschlüsseln im Auslieferungszustand nur opportunistisch - also nur wenn der Verbindungsaufbau so funktioniert. Das macht Verbindungen anfällig für Downgrade-Angriffe. Diese lassen sich verhindern, indem unverschlüsselte Verbindungen vollständig deaktiviert werden. Andererseits kann es dadurch auch zu Verbindungsproblemen mit Servern kommen, die überhaupt keine Verschlüsselung mit aktuellen Protokollen unterstützen. Für aktuelle Verschlüsselungsverfahren siehe BSI TR-02102.</p></td></tr><tr valign="top"><td>KONF.14.1.2: Ende-zu-Ende-Verschlüsselung</td><td><p>Konfiguration für Anwendungen KANN die Kommunikation Ende-zu-Ende über Netze verschlüsseln.</p></td><td><p>Eine Ende-zu-Ende-Verschlüsselung stellt sicher, dass auch Server auf dem Weg zwischen den Endpunkten die Kommunikation nicht auslesen können. Die Unterstützung von Ende-zu-Ende-Verschlüsselung unterscheidet sich zwischen verschiedenen Kommunikationsanwendungen noch immer eheblich: Viele E-Mail-Server verschlüsseln gar nicht oder nur bei Verwendung spezieller Erweiterungen so, während viele Messenger-Apps die Ende-zu-Ende-Verschlüsselung ohne Nutzerinteraktion automatisch erzwingen. Dies kann je nach Anwendung z.B. mittels OpenPGP, S/MIME oder Signal Protocol geschehen. Für aktuelle Verschlüsselungsverfahren siehe BSI TR-02102. Für weitere Details zur Telekommunikation siehe <b>„Kompendium für organisationsinterne Telekommunikationssysteme mit erhöhtem Schutzbedarf“</b>.</p></td></tr><tr valign="top"><td>KONF.14.2: Source Port Randomisierung</td><td><p>Konfiguration für DNS-Server SOLLTE Source Port Randomisierung aktivieren.</p></td><td><p>Die mehrfache Verwendung gleicher Source Ports erleichtert Angreifern das Erraten gültiger Antworten, z.B. bei DNS-Spoofing oder Cache-Poisoning-Angriffen. Sourceport-Randomisierung (IETFC RFC 5452) erhöht die Anzahl möglicher Kombinationen und erschwert derartige Angriffe.</p></td></tr><tr valign="top"><td>KONF.14.3: Iterative Beantwortung</td><td><p>Konfiguration für DNS-Server SOLLTE die iterative Beantwortung von DNS-Anfragen aus dem Internet aktivieren.</p></td><td><p>Bei iterativen Anfragen kommt die Antwort direkt vom autoritativen Server, statt auf zwischengespeicherte Antworten anderer DNS-Resolver zu vertrauen. Dies reduziert die Angriffsfläche für Cache Poisoning und erschwert DNS-Tunneling zur Datenexfiltration oder Command-and-Control-Kommunikation.</p></td></tr><tr valign="top"><td>KONF.14.4: Caching</td><td><p>Konfiguration für Anwendungen von Endgeräten KANN eine Zwischenspeicherung häufig verwendeter Daten aktivieren.</p></td><td><p>Caches sind lokale Zwischenspeicher, die Zugriffe beschleunigen oder bei Netzstörungen ersetzen können. Kann durch Caching-Funktionen auf dem Client, auf Servern in Außenstellen (z.B. Windows BranchCache, Squid Proxy Cache oder CacheFS) oder Caching auf WAN-Netzkomponenten umgesetzt werden.</p></td></tr><tr valign="top"><td>KONF.14.5: Zeitüberschreitung von Netzverbindungen</td><td><p>Konfiguration für Anwendungen SOLLTE Netzverbindungen bei Zeitüberschreitung blockieren.</p></td><td><p>Dauerhaft aufrecht erhaltene, ungenutzte Verbindungen erhöhen die Gefahr unbefugter Zugriffe auf die Anwendung oder eines Überlaufens von Systemressourcen.</p></td></tr></table><h2>KONF.15: Ressourcenauslastung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>KONF.15.1: Begrenzung des Speicherplatzes</td><td><p>Konfiguration für Anwendungen von Hostsystemen KANN in der Anwendung zur Verfügung stehenden Speicherplatz pro <i>Zugangskonto oder Mandant</i> anhand von <i>Schwellwerten</i> einschränken.</p></td><td><p>Dies ist besonders in Multi-Tenant-Architekturen relevant, wie sie häufig bei Cloud-Diensten oder SaaS-Anwendungen (Software as a Service) zum Einsatz kommen. Ein solcher maximaler Schwellwert (engl. threshold) könnte beispielsweise 5 GB oder 10 GB betragen und stellt die Obergrenze für den Speicherplatz dar, der einem einzelnen Konto oder Mandanten zugewiesen wird. Die Beschränkung des verfügbaren Speicherplatzes kann verhindern, dass ein einzelnes Konto oder ein Mandant die gesamten Ressourcen des Hostsystems belegt und so die Leistung für andere Nutzer negativ beeinflusst, was zu einer Denial-of-Service-Situation (DoS) führen könnte. Bei der Umsetzung ist es sinnvoll auch ein Benachrichtigungssystem zu etablieren, das Nutzer oder Administratoren informiert, wenn ein Schwellenwert kurz vor der Überschreitung steht. Zudem können automatisierte Prozesse zur Datenbereinigung (data lifecycle management) in Betracht gezogen werden, die ältere oder nicht mehr benötigte Dateien in solchen Fällen archivieren oder löschen, um den Speicherplatz effizient zu nutzen. Die Institution kann auch verschiedene Schwellenwerte für unterschiedliche Kontotypen oder Mandanten festlegen, basierend auf deren spezifischen Bedürfnissen.</p></td></tr><tr valign="top"><td>KONF.15.2: Begrenzung der Rechenleistung</td><td><p>Konfiguration für Anwendungen von Hostsystemen KANN die Rechenleistung einschränken.</p></td><td><p>Kann durch eine Beschränkung der Anzahl verwendeter Rechenkerne, der Rechenleistung pro Rechenkern oder durch eine indirekte Beschränkung (z.B. eine begrenzte Menge an Anfragen oder Eingabetoken) umgesetzt werden. Beispielsweise kann in einem Verzeichnisdienst ein maximaler Schwellwert für die Zeit eingestellt werden, die eine Suchanfrage in Anspruch nehmen darf, um die Auslastung des Verzeichnisdienstes durch einzelne Anfragen nicht zu gefährden.</p></td></tr><tr valign="top"><td>KONF.15.3: Denial of Service</td><td><p>Konfiguration für Anwendungen von Hostsystemen KANN Schutzmaßnahmen gegen Denial of Service aktivieren.</p></td><td><p>Denial-of-Service-Angriffe zielen darauf ab, die Webanwendung für legitime Nutzende nicht mehr erreichbar zu machen. Webanwendungen im öffentlichen Interesse sind häufig Ziel derartiger Angriffe. Mechanismen wie Content Delivery Network und Load Balancer können die Lastfähigkeit der Anwendung erhöhen, während Filterfunktionen Angriffsmuster erkennen und aus den Anfragen herausfiltern können.</p></td></tr><tr valign="top"><td>KONF.15.4: Überbuchung von virtualisierten Ressourcen</td><td><p>Konfiguration für Virtualisierungslösungen KANN die Überbuchung von virtualisierten Ressourcen deaktivieren.</p></td><td><p>Die Überbuchung (engl. overcommitment) beschreibt in Virtualisierungslösungen die Zuweisung von mehr virtuellen Ressourcen – etwa CPU-Kernen, Arbeitsspeicher oder Speicherplatz – an virtuelle Instanzen, als physisch tatsächlich vorhanden sind. Dies kann kurzfristig zu einer höheren Auslastung und Dichte von virtuellen Instanzen führen, birgt jedoch das Risiko, dass die zugrunde liegende Hardware unter Last nicht mehr alle angefragten Ressourcen bereitstellen kann. Der Zweck der Anforderung liegt darin, die Stabilität, Verfügbarkeit und Vorhersehbarkeit der virtualisierten Umgebung sicherzustellen. Ohne diese Begrenzung könnte es unter hoher Auslastung zu Leistungseinbrüchen, Systemabstürzen oder inkonsistenten Speicherzuständen kommen, während eine restriktive Konfiguration die Zuverlässigkeit und die Berechenbarkeit der Performance einer virtuellen Infrastruktur deutlich verbessern kann. Eine Institution kann die Umsetzung dieser Vorgabe durch verschiedene Maßnahmen erreichen: (1) In der Hypervisor-Konfiguration kann die Vergabe virtueller CPUs und Arbeitsspeicher exakt auf die physisch vorhandenen Ressourcen begrenzt werden. (2) Es kann sinnvoll sein, Profile oder Templates für virtuelle Maschinen zu nutzen, die konservative Standardwerte vorgeben, sodass die Gefahr unbeabsichtigter Überbuchung reduziert wird.</p></td></tr></table><h1>DLS: Dienstleistersteuerung</h1><p>Die Praktik Dienstleistersteuerung regelt die kontinuierliche Überwachung und Steuerung externer Dienstleister, wie etwa Outsourcing-Partner oder Cloud-Anbieter. Sie stellt sicher, dass die erbrachten Leistungen den vereinbarten Sicherheitsanforderungen entsprechen und die Dienstleister ihre vertraglichen Verpflichtungen in Bezug auf die Informationssicherheit erfüllen. Im Gegensatz dazu befasst sich die Praktik Beschaffungsmanagement mit der Auswahl von Dienstleistern sowie der vertraglichen Absicherung, wobei die Integration von Informationssicherheitsanforderungen in den Beschaffungsprozess im Vordergrund steht. Während das Beschaffungsmanagement also die Grundlage für die Zusammenarbeit mit externen Dienstleistern schafft, übernimmt die Dienstleistersteuerung die fortlaufende Kontrolle und das Management dieser Beziehungen, um sicherzustellen, dass die vereinbarten Sicherheitsstandards auch langfristig eingehalten werden.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>DLS.1: Grundlagen</td><td align="right">5</td></tr><tr valign="top"><td>DLS.2: Nutzung von digitalen Dienstleistungen</td><td align="right">3</td></tr><tr valign="top"><td>DLS.3: Kontrolle von Dienstleistern</td><td align="right">7</td></tr><tr valign="top"><td>DLS.4: Dekommissionierung von Dienstleistern</td><td align="right">3</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>18</b></td></tr></table><h2>DLS.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DLS.1.1: Verfahren und Regelungen</td><td><p>Dienstleistersteuerung MUSS ein Verfahren zur Steuerung und geordneten Beendigung von Dienstleistungsverträgen verankern.</p></td><td><p>Hierzu gehört die Kontrolle der Einhaltung von Vereinbarungen zur Sicherheit mit Dienstleistern und (falls erforderlich) einen geeigneten Weg für die Beendigung von Verträgen vorzubereiten. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>DLS.1.1.1: Dokumentation</td><td><p>Dienstleistersteuerung MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>DLS.1.1.2: Zuweisung der Aufgaben</td><td><p>Dienstleistersteuerung MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>DLS.1.1.3: Bekanntgabe</td><td><p>Dienstleistersteuerung MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>DLS.1.2: Regelmäßige Überprüfung</td><td><p>Dienstleistersteuerung MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr></table><h2>DLS.2: Nutzung von digitalen Dienstleistungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DLS.2.1: Mehr-Faktor-Authentifizierung</td><td><p>Dienstleistersteuerung für Dienstleistungen SOLLTE Mehr-Faktor-Authentifizierung bei Login in Online-Dienste aktivieren.</p></td><td><p>Online-Dienste wie die Verwaltung von TK-Rufnummern oder Cloud-Office-Anwendungen sind ein beliebtes Ziel für Angriffe durch Phishing oder Datenleaks. Sichern Sie diese Zugänge mit Mehr-Faktor-Authentifizierung (z.B. OTP) ab.</p></td></tr><tr valign="top"><td>DLS.2.2: Transportverschlüsselung</td><td><p>Dienstleistersteuerung für Daten SOLLTE den Transport bei der Übertragung zum Anbieter nach <i>einem anerkannten Standard</i> verschlüsseln.</p></td><td><p>„Transport“ bedeutet hier der technische Vorgang der Datenübertragung zwischen der Institution und dem Dienstleister, also etwa über das Internet oder dedizierte Leitungen. Der Sinn dieser Vorschrift liegt darin, die Vertraulichkeit und Integrität von Informationen zu schützen, wenn sie in fremde Infrastrukturen überführt werden. Ohne eine solche Maßnahme könnte ein Angreifer Daten während der Übertragung abfangen oder manipulieren, beispielsweise über „Man-in-the-Middle“-Angriffe oder durch Abhören unsicherer Netze. Da beschaffte Dienstleistungen typischerweise außerhalb der direkten Kontrolle der Institution liegen, gibt es hier eine eigene Vorgabe, um die besondere Risikosituation beim Übergang von interner zu externer Infrastruktur gezielt abzusichern. Eine Institution kann die Anforderung praktisch umsetzen, indem sie (1) den Einsatz von Protokollen wie TLS in allen Web- und API-basierten Schnittstellen zum Anbieter sicherstellt, (2) für administrative Zugänge oder besonders sensible Datenübertragungen zusätzlich VPN-Verbindungen nutzen kann, und (3) Zertifikatsprüfungen so konfiguriert, dass unsichere oder abgelaufene Zertifikate nicht akzeptiert werden.</p></td></tr><tr valign="top"><td>DLS.2.3: Vollverschlüsselung</td><td><p>Dienstleistersteuerung für Daten KANN diese, wenn der Anbieter deren Inhalt zur Vertragserbringung nicht kennen muss, für diesen nicht entschlüsselbar vor der Übertragung zum Dienstleister verschlüsseln.</p></td><td><p>Hierbei handelt es sich um eine Verschlüsselung at-rest, bei welcher der Dienstleister keinen Zugang zum Schlüssel erhält. Die Umsetzung kann z.B. auf Dateiebene oder durch Container erfolgen.</p></td></tr></table><h2>DLS.3: Kontrolle von Dienstleistern</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DLS.3.1: Einhaltung der Sicherheitsvorgaben</td><td><p>Dienstleistersteuerung für Dienstleistungen SOLLTE die Einhaltung der Sicherheitsvorgaben durch den Dienstleister <i>regelmäßig</i> überprüfen.</p></td><td><p>Hierzu ist zu prüfen, ob Anzeichen vorliegen, dass der Dienstleister die im Vertrag geforderten Vorgaben nicht einhält und falls erforderlich Gegenmaßnahmen einzuleiten. Die Prüfung kann z.B. Zertifikate, regelmäßige Stichproben oder das Monitoring von Datenleaks vorsehen.</p></td></tr><tr valign="top"><td>DLS.3.1.1: Audit oder Zertifikat</td><td><p>Dienstleistersteuerung für Outsourcing SOLLTE die Einhaltung der Sicherheitsvorgaben anhand eines <i>Audits, Zertifikates oder vergleichbaren Sicherheitsnachweises</i> <i>regelmäßig</i> überprüfen.</p></td><td><p>„Audit“ bezeichnet in diesem Zusammenhang eine systematische, unabhängige Überprüfung der vereinbarten Sicherheitsmaßnahmen durch fachkundige Dritte, beispielsweise in Form interner oder externer Prüfungen mit dokumentierten Ergebnissen. Ein „Zertifikat“ ist ein formaler Nachweis einer akkreditierten Prüfstelle, dass ein Dienstleister ein anerkanntes Sicherheitsframework eingehalten hat, wie etwa IT-Grundschutz oder ISO/IEC 27001. Ein „vergleichbarer Sicherheitsnachweis“ kann auch ein Prüfbericht, ein BSI C5-Testat oder eine Bestätigung unabhängiger Gutachter sein, sofern er inhaltlich nachvollziehbar darlegt, dass definierte Sicherheitsanforderungen wirksam umgesetzt wurden. Ohne Nachweise könnte ein Dienstleister vereinbarte Sicherheitsmaßnahmen vernachlässigen, was zu unbemerkten Datenabflüssen, unzureichendem Patch-Management oder Ausfällen durch mangelhafte Notfallvorsorge führen könnte. Durch nachvollziehbare Prüfungen kann dagegen erreicht werden, dass Sicherheitsstandards eingehalten werden, Schwachstellen frühzeitig sichtbar werden und ein belastbares Vertrauen in die Dienstleisterbeziehung entsteht.</p></td></tr><tr valign="top"><td>DLS.3.2: Checkup</td><td><p>Dienstleistersteuerung für Outsourcing KANN die risikoorientierte Entscheidung über Outsourcing auf Grundlage der Geschäftsprozessprofile auf Änderungen der Gefährdungslage oder Prozessinhalte <i>regelmäßig</i> überprüfen.</p></td><td><p>Die risikoorientierte Entscheidung über Outsourcing kann in diesem Kontext als wiederkehrende Bewertung der Abhängigkeiten und Gefahren verstanden werden, die durch externe Dienstleister in den Geschäftsprozessen einer Institution entstehen. Der Parameter regelmäßig kann je nach Kritikalität der ausgelagerten Prozesse sinnvoll mit Werten wie halbjährlich, jährlich oder nach definierten Ereignissen (z. B. Einführung neuer regulatorischer Vorgaben oder Sicherheitsvorfälle) ausgefüllt werden. Änderungen der Gefährdungslage beziehen sich auf die dynamische Entwicklung von Bedrohungen wie Cyberangriffe, Lieferkettenstörungen oder neue regulatorische Anforderungen, während Änderungen der Prozessinhalte vor allem die Anpassung oder Erweiterung der durch Dienstleister erbrachten Leistungen umfassen. Der Zweck dieser Vorschrift liegt darin, frühzeitig sicherzustellen, dass die bisherigen Risikoeinschätzungen und Dienstleistervereinbarungen weiterhin tragfähig sind und nicht durch externe Veränderungen entwertet werden. Ohne eine solche Überprüfung könnte beispielsweise ein Dienstleister aufgrund verschärfter Bedrohungen unzureichenden Schutz bieten oder durch eine stillschweigende Ausweitung von Leistungen in Bereiche gelangen, die ursprünglich nicht risikobewertet wurden. Eine regelmäßige Kontrolle kann dagegen dafür sorgen, dass Risiken durch Outsourcing transparent bleiben und rechtzeitig nachjustiert werden. Zur praktischen Umsetzung kann eine Institution beispielsweise (1) eine Checkliste führen, die bei jeder Neubewertung konkrete Aspekte wie Datenlokation, technische Sicherheitsmaßnahmen oder Zertifikatsgültigkeiten abfragt und (2) ein automatisiertes Monitoring nutzen, das öffentliche Sicherheitsnachweise wie Testate nach BSI C5 oder SOC-Reports erfasst und in die Bewertung einbindet. Auch die Nutzung von Incident-Datenbanken oder branchenspezifischen Threat-Feeds kann helfen, Gefährdungslagen aktuell einzuschätzen. Ein bewährter Tipp ist es, nicht nur formale Unterlagen zu prüfen, sondern auch technische Stichproben durchzuführen, etwa in Form von Konfigurationsprüfungen oder Penetrationstests, sofern dies durch den Dienstleister gestattet wird. Damit kann die Institution sicherstellen, dass die theoretische Risikoabwägung durch reale Prüfungen gestützt wird und sich an tatsächlichen Veränderungen orientiert.</p></td></tr><tr valign="top"><td>DLS.3.3: Strategie-Check</td><td><p>Dienstleistersteuerung für Outsourcing KANN die Strategie auf Vollständigkeit und Korrektheit in Bezug auf die betrachteten Geschäftsprozesse bei Änderungen der Geschäftsprozessprofile überprüfen.</p></td><td><p>Vollständigkeit bedeutet hier, dass die Gesamtheit der ausgelagerten Prozesse erfasst, beschrieben und in ihrer Abhängigkeit zu internen Prozessen berücksichtigt ist. Korrektheit meint, dass die Beschreibungen, Schnittstellen und Verantwortlichkeiten zwischen Institution und Dienstleister sachlich richtig, aktuell und belastbar dokumentiert sind. Zur Umsetzung kann eine Institution strukturierte Verfahren einführen, die bei Änderungen in den Prozessprofilen automatisch eine Prüfung des Outsourcing-Setups auslösen. Dies kann z. B. durch Abgleich der aktuellen Servicebeschreibungen mit Prozesslandkarten erfolgen, sodass fehlende oder doppelt definierte Zuständigkeiten sichtbar werden.</p></td></tr><tr valign="top"><td>DLS.3.4: Anhörung</td><td><p>Dienstleistersteuerung für Outsourcing SOLLTE den Dienstleister zu Sicherheitsmaßnahmen für betroffene Zielobjekte anhören.</p></td><td><p>Betroffen sind alle Zielobjekte, zu denen vom Dienstleister (Teil-)Leistungen erbracht werden. Für eine Anhörung ist es erforderlich, dass der Dienstleister über die geplanten Maßnahmen informiert ist und ausreichend Gelegenheit zur Stellungnahme erhält.</p></td></tr><tr valign="top"><td>DLS.3.5: Blockierung unzuverlässiger Dienstleister</td><td><p>Dienstleistersteuerung SOLLTE unzuverlässige Dienstleister oder Subdienstleister blockieren.</p></td><td><p>Ein Dienstleister gilt als unzuverlässig, wenn zukünftig mit Verstößen gegen die Schutzziele Vertraulichkeit, Verfügbarkeit oder Integrität durch ihn zu rechnen ist (d.h. eine Prognose der Vertrauenswürdigkeit). Dies ist insbesondere dann der Fall, wenn erhebliche Verstöße gegen die Schutzziele bereits durch ihn begangen wurden oder Anzeichen dafür vorliegen, dass bei einer weiteren Verwendung mit solchen Verstößen zu rechnen ist. Beispielsweise kann dies eintreten, wenn die Verwendung des DNS-Servers eines wirtschaftlichen Konkurrenten diesem die schützenswerten Adressen von der Institution besuchter Internetseiten ausliefert, oder eine Behörde Software mit Internetzugriff einsetzen möchte, die jedoch von einem Hersteller stammt, dessen Hauptsitz in einem öffentlich für politische Spionage bekannten Staat liegt. Dies kann durch eine Liste blockierter Vertragspartner umgesetzt werden. Eine Umsetzung für Subdienstleister kann z.B. durch die Benennung autorisierter Subdienstleister, oder die Weitergabe von Kriterien für Subdienstleister an den Dienstleister erfolgen.</p></td></tr><tr valign="top"><td>DLS.3.6: Portabilität</td><td><p>Dienstleistersteuerung für Outsourcing KANN die Portabilität des ausgelagerten Prozesses <i>regelmäßig</i> überprüfen.</p></td><td><p>Hierunter ist zu verstehen, dass regelmäßig ein Test durchgeführt wird, bei dem die Funktionsfähigkeit des ausgelagerten (Teil-) Prozesses in einer Umgebung, die nicht bei diesem Dienstleister liegt, überprüft wird. Ziel ist es sicherzustellen, dass der Prozess bei einem Ausfall des Dienstleisters an anderer Stelle zeitnah gestartet werden kann.</p></td></tr></table><h2>DLS.4: Dekommissionierung von Dienstleistern</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DLS.4.1: Dekomissionierung</td><td><p>Dienstleistersteuerung für Dienstleistungen SOLLTE eine Vorgehensweise zur Dekommissionierung vor Vertragsende verankern.</p></td><td><p>Der Begriff Dekommissionierung bezeichnet hier das strukturierte und nachweisbare Vorgehen, wie eine Institution die Nutzung eines Dienstes oder die Zusammenarbeit mit einem Dienstleister kontrolliert beendet, ohne dass Informationssicherheit, Verfügbarkeit oder Nachvollziehbarkeit beeinträchtigt werden. Der Sinn dieser Vorgabe liegt darin, Risiken wie den unkontrollierten Verbleib sensibler Daten bei einem Dienstleister oder unerkannte Abhängigkeiten von dessen Infrastruktur zu vermeiden. Ohne ein definiertes Vorgehen könnte etwa ein Anbieter weiterhin Zugriff auf produktive Systeme behalten oder Kopien vertraulicher Daten in seiner Umgebung zurückhalten, was ein erhebliches Risiko darstellen könnte. Die praktische Umsetzung kann in mehreren abgestuften Maßnahmen bestehen: (1) Ein geplanter Abschalttermin kann genutzt werden, um Systeme, Schnittstellen und Berechtigungen kontrolliert zurückzubauen und anschließend durch ein Freigabeprotokoll zu bestätigen. (2) Ein Prozessleitfaden kann die frühzeitige Identifikation von zu dekommissionierenden Schnittstellen, Zugangsdaten und Subdienstleistern vorsehen, damit deren Abschaltung rechtzeitig koordiniert werden kann. (3) Eine Checkliste kann sicherstellen, dass auch weniger offensichtliche Abhängigkeiten – etwa hinterlegte API-Tokens, Support-Zugänge oder im Monitoring integrierte Endpunkte – im Abschlussprozess berücksichtigt werden. (4) Technisch kann die Nutzung von zentral verwalteten Zugriffskonten und Logging-Systemen die Überprüfung erleichtern, ob ein Dienstleister nach der Deaktivierung tatsächlich keinen Zugriff mehr hat. Auf diese Weise kann die Institution die Dienstleistersteuerung auch vorzeitig geordnet beenden, ohne dass Informationssicherheitsrisiken unkontrolliert fortbestehen.</p></td></tr><tr valign="top"><td>DLS.4.1.1: Unabhängigkeit</td><td><p>Dienstleistersteuerung für Outsourcing SOLLTE die Unabhängigkeit der Verarbeitung schützenswerter Informationen vor der Außerbetriebnahme testen.</p></td><td><p>„Unabhängigkeit der Verarbeitung“ meint hier die Fähigkeit, dass die Nutzung von Informationen in Geschäftsprozessen der Institution nicht von den Systemen, Verfahren oder Interessen des externen Dienstleisters abhängig ist, sodass ihre Integrität, Verfügbarkeit und Vertraulichkeit auch nach einer Außerbetriebnahme des Outsourcings gewährleistet bleibt. Die Vorschrift dient dem Zweck, die Risiken zu minimieren, die entstehen können, wenn ein Dienstleister seine Leistung einstellt, Verträge beendet werden oder ein abruptes Ende der Zusammenarbeit erfolgt. Ohne Vorkehrungen könnte dies dazu führen, dass kritische Daten unzugänglich bleiben, unkontrolliert gelöscht werden oder in Abhängigkeit von proprietären Formaten verloren gehen. Zur Umsetzung kann die Institution verschiedene Maßnahmen prüfen: (1) Ein systematischer Test, ob Daten in standardisierten, portablen Formaten exportierbar sind und in eigenen oder alternativen Systemen fehlerfrei weiterverarbeitet werden können. (2) Ein Probelauf, bei dem die Verbindung zum Dienstleister gezielt getrennt wird, um zu überprüfen, ob die Institution ihre Geschäftsprozesse auch ohne aktive Anbindung fortführen kann. (3) Ein kontrolliertes Abschalten einzelner vom Dienstleister erbrachter Dienste, um zu verifizieren, ob vorbereitete Ersatzprozesse oder interne Systeme die Funktion übernehmen. (4) Eine Teststellung für die Rückgabe von Datenbeständen am Ende der Vertragslaufzeit, bei der die Vollständigkeit, Konsistenz und Nutzbarkeit der gelieferten Daten geprüft wird. Mit solchen Maßnahmen kann die Institution sicherstellen, dass die Verarbeitung schützenswerter Informationen eigenständig aufrechterhalten werden kann.</p></td></tr><tr valign="top"><td>DLS.4.1.2: Berechtigungen deaktivieren</td><td><p>Dienstleistersteuerung für Dienstleistungen SOLLTE für den Vertrag benötigte Berechtigungen bei Vertragsende unverzüglich deaktivieren.</p></td><td><p>Berechtigungen sind hier alle Zugangs-, Zutritts- und Zugriffsrechte, die von der Institution für Mitarbeitende, Organisationseinheiten oder Subunternehmer des Dienstleisters eingerichtet oder geändert wurden. Hierzu können diese Rechte gelöscht, deaktiviert oder reduziert werden, soweit sie nicht mehr (z.B. für andere Verträge) benötigt werden.</p></td></tr></table><h1>GEB: Gebäudemanagement</h1><p>Das Gebäudemanagement sorgt für die Implementierung von physischen Sicherheitsmaßnahmen in und um das Gebäude. Dazu gehören insbesondere Zutrittskontrollen, Überwachungsmechanismen und die Sicherstellung geeigneter Umgebungsbedingungen, um sensible IT-Systeme und Informationen vor physischen Bedrohungen zu schützen.  Diese Praktik fokussiert sich auf den Schutz der physischen Umgebung (z.B. Gebäude, Räume), während andere Praktiken wie IT-Betrieb oder Berechtigungen sich mit systemseitigen und personellen Sicherheitsmaßnahmen beschäftigen. Das Gebäudemanagement stellt sicher, dass die physische Infrastruktur so gestaltet ist, dass sie IT-Systeme und sensible Daten bestmöglich schützt.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>GEB.1: Grundlagen</td><td align="right">9</td></tr><tr valign="top"><td>GEB.2: Physischer Perimeter</td><td align="right">4</td></tr><tr valign="top"><td>GEB.3: Physischer Zutritt</td><td align="right">12</td></tr><tr valign="top"><td>GEB.4: Umwelteinflüsse</td><td align="right">4</td></tr><tr valign="top"><td>GEB.5: Sicherheitsbereiche</td><td align="right">4</td></tr><tr valign="top"><td>GEB.6: Gemeinsame Arbeitsbereiche</td><td align="right">5</td></tr><tr valign="top"><td>GEB.7: Platzierung von Assets</td><td align="right">5</td></tr><tr valign="top"><td>GEB.8: Schlüsselverwaltung</td><td align="right">3</td></tr><tr valign="top"><td>GEB.9: Verwahrung von Speichermedien</td><td align="right">5</td></tr><tr valign="top"><td>GEB.10: Versorgungseinrichtungen</td><td align="right">12</td></tr><tr valign="top"><td>GEB.11: Schutz vor Elementarschäden</td><td align="right">15</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>78</b></td></tr></table><h2>GEB.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.1.1: Verfahren und Regelungen</td><td><p>Gebäudemanagement MUSS Verfahren und Regelungen zum physischen Schutz von Standorten, an denen schützenswerte Informationen verarbeitet oder gespeichert werden, verankern.</p></td><td><p>Ein Verfahren zum Gebäudemanagement stellt sicher, dass die zum Betrieb von Geschäftsprozessen erforderliche Infrastruktur vorhanden ist und schützt Zielobjekte dort vor dem Zugriff Unbefugter und vor Elementarschäden wie Feuer, Wind und Wetter. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>GEB.1.1.1: Dokumentation</td><td><p>Gebäudemanagement MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>GEB.1.1.2: Zuweisung der Aufgaben</td><td><p>Gebäudemanagement MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>GEB.1.1.3: Bekanntgabe</td><td><p>Gebäudemanagement MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>GEB.1.2: Regelmäßige Überprüfung</td><td><p>Gebäudemanagement MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr><tr valign="top"><td>GEB.1.3: Autorisierung von Standorten</td><td><p>Gebäudemanagement für Standorte SOLLTE Standorte für die Stationierung von Assets autorisieren.</p></td><td><p>Die gezielte Autorisierung von Standorten für die Stationierung von Assets kann dazu beitragen, dass Informationen und Systeme nur an physischen Orten verarbeitet oder aufbewahrt werden, die zuvor auf ihre Sicherheitsanforderungen hin geprüft wurden. So kann beispielsweise verhindert werden, dass sensible Server in unkontrollierten Räumen ohne Zutrittskontrolle oder redundante Stromversorgung betrieben werden – ein Fehlen dieser Maßnahmen könnte im Ernstfall zu Datenverlust bei einem Kurzschluss oder unbefugtem Zugriff durch Dritte führen. Ebenso kann die Prüfung und Freigabe durch eine zuständige Rolle dafür sorgen, dass neue Außenstellen erst dann in den Betrieb gehen, wenn etwa Brandmelde‑, Videoüberwachungs‑ oder Netzwerksicherheitsanforderungen erfüllt sind; andernfalls könnte eine unerkannte technische Schwachstelle in einem Zweigstellenrechner dazu führen, dass Schadcode sich ins gesamte Unternehmensnetz ausbreitet. Auch bei der Nutzung von Cloud‑ oder Colocation‑Rechenzentren kann eine formale Freigabe sicherstellen, dass vorab vertraglich vereinbarte Sicherheits- und Compliance‑Anforderungen – wie beispielsweise ISO‑27001‑Zertifizierung oder Verschlüsselung im Ruhezustand – tatsächlich gegeben sind, andernfalls könnte es zu Datenschutzverletzungen oder Regulierungsstrafen kommen.  Zur praktischen Umsetzung kann ein Standort‑Freigabeprozess definiert werden, der folgende Elemente enthält: eine Checkliste für physische Sicherheitskriterien (Zutrittskontrolle, Umwelt‑ und Brandschutz), eine technische Abnahmematrix (Netzwerksegmentierung, Monitoring, Backup‑Anbindung) sowie die Benennung einer verantwortlichen Person oder Rolle, die das Go‑No‑Go‑Entscheidungsrecht hält. Bei Änderungen am Standort oder an den Assets kann diese Rolle regelmäßige Reviews anstoßen, wodurch nachträgliche Kontrollen möglich werden. Automatisierte Workflow‑Tools können dabei unterstützen, Prüf‑ und Genehmigungsschritte nachvollziehbar zu dokumentieren und Eskalationspfade abzubilden.</p></td></tr><tr valign="top"><td>GEB.1.3.1: Abnahme von Standorten</td><td><p>Gebäudemanagement für Standorte SOLLTE Standorte vor Autorisierung anhand von <i>Kriterien</i> testen.</p></td><td><p>Eine Abnahme anhand von Sicherheitskriterien stellt sicher, dass Sicherheitsaspekte bereits in der Planungsphase vor der ersten Nutzung eines Standortes berücksichtigt werden. Die Kriterien ergeben sich aus den weiteren Anforderungen dieser Praktik, sowie aus Compliance-Verpflichtungen. Denken Sie hierbei an den Schutz vor Elementarschäden, den Zutrittsschutz, den voraussichtlichen Versorgungsbedarf mit Strom, Netzanbindung, eine strukturierte Verkabelung und Wasserleitungen, sowie die Gebäudeautomatisierung. Kann z.B. mit Building Information Modeling (BIM) umgesetzt werden.  Wurde ein Standort bereits bezogen, so gilt die Anforderung als umgesetzt, wenn die Erfüllung der Kriterien nachträglich (z.B. durch eine Begehung) sichergestellt wurde.</p></td></tr><tr valign="top"><td>GEB.1.4: Exponierte Bereiche</td><td><p>Gebäudemanagement für Standorte SOLLTE schützenswerte Assets oder zugehörige Infrastrukturen nur außerhalb exponierter oder besonders gefährdeter Bereiche platzieren.</p></td><td><p>Wenn schützenswerte Räume wie Datenträgerarchive, Hostsysteme oder zentrale Infrastrukturen wie die Strom- und Netzversorgung in besonders exponierten Gebäudeteilen oder unter freiem Himmel lokalisiert werden, erhöht dies das Risiko für Ausfälle. Beispiele für gefährdete Bereiche sind ein überflutungsgefährdeter Keller, an der Gebäudekante direkt neben einer Bundesstraße oder an einer von Außen leicht einsehbaren Stelle. Welche Bereiche gefährdet sind kann oft von lokalen oder nationalen staatlichen Stellen bezogen werden.  Wenn der gesamte Standort besonders exponiert oder gefährdet ist, kann dies nur durch die Nutzung anderer Standorte umgesetzt werden.</p></td></tr><tr valign="top"><td>GEB.1.5: Strukturpläne</td><td><p>Gebäudemanagement für Standorte SOLLTE Strukturpläne dokumentieren.</p></td><td><p>Strukturpläne enthalten Grundrisse und Verlaufswege für physische Perimeter oder Versorgungseinrichtungen. Beispielsweise enthalten Gebäudepläne üblicherweise Zeichnungen der einzelnen Etagen und der Gebäudestrukturen darin. Diese Pläne sind hilfreich um Schwachstellen oder Störquellen aufzudecken und zielgerichtet zu behandeln. Dazu gehören Versorgungsleitungen, Netzanschlüsse, sowie Aus- und Zugänge für den regulären Betrieb und für Notfälle.</p></td></tr></table><h2>GEB.2: Physischer Perimeter</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.2.1: Installation von Perimetern</td><td><p>Gebäudemanagement für Standorte SOLLTE Sicherheitsperimeter installieren.</p></td><td><p>Die Installation physischer Sicherheitsperimeter dient dem grundlegenden Schutz von Informationsressourcen und kritischer Infrastruktur vor unbefugtem Zugriff und physischen Bedrohungen. Ein effektiver Sicherheitsperimeter kann als mehrschichtige Barriere fungieren, die sensible Bereiche vor verschiedenen Risiken wie Einbruch, Diebstahl oder Sabotage schützt. Ohne angemessene physische Sicherheitsmaßnahmen könnten unbefugte Personen z.B. Zugang zu Serverräumen erlangen und dort Datenträger entwenden, Schadcode installieren oder Hardwarekomponenten manipulieren. Auch Naturereignisse wie Überschwemmungen oder Brände könnten ohne geeignete Perimeter leichter zu Datenverlust oder Betriebsunterbrechungen führen.  Bei der Implementierung physischer Sicherheitsperimeter kann eine Kombination verschiedener Sicherheitsebenen erwogen werden, beginnend mit äußeren Barrieren wie Zäunen, Schranken oder gesicherten Eingangsbereichen, die den Zugang zum Gelände regulieren. Im Gebäudeinneren können Zugangskontrollsysteme mit unterschiedlichen Authentifizierungsmethoden (Chipkarten, biometrische Verfahren, PIN-Codes) eingesetzt werden, um den Zutritt zu sensiblen Bereichen auf autorisierte Mitarbeiter zu beschränken. Die Effektivität dieser Maßnahmen kann durch ergänzende Systeme wie Videoüberwachung, Alarmanlagen oder Bewegungsmelder verstärkt werden, wobei ein ausgewogenes Verhältnis zwischen Sicherheitsanforderungen und Praktikabilität für den Arbeitsalltag zu finden ist. Bei der Planung kann eine Risikobewertung helfen, um festzulegen, welche Bereiche besonders schutzbedürftig sind und entsprechend abgesichert werden, etwa durch Sicherheitszonen mit gestaffelten Zugangsrechten oder spezielle Brandschutzbereiche für kritische IT-Infrastruktur.</p></td></tr><tr valign="top"><td>GEB.2.2: Dokumentation öffentlicher Bereiche</td><td><p>Gebäudemanagement für Gebäude SOLLTE Bereiche, die ohne Authentifizierung zugänglich sind, mit Begründung dokumentieren.</p></td><td><p>Gebäude sind als stabiler und klar ersichtlicher Sicherheitsperimeter besonders geeignet. Viele Institutionen benötigen für ihre Aufgaben jedoch Bereiche, die ohne Authentifizierung zugänglich sind, z.B. Empfangs- oder Lieferzonen, Bürgerbüros, Kundenräume. Hierdurch könnte es leicht zu versehentlichen oder zielgerichteten Schäden an Assets, unbefugten Zutritten oder dem Abfluss vertraulicher Daten kommen. Daher ist es sinnvoll, diese Bereiche zu dokumentieren und die Gründe für ihre Bereitstellung nachzuhalten, um sicherzustellen, dass der Sicherheitsperimeter auch im Gebäude korrekt verläuft und geschützt ist.</p></td></tr><tr valign="top"><td>GEB.2.3: Erkundung aus dem öffentlichen Raum</td><td><p>Gebäudemanagement für Standorte SOLLTE Hör- und Sehschutz gegen den öffentlichen Raum testen.</p></td><td><p>Erkundung aus dem öffentlichen Raum ist die systematische Sammlung von Informationen, die ausschließlich von öffentlich zugänglichen Bereichen aus durchgeführt wird, um die Schwachstellen eines Standortes zu bewerten, ohne in Sperrzonen einzudringen. Hierbei könnten z.B. Sicherheitssysteme, Zugangspunkte und Personalroutinen ausgeforscht werden; Gespräche in offenen Bereichen wie Lobbys oder Raucherzonen aufgezeichnet werden, in denen sensible Informationen versehentlich preisgegeben werden könnten; zusätzliche Techniken wie das Durchsuchen von Mülltonnen (Dumpster Diving), drahtlose Signalanalyse und Social Engineering von öffentlichen Aussichtspunkten aus könnten zahlreiche Informationen ungewollt preisgeben. Hierbei sind sowohl Einblicke von öffentlichen Straßen, Plätzen oder sonstigen Flächen außerhalb des Perimeters relevant, als auch die Erkundung von höher gelegenen Positionen, z.B. gegenüberliegenden Hochhäusern oder Flugmaschinen wie Drohnen, bis hin zu Satellitenaufnahmen. Maßnahmen können z.B. Begehungen des Perimeters oder von höher gelegenen Räumlichkeiten, die Auswertung öffentlicher Sattelitenbilder oder eigene Drohnenflüge sein. Kann auch durch einen physischen Penetration Test sichergestellt werden.</p></td></tr><tr valign="top"><td>GEB.2.4: Elektromagnetische Abschirmung</td><td><p>Gebäudemanagement für Standorte KANN die Elektromagnetische Abschirmung testen.</p></td><td><p>Die elektromagnetische Abschirmung von Standorten dient dem Schutz vertraulicher Informationen vor unbefugter Erfassung durch elektromagnetische Abstrahlung. Computersysteme, Netzwerkgeräte und andere elektronische Ausrüstungen senden elektromagnetische Signale aus, die außerhalb des Gebäudes abgefangen werden könnten. Dies könnte zur ungewollten Offenlegung sensibler Daten führen, wie etwa bei Van-Eck-Phreaking, bei dem Bildschirminhalte aus der Ferne rekonstruiert werden können. Ein Angreifer könnte beispielsweise mit speziellem Equipment die ausgesendeten Signale eines Monitors oder Netzwerkkabels abfangen und daraus Passwörter, Finanzdaten oder Geschäftsgeheimnisse extrahieren, ohne physischen Zugang zum Gebäude zu benötigen.  Bei der Umsetzung kann eine mehrstufige Strategie verfolgt werden. Die Räumlichkeiten können mit speziellen abschirmenden Materialien wie metallischen Geweben, leitfähigen Farben oder Folienbeschichtungen ausgekleidet werden, die als <b>„Faradayscher Käfig“</b> wirken. Fenster können mit metallbeschichteten Gläsern oder speziellen Folien versehen werden, die elektromagnetische Strahlung blockieren. Sicherheitsbereiche können nach Sensitivität der dort verarbeiteten Daten in verschiedene Zonen eingeteilt werden, wobei nur die kritischsten Bereiche vollständig abgeschirmt werden.</p></td></tr></table><h2>GEB.3: Physischer Zutritt</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.3.1: Überwachung von Zutrittspunkten</td><td><p>Gebäudemanagement für Standorte SOLLTE Zutrittspunkte auf unbefugte Zutritte überwachen.</p></td><td><p>Eine kontinuierliche Überwachung der Zugangsmöglichkeiten, z.B. verschlossener Türen und Fenster an der Gebäudeaußenseite, verhindert, dass sich Unbefugte Zutritt verschaffen. Der hierzu erforderliche Personalbedarf hängt von Gebäudegröße und Schutzbedarf ab. Um den für eine kontinuierliche Überwachung erforderlichen Personalbedarf wirtschaftlich zu decken ist es zweckmäßig, Unterstützungssysteme wie Videokameras oder Einbruchsalarme einzusetzen. Die Umsetzung kann z.B. erfolgen durch Umzäunung, Kameraüberwachung, Bewegungsmelder und einen Wachdienst.</p></td></tr><tr valign="top"><td>GEB.3.1.1: Videoüberwachung</td><td><p>Gebäudemanagement für Standorte KANN Zutritte per Video überwachen.</p></td><td><p>Die Auswertung der Videoaufzeichnungen kann je nach Risikoprofil und Geschäftsprozessen anlassbezogen und stichpunktartig, kontinuierlich durch Wachpersonal oder durch Verwendung von KI-Videoanalyse, z.B. zur Erkennung von „tail-gating“ oder zurückgelassenen Gegenständen, erfolgen. Hier besteht ein enger Zusammenhang zu Compliance-Verpflichtungen zum Datenschutz (z.B. Informationspflichten), insbesondere im öffentlichen Raum.</p></td></tr><tr valign="top"><td>GEB.3.1.2: Überprüfung mitgeführter Gegenstände</td><td><p>Gebäudemanagement für Standorte KANN das Mitführen von Gegenständen überwachen.</p></td><td><p>Die Überwachung des Mitführens von Gegenständen (z.B. am Empfang) kann an Standorten mit besonderen Sicherheitsrisiken dazu beitragen, unerlaubtes Einschleusen von Diebstahlwerkzeugen, schädlichen Datenträgern oder gefährlichen Gegenständen zu verhindern. Durch eine stichprobenartige Kontrolle von Taschen, Rucksäcken oder Paketlieferungen kann erkannt werden, ob unbeaufsichtigt Materialien wie USB‑Sticks, externe Festplatten oder andere Speichermedien ins Gebäude gelangen, die vertrauliche Informationen unbemerkt abziehen könnten. Ebenso kann das Verfahren auf Metallgegenstände oder Flüssigkeiten ausgeweitet werden, um das Risiko von Diebstahl, Sabotage oder physischen Angriffen zu reduzieren. Beispielsweise könnte ein nicht registrierter Besucher eine Videokamera einschleusen und damit sensible Produktionsprozesse filmen, oder ein unbeaufsichtigter Paketbote könnte Malware‑belastete Hardware mitliefern – durch die Kontrolle am Empfang kann solchen Szenarien vorgebeugt werden.  Die Umsetzung kann stichprobenartig oder durchgehend erfolgen: Einmal täglich kann eine Auswahl von Taschen stichprobenartig geöffnet und mit einer Liste erlaubter Gegenstände abgeglichen werden; hierbei kann ein einfaches Check‑in‑Formular eingesetzt werden, in das Besucherinnen und Besucher freiwillig ihre mitgeführten Gegenstände eintragen können. Ergänzend kann ein abschließender Scan mit einem Metalldetektor oder ein kurzer Blick in unverschlossene Fächer erfolgen, was den Aufwand gering hält und den Durchfluss am Empfang weniger beeinträchtigt. Hier besteht ein enger Bezug zu den Persönlichkeitsrechten der Betroffenen. Eine klar kommunizierte Hausordnung oder ein Informationsblatt kann helfen die Maßnahmen zu erläutern, sodass Besucher erkennen, dass die Kontrollen dem Schutz aller Beteiligten dienen. Gegenstände, die vorübergehend nicht mitgeführt werden dürfen, können gegen Quittung sicher deponiert werden. Auf diese Weise entsteht eine nachvollziehbare Historie, die im Fall eines Vorfalls als Nachweis dienen kann.</p></td></tr><tr valign="top"><td>GEB.3.2: Anmelde- und Empfangsbereiche</td><td><p>Gebäudemanagement für Standorte SOLLTE Anmelde- und Empfangsbereiche installieren.</p></td><td><p>Die Einrichtung definierter Anmelde- und Empfangsbereiche dient der Kontrolle des physischen Zugangs zum Standort. Diese Bereiche können als erste Verteidigungslinie fungieren, indem sie einen klaren Trennpunkt zwischen öffentlichen und geschützten Zonen etablieren. Durch die strukturierte Implementierung solcher Bereiche können unbefugte Zutritte vermieden werden, die andernfalls zu Sicherheitsverletzungen führen könnten. Ein fehlendes oder unzureichendes Empfangsmanagement könnte beispielsweise dazu führen, dass nicht autorisierte Personen unkontrolliert Zugang zu sensiblen Bereichen erhalten, vertrauliche Dokumente einsehen, Firmengeheimnisse entwenden oder sogar physische Sabotageakte durchführen.  Bei der Umsetzung können verschiedene Ansätze verfolgt werden, die je nach Institution und sonstigen angewendeten Sicherheitsanforderungen variieren. Der Anmeldebereich kann mit einem digitalen Besuchermanagementsystem ausgestattet werden, welches die Authentifizierung und Registrierung von Besuchern erleichtert und eine lückenlose Dokumentation ermöglicht. Ergänzend hierzu kann die räumliche Gestaltung durch klare Beschilderung, bauliche Trennung mittels Schranken oder Drehkreuzen sowie die strategische Positionierung des Empfangsbereichs optimiert werden. Zudem kann die Schulung des Empfangspersonals in Sicherheitsprotokollen und die Einführung von Besucherausweisen mit temporären Zugriffsrechten die Effektivität dieser Sicherheitsmaßnahme verstärken. Die Integration mit anderen Sicherheitssystemen wie Videoüberwachung oder elektronischen Zutrittskontrollsystemen kann ebenfalls in Betracht gezogen werden, um ein umfassendes Sicherheitskonzept zu gewährleisten.</p></td></tr><tr valign="top"><td>GEB.3.3: Authentifizierung vor Zutritt</td><td><p>Gebäudemanagement für Standorte SOLLTE Zutritte im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements authentifizieren.</p></td><td><p>Der Zweck der Authentifizierung von Zutritten liegt in der grundlegenden Absicherung physischer Zugänge gegen unbefugte Nutzung. Dies kann verhindern, dass Unbefugte Zugang zu sensiblen Bereichen oder Informationen erhalten. Ohne angemessene Zutrittskontrolle könnte beispielsweise ein nicht autorisierter Besucher in einen Serverraum gelangen und dort Hardware manipulieren, Datenträger entwenden oder Netzwerkkabel umstecken. Ebenso könnte ein ehemaliger Mitarbeiter ohne wirksame Authentifizierung weiterhin auf Systeme zugreifen und vertrauliche Daten entwenden oder geschäftskritische Informationen kompromittieren.  Bei der Umsetzung kann ein mehrstufiger Ansatz verfolgt werden, der verschiedene Authentifizierungsfaktoren kombiniert: Wissen (z.B. PIN-Codes, Passwörter), Besitz (z.B. Chipkarten, Tokens, Schlüssel) und biometrische Merkmale (z.B. Fingerabdruck, Gesichtserkennung). Die Stärke der Authentifizierung kann dabei an die Schutzbedürftigkeit des zu schützenden Bereichs angepasst werden – für hochsensible Bereiche können Zwei- oder Mehr-Faktor-Authentifizierungen implementiert werden. Als ergänzende Maßnahme kann ein Monitoring der Zutrittsereignisse eingerichtet werden, das ungewöhnliche Zugriffsversuche erkennt und meldet. Zudem kann die regelmäßige Überprüfung und Aktualisierung der Zutrittsberechtigungen dazu beitragen, dass nur aktuell berechtigte Personen Zugang erhalten. Die Formulierung <b>„im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik IDM festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>GEB.3.3.1: Zugangskontrollanlage</td><td><p>Gebäudemanagement für Standorte KANN Zutritte automatisch im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements authentifizieren.</p></td><td><p>Der Einsatz einer automatischen Zugangskontrollanlage zur Authentifizierung von Personen dient primär dem Schutz von sensiblen Bereichen, vertraulichen Informationen und kritischer Infrastruktur. Durch diese Maßnahme kann sichergestellt werden, dass nur autorisierte Personen Zutritt zu geschützten Bereichen erhalten, wodurch das Risiko von Industriespionage, Datendiebstahl oder Sabotage erheblich reduziert werden kann. Ohne eine solche Kontrolle könnte es beispielsweise zu unbefugtem Zutritt durch Fremde kommen, die sich als Mitarbeiter ausgeben, oder zu einem <b>„Tailgating“</b>-Vorfall, bei dem Unbefugte autorisierten Personen unbemerkt folgen und sich so Zugang verschaffen.  Bei der Implementierung einer automatischen Zugangskontrollanlage kann eine mehrfaktorielle Authentifizierung in Betracht gezogen werden, die auf einer Kombination aus Besitz (z.B. Chipkarte, Token), Wissen (PIN-Code, Passwort) und/oder biometrischen Merkmalen (Fingerabdruck, Gesichtserkennung) basiert. Die Zugangsrechte können granular nach Personengruppen, Zeitfenstern und Bereichen differenziert werden, was die Sicherheit weiter erhöht. Für eine effektive Umsetzung kann die regelmäßige Überprüfung der Protokolle der Zugangskontrollanlage auf ungewöhnliche Aktivitäten hilfreich sein, ebenso wie regelmäßige Sensibilisierungsmaßnahmen für Mitarbeiter bezüglich der korrekten Nutzung der Anlage und der Vermeidung von Sicherheitslücken wie dem gemeinsamen Nutzen von Zugangsmitteln. Die Formulierung <b>„im Einklang mit den Festlegungen des Identitäts- und Berechtigungsmanagements“</b> bedeutet, dass die Authentifizierung so erfolgt, wie in der Praktik IDM festgelegt. Hierzu gehört insbesondere die Verwendung aktueller kryptographischer Verfahren, wie sie im Thema Kryptographie zu finden ist.</p></td></tr><tr valign="top"><td>GEB.3.3.2: Dokumentation von Zutritten</td><td><p>Gebäudemanagement für Standorte KANN Zutritte und Austritte mit Identität und Zeitpunkt dokumentieren.</p></td><td><p>Im Kontext dieser Anforderung bedeutet Identität die eindeutige Zuordnung einer Person zu einem Zutritt oder Austritt, etwa durch Namensangabe, Personalnummer oder ein elektronisches Identifikationsmerkmal wie eine Chipkarte. Der Zeitpunkt ist die präzise Erfassung von Datum und Uhrzeit, an dem ein Zutritts- oder Austrittsvorgang stattfindet. Diese beiden Informationen können so kombiniert werden, dass nachvollziehbar wird, wer zu welchem Zeitpunkt ein Gebäude oder einen bestimmten Bereich betreten oder verlassen hat. Dies gilt sowohl für Mitarbeitende als auch für Besuchende. Für die Umsetzung kann eine Institution z.B. elektronische Zutrittskontrollsysteme einsetzen, die beim Karten- oder Transpondereinsatz automatisch Identität und Zeitpunkt speichern. Auch ein biometrisches Terminal kann die Anforderung erfüllen, wenn es die Daten mit Zeitstempel dokumentiert. Als einfachere Variante kann ein digital geführtes Besucherbuch genutzt werden, in das Namen und Uhrzeit bei Ein- und Austritt eingetragen werden. Eine Institution kann ergänzend festlegen, dass Daten regelmäßig exportiert und manipulationssicher archiviert werden, sodass spätere Prüfungen möglich sind. Hilfreich kann zudem sein, bei Zutrittskarten eine Schnittstelle zur HR-Verwaltung einzurichten, damit Identitäten bei Austritt von Mitarbeitenden automatisch deaktiviert werden und die Dokumentation lückenfrei bleibt. Diese Protokolle dienen als wichtige Grundlage für forensische Analysen und können zur Aufklärung von Diebstahl, Sabotage oder unbefugtem Datenzugriff beitragen.</p></td></tr><tr valign="top"><td>GEB.3.3.3: Besucheranmeldung</td><td><p>Gebäudemanagement für Standorte SOLLTE Besuche autorisieren.</p></td><td><p>Der Begriff „Besuche“ bezeichnet in diesem Kontext physische Zutritte externer Personen wie Dienstleister, Lieferanten oder Gäste, die sich nicht dauerhaft im Gebäude aufhalten und daher besondere Anforderungen an die Zutrittsregelung stellen. Die Autorisierung von Besuchen meint hier, dass ein Besuch vor Betreten der Räumlichkeiten durch eine verantwortliche Stelle vorab geprüft, freigegeben und dokumentiert wird – dies kann formell (z. B. digitaler Antrag) oder informell (z. B. Genehmigung per E-Mail) erfolgen. Der Zweck dieser Vorschrift liegt darin, unkontrollierten Zutritt und damit verbundene Risiken zu verhindern: Unangemeldete Besucher könnten beispielsweise unbefugt vertrauliche Informationen einsehen oder technische Anlagen manipulieren. Eine klare Autorisierung kann dagegen sicherstellen, dass nur berechtigte Personen Zutritt erhalten und gleichzeitig nachvollziehbar bleibt, wer sich wann und aus welchem Grund im Gebäude aufgehalten hat. Für die Umsetzung kann eine Institution etwa ein digitales Besuchermanagementsystem einsetzen, das Einladungen erstellt, Genehmigungen einholt und Einlasscodes zeitlich begrenzt vergibt. Alternativ kann ein analoges Verfahren genutzt werden, bei dem Besucherausweise am Empfang ausgegeben und gegen Vorlage eines Ausweisdokuments registriert werden. Um Warteschlangen am Empfang zu verringern, kann die Autorisierung des Besuchs auch im Voraus abgewickelt werden, z.B. über eine mobile QR-Vorregistrierung mit Verifizierung der Identität über den digitalen Ausweis. Eine einfache, aber wirksame Maßnahme kann auch die Vorabstimmung über Besuchslisten sein, die tagesaktuell an Empfang oder Sicherheitspersonal übermittelt werden.</p></td></tr><tr valign="top"><td>GEB.3.4: Berechtigungsmarkierung</td><td><p>Gebäudemanagement für Nutzende von Standorten KANN zum Tragen von gut sichtbaren Berechtigungsmarkierungen innerhalb des Sicherheitsperimeters anweisen.</p></td><td><p>Unter Berechtigungsmarkierungen sind physische Kennzeichen wie Ausweise, Badges, Namensschilder oder Kartenhalter zu verstehen, die eine eindeutige Zuordnung einer Person zu ihrer Zugangsberechtigung ermöglichen. Sie können zudem farblich, mit Fotos oder Barcodes gestaltet sein, um unterschiedliche Zutrittsrechte auf einfache Weise erkennbar zu machen. Der Sinn einer solchen Vorgabe liegt darin, dass unbefugte Personen leichter auffallen und damit potenzielle Gefährdungen frühzeitig erkannt werden. So könnte ein Vorfall entstehen, wenn sich Unbefugte unbemerkt Zutritt zu kritischen Bereichen verschaffen, indem sie sich in einer Gruppe mit berechtigten Personen bewegen. Dagegen kann eine sichtbare Berechtigungsmarkierung helfen, Anomalien rasch zu erkennen und eine unauffällige, aber effektive Zugangskontrolle im Alltag zu unterstützen. Dies gilt sowohl für Mitarbeitende als auch für Besuchende. Für die Umsetzung kann eine Institution beispielsweise darauf achten, dass Markierungen gut sichtbar an Kleidung oder einem Schlüsselband getragen werden können. Sie kann auch unterschiedliche Farbkennungen nutzen, um klar zwischen Besuchenden, Dienstleistern und Mitarbeitenden zu unterscheiden. Für Besuche kann ein einfaches Verfahren eingeführt werden, mit dem Besuchende beim Betreten des Gebäudes ein temporäres Ausweisdokument erhalten, das bei Verlassen wieder zurückzugeben ist. Um die Akzeptanz zu erhöhen, kann das Gebäudemanagement praktikable Trageoptionen wie Clips, Lanyards oder magnetische Halterungen bereitstellen, die den Alltag nicht behindern.</p></td></tr><tr valign="top"><td>GEB.3.5: Einbruchhemmung</td><td><p>Gebäudemanagement für Standorte KANN einbruchhemmende Bauteile nach <i>einer entsprechenden Norm</i> installieren.</p></td><td><p>Befinden sich am Standort Assets oder Geschäftsprozesse mit erhöhtem Schutzbedarf, so ist es sinnvoll, diese auch gegen hartnäckigere Einbruchsversuche zu schützen, z.B. größere Serverräume oder Datenträgerarchive, sowie Standorte im Fokus der Öffentlichkeit oder von ideologischen Gewalttätern.   Die passenden Maßnahmen richten sich nach dem Risikoprofil der zu schützenden Assets, sowie der potenziellen Täter. So kann der Einbau rundum einbruchsicherer Bauteile wie Wände und Türen nach DIN EN 1627 RC3 oder besser sinnvoll sein. Für massive Bedrohungen von Außen bieten sich Poller oder hydraulische Straßensperren, ausgelegt für ein bestimmtes Gewicht bei einer bestimmten Geschwindigkeit, an.  Die Anforderung ist auch dann erfüllt, wenn der Standort bereits von Dritten nach Normen wie DIN EN 1627 RC3 erbaut und abgenommen wurde.</p></td></tr><tr valign="top"><td>GEB.3.6: Einbruchmeldeanlagen</td><td><p>Gebäudemanagement für Standorte KANN Einbrüche nach <i>einer entsprechenden Norm</i> überwachen.</p></td><td><p>Für Standorte mit erhöhtem Schutzbedarf ist eine Einbruchmeldeanlage sinnvoll. Die Anforderung gilt erst dann als umgesetzt, wenn alle vorhandenen Türen, Fenster und sonstige geschützte Öffnungen über die Einbruchmeldeanlage auf Verschluss, Verriegelung und Durchbruch überwacht werden.</p></td></tr><tr valign="top"><td>GEB.3.7: Kontrolle der Zutrittskontrolle</td><td><p>Gebäudemanagement für Standorte SOLLTE die angewendeten Zutrittskontrollmaßnahmen <i>regelmäßig</i> überprüfen.</p></td><td><p>Die Funktionsfähigkeit von Zugangkontrollen wie Wachdiensten und Schließanlagen ist essenziell,  um den Zutritt Unbefugter wirksam verhindern zu können. Regelmäßige Überprüfungen können beispielsweise durch angekündigte oder unangekündigte Rundgänge, die stichprobenartige Auswertung von Kameraaufzeichnungen und Logbüchern oder die Analyse verschiedener Kennzahlen erfolgen.</p></td></tr></table><h2>GEB.4: Umwelteinflüsse</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.4.1: Klimatisierung</td><td><p>Gebäudemanagement für Standorte SOLLTE eine ausreichende Klimatisierung von Räumlichkeiten anhand von <i>Schwellwerten</i> installieren.</p></td><td><p>Klimatisierung meint das Erzeugen und Aufrechterhalten von Temperatur und Luftfeuchtigkeit innerhalb bestimmter Schwellwerte.   Zur Bestimmung der Schwellwerte können verschiedene Angaben herangezogen werden, u.a. Herstellerangaben für die am Standort betriebenen Systeme, Compliance-Vorgaben zur Arbeitsplatzsicherheit, branchenspezifische Normen und Standards (z.B. DIN EN ISO 7730), Energieeffizienzrichtlinien und Umweltvorschriften, sowie wissenschaftliche Erkenntnisse zu optimalen Arbeitsbedingungen.  Die Implementierung kann umfassen: Die Gestaltung von Räumen mit klarer Trennung von Zu- und Abluftwegen, um Innenzirkulation zu vermeiden; Beseitigung von Hindernissen in kritischen Luftstromwegen; Implementierung geeigneter Einschlusslösungen für bestimmte Anwendungsfälle (z. B. heiße/kalte Servergänge oder Reinräume in der Fertigung); Optimierung der Geräteplatzierung zur Maximierung einer effizienten Luftverteilung; regelmäßige Wartung der Belüftungssysteme, einschließlich Filteraustausch und Kanalreinigung; strategische Platzierung von Ablenkblechen oder Deflektoren zur Lenkung des Luftstroms; saisonale Anpassung der HLK-Einstellungen an sich ändernde äußere Bedingungen; Einsatz drehzahlvariabler Ventilatoren und intelligenter Steuerungen, um dynamisch auf sich ändernde Lasten zu reagieren; regelmäßige Wärmebildaufnahmen, um entstehende Probleme zu erkennen. Den größen Nutzen bringt es in der Regel zunächst die größten Hindernisse zu beseitigen, sowie die Abdichtung unerwünschter Luftwege und die Optimierung der wichtigsten lufttechnischen Anlagen zu beachten. In Serverräumen empfiehlt sich oft eine gedrehte Rack-Ausrichtung, sodass die Luftzufuhr der Geräte aus kalten Gängen erfolgt, während die Abluft direkt in warmen Gänge geleitet wird, wodurch eine Rezirkulation verhindert und die Kühlung aufrechterhalten wird. Gleichzeitig verbessert diese Konfiguration die Betriebspraktikabilität durch die Positionierung der Kabelanschlüsse für einen bequemen Zugang der Techniker, ohne die Luftstrommuster zu unterbrechen.</p></td></tr><tr valign="top"><td>GEB.4.1.1: Luftstrom-Analyse</td><td><p>Gebäudemanagement für Serverräume KANN den Klimatisierungsbedarf anhand einer Luftstrom-Analyse <i>regelmäßig</i> überprüfen.</p></td><td><p>Luftstromanalyse ist die systematische Bewertung von Luftbewegungsmustern zur Optimierung der Kühleffizienz und zur Vermeidung von Geräteausfällen. Dabei wird untersucht, wie die kalte Luft in der Einrichtung verteilt wird, es werden potenzielle Hotspots oder Bereiche mit Stagnation identifiziert, und es wird ein ordnungsgemäßer Wärmeaustausch durch die Überwachung der Einlass- und Auslasstemperaturen in den Serverracks sichergestellt. Zu den möglichen Methoden gehören CFD-Modelle (Computational Fluid Dynamics) zur Simulation von Luftströmungsmustern vor der Implementierung, der Einsatz von Temperatur- und Luftströmungssensoren an strategischen Stellen, Rauchtests zur visuellen Verfolgung der Luftbewegungspfade und Druckdifferenzmessungen zur Überprüfung der Integrität des Containments. Ein gut ausgeführtes Luftstrommanagement steht außerdem in direktem Zusammenhang mit geringeren Kühlkosten (oft 20-30 % Einsparungen), einer längeren Lebensdauer der Geräte und einer höheren Rechendichte pro Quadratmeter.  Zu den bewährten Lösungen zur besser Zirkulation gehören die Eingrenzung von Warm- und Kaltgängen, um eine Vermischung der Luftströme zu verhindern, die Aufrechterhaltung optimaler Rack-Einlasstemperaturen, die Sicherstellung einer angemessenen Perforation der Bodenfliesen in Doppelbodenumgebungen, die Optimierung der Serverplatzierung, um einen Bypass-Luftstrom zu vermeiden, und die Durchführung regelmäßiger Wärmebilduntersuchungen, um sich entwickelnde Probleme zu erkennen. Besonderer Aufmerksamkeit bedarf das Kabelmanagement, da eine ungeordnete Verkabelung den Luftstrom um bis zu 60 % behindern kann; ebenso ist es sinnvoll Abdeckplatten aller ungenutzten Rack-Räume abzudichten, um eine innere Zirkulation heißer Luft zu verhindern.</p></td></tr><tr valign="top"><td>GEB.4.1.2: Klimamessung</td><td><p>Gebäudemanagement für Serverräume SOLLTE Lufttemperatur und Luftfeuchtigkeit anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>IT-Infrastruktur benötigt typischerweise eine Umwelttemperatur von nicht viel mehr als 25°C und eine Luftfeuchtigkeit von nicht über 60%. Bei höheren Werten altern Komponenten schneller und das Risiko von Ausfällen durch Abwärme oder Spannungsüberschläge steigt. Ermitteln Sie Grenzwerte anhand der Herstellerangaben der im Raum eingesetzten Komponenten. Die Überwachung kann mit klimatechnischen Sensoren in den Geräten selbst oder im Raum realisiert werden. Eine saisonale Anpassung der Lüftungsanlagen kann erforderlich sein, insbesondere in Einrichtungen, die mit Eco-Modus arbeiten.</p></td></tr><tr valign="top"><td>GEB.4.1.3: Redundante Klimatisierung</td><td><p>Gebäudemanagement für Standorte KANN redundante Klimasysteme installieren.</p></td><td><p>Redundant ist eine Klimatisierung, wenn alle zu ihrer Funktionsfähigkeit erforderlichen Komponenten und Anbindungen redundant sind, d.h. kein einzelner Fehlerpunkt zu einem Ausfall führen würde (Single Point of Failure).</p></td></tr></table><h2>GEB.5: Sicherheitsbereiche</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.5.1: Einrichtung</td><td><p>Gebäudemanagement für Standorte KANN geschlossene Sicherheitsbereiche installieren.</p></td><td><p>Ein Sicherheitsbereich ist ein klar abgegrenzter physischer Raum, für die ein eigener Perimeter eingerichtet wird und dessen Betreten ausschließlich autorisiertem Personal oder unter engen Voraussetzungen gestattet wird. Solche Bereiche dienen dem Schutz von Personen, Anlagen, sensiblen Informationen oder betriebskritischen Prozessen. Standorte oder Teile eines Standortes mit erhöhtem Schutzbedarf können so vor unbefugten Eingriffen geschützt werden, z.B. Serverräume, Arbeitsplätze für Administrierende oder die Institutionsleitung. Zur Umsetzung können z.B. Zutrittskontrollanlagen oder Bewachung eingesetzt werden. Wenn es sich um Hochsicherheitsbereiche handelt, kann der Zutritt mit einem Mehr-Faktor-Verfahren (z.B. Smartcard mit PIN) davor geschützt werden, dass Unbefugte sich durch entwendete Schlüssel oder Authentifizierungstoken Zugang verschaffen.</p></td></tr><tr valign="top"><td>GEB.5.2: Gesonderte Autorisierung</td><td><p>Gebäudemanagement für Standorte KANN die Zutrittsberechtigung zu diesem Sicherheitsbereich durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Eine zuständige Person oder Rolle kann beispielsweise die Sicherheitsbeauftragte, der Standortleiter, eine definierte Facility-Management-Rolle oder ein zentrales Berechtigungsmanagement sein. Die Anforderung bedeutet, dass der Zutritt zu einem definierten Sicherheitsbereich – also einem räumlich abgegrenzten Bereich, in dem sensible Werte wie IT-Systeme, Netzwerktechnik oder vertrauliche Unterlagen geschützt werden – nicht automatisch, sondern nur durch eine bewusste Autorisierung erteilt werden kann. Sinn und Zweck dieser Regelung liegt darin, unbefugte Zugriffe zu verhindern, die etwa durch unkontrollierte Weitergabe von Schlüsseln oder Zutrittskarten entstehen könnten. Ein Vorfall könnte sein, dass ein ehemaliger Mitarbeiter noch Zugang erhält und vertrauliche Unterlagen entwendet; durch eine klare Autorisierung kann sichergestellt werden, dass nur tatsächlich berechtigte Personen Zutritt erhalten. Zur Umsetzung kann eine Institution ein abgestuftes Verfahren einrichten, bei dem die Autorisierung dokumentiert und nachvollziehbar erfolgt. Dies kann z. B. durch ein zentrales elektronisches Zutrittskontrollsystem erfolgen, bei dem eine zuständige Rolle die Rechte gezielt freischalten und zeitlich begrenzen kann. Auch eine papierbasierte Liste mit Zutrittsberechtigungen kann sinnvoll sein, solange sie regelmäßig geprüft und aktualisiert wird. Praktisch hilfreich kann es sein, wenn (1) jede Berechtigung mit einem Enddatum versehen wird, (2) der Widerruf von Berechtigungen in die Prozesse für Personaländerungen integriert wird, und (3) das Gebäudemanagement regelmäßig Berichte über aktive Berechtigungen an die zuständige Person liefert. So kann sichergestellt werden, dass Zutrittsrechte nicht veralten und jederzeit eine klare Zuordnung von Personen zu Sicherheitsbereichen besteht.</p></td></tr><tr valign="top"><td>GEB.5.3: Schleusen</td><td><p>Gebäudemanagement für Standorte KANN Schleusen an Zugangspunkten installieren.</p></td><td><p>Eine Schleuse bezeichnet im Gebäudemanagement eine bauliche oder technische Einrichtung, die den Zutritt an einem Zugangspunkt so regelt, dass jeweils nur eine Person oder ein definiertes Objekt kontrolliert den Bereich passieren kann. Typische Formen sind Personenvereinzelungsanlagen wie Drehkreuze, Sicherheitsschleusen mit zwei Türen, die nie gleichzeitig geöffnet sind, oder Materialschleusen für Lieferungen. Der Sinn einer solchen Einrichtung liegt darin, unkontrolliertes Eindringen oder das Einschleusen unbefugter Personen zu verhindern. Ohne Schleusen könnte etwa jemand einer berechtigten Person unbemerkt folgen („Tailgating“) oder mehrere Personen gleichzeitig eine Zugangskarte verwenden. Mit Schleusen kann dagegen sichergestellt werden, dass jede Person oder jedes Transportgut einzeln überprüft wird und Manipulationsversuche erkannt werden.  Für die Umsetzung kann eine Institution verschiedene Maßnahmen wählen: (1) Eine Schleuse kann mit Zutrittskontrollsystemen gekoppelt werden, sodass Türen erst nach erfolgreicher Authentifizierung (z. B. Kartenleser oder biometrische Erkennung) freigegeben werden. (2) Sensoren wie Gewichtssensoren oder 3D-Kameras können zusätzlich eingesetzt werden, um das Mitführen weiterer Personen zu erkennen. (3) Bei Material- oder Lieferantenschleusen kann ein Zwei-Personen-Prinzip implementiert werden, sodass ein Mitarbeiter der Institution den Vorgang begleitet. Auch prozessuale Ergänzungen wie regelmäßige Tests der Schleusenfunktionen, klare Regelungen zum Verhalten bei Fehlalarmen oder Hinweisschilder für Besucher können die Wirksamkeit erhöhen. So kann der Zugang zum Gebäude an kritischen Punkten kontrolliert und ein hohes Maß an physischer Sicherheit erzielt werden.</p></td></tr><tr valign="top"><td>GEB.5.4: Vereinzelungsanlage</td><td><p>Gebäudemanagement für Standorte KANN Vereinzelungsanlagen an Zugangspunkten installieren.</p></td><td><p>Eine Vereinzelungsanlage ist eine technische Einrichtung, die den gleichzeitigen Zutritt mehrerer Personen verhindert und so den Zugang zu besonders sensiblen Bereichen kontrolliert. Typische Beispiele sind Drehkreuze, Personenschleusen oder Sicherheitsschleusen mit Gewichtssensoren. Der Sinn dieser Maßnahme liegt darin, unbefugtes Betreten durch sogenanntes „Tailgating“ (eine Person folgt unberechtigt einer berechtigten Person) oder durch Einschleusen mehrerer Personen mit einem Zugangsausweis zu verhindern. Ohne solche Einrichtungen könnte es passieren, dass fremde Personen unerkannt in Serverräume oder Entwicklungsbereiche gelangen. Mit einer Vereinzelungsanlage kann hingegen zuverlässig sichergestellt werden, dass nur eine eindeutig identifizierte Person Zutritt erhält.  Für die Umsetzung kann eine Institution mehrere Möglichkeiten nutzen: (1) Drehkreuze oder Sensorschleusen können an Hauptzugängen zu Bereichen mit kritischen Informationen eingesetzt werden, wobei sie mit Zutrittskontrollsystemen wie Chipkarten- oder Biometrie-Lesern kombiniert werden können. (2) Eine Zwei-Türen-Schleuse kann eingerichtet werden, die erst die zweite Tür freigibt, wenn die erste korrekt geschlossen ist und die Person authentifiziert wurde. (3) Sensorische Zusatzkontrollen wie Gewichtserkennung oder Volumendetektion können dabei helfen, dass keine zweite Person unerkannt mit hindurchgeht. Zudem kann die Wirksamkeit erhöht werden, wenn diese Systeme mit klaren Nutzungsregeln, wie Schulungen zum richtigen Durchschreiten und Hinweisschildern, ergänzt werden. Auch ein regelmäßiger Funktionstest der Anlagen kann helfen, Manipulation oder Fehlfunktionen frühzeitig zu erkennen.</p></td></tr></table><h2>GEB.6: Gemeinsame Arbeitsbereiche</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.6.1: Clean Desk</td><td><p>Gebäudemanagement für Räume SOLLTE zum Aufräumen von vertraulichen Dokumenten und Datenträgern vor dem Verlassen des Arbeitsplatzes anweisen.</p></td><td><p>Ein aufgeräumter Arbeitplatz („Clean Desk Policy“) kann dazu beitragen, Informationssicherheit und Datenschutz am Arbeitsplatz zu stärken, indem sie verhindert, dass vertrauliche Unterlagen, Datenträger oder elektronische Geräte unbefugt eingesehen oder entwendet werden. Durch konsequentes Aufräumen am Ende des Arbeitstages oder bei längeren Abwesenheiten kann das Risiko von Datenlecks, Industriespionage oder versehentlicher Offenlegung sensibler Informationen minimiert werden. Gleichzeitig kann eine aufgeräumte Arbeitsumgebung die Konzentration und Effizienz der Mitarbeitenden fördern, da unnötige Ablenkungen reduziert werden und das Wiederfinden wichtiger Unterlagen beschleunigt wird.  Hierzu gehören sowohl physische Unterlagen wie Akten, Notizzettel oder Ausdrucke mit personenbezogenen oder geschäftskritischen Daten, als auch elektronische Datenträger oder Bildschirminhalte.</p></td></tr><tr valign="top"><td>GEB.6.2: Screen Lock</td><td><p>Gebäudemanagement für Räume SOLLTE zum Sperren von IT-System vor dem Verlassen des Arbeitsplatzes anweisen.</p></td><td><p>Diese Vorgehensweise hilft dabei, unbefugten Zugriff auf sensible Informationen zu verhindern, die auf dem Bildschirm angezeigt werden könnten. Ansonsten könnte es zu unbefugten Zugriffen auf Daten oder die Systeme selber kommen, wenn diese unbewacht und ungesperrt zurückgelassen werden.</p></td></tr><tr valign="top"><td>GEB.6.3: Lieferzugang</td><td><p>Gebäudemanagement für Standorte SOLLTE einen Zugang für die Abwicklung von Lieferungen ohne unbefugten Zugang zum restlichen Standort installieren.</p></td><td/></tr><tr valign="top"><td>GEB.6.4: Schutz gegen Manipulation</td><td><p>Gebäudemanagement für IT-Systeme KANN Manipulationsschutzvorkehrungen installieren.</p></td><td/></tr><tr valign="top"><td>GEB.6.5: Mikrosegmentierung</td><td><p>Gebäudemanagement für IT-Systeme KANN eine physische Mikrosegmentierung installieren.</p></td><td><p>Bei der physischen Mikrosegmentierung in der Sicherheitsarchitektur geht es darum, unterschiedliche physische Grenzen innerhalb gemeinsam genutzter Einrichtungen zu schaffen, um verschiedene Sicherheitsbereiche zu isolieren und zu schützen. Dies ist besonders wichtig für Umgebungen, in denen Assets mit verschiedenen Sicherheitseigenschaften nebeneinander existieren. Bei dieser Strategie werden bauliche Maßnahmen eingesetzt, wie z. B. getrennte Eingänge, dedizierte Versorgungssysteme, Fallen, abgeschottete HLK-Anlagen, physisch getrennte Netzwerkinfrastrukturen und zugangskontrollierte Zonen, um die seitliche Bewegung von Bedrohungen zu verhindern und gleichzeitig die Einhaltung von Vorschriften zu gewährleisten. Zu den üblichen Anwendungen gehören Bürogebäude mit mehreren Mietparteien, in denen verschiedene Institutionen eine Trennung benötigen, Colocation-Rechenzentren mit kundenspezifischer Geräteisolierung, gemeinsam genutzte Regierungseinrichtungen mit unterschiedlichen Klassifizierungsanforderungen und Campus-Umgebungen, in denen miteinander verbundene Gebäude unterschiedliche Sicherheitsperimeter aufrechterhalten müssen - all dies unterstützt ein umfassendes Risikomanagement und die Eindämmung von Vorfällen.  Maßnahmen können z.B. intelligenten Schlössern an Käfigtüren und Sensoren an den Seitenwänden von Serverracks sein.</p></td></tr></table><h2>GEB.7: Platzierung von Assets</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.7.1: Zugang zu Ausgabesystemen</td><td><p>Gebäudemanagement für IT-Systeme SOLLTE den Zugang zu nicht-öffentlichen Ausgabesystemen einschränken.</p></td><td><p>Ausgabesysteme sind z.B. Monitore oder Drucker. Nicht-öffentlich sind diese, wenn darauf schützenswerte Inhalte ausgegeben werden, z.B. Arbeitsplätze von internen Sachbearbeitern, Netzdrucker der Personalabteilung.</p></td></tr><tr valign="top"><td>GEB.7.2: Geschützte Aufstellung</td><td><p>Gebäudemanagement für IT-Systeme SOLLTE diese geschützt vor dem Zugriff von Unbefugten platzieren.</p></td><td><p>„Unbefugter Zugriff“ bedeutet in diesem Kontext jeder physische Zutritt oder jede Manipulation durch Personen, die keine rechtmäßige Berechtigung für die Nutzung, Wartung oder Überwachung dieser Systeme besitzen. Der Sinn und Zweck dieser Vorgabe liegt im Schutz vor Verlust, Manipulation oder Unterbrechung des Betriebs durch unkontrollierte physische Einwirkungen. Ohne geeignete Schutzmaßnahmen könnte ein unbefugter Dritter Systeme entwenden, manipulieren oder absichtlich beschädigen; ebenso könnte durch unkontrollierten Zutritt das Risiko von Stromausfällen oder Fehlbedienungen entstehen. Eine angemessene bauliche Platzierung kann hingegen sicherstellen, dass nur autorisierte Personen Zugang erhalten und die Verfügbarkeit sowie Integrität der Systeme langfristig gewährleistet bleibt. Eine Umsetzung kann durch baulich-technische Maßnahmen wie verschließbare Serverschränke mit dokumentierter Schlüsselverwaltung oder den Einsatz von Zugangskontrollen mit elektronischen Schließsystemen erfolgen.</p></td></tr><tr valign="top"><td>GEB.7.2.1: Hostsysteme</td><td><p>Gebäudemanagement für Hostsysteme SOLLTE diese ausschließlich in Serverräumen platzieren.</p></td><td><p>Sinn und Zweck dieser Anforderung liegt darin, die Risiken durch unkontrollierten physischen Zugriff oder Umwelteinflüsse zu reduzieren: Ohne räumliche Trennung könnte ein Mitarbeiter versehentlich gegen ein frei im Büro aufgestelltes Hostsystem stoßen und es beschädigen, oder ein Besucher könnte unbemerkt Manipulationen vornehmen. Durch Platzierung in einem Serverraum kann hingegen erreicht werden, dass Geräte vor unbefugtem Zugriff geschützt sind und kontrollierte Umgebungsbedingungen wie Temperatur oder Luftfeuchtigkeit den zuverlässigen Betrieb fördern. Praktisch kann es hilfreich sein, Hostsysteme in standardisierten Serverschränken unterzubringen, die zusätzlich verschließbar sind, und regelmäßig zu prüfen, ob keine Fremdgeräte unautorisiert im Serverraum abgestellt wurden. Auf diese Weise kann die Institution sicherstellen, dass Hostsysteme physisch geschützt und unter stabilen Betriebsbedingungen betrieben werden.</p></td></tr><tr valign="top"><td>GEB.7.3: Netzkomponenten</td><td><p>Gebäudemanagement für Netze SOLLTE für die Funktionsfähigkeit des Netzes erforderliche Systeme ausschließlich in Räumen für technische Infrastruktur platzieren.</p></td><td/></tr><tr valign="top"><td>GEB.7.4: Normgerechte Rechenzentren</td><td><p>Gebäudemanagement für Serverräume KANN diese ausschließlich in normgerechten Rechenzentren platzieren.</p></td><td><p>Serverräume enthalten für den Betrieb essenzielle IT-Systeme. Für Serverräume mit höherem Schutzbedarf ist es daher sinnvoll diese ausschließlich in Rechenzentren, die nach DIN EN 50600 gesichert sind, zu betreiben.</p></td></tr></table><h2>GEB.8: Schlüsselverwaltung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.8.1: Schlüsselbeauftragte</td><td><p>Gebäudemanagement für Standorte SOLLTE die Verwaltung von Schlüsseln <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Bei der Verwaltung von Schlüsseln werden physische Schlüssel und digitale Zugangsmittel wie RFIDs für Gebäude, Räume oder Schränke ausgegeben, zurückgenommen und deren Nutzung dokumentiert. Mögliche Ausprägungen für zuständige Personen oder Rollen können (1) Facility-Management, (2) IT-Sicherheitsbeauftragte, (3) Empfangs- oder Pförtnerdienste oder (4) ein zentrales Schlüsselmanagement-Team sein. Der Zweck der Vorschrift liegt darin, Risiken durch unkontrollierte Schlüsselvergabe zu reduzieren. Ohne klare Zuweisung könnte es zu unbefugtem Zutritt, Diebstahl oder Manipulation an kritischen Bereichen kommen. Durch eine geregelte Schlüsselverwaltung kann hingegen nachvollziehbar und kontrolliert gesteuert werden, wer physischen Zugang zu sicherheitsrelevanten Bereichen erhält. Zur Umsetzung können Institutionen (1) Schlüssellisten auf Papier oder in Form einer Berechtigungsmatrix führen, die regelmäßig gepflegt und abgeglichen wird, (2) Reserveschlüssel zentral und sicher verwahren, damit im Verlustfall ein geregelter Ersatz möglich ist, und (3) sicherstellen, dass nicht mehr benötigte Schlüssel zeitnah zurückgenommen und dokumentiert werden. Technisch kann die Verwaltung durch nummerierte Schlüsselanhänger oder anonymisierte Kennzeichnungen unterstützt werden, sodass keine Rückschlüsse auf den Einsatzort möglich sind. Auch ein einfaches Verfahren, bei dem die Rücknahme von Schlüsseln mit Datum und Unterschrift bestätigt wird, kann Transparenz schaffen und spätere Unklarheiten verhindern.</p></td></tr><tr valign="top"><td>GEB.8.2: Verwahrung von Schlüsseln</td><td><p>Gebäudemanagement für Standorte SOLLTE zur Verwahrung von Schlüsseln anweisen.</p></td><td><p>Eine Verwahrung ist eine Aufbewahrung von Zugangssschlüsseln derart, dass Unbefugte keinen Zugriff hierauf haben. Dies kann durch das Mitführen der Schlüssel, oder durch eine verschlossene Aufbewahrung, z.B. in einem Schlüsselschrank, umgesetzt werden.</p></td></tr><tr valign="top"><td>GEB.8.3: Schlüsselaudit</td><td><p>Gebäudemanagement für Standorte SOLLTE die vorhandenen Schlüssel <i>regelmäßig</i> überprüfen.</p></td><td><p>Ohne eine solche Kontrolle könnten z. B. verlorene, vergessene oder unregistrierte Schlüssel im Umlauf bleiben, was zu einem unerkannten Sicherheitsrisiko führt. Ein Vorfall könnte darin bestehen, dass ein ehemaliger externer Dienstleister noch Zugang zu Räumen hat, in denen vertrauliche Unterlagen oder wertvolle Geräte aufbewahrt werden, oder dass ein entwendeter Schlüssel später unbemerkt für Einbruch und Diebstahl genutzt wird. Praktisch kann eine Institution dies umsetzen, indem sie ein aktuelles Schlüsselinventar führt und dieses in festgelegten Abständen mit den tatsächlich im Umlauf befindlichen Schlüsseln abgleicht. Sinnvoll ist auch, bei der Überprüfung nicht nur auf Vollständigkeit, sondern auf Plausibilität zu achten – beispielsweise ob Schlüssel für inzwischen nicht mehr genutzte Räume weiterhin im Umlauf sind. Bei normalen Schutzbedarf genügt eine stichprobenartige Kontrolle, Schlüssel mit höherem Schutzbedarf (z.B. für Sicherheitsbereiche) dagegen bedürfen in der Regel einer häufigeren, vollständigen Kontrolle.</p></td></tr></table><h2>GEB.9: Verwahrung von Speichermedien</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.9.1: Gesonderte Aufbewahrung</td><td><p>Gebäudemanagement für Standorte SOLLTE geschäftskritische Speichermedien in verschließbaren Schutzeinrichtungen platzieren.</p></td><td><p>Herumliegende vertrauliche Speichermedien - sowohl analoge Dokumente als auch digitale  Datenträger - sind ein leichtes Ziel für Diebe und können versehentlich verloren gehen oder beschädigt werden.   Kann durch abschließbare Schränke oder Safes oder dedizierte Räumlichkeiten umgesetzt werden. Die Anforderung ist auch dann erfüllt, wenn das Behältnis fest verbaut ist (z.B. Safe-Raum).</p></td></tr><tr valign="top"><td>GEB.9.1.1: Archiv</td><td><p>Gebäudemanagement für Standorte KANN geschäftskritische Speichermedien in Datenträgerarchiven platzieren.</p></td><td/></tr><tr valign="top"><td>GEB.9.2: Staub und Schmutz</td><td><p>Gebäudemanagement für Datenträgerarchiv KANN Maßnahmen zum Schutz der Datenträger vor Staub und Schmutz verankern.</p></td><td><p>Werden analoge und digitale Datenträger länger im Archiv aufbewahrt, so besteht das Risiko der schleichenden Zersetzung durch Staub und Schmutz. Maßnahmen sind z.B. staubdichte und antistatische Lagerung in Schutzschränken, Klimatisierung, Schutzkleidung, trockene Reinigung.</p></td></tr><tr valign="top"><td>GEB.9.3: Schutz der Datenträger vor Brandschäden</td><td><p>Gebäudemanagement für Standorte KANN feuerfeste Behältnisse nach <i>einem anerkannten Standard</i> installieren.</p></td><td><p>Datenträgerarchive sind bei Bränden besonders schützenswert, da hier häufig die langzeitig kritischen Daten gelagert werden. Kann durch Brandschutzschränke oder Datensafes umgesetzt werden, die nach DIN EN 1047-1 oder ISO 11799 zertifiziert sind.</p></td></tr><tr valign="top"><td>GEB.9.4: Überwachung schonender Klimatisierung</td><td><p>Gebäudemanagement für Datenträgerarchiv KANN für die Datenträger schonende Temperatur und Luftfeuchtigkeit anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>IT-Infrastruktur benötigt typischerweise eine Umwelttemperatur von nicht viel mehr als 25°C und eine Luftfeuchtigkeit von nicht über 60%. Bei höheren Werten altern Komponenten schneller und das Risiko von Ausfällen durch Abwärme oder Spannungsüberschläge steigt. Grenzwerte können anhand der Herstellerangaben der im Raum eingesetzten Datenträger ermittelt werden. Die Überwachung kann mit klimatechnischen Sensoren im Raum realisiert werden.</p></td></tr></table><h2>GEB.10: Versorgungseinrichtungen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.10.1: Normgerechte Stromversorgung</td><td><p>Gebäudemanagement für Standorte SOLLTE eine norm- und bedarfsgerechte Stromversorgung und -verkabelung installieren.</p></td><td><p>Eine Stromversorgung ist normgerecht, wenn Normen zur Bereitstellung und Verkabelung wie DIN VDE 0100 eingehalten werden. Bedarfsgerecht ist eine Stromversorgung, wenn sie den Strombedarf der IT-Systeme und anderen Geräte im Gebäude deckt und Reserven für Erweiterungen oder Notfälle bietet. Das betrifft sowohl zentrale Versorgungsanschlüsse, Unterverteilungen als auch die Zuleitung in die einzelnen Räume. Die Anforderung ist auch dann erfüllt, wenn eine den Compliance-Vorschriften für Strom entsprechende Versorgung bereits im Gebäude vorhanden ist. Im Fall von Rechenzentren ist auch auf die Möglichkeit der Notabschaltung der Stromversorgung (für einzelne elektrische Verbraucher) zu achten. Hier ist eine sinnvolle Parzellierung und Zielgerichtetheit bei der Notabschaltung von Bedeutung.</p></td></tr><tr valign="top"><td>GEB.10.1.1: Vorausschauende Lastanalyse</td><td><p>Gebäudemanagement für Standorte KANN die bedarfsgerechte Stromversorgung <i>regelmäßig</i> vorausschauend überprüfen.</p></td><td><p>Die prädiktive Lastanalyse in Stromversorgungssystemen bezieht sich auf die ausgefeilte Analyse von elektrischen Lastmustern, einschließlich Oberschwingungen der Stromqualität, um den zukünftigen Stromverbrauch und Qualitätsprobleme vorherzusagen, bevor sie auftreten. Sie kann in Bereichen, in denen die Stromversorgung von höchster Bedeutung ist, helfen, die kontinuierliche Verfügbarkeit der IT-Infrastruktur durch Überwachung und Vorhersage potenzieller Stromanomalien sicherzustellen, die die Systemintegrität gefährden könnten. Im Gegensatz zu reaktiven Ansätzen, die Probleme erst nach ihrem Auftreten angehen, werden bei der vorausschauenden Lastanalyse fortschrittliche Algorithmen zur Analyse historischer Stromverbrauchsdaten, harmonischer Verzerrungen und Spannungsschwankungen eingesetzt, um Muster zu erkennen, die auf bevorstehende Stromversorgungsprobleme hinweisen.  Die Implementierung kann mit Netzqualitätsanalysatoren an kritischen Infrastrukturpunkten, Integration mit SCADA-Systemen und durch Analyse mit Algorithmen des maschinellen Lernens, die Netzanomalien mit bestimmten Betriebsbedingungen korrelieren, geschehen. Eine regelmäßige Validierung der Vorhersagemodelle anhand tatsächlicher Vorfälle hilft die Analyse zu verbessern, während die Integration mit automatisierten Energieverwaltungssystemen einen dynamischen Lastausgleich während vorhergesagter Stressperioden ermöglichen kann, wodurch sowohl die Stromqualität, als auch die Systemverfügbarkeit ohne menschliches Eingreifen aufrechterhalten werden.</p></td></tr><tr valign="top"><td>GEB.10.1.2: Dedizierte Elektrounterverteilung</td><td><p>Gebäudemanagement für Standorte KANN eine ausschließlich für diesen Standort bestimmte Elektrounterverteilung die direkt von der Niederspannungshauptverteilung (NSHV) versorgt wird installieren.</p></td><td/></tr><tr valign="top"><td>GEB.10.1.3: Redundante Stromversorgung</td><td><p>Gebäudemanagement für Standorte KANN eine redundante Stromversorgung für <i>eine Stützzeit</i> installieren.</p></td><td><p>Wenn die Stromzufuhr ausfällt, könnten geschäftskritische Anwendungen unerwartet ausfallen oder Daten verlorengehen.   Die Redundanz der Stromquelle kann z.B. durch einen im System integrierten Akku, durch eine eigenständige unterbrechungsfreie Stromversorgung (USV) oder durch die Anbindung an ein sekundäres Stromnetz gewährleistet werden. Bei Bedarf kann sie auch die Übergangszeit bis zum Anlauf einer längerfristigen Netzersatzanlage überbrücken. Beim Betrieb einer USV ist auf die Einhaltung eines akzeptablen Temperaturbereichs der Batterie zu achten. Bei relevanten Änderungen an den Verbrauchern könnte es vorkommen, dass die USV-Systeme nicht mehr ausreichend dimensioniert sind. Da der Leistungsbedarf von Klimaanlagen oft zu hoch für eine USV ist, empfiehlt es sich zumindest die Steuerung der Anlagen an die unterbrechungsfreie Stromversorgung anzuschließen. Eine regelmäßige Wartung (u.U. nach Vorgabe des Herstellers) der USV und eine Trennung der Leistungselektronik von der Batterie ist empfohlen. Bei sehr hohem Schutzbedarf empfiehlt sich eine redundante Auslegung der USV.  Die minimale Stützzeit (Autonomiezeit) ergibt sich als Stützzeit = Wartezeit auf mögliche Wiederkehr der Stromversorung + 2 * Zeit zum Herunterfahren der Komponenten. Bei sehr hohem Schutzbedarf empfiehlt sich eine redundante Auslegung der USV.  Die Verkabelungswege sind redundant, wenn die Leitungen über verschiedene Wege geführt sind, sodass z.B. eine versehentliche Trennung nicht beide Leitungen betrifft.</p></td></tr><tr valign="top"><td>GEB.10.1.4: Langanhaltende Sekundärversorgung</td><td><p>Gebäudemanagement für Standorte KANN eine redundante Stromversorgung für <i>eine längere Stützzeit</i> installieren.</p></td><td><p>Eine längere Stützzeit bezeichnet im Kontext der Stromversorgung die Fähigkeit, elektrische Energie über einen Zeitraum von mehreren Stunden oder sogar Tagen aufrechtzuerhalten, typischerweise durch den Einsatz einer Netzersatzanlage (NEA) oder vergleichbarer Infrastruktur. Während eine kurzzeitige Überbrückung durch unterbrechungsfreie Stromversorgungen (USV) lediglich Sekunden bis Minuten abdeckt, kann eine NEA längere Stromausfälle abfangen und die Betriebsfähigkeit kritischer Systeme dauerhaft sicherstellen. Risiken bestehen darin, dass ein Standort bei einem längerfristigen Netzausfall ohne redundante Stromversorgung seine sicherheitskritischen Prozesse nicht mehr betreiben könnte, was etwa zu Datenverlusten, Produktionsstillständen oder Ausfällen der Zutrittskontrolle führen könnte. Eine redundante Stromversorgung kann dem entgegenwirken, indem sie kritische Infrastrukturen wie Rechenzentren, Kommunikationssysteme oder Zutrittssysteme auch bei großflächigen Netzstörungen handlungsfähig hält. Zur Betriebsfähigkeit gehört auch die regelmäßige Wartung und Überprüfung des Betriebsmittelvorrats. Eine Institution kann die Anforderung umsetzen, indem sie geeignete technische Maßnahmen einplant: (1) Installation einer Netzersatzanlage mit automatischer Umschaltung auf Diesel- oder Gasgeneratoren, (2) Bereitstellung von Kraftstoffvorräten für eine definierte Stützzeit von beispielsweise 24, 48 oder 72 Stunden, (3) regelmäßige Lasttests, um sicherzustellen, dass die Anlage die notwendige Kapazität unter Realbedingungen liefern kann. Ergänzend kann eine Institution durch redundante Einspeisungen vom Energieversorger oder die Kombination mehrerer NEA-Module eine Ausfallsicherheit erhöhen. Prozessual kann sie Wartungspläne etablieren, die auch die Prüfung von Kraftstoffqualität, Starterbatterien und Umschalteinrichtungen umfassen. Praktische Umsetzungstipps sind etwa, NEA-Anlagen in geschützten Gebäudebereichen mit ausreichender Belüftung und Brandschutz vorzusehen, die Abgasführung nach außen zu gewährleisten und einen sicheren, vor Manipulation geschützten Tankstandort zu wählen.</p></td></tr><tr valign="top"><td>GEB.10.2: Lasttest</td><td><p>Gebäudemanagement für Standorte KANN die Belastbarkeit der Stromversorgung <i>regelmäßig</i> überprüfen.</p></td><td><p>Die Maßnahmen richten sich nach den geltenden Anforderungen an die Stromversorgung. Beispiele sind ein monatlicher USV-Selbsttest oder ein halbjährlicher Volllastbetrieb des Generators für mindestens 30 Minuten.</p></td></tr><tr valign="top"><td>GEB.10.3: Notaus</td><td><p>Gebäudemanagement für Standorte KANN eine Notausschaltung für die Versorgungseinrichtungen installieren.</p></td><td><p>Eine Notausschaltung bezeichnet in diesem Kontext eine zentral verfügbare, technisch implementierte Vorrichtung, mit der im Gefahrenfall die Energieversorgung kritischer Versorgungseinrichtungen wie Strom, Gas oder Klimaanlagen unmittelbar und vollständig unterbrochen werden kann. Der Sinn und Zweck einer solchen Einrichtung liegt darin, Gefahren für Menschen, Technik und Informationen schnell eingrenzen zu können: Ein unkontrollierter Brand könnte sich durch weiterlaufende Klimageräte verstärken, ein Stromschlag durch beschädigte Leitungen könnte Menschen gefährden, oder ein Wasserschaden durch defekte Kühlung könnte weitere Systeme zerstören. Gleichzeitig kann eine sofortige Unterbrechung der Energiezufuhr Folgeschäden eindämmen, indem Brandlast reduziert oder die Ausbreitung toxischer Gase verhindert werden kann. Zur Umsetzung kann eine Institution beispielsweise (1) physische Notausschalter an klar gekennzeichneten, jederzeit zugänglichen Stellen nahe den Ausgängen oder im Leitstand installieren, (2) die Schalter so konzipieren, dass sie nur für definierte Versorgungskreise wie IT-Serverräume oder Technikzonen wirken und nicht die gesamte Einrichtung unkontrolliert lahmlegen, und (3) ergänzende visuelle Hinweise oder Leitsymbole anbringen, die die Bedienung im Ernstfall erleichtern.</p></td></tr><tr valign="top"><td>GEB.10.4: Überspannungsschutz</td><td><p>Gebäudemanagement für Standorte KANN Überspannungsschutzeinrichtungen installieren.</p></td><td><p>Überspannungsschutzeinrichtungen sind technische Komponenten, die elektrische und elektronische Systeme vor plötzlich auftretenden Spannungsspitzen im Stromnetz oder in Datenleitungen schützen. Sie wirken, indem sie kurzzeitig auftretende Energie in sichere Bahnen ableiten oder begrenzen, sodass angeschlossene Geräte nicht beschädigt werden. Der Sinn und Zweck liegt darin, sensible IT- und Kommunikationssysteme sowie die Infrastruktur der Institution vor Schäden zu bewahren. Ohne Schutz könnte ein Spannungssprung aus dem Stromnetz eine zentrale Serveranlage zerstören oder den Ausfall von Brandmelde- und Zutrittskontrollsystemen verursachen, wohingegen ein korrekt eingesetzter Überspannungsschutz kann die Betriebsfähigkeit und Datenintegrität sicherstellen. Diese Anforderung bezieht sich ausschließlich auf Überspannungen aus dem Netzbetrieb oder aus benachbarten Stromkreisen; für den äußeren Blitzschutz gilt eine verwandte Anforderung. Zur Umsetzung können an kritischen Punkten Überspannungsschutzeinrichtungen installiert werden: (1) in zentralen Verteilungen, um das gesamte Gebäude gegen Netzstörungen abzusichern, (2) in Unterverteilungen oder einzelnen Stromkreisen, die besonders sensible IT-Systeme versorgen, und (3) an Kommunikations- oder Datenleitungen, etwa für Netzwerk- oder Telefonverkabelungen. Eine Institution kann durch gestufte Schutzkonzepte („Grobschutz“ im Hauptverteiler, „Feinschutz“ in Nähe der Endgeräte) eine höhere Wirksamkeit erreichen. Es kann sinnvoll sein, bei Neubauten Steckdosen mit integriertem Feinschutz vorzusehen oder bei Bestandsanlagen nachträglich modulare Schutzgeräte in die Verteilungen einzusetzen. Prozessual kann regelmäßige Prüfung der eingebauten Schutzmodule helfen, da viele Modelle nach einem Ereignis verbraucht sind und ausgetauscht werden müssen. Auch eine Dokumentation der Einbauorte kann den Überblick erleichtern und gewährleisten, dass keine kritischen Systeme ungeschützt bleiben.</p></td></tr><tr valign="top"><td>GEB.10.5: Strukturierte Datenverkabelung</td><td><p>Gebäudemanagement für Standorte SOLLTE eine norm- und bedarfsgerechte Datenverkabelung installieren.</p></td><td><p>Normgerecht ist eine Datenverkabelung, wenn Normen für Verkabelungssysteme wie DIN EN 50173 und DIN EN 50174, sowie bei Glasfaser DIN EN 60794 eingehalten werden. Sie ist auch bedarfsgerecht, wenn die verwendete Verkabelung ausreicht, um festgelegte Bandbreite und Antwortzeit zu erreichen. Das betrifft sowohl zentrale Netzanschlüsse, als auch Unterverteiler und die Zuleitung in die einzelnen Räume.  Zur Umsetzung ist es sinnvoll ein Kabelverlegungsdiagramm und eine standortspezifische Inspektionscheckliste zu erstellen oder erstellen zu lassen.</p></td></tr><tr valign="top"><td>GEB.10.5.1: Physisch geschützte Verlegung</td><td><p>Gebäudemanagement für Standorte SOLLTE eine geschützte Kabelverlegung installieren.</p></td><td><p>Freigelegte Glasfaser- oder Kupferleitungen könnten angezapft oder durchtrennt werden.  Die Implementierung kann z.B. Erfolgen durch: Das Verlegen von Backbone-Kabeln in Metallrohren oder verschlossenen Kabelschränken; manipulationssichere Siegel an Stellen, an denen die Kabel die Sicherheitsbereiche verlassen.</p></td></tr><tr valign="top"><td>GEB.10.6: Zugang zu Räumen für technische Infrastruktur</td><td><p>Gebäudemanagement für Räume für technische Infrastruktur SOLLTE den Zugang zu Räumen für technische Infrastruktur auf <i>für den Betrieb zuständige Personen oder Rollen</i> einschränken.</p></td><td><p>HIerzu gehören insbesondere Versorgungsverteiler, z.B. für Netzverteilung, Frischwasser, Abwasser, Stromversorgung und andere zentrale Versorgungseinrichtungen. sind essenziell für die Einsatzfähigkeit und den Schutz des Gebäudes. Der Zugang zu diesen Verteilern kann z.B. durch Schließanlagen, Bewachung und Einbruchmeldesysteme realisiert werden.</p></td></tr><tr valign="top"><td>GEB.10.7: Zweckentfremdung</td><td><p>Gebäudemanagement für Räume für technische Infrastruktur SOLLTE die Verwendung der Räume zu anderen Zwecken untersagen.</p></td><td><p>Werden Räume für technische Infrastruktur zu weiteren Zwecken, z.B. als Arbeitsplatz, Durchgangsraum oder Abstellraum genutzt, so erhöht dies das Risiko versehentlicher Schäden oder des Zugriffs Unbefugter auf die Infrastruktur.</p></td></tr></table><h2>GEB.11: Schutz vor Elementarschäden</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>GEB.11.1: Brandschutz</td><td><p>Gebäudemanagement für Standorte SOLLTE Brandschutz nach den entsprechenden Normen verankern.</p></td><td><p>Maßnahmen können z.B. die Verwendung nicht brennbarer Baumaterialien (u.a. DIN 4102, DIN EN 13501), brandsichere Elektroinstallation, Feuerlöscher (DIN 14406), Rauchabzugsanlagen (DIN 18232) sowie Brandmelde- (DIN EN 54) und Löschanlagen (DIN EN 671) sein. Bei der Planung kann die örtliche Feuerwehr hinzugezogen werden. Gesetzliche Anforderungen hierzu sind in der Praktik Compliance zu berücksichtigen.</p></td></tr><tr valign="top"><td>GEB.11.1.1: Baulicher Brandschutz</td><td><p>Gebäudemanagement für Räume SOLLTE bauliche Brandschutzeinrichtungen nach den entsprechenden Normen installieren.</p></td><td><p>Relevant ist für das Brandverhalten von Bauprodukten und Bauarten die europäische Normenreihe DIN EN 13501 mit ihren sieben Klassen (A1, A2, B, C, D, E, F).</p></td></tr><tr valign="top"><td>GEB.11.1.2: Brandabschnitte</td><td><p>Gebäudemanagement für Räume SOLLTE Brandabschnitte nach den entsprechenden Normen installieren.</p></td><td><p>Brandabschnitte sind baulich abgegrenzte Bereiche in Gebäuden, die im Brandfall verhindern sollen, dass das Feuer auf andere Bereiche übergreift. Sie werden durch feuerfeste Wände, Decken und andere raumabschließende Bauteile voneinander getrennt. Hier besteht ein enger Zusammenhang zu Compliance-Anforderungen: Größe und Anzahl von Brandabschnitten werden auch durch die Bauordnung und andere Vorschriften festgelegt, abhängig von der Nutzung und Größe des Gebäudes. Für die Informationssicherheit relevant ist darüber hinaus, ob die Auswahl der Brandabschnitte den darin befindlichen Informationen und damit verbundenen Assets ausreichenden Schutz gewährt, um deren Verfügbarkeit aufrecht zu erhalten.</p></td></tr><tr valign="top"><td>GEB.11.1.3: Rauchdichtheit</td><td><p>Gebäudemanagement für Räume KANN alle raumbildende Teile rauchdicht installieren.</p></td><td><p>Hierunter ist zu verstehen, dass alle raumbildenden Teile (Wände, Türen und falls benötigt Fenster) rauchdicht sind.</p></td></tr><tr valign="top"><td>GEB.11.1.4: Brandwiderstandsklassen</td><td><p>Gebäudemanagement für Räume KANN feuerfeste Materialen für alle raumbildenden Teile , sodass sie Feuern für <i>eine bestimmte Frist</i> standhalten, installieren.</p></td><td><p>Der Einsatz feuerfester Materialien für raumbildende Teile – also Wände, Decken, Türen und gegebenenfalls auch Bodenaufbauten – kann das Risiko erheblich reduzieren, dass sich ein Brand innerhalb eines Gebäudes schnell ausbreitet oder sicherheitsrelevante Bereiche in kurzer Zeit unbenutzbar werden könnten. Ohne geeignete Materialien könnte ein kleiner Kabelbrand beispielsweise binnen Minuten auf benachbarte Räume mit Servern, Schaltanlagen oder Dokumenten übergreifen und kritische Infrastruktur unbrauchbar machen. Mit feuerfesten Materialien kann eine Institution die Zeitspanne verlängern, in der Personen evakuiert, Brandbekämpfungsmaßnahmen eingeleitet oder Systeme geordnet heruntergefahren werden können. Der Begriff „feuerfest“ bedeutet im baulichen Kontext nicht absolute Unzerstörbarkeit, sondern eine definierte Widerstandsfähigkeit gegen Feuer über eine bestimmte Frist (z. B. 30, 60 oder 90 Minuten), die durch Normen wie die europäische Klassifizierung REI angegeben wird. Diese Frist beschreibt, wie lange ein Bauteil seine tragende Funktion (R), Dichtheit (E) und Wärmedämmung (I) im Brandfall aufrechterhalten kann. Zur praktischen Umsetzung können im Gebäudemanagement verschiedene Maßnahmen berücksichtigt werden: Wände und Decken können aus nicht brennbaren Baustoffen wie Beton oder speziellen Gipsfaserplatten ausgeführt werden, Türen können durch Brandschutztüren mit entsprechender Klassifizierung ersetzt werden, und Kabel- sowie Rohrdurchführungen können mit geprüften Brandschutzmanschetten oder -schotts ausgestattet werden. Auch abgehängte Decken oder Zwischenwände in Leichtbauweise können mit feuerhemmenden Platten verkleidet werden, um die Widerstandsdauer zu erhöhen. Eine Institution kann bei Umbauten oder Neubauten frühzeitig auf geprüfte Baustoffe achten und im Bestand gezielt besonders gefährdete Räume wie Serverräume, Archive oder Batterieräume nachrüsten.</p></td></tr><tr valign="top"><td>GEB.11.1.5: Vermeidung von Brandlasten</td><td><p>Gebäudemanagement für Standorte SOLLTE das ungesicherte Hinterlassen von Brandlasten untersagen.</p></td><td><p>Befinden sich Brandlasten wie Kartons, brennbare Dämmstoffe, Batterien oder Holzmöbel in der Nähe (oder sogar in) Räumen für technische Infrastruktur oder zentraler Versorgungseinrichtungen, so erhöhen sich Wahrscheinlichkeit und durchschnittliches Schadensausmaß von Bränden. Dies gilt auch für das Rauchen von Zigaretten oder Zigarren. Der einzuhaltende Abstand ergibt sich aus der Größe der Brandlast und dem Schutzbedarf des Ortes von dem Abstand zu halten ist - wenn möglich ist ein Abstand von mindestens einem Zwischenraum sinnvoll.</p></td></tr><tr valign="top"><td>GEB.11.1.6: Brandmeldeanlagen</td><td><p>Gebäudemanagement für Standorte SOLLTE das Entstehen von Bränden überwachen.</p></td><td><p>Die Umsetzung kann durch Brandmeldezentralen oder dezentrale Brandmeldealarmierung erfolgen, siehe DIN EN 54 und DIN VDE 0833-2.</p></td></tr><tr valign="top"><td>GEB.11.1.7: Brandunterdrückung</td><td><p>Gebäudemanagement für Serverräume KANN Brandunterdrückungssysteme installieren.</p></td><td><p>Kann z.B. durch eine Anlage zur Sauerstoffreduktion unter 15 Volumenprozent umgesetzt werden, da Feuer sich so kaum entzünden kann. Siehe ISO 20338. Denken Sie dabei auch an den Schutz des Personals, siehe Arbeitstättenverordnung (ArbStättV).</p></td></tr><tr valign="top"><td>GEB.11.1.8: Brandschutzprüfung</td><td><p>Gebäudemanagement für Standorte SOLLTE die Wirksamkeit der Brandschutzmaßnahmen <i>regelmäßig</i> überprüfen.</p></td><td><p>Eine regelmäßige Überprüfung von Brandmeldeanlagen, Rauchmeldern und organisatorische Maßnahmen stellt sicher, dass diese weiterhin funktionieren.  Hier besteht ein enger Zusammenhang zu Compliance-Verpflichtungen, die Brandschutzprüfungen fordern.</p></td></tr><tr valign="top"><td>GEB.11.2: Wasserschutz</td><td><p>Gebäudemanagement für Standorte SOLLTE zwischen Assets und Witterungs- sowie Wassergefahrenstellen mindestens eine physische Schutzmaßnahme vor Wasser nach den entsprechenden Normen installieren.</p></td><td><p>Relevant ist hierbei sowohl Wasser von oben (Regen und Schnee), als auch von unten (Überflutungen, gesammeltes Regenwasser).  Maßnahmen können z.B. witterungsbeständige Baumaterialien, Abdichtungen, Überdachungen, Entwässerungssysteme oder eine erhöhte Positionierung, die eher nicht in überfluteten Bereichen liegen wird, sein. Schränke und Gehäuse können auch mit einer geeigneten IP-Schutzklasse (z.B. IP65) gegen Wasser geschützt werden.</p></td></tr><tr valign="top"><td>GEB.11.2.1: Doppelter baulicher Wasserschutz</td><td><p>Gebäudemanagement für Standorte KANN zwischen Wassergefahrenstellen und Assets mindestens zwei bauliche Schutzmaßnahmen vor Wasser nach den entsprechenden Normen installieren.</p></td><td><p>Relevant ist hierbei sowohl Wasser von oben (Regen und Schnee), als auch von unten (Überflutungen, gesammeltes Regenwasser).   Maßnahmen können z.B. witterungsbeständige Baumaterialien, Abdichtungen, Abkofferungen, Überdachungen, oder Entwässerungssysteme sein. Schränke und Gehäuse können auch mit einer geeigneten IP-Schutzklasse (z.B. IP65) gegen Wasser geschützt werden.</p></td></tr><tr valign="top"><td>GEB.11.2.2: Leckagesensor</td><td><p>Gebäudemanagement für Standorte KANN Wassereinbrüche überwachen.</p></td><td><p>Maßnahmen können z.B. Wassersensorstreifen unter Doppelböden sein, die SNMP-Traps an ein Building Management System (BMS) senden.</p></td></tr><tr valign="top"><td>GEB.11.3: Blitzschutzeinrichtungen</td><td><p>Gebäudemanagement für Standorte SOLLTE Blitzschutzeinrichtungen nach <i>einem anerkannten Standard</i> installieren.</p></td><td><p>Blitzschutzeinrichtungen sind bauliche oder technische Maßnahmen, die Gebäude, Anlagen und darin befindliche Systeme vor den direkten und indirekten Auswirkungen eines Blitzeinschlags schützen. Der Zweck dieser Regelung liegt darin, Risiken durch Blitzeinschläge zu reduzieren: Ein direkter Einschlag könnte Gebäudestrukturen beschädigen, Brände verursachen oder elektrische Systeme zerstören. Indirekte Einschläge könnten durch Überspannungen Datenverluste oder den Ausfall kritischer Systeme hervorrufen. Die Installation nach anerkannten Standards kann hier Schäden an Bausubstanz, Stromversorgung und Informationssystemen verhindern und die Verfügbarkeit sensibler Infrastruktur sichern. Ein anerkannter Standard ist hier die DIN EN 62305, die Anforderungen an Planung, Errichtung und Prüfung von Einrichtungen wie Fangstangen oder Erdungsanlagen definiert. Sie kennt verschiedene Schutzklassen. Für Standorte mit normalem Schutzbedarf wird Schutzklasse II oder besser gemäß DIN EN 62305 empfohlen. Für Räume für technische Infrastruktur oder Rechenzentren ist mindestens die Blitzschutzzone 2 (LPZ 2) sinnvoll.</p></td></tr><tr valign="top"><td>GEB.11.3.1: Niederohmigkeit</td><td><p>Gebäudemanagement für Standorte KANN Blitzschutzeinrichtungen <i>regelmäßig</i>  auf Niederohmigkeit überprüfen.</p></td><td><p>Eine niedrige Ohmzahl in Erdungs- und Potentialausgleichseinrichtungen gewährleistet, dass Blitzströme schnell und wirksam abgeleitet werden. Siehe DIN VDE 0100-443 u. -534. Beachten Sie dabei auch die Prüfpflicht aus der Betriebssicherheitsverordnung (BetrSichV).</p></td></tr><tr valign="top"><td>GEB.11.4: Ableitfähiger Fußbodenbelag</td><td><p>Gebäudemanagement für Räume für technische Infrastruktur KANN im Nahfeld von Systemen einen ableitfähigen Fußbodenbelag installieren.</p></td><td><p>Ein ableitfähiger Boden ist ein Fußbodenbelag, der es ermöglicht, statische Aufladungen abzuleiten, beispielsweise durch eine geerdete Verbindung. Er zeichnet sich durch einen elektrischen Widerstand zwischen 106 und 109 Ohm aus. Ableitfähige Böden werden in Bereichen eingesetzt, in denen elektrostatische Entladungen (ESD) vermieden werden müssen.  Die Umsetzung kann nach DIN EN 14041 oder DIN IEC 61340-4-1 erfolgen.</p></td></tr></table><h1>BER: Berechtigung</h1><p>Die Praktik Berechtigung stellt sicher, dass ausschließlich autorisierte Personen und IT-Systeme Zugriff auf sensible Informationen und Ressourcen erhalten. Sie regelt die Verwaltung von Identitäten und Berechtigungen, um die Vertraulichkeit, Integrität und Verfügbarkeit von Informationen zu gewährleisten.  Dabei bildet die Praktik Berechtigung eine zentrale Schnittstelle zwischen den Praktiken Personal, Dienstleistersteuerung, Asset Management und Gebäudemanagement. Während IT-Systeme den Zugriff regeln, behandeln die Praktik Personal den Umgang mit Mitarbeitenden. Die Praktik Berechtigung vereint diese organisatorischen und technischen Aspekte, um Zugriffsrechte sicher und effizient zu verwalten.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>BER.1: Grundlagen</td><td align="right">7</td></tr><tr valign="top"><td>BER.2: Identitätsmanagement</td><td align="right">6</td></tr><tr valign="top"><td>BER.3: Zugangskonten</td><td align="right">20</td></tr><tr valign="top"><td>BER.4: Berechtigungsmanagement</td><td align="right">10</td></tr><tr valign="top"><td>BER.5: Passwortgebrauch</td><td align="right">9</td></tr><tr valign="top"><td>BER.6: Authentifizierung</td><td align="right">4</td></tr><tr valign="top"><td>BER.7: Schlüsselmanagement</td><td align="right">22</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>78</b></td></tr></table><h2>BER.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BER.1.1: Verfahren und Regelungen</td><td><p>Berechtigung MUSS Verfahren und Regelungen zum Identitäts- und Berechtigungsmanagement verankern.</p></td><td><p>Ziel ist einen dokumentierten Prozess einzurichten, der die Vergabe, Verwaltung und Entfernung von Zugangs- und Zugriffsberechtigungen, sowie der damit verbundenen Identitäten regelt. Zu berücksichtigen sind insbesondere Neueinstellungen, Versetzungen und Entlassungen. Empfehlenswert ist die die Vergabe und den Entzug von Berechtigungen so weit wie möglich zu automatisieren. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>BER.1.1.1: Dokumentation</td><td><p>Berechtigung MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>BER.1.1.2: Zuweisung der Aufgaben</td><td><p>Berechtigung MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>BER.1.1.3: Bekanntgabe</td><td><p>Berechtigung MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>BER.1.2: Regelmäßige Überprüfung</td><td><p>Berechtigung MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr><tr valign="top"><td>BER.1.3: Inventar Authentifizierungs- und Autorisierungssysteme</td><td><p>Berechtigung SOLLTE ein Inventar der Systeme zur Authentifizierung und Autorisierung dokumentieren.</p></td><td><p>Ein dokumentiertes Inventar der Authentifizierungs- und Autorisierungssysteme kann eine zentrale Grundlage sein, um den Überblick über sicherheitsrelevante Zugangskontrollen zu behalten, sowohl lokal als auch in der Cloud. Solche Systeme sind dafür zuständig zu prüfen, wer Zugriff auf IT-Ressourcen erhält (Authentifizierung) und was dieser Zugriff umfassen darf (Autorisierung). Wird kein vollständiges und gepflegtes Inventar geführt, könnten Schwachstellen unentdeckt bleiben, z.B. veraltete Login-Dienste, falsch konfigurierte Rollen oder Schatten-Identitäten in cloudbasierten Identitätsplattformen. In einem konkreten Vorfall könnte etwa ein ehemals genutzter Verzeichnisdienst (z.B. ein ausgemusterter LDAP-Server) unbemerkt weiterhin aktiv sein und von Angreifern für unautorisierte Zugriffe verwendet werden. Ebenso könnte ein unerkannter Konfigurationsfehler in einem Authentifizierungs-Gateway dazu führen, dass privilegierte Nutzerrollen ohne Zwei-Faktor-Absicherung zugänglich sind.  Zu Authentifizierungs- und Autorisierungssystemen zählen beispielsweise Verzeichnisdienste (Directory Services), Identity Provider (IdPs), Single Sign-On-Plattformen (SSO), lokale Passwortdatenbanken sowie API-Gateways mit Zugriffskontrolllogik. Eine Möglichkeit zur Umsetzung kann darin bestehen, auf eine Liste aller Systeme des Informationsverbundes zurückzugreifen und Informationen zum Berechtigungsmanagement zu ergänzen – inklusive ihrer Funktion, angebundenen Anwendungen, unterstützten Protokollen (wie SAML, OAuth2, OpenID Connect) sowie Zuständigkeiten. Die Pflege dieses Inventars kann über ein zentrales Configuration Management Database (CMDB) erfolgen oder alternativ über eine revisionsfähige Tabellenstruktur mit Zugriffskontrollen. Hilfreich kann es sein, den Lifecycle einzelner Systeme zu erfassen, etwa ob sich diese in Einführung, Nutzung oder Stilllegung befinden. Ein Abgleich mit dem Rollen- und Rechtemanagement der Institution kann die Konsistenz zusätzlich verbessern.</p></td></tr><tr valign="top"><td>BER.1.4: Inventar der Berechtigungen</td><td><p>Berechtigung SOLLTE ein Inventar der Berechtigungen mit Personen, Identitäten, Zugangskonten, Berechtigungen und deren jeweiliger Zuordnung dokumentieren.</p></td><td><p>Ein Inventar der Berechtigungen kann helfen, Zugriffsrechte innerhalb einer Institution transparent zu machen und unnötige oder riskante Berechtigungen zu erkennen. Es dokumentiert, welche Identitäten – also digitale Repräsentationen von Personen oder Systemen – über welche Konten und Berechtigungen verfügen. So können potenzielle Risiken wie verwaiste Konten oder unautorisierte Privilegien sichtbar werden. Beispielsweise könnte ein ehemaliger Mitarbeitender noch aktive Zugänge besitzen, oder ein Dienstkonto könnte über weitreichende Rechte verfügen, obwohl der Einsatz längst beendet ist – beides kann ein Einfallstor für Missbrauch sein. Relevant sind neben den Berechtigungen von Personen auch Dienstekonten, Cloud-Zugänge und physische Zugangsberechtigungen wie Schlüssel-Schließpläne.  Berechtigungen bezeichnen konkrete Zugriffsrechte auf Ressourcen (z. B. Lesen oder Administrieren). Eine Institution kann dies etwa durch einen Verzeichnisdienst, ein zentrales Berechtigungsmanagement oder gepflegte Berechtigungsverzeichnisse abbilden. Die Benennung von Zuständigen je Fachbereich, regelmäßige Überprüfungen und der Einsatz von klaren Rollenkennzeichnungen (z. B. „temporär“, „Admin“) können helfen, das Inventar aktuell und verständlich zu halten. Auch eine strukturierte Offboarding-Checkliste kann sicherstellen, dass veraltete Zugänge rechtzeitig entfernt werden.</p></td></tr></table><h2>BER.2: Identitätsmanagement</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BER.2.1: Person-Identität</td><td><p>Berechtigung SOLLTE eine eindeutige Identität zu genau einer natürlichen Person oder einem IT-System zuweisen.</p></td><td><p>Hier wird eine Identität (<b>„muellera“</b>) genau einer natürlichen Person (<b>„Andrea Müller“</b>) zugewiesen, oder einem IT-System (<b>„pc02348“</b> zu <b>„pc02348.our.domain“</b>).</p></td></tr><tr valign="top"><td>BER.2.2: Einschränkung</td><td><p>Berechtigung SOLLTE die Einrichtung, Änderung oder Löschung einer Identität einschränken.</p></td><td><p>Das Identitäts- und Berechtigungsmanagement ist entscheidend für die sichere Authentifizierung vor Zugang zu Informationen. Identitäten sind die Grundlage hierfür. Je nach Organisationsstruktur benötigen z.B. das Personalmanagement oder Administrierende schreibenden Zugang zu Identitäten.</p></td></tr><tr valign="top"><td>BER.2.3: Stammdatenprüfung</td><td><p>Berechtigung SOLLTE Stammdaten einer Identität anhand allgemeiner Stammdaten <i>regelmäßig</i> überprüfen.</p></td><td><p>Allgemeine Stammdaten können z.B. sein: Unterlagen der Personalabteilung, Ergebnisse von Netzwerkscans für IT-Systeme, CMDB. Der Abgleich kann auch automatisiert vorgenommen werden.</p></td></tr><tr valign="top"><td>BER.2.4: Protokollierung von Stammdatenänderungen</td><td><p>Berechtigung SOLLTE Änderungen von Identitäts-Stammdaten protokollieren.</p></td><td><p>Zu einem Ereignisprotokoll gehört der Zeitpunkt, das Zugangskonto, sowie welche Änderungen vorgenommen wurden.</p></td></tr><tr valign="top"><td>BER.2.5: Weggang</td><td><p>Berechtigung SOLLTE die zugeordnete Identität bei Weggang von Nutzenden deaktivieren.</p></td><td><p>Weggang meint hier die nicht nur kurzfristige Beendigung der Aktivitäten der Identität, z.B. bei Kündigung, Elternzeit, Sabbatical. Die Anforderung ist auch umgesetzt, wenn die Identität gelöscht wird. Empfehlenswert ist die Löschung jedoch erst nach Ablauf längerer Löschfristen, um die Nachvollziehbarkeit von Aktionen im Audit Log zu erhalten.</p></td></tr><tr valign="top"><td>BER.2.6: Löschen</td><td><p>Berechtigung SOLLTE nicht mehr benötigte Identitäten nach Ablauf der Löschfristen löschen.</p></td><td><p>Gesetzliche Aufbewahrungs- und Löschfristen ergeben sich aus dem Compliance-Management, z.B. aus Regelungen der DSGVO oder dem Handels- und Steuerrecht. Sicheres Löschen bedeutet, Daten so zu entfernen, dass sie mit vertretbarem Aufwand (auch forensisch) nicht mehr rekonstruierbar sind. Je nach Medium geschieht das z. B. durch verifizierbares Überschreiben, kryptografisches Löschen (Schlüsselvernichtung) oder physische Zerstörung (inklusive zugehöriger Metadaten, Caches und Datensicherungen.</p></td></tr></table><h2>BER.3: Zugangskonten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BER.3.1: Zentrales Management</td><td><p>Berechtigung SOLLTE ein zentrales Managementsystem für Zugangskonten installieren.</p></td><td><p>Wenn Zugangskonten lokal auf jedem Gerät einzeln verwaltet werden, könnte es zu inkonsistenten und veralteten Zugängen und Berechtigungen kommen. Ein zentrales System steuert Benutzeridentitäten und Zugriffsrechte übergreifend – oft als Identity and Access Management (IAM) oder bei sensiblen Konten als Privileged Access Management (PAM) bezeichnet. Es kann die Nachvollziehbarkeit erhöhen, Audits erleichtern und gerade in komplexen IT-Umgebungen Transparenz schaffen. Umsetzbar ist dies etwa über Verzeichnisdienste wie LDAP oder Active Directory, ergänzt durch rollenbasierte Zugriffsmodelle (RBAC). Praktische Maßnahmen zum Management können Self-Service-Portale, automatische Genehmigungsworkflows und regelmäßige Rechteüberprüfungen umfassen. Für den Einstieg kann eine Institution kritische Systeme priorisieren und Prozesse schrittweise zentralisieren.</p></td></tr><tr valign="top"><td>BER.3.2: Einschränkung des Managements</td><td><p>Berechtigung SOLLTE das Management von Zugangskonten auf Administrierende einschränken.</p></td><td><p>Management meint hier Aktionen wie z.B. das Erstellen oder Ändern von Metadaten oder Berechtigungen oder die Löschung des Zugangskontos.</p></td></tr><tr valign="top"><td>BER.3.3: Protokollierung von Änderungen</td><td><p>Berechtigung SOLLTE Aktionen an Zugangskonten revisionsfähig protokollieren.</p></td><td><p>Werden Aktionen an Zugangskonten wie die Erstellung, Veränderung von Metadaten oder Berechtigungen, Aktivierung, Deaktivierung oder Löschung von Zugangskonten automatisch protokolliert, so können Sicherheitsverstöße erkannt und nachgewiesen werden. Siehe auch Praktik Detektion.</p></td></tr><tr valign="top"><td>BER.3.4: Identität-Zugangskonto</td><td><p>Berechtigung SOLLTE ein Zugangskonto zu genau einer Identität zuweisen.</p></td><td><p>Wenn ein Zugangskonto genau einer Identität zugewiesen ist erleichtert dies die Vergabe von Berechtigungen nach dem Need-to-know-Prinzip. Außerdem kann so bei einem Vorfall nachvollzogen werden, welche Person welche Befehle ausgeführt hat, z.B. mittels des Audit Logs. Anders herum können einer Identität auch mehrere Zugangskonten zugewiesen sein, z.B. ein normalen Nutzungskonto und ein Zugangskonto für die Systemadministration.</p></td></tr><tr valign="top"><td>BER.3.5: Privilegierte Zugangskonten</td><td><p>Berechtigung für Administrierende SOLLTE separate Zugangskonten für administrative Tätigkeiten (Administrationskonten) verankern.</p></td><td><p>Zugangskonten mit privilegierten Rechten (Superuser wie z.B. root) könnten durch menschliche Fehler oder Schadcode weitreichende Probleme verursachen. Bewährt hat es sich daher für administrative Tätigkeiten wie die Installation von Anwendungen dedizierte Zugangskonten einzurichten und diese auch nur für derartige Tätigkeiten zu verwenden. Für normale Geschäftsaktivitäten wie E-Mail oder Webbrowser nutzen auch Administrierende dann ausschließlich Zugangskonten ohne administrative Berechtigungen.</p></td></tr><tr valign="top"><td>BER.3.6: Single-Sign-On</td><td><p>Berechtigung für Anwendungen SOLLTE die Anmeldung über einen zentralen Identitätsprovider aktivieren.</p></td><td><p>Bei Single Sign-on authentifizieren sich Nutzende bei einem zentralen Identity Provider, der auch die Berechtigungen zur Nutzung der Anwendung prüft. Bei erfolgreicher Authentifizierung und passenden Berechtigungen wird für die Sitzung ein Token ausgestellt, das den Zugang zur Anwendung ermöglicht.  Da Nutzende durch Single-Sign-On weniger Anmeldeinformationen benötigen, wird es leichter, sich komplexe Passwörter zu merken oder zentrale gepflegte Schutzmaßnahmen, wie eine Mehr-Faktor-Authentifizierung oder Überwachung von Anmeldeinformationen, auch auf die Anwendung anzuwenden. Zudem erschwert Single-Sign-On auch Phishing-Angriffe, da Anmeldeinformationen nur noch an zentraler Stelle und nicht mehr verstreut in einzelne Anwendungen oder Webseiten abgefragt werden. Andererseits ist bei der Kompromittierung des Single-Sign-On-Logins auch die Authentifizierung an der Anwendung kompromittiert und die Verfügbarkeit der Anwendung hängt auch von der Verfügbarkeit des zentralen Logins ab.  Dies kann unter Windows durch Nutzung eines Windows Server Domain Controllers und unter Linux durch Samba mit aktiviertem Heimdal Kerberos Key Distribution Center (KDC) umgesetzt werden.</p></td></tr><tr valign="top"><td>BER.3.7: Ereignisgesteuerte Deaktivierung</td><td><p>Berechtigung SOLLTE Zugangskonten ereignisgesteuert deaktivieren.</p></td><td><p>Ungenutzte Zugangskonten stellen ein unnötiges Risiko für unberechtigte Zugriffe dar. Werden sie z.B. bei längerer Inaktivität, bei Personalweggang oder bei Verletzung von Richtlinien unverzüglich deaktiviert, so vermindert sich das Risiko eines Missbrauchs erheblich.</p></td></tr><tr valign="top"><td>BER.3.8: Anmeldeversuchsgrenze am System</td><td><p>Berechtigung für IT-Systeme SOLLTE weitere Anmeldeversuche nach Erreichen von <i>einem maximalen Schwellwert an</i> fehlgeschlagenen Versuchen vorübergehend blockieren.</p></td><td><p>Betrifft sowohl die lokale Anmeldung über eine Benutzeroberfläche als auch den Zugriff über Fernwartungsprotokolle oder -anwendungen wie RDP, SNMP, wenn diese vorhanden sind.  Die Umsetzung erfolgt im einfachsten Fall durch ein Login, bzw. eine Bildschirmsperre für das IT-System. Biometrische Daten wie Fingerabdrücke können gefälscht werden und sind nicht so leicht zu ändern wie Passwörter. Setzen Sie Biometrie daher nicht als einzigen Authentifizierungsfaktor ein, sondern wenn, dann nur zur Ergänzung (Mehr-Faktor-Authentifizierung).  Die Anforderung ist entbehrlich, wenn das System keinen Zugriff auf schützenswerte Daten erlaubt, z.B. bei Nutzung als Kiosk.</p></td></tr><tr valign="top"><td>BER.3.9: Anmeldeversuchsgrenze an der Anwendung</td><td><p>Berechtigung für Anwendungen SOLLTE weitere Anmeldeversuche nach Erreichen von einem maximalen Schwellwert an fehlgeschlagenen Versuchen vorübergehend blockieren.</p></td><td><p>Häufen sich Anmeldeversuche, so könnte ein Angreifer Zugangsdaten durchprobieren. Durch eine Anmeldeversuchsgrenze wird der Zugriff durch das massenhafte Durchprobieren von Zugangsdaten (Credential Stuffing) verhindert. Dies kann z.B. durch die Begrenzung der Anmeldeversuche pro Client oder pro IP erfolgen. Dies betrifft sowohl die Anmeldung an der Benutzeroberfläche als auch über das Netz. Relevant sind hierbei sowohl primäre als auch ggf. vorhandene sekundäre Zugänge (z.B. Sicherheitsfragen, Passwort zurücksetzen).  Für die Wahl des Schwellwertes ist die Anzahl der betroffenen Zugangskonten, die Passwortlänge und der Schutzbedarf der Anwendung von Bedeutung. Je nach Risikoprofil der Anwendung sind verschiedene Lösungen denkbar, z.B. die Verwendung von CAPTCHAS bei Erreichen der Anmeldeversuchsgrenze oder indem der Zeitraum einer Blockierung nach jedem fehlgeschlagenen Anmeldeversuch erhöht wird.   Erfordert die Anwendung keine Zugangsdaten, so ist auch diese Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>BER.3.10: Systemsperre bei Inaktivität</td><td><p>Berechtigung für IT-Systeme SOLLTE eine Sperre bei Inaktivität nach <i>einer Frist</i> aktivieren.</p></td><td><p>Kann durch eine Bildschirmsperre oder Abmeldung (Automatic Session Locking) umgesetzt werden. Eine längere Inaktivität kann z.B. 5-15 Minuten lang sein. Verwendet das System keine eigene Authentifizierung, so ist auch diese Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>BER.3.11: Sperre der Anwendung bei Inaktivität</td><td><p>Berechtigung für Anwendungen SOLLTE eine Sperre bei Inaktivität nach <i>einer Frist</i> aktivieren.</p></td><td><p>Kann je nach Anmeldeweg durch eine Abmeldung (Automatic Session Locking) direkt an der Anwendung, über Single-Sign-On oder (bei Anmeldung über das Netz) die Trennung der Netzverbindung umgesetzt werden. Eine längere Inaktivität kann z.B. 5-15 Minuten lang sein. Verfügt die Anwendung über keine eigene Authentifizierungsmethode, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>BER.3.12: Löschen</td><td><p>Berechtigung SOLLTE nicht mehr benötigte Zugangskonten nach Ablauf der Löschfristen löschen.</p></td><td><p>Die Löschfristen ergeben sich aus gesetzlichen Aufbewahrungs- und Löschfristen, die dem Compliance-Management entnommen werden können. Sicheres Löschen bedeutet, Daten so zu entfernen, dass sie mit vertretbarem Aufwand (auch forensisch) nicht mehr rekonstruierbar sind. Je nach Medium geschieht das z. B. durch verifizierbares Überschreiben, kryptografisches Löschen (Schlüsselvernichtung) oder physische Zerstörung (inklusive zugehöriger Metadaten, Caches und Datensicherungen.</p></td></tr><tr valign="top"><td>BER.3.13: Zugang nur durch zwei Personen</td><td><p>Berechtigung KANN die Aufteilung von Authentisierungsmitteln auf mehrere Personen verankern.</p></td><td><p>Dient zur Absicherung des Zugriffs auf Daten, deren Vertraulichkeit oder Integrität als hoch einzuschätzen ist, nach dem Vier-Augen-Prinzip. Dazu kann z.B. Person #1 die ersten zehn Stellen eines Passwort kennen und Person #2 die hinteren zehn Stellen eines Passwortes. Oder aber Person #1 erhält einen Hardwaretoken, während Person #2 das Passwort kennt.</p></td></tr><tr valign="top"><td>BER.3.14: Gruppenkonten</td><td><p>Berechtigung SOLLTE Gruppenkonten untersagen.</p></td><td><p>Werden Zugangskonten von mehr als einer Person genutzt, so kann später nur noch schwer ermittelt werden, wer eine bestimmte Tätigkeit mit dem Konto ausgeführt hat.</p></td></tr><tr valign="top"><td>BER.3.15: Gruppenkonten - MFA</td><td><p>Berechtigung SOLLTE für Gruppenkonten die Mehr-Faktor-Authentisierung aktivieren.</p></td><td><p>Werden trotz des damit verbundenen Risikos Gruppenkonten genutzt, so kann mit Mehr-Faktor-Authentifizierung der Mißbrauch von Zugangsdaten erschwert werden. Kann zum Beispiel durch mehrere dem Zugangskonto zugewiesene Hardwaretoken oder durch OTP-Apps umgesetzt werden. Falls keine Gruppenkonten verwendet werden, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>BER.3.16: Gruppenkonten - Wechsel dokumentieren</td><td><p>Berechtigung SOLLTE für Gruppenkonten die Identitäten, welche die Möglichkeit zum Zugriff haben, zum Wechselzeitpunkt dokumentieren.</p></td><td><p>Es kann z.B. anhand von Dienst- oder Anwesenheitsplänen nachvollzogen werden, wer wann theoretisch Zugriff gehabt haben könnte. Werden keine Gruppenkonten verwendet, so ist die Anforderung entbehrlich.</p></td></tr><tr valign="top"><td>BER.3.17: Zwischenspeicherung von Zugangsdaten</td><td><p>Berechtigung für IT-Systeme SOLLTE die Zwischenspeicherung der Zugangsdaten von Nutzern deaktivieren.</p></td><td><p>Wird die Zwischenspeicherung von Zugangsdaten auf IT-Systemen deaktiviert, so wird Angreifern deren Diebstahl erschwert. Kann unter Windows ab Server 2012 R2 durch Zuweisung aller Zugangskonten zur Gruppe <b>„Geschützte Benutzer“</b> (Protected Users) umgesetzt werden. Konten für Dienste und Computer brauchen nicht Mitglied von „Geschützte Nutzer“ sein.</p></td></tr><tr valign="top"><td>BER.3.18: Dienstekonten</td><td><p>Berechtigung für Hostsysteme SOLLTE eine automatische Verwaltung der Zugangsdaten von Dienste-Konten aktivieren.</p></td><td><p>Erfolgt bei Zugangskonten für automatisierte Dienste eine automatische Rotation von Passwörtern oder Anmeldezertifikaten, so werden statische Passwörter oder plötzliche Fehlfunktionen durch Zertifikatsablauf vermieden. Kann unter Windows ab Server 2008 R2 durch die Zuweisung aller Dienste-Konten zur Gruppe <b>„Managed Service Account“</b> umgesetzt werden.</p></td></tr><tr valign="top"><td>BER.3.19: Notfallzugang</td><td><p>Berechtigung KANN Notfallzugangskonten installieren.</p></td><td><p>Ein Notfallzugangskonto (sog. Break Glass Account) ist ein Zugang mit privilegierten Berechtigungen, der bei Notfällen als letztes Mittel zum Zugang zu wichtigen Systemen verwendet werden kann, z.B. Verzeichnisdienste, Cloud-Infrastrukturen. Es empfiehlt sich für diese Konten die Verwendung langer Passwörter und die Aufbewahrung dieser z.B. in einem Safe oder aufgeteilt auf mehrere Administrierende.</p></td></tr><tr valign="top"><td>BER.3.20: Notfallzugang Verzeichnisdienst</td><td><p>Berechtigung für Verzeichnisdienste SOLLTE ein Notfallzugangskonto installieren.</p></td><td><p>Ein Notfallzugangskonto (sog. Break Glass Account) ist ein Zugang mit privilegierten Berechtigungen, der bei Notfällen als letztes Mittel zum Zugang zu wichtigen Systemen verwendet werden kann, z.B. Verzeichnisdienste, Cloud-Infrastrukturen. Verwenden Sie für diese Konten lange Passwörter und bewahren Sie diese z.B. in einem Safe oder aufgeteilt auf mehrere Administrierende auf.</p></td></tr></table><h2>BER.4: Berechtigungsmanagement</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BER.4.1: Prinzip der geringsten Berechtigungen</td><td><p>Berechtigung SOLLTE die Vergabe von Berechtigungen nach dem Prinzip der geringsten Berechtigungen einschränken.</p></td><td><p>Das Prinzip der geringsten Berechtigungen, im Englischen als Principle of Least Privilege (PoLP) bekannt, besagt, dass Nutzende, Prozesse oder Systeme nur die minimal notwendigen Zugriffsrechte erhalten dürfen, um die ihnen jeweils zugewiesenen Aufgaben zu erfüllen. Dies dient primär der Minimierung der Angriffsfläche und der Begrenzung potenzieller Schäden. Sollte beispielsweise ein Zugangskonto durch Phishing kompromittiert werden, könnte ein Angreifer ohne dieses Prinzip weitreichenden Zugriff auf kritische Daten oder Systeme erlangen und diese manipulieren, exfiltrieren oder verschlüsseln. Die konsequente Anwendung dieses Grundsatzes kann die Ausbreitung von Schadsoftware nach einem ersten Eindringen erheblich erschweren und sicherstellen, dass Mitarbeitende nur jene Informationen einsehen, die für ihre Tätigkeit unmittelbar relevant sind. Hierdurch wird auch das Risiko von Datendiebstahl durch Innentäter reduziert. Es empfiehlt sich als Ergänzung hier auch das <b>„Need to know“</b>-Prinzip zu betrachten, da sich beide Prinzipien ergänzen. Während das <b>„Least Privilege“</b>-Prinzip auf Systremrechte, Rollen und Berechtigungen fokussiert, liegt der Fokus des <b>„Need to know“</b>-Prinzips mehr auf Informationen und Datenzugriff. Zur sinnvollen Umsetzung kann die Institution ein rollenbasiertes Berechtigungskonzept (Role-Based Access Control, RBAC) etablieren, bei dem Berechtigungen nicht an einzelne Personen, sondern an vordefinierte Rollen (z.B. <b>„Finanzbuchhaltung“</b> oder <b>„Netzwerkadministrator“</b>) gebunden werden. Für die Einführung in eine bestehende Umgebung kann ein gestuftes Vorgehen gewählt werden: (1) Zunächst wird ein Überwachungsmodus (<b>„Audit-Only“</b>) aktiviert, der protokolliert, welche Zugriffe durch eine strengere Richtlinie verweigert würden, ohne sie tatsächlich zu blockieren. (2) Anschließend werden diese Protokolle analysiert, um legitime, für den Geschäftsbetrieb notwendige Zugriffe zu identifizieren und diese gezielt in die jeweiligen Rollen und Berechtigungsgruppen aufzunehmen. (3) Erst wenn keine legitimen Zugriffe mehr in den Protokollen als <b>„verweigert“</b> auftauchen, wird die Richtlinie scharf geschaltet und blockiert aktiv alle nicht explizit erlaubten Zugriffe. Alle relevanten Anforderungen zur Vergabe von Berechtigungen können mit den Handlungsworten <b>„authentifizieren“</b>, <b>„autorisieren“</b> und <b>„einschränken“</b> gefunden werden.</p></td></tr><tr valign="top"><td>BER.4.1.1: Rollenbasierte Berechtigung</td><td><p>Berechtigung SOLLTE Berechtigungen rollenbasiert zuweisen.</p></td><td><p>Aus Gründen der Nachvollziehbarkeit und des administrativen Aufwands wird die direkte Vergabe von Berechtigungen an Einzelkonten vermieden. Berechtigungen werden gemäß dem Least-Privilege-Prinzip in Rollen gebündelt, wobei die Zuweisung und der Entzug ausschließlich über diese Rollen erfolgt. Etwaige Ausnahmen, beispielsweise für temporäre Spezialrechte, werden restriktiv gehandhabt, nachvollziehbar dokumentiert und zeitlich befristet.</p></td></tr><tr valign="top"><td>BER.4.2: Begründung von Berechtigungen</td><td><p>Berechtigung SOLLTE die Vergabe von Berechtigungen und Änderungen an Berechtigungen mit einer Begründung dokumentieren.</p></td><td><p>Zweck ist die Nachvollziehbarkeit der Vergabe von Berechtigungen. Die Dokumentation kann z.B. mit einem Identity-Access-Management oder Personalmanagementsystem automatisiert werden.</p></td></tr><tr valign="top"><td>BER.4.3: Überprüfung von Berechtigungen</td><td><p>Berechtigung SOLLTE vergebene Berechtigungen <i>regelmäßig</i> auf Erforderlichkeit überprüfen.</p></td><td><p>Erforderlichkeit bedeutet in diesem Kontext, dass eine vergebene Berechtigung nur dann als gerechtfertigt gilt, wenn sie für die aktuelle Aufgabenwahrnehmung, Rolle oder Funktion einer Person tatsächlich benötigt wird. Dabei kann zwischen fachlicher Notwendigkeit (z. B. Zugriff auf eine bestimmte Anwendung, um Kernaufgaben erfüllen zu können) und zeitlicher Relevanz (z. B. Projektzugriff, der nur für die Dauer des Projekts sinnvoll ist) unterschieden werden. Als mögliche Werte für den Parameter regelmäßig bieten sich an: (1) quartalsweise, (2) halbjährlich, (3) jährlich – je nach Kritikalität der Systeme und Sensibilität der Daten. Die regelmäßige Überprüfung der Erforderlichkeit kann verhindern, dass sich unbemerkt überhöhte Rechte („Privilege Creep“) ansammeln, die Angreifern im Falle einer Kompromittierung zusätzlichen Spielraum eröffnen könnten. Ohne solche Kontrollen könnte ein ehemaliger Projektmitarbeiter weiterhin Zugang zu sensiblen Daten haben oder ein interner Angreifer auf nicht benötigte Administrationsrechte stoßen. Umgekehrt kann die Überprüfung sicherstellen, dass Berechtigungen stets am aktuellen Aufgabenprofil ausgerichtet bleiben und so Schaden durch Missbrauch oder Fehlhandlungen eingedämmt werden kann. Zur Umsetzung kann eine Institution rollenbasierte Zugriffskonzepte einsetzen, die regelmäßig mit den Ist-Berechtigungen der Nutzer abgeglichen werden („Access Reviews“). Dies kann durch automatisierte Reports aus Verzeichnisdiensten, Datenbanken oder Fachanwendungen erfolgen, die Verantwortlichen zur Bestätigung oder Korrektur vorgelegt werden. Hilfreich kann auch ein Vier-Augen-Prinzip sein, bei dem Vorgesetzte die Notwendigkeit von Berechtigungen bestätigen. Darüber hinaus kann es nützlich sein, temporäre Projekt- oder Sonderrechte mit Ablaufdatum zu vergeben, sodass diese automatisch entzogen werden, wenn sie nicht mehr bestätigt werden.</p></td></tr><tr valign="top"><td>BER.4.3.1: Überprüfung tatsächlicher Berechtigungen</td><td><p>Berechtigung SOLLTE dokumentierte und tatsächlich vergebene Berechtigungen <i>regelmäßig</i> auf Übereinstimmung überprüfen.</p></td><td><p>Der Sinn und Zweck der Vorgabe liegt darin, eine unbemerkte Abweichung zwischen Dokumentation und Realität frühzeitig zu erkennen. Ohne diesen Abgleich könnte es vorkommen, dass ehemalige Mitarbeitende weiterhin Zugriff auf interne Systeme behalten oder dass sich im Laufe der Zeit unautorisierte Rechteanhäufungen einschleichen. Durch eine wirksame Überprüfung kann hingegen sichergestellt werden, dass nur aktuelle, geprüfte und erforderliche Zugriffsrechte bestehen bleiben und so die Angriffsfläche der Institution reduziert werden kann. Zur Umsetzung kann die Institution Berechtigungsübersichten automatisiert aus IT-Systemen exportieren und diese mit den in Verzeichnissen oder Rollenmodellen hinterlegten Daten vergleichen, z.B. anhand eines automatisierten Abgleiches mit Personalstammdaten einmal pro Quartal. Diese Anforderung ist auch dann erfüllt, wenn Dokumentation der Berechtigungen und tatsächliche Berechtigung (z.B. ein Verzeichnisdienst) dasselbe sind. Bitte beachten Sie dabei, dass die generelle Anforderung zur Überprüfung vergebener Berechtigungen weiter gefasst ist und z.B. auch den Abgleich zwischen tatsächlich vergebenen Berechtigungen und nicht dokumentieren Erfordernissen (beispielsweise durch die Vorlage bei Vorgesetzten) umfassen kann.</p></td></tr><tr valign="top"><td>BER.4.4: Kompromittierte Berechtigungsmittel</td><td><p>Berechtigung SOLLTE kompromittierte Berechtigungsmittel deaktivieren.</p></td><td><p>Ein Berechtigungsmittel gilt als kompromittiert, wenn Anzeichen bestehen, dass Unbefugte es nutzen oder Zugriff darauf gehabt haben könnten. Beispiele sind Passwörter, die durch Datenlecks öffentlich geworden sind, oder biometrische Merkmale (z. B. Fingerabdrücke), die Unbefugten vorliegen. In solchen Fällen ist das Berechtigungsmittel zu sperren oder zu entziehen, etwa durch den Einsatz von Sperrlisten. Bei biometrischen Merkmalen besteht zusätzlich ein enger Bezug zu datenschutzrechtlichen Anforderungen, da diese Daten nicht einfach ausgetauscht werden können.</p></td></tr><tr valign="top"><td>BER.4.5: Systemfunktionen ohne Authentifizierung</td><td><p>Berechtigung für IT-Systeme SOLLTE Funktionen, auf die ohne vorherige Authentifizierung zugegriffen werden kann, dokumentieren.</p></td><td><p>Funktionen ohne Authentifizierung sind alle Zugriffsmöglichkeiten auf Schnittstellen oder Daten des Systems, für die keine Authentifizierung erforderlich ist. Hierzu gehören z.B. Sprachassistenten, offene Webserver-Ports oder das Einblenden von Inhalten aus Apps auf dem Sperrbildschirm, wodurch persönliche Nachrichten oder Logintoken für Unbefugte zugänglich sein könnten. Solche Funktionen sind häufige Einfallstore für Angriffe auf das System oder für Datenleaks. Daher ist es sinnvoll eine Übersicht dieser Funktionen zu führen, selbst wenn die Funktionen benötigt werden.</p></td></tr><tr valign="top"><td>BER.4.6: Anwendungsfunktionen ohne Authentifizierung</td><td><p>Berechtigung für Anwendungen SOLLTE Funktionen, auf die ohne vorherige Authentifizierung zugegriffen werden kann, dokumentieren.</p></td><td><p>Hierzu gehören z.B. der Zugriff auf öffentliche Inhalte oder Funktionen zum Zurücksetzen des Passwortes, wodurch persönliche Daten oder Logintoken für Unbefugte zugänglich sein könnten. Allerdings kann es auch unauthentifizierte Funktionen geben, die für Betrieb oder Informationssicherheit benötigt werden, z.B. Meldeformulare für Sicherheitsvorfälle oder öffentliche Webseiteninhalte.</p></td></tr><tr valign="top"><td>BER.4.7: IT-System-Zugangskonto</td><td><p>Berechtigung für IT-Systeme KANN diese genau einem Zugangskonto zuweisen.</p></td><td><p>Wenn ein besonders schützenswertes IT-System nur von einer Person oder Identität genutzt wird, empfiehlt es sich dieses mit genau einem zugehörigen Zugangskonto zu verknüpfen. Dadurch wird ausgeschlossen, dass weitere Konten unnötig Zugriff erhalten. Bei Revisionen ist auf diese Weise eindeutig nachvollziehbar, welche Identität Zugriff auf das System hatte. Das Vorgehen ist auch auf virtualisierte IT-Systeme übertragbar. Ein Beispiel ist eine spezielle Administrationskonsole, die ausschließlich einem dedizierten Admin-Konto zugeordnet ist.</p></td></tr><tr valign="top"><td>BER.4.8: Entzug von Berechtigungen</td><td><p>Berechtigung SOLLTE eine Vorgehensweise zum Entzug von Berechtigungen verankern.</p></td><td><p>Innerhalb der Institution ist ein Prozess etabliert, mit dem Berechtigungen system- und anwendungsübergreifend entzogen sowie Zugänge deaktiviert oder gelöscht werden, sobald diese nicht mehr benötigt werden. Dadurch wird sichergestellt, dass bei Personalwechseln oder Aufgabenänderungen keine Berechtigungen für einzelne Systeme oder Anwendungen bestehen bleiben. Der Entzug von Berechtigungen bei Kündigungen, Versetzungen oder Änderungen von Zuständigkeiten ist, soweit möglich, als automatisierter Ablauf umgesetzt.</p></td></tr></table><h2>BER.5: Passwortgebrauch</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BER.5.1: Vorkonfigurierte Authentisierungsmittel</td><td><p>Berechtigung SOLLTE vorkonfigurierte Authentisierungsmittel deaktivieren.</p></td><td><p>Herstellerseitige Standardkonten und Default-Passwörter stellen ein beliebtes Eingangstor für Angreifer dar. Wenn vorhanden können auch andere Zugangsmittel wie Hardware-Zugangstoken, Zertifikate oder physische Zugangskontrollsysteme als Authentisierungsmittel verstanden werden.</p></td></tr><tr valign="top"><td>BER.5.2: Deaktivierung einfacher Biometrie</td><td><p>Berechtigung SOLLTE die Authentifizierung nur anhand von Biometrie deaktivieren.</p></td><td><p>Wenn die Authentifizierung nur biometrisch vorgenommen wird (z.B. anhand von Fingerabdrücken oder Abbildern des Gesichtes), dann könnten Angreifer Fälschungen oder gestohlene Fingerabdrücke missbrauchen, um sich Zugang zu verschaffen. Werden biometrische Verfahren dagegen mit weiteren Authentisierungsmittel (z.B. einer PIN) kombiniert, können sie den Zugriffsschutz verbessern. Ein häufig vorkommendes Beispiel sind Mobilgeräte wie Smartphones, die durch Fingerabdruck den Zugriff auf Daten oder Funktionen wie das mobile Bezahlen gestatten - obwohl auf dem Gerät selbst häufig noch Fingerabdrücke erkennbar sind.</p></td></tr><tr valign="top"><td>BER.5.3: Mehr-Faktor-Authentisierung am Perimeter</td><td><p>Berechtigung für Anwendungen von Externe Netzanschlüssen SOLLTE Mehr-Faktor-Authentisierung aktivieren.</p></td><td><p>Aus externen Netzen wie dem Internet erreichbaren Anwendungen (insbesondere die VPN-Einwahl oder Cloud-Anwendungen) stellen ein beliebtes Ziel für Angreifer dar. Eine Mehr-Faktor-Authentifizierung erschwert einen unberechtigten Zugang zu diesen extern erreichbaren Anwendungen.</p></td></tr><tr valign="top"><td>BER.5.4: Mehr-Faktor-Authentisierung für weitreichende Berechtigungen</td><td><p>Berechtigung SOLLTE Mehr-Faktor-Authentisierung für weitreichende Berechtigungen aktivieren.</p></td><td><p>Eine Mehr-Faktor-Authentifizierung bei Zugängen mit weitreichenden Berechtigungen, z.B. Administrationskonten die Zugriff auf wichtige Server wie den Verzeichnisdienst, das MDM, EDR oder DNS haben, erschwert den unberechtigten Zugang zu diesen Zugängen. Auch der Zugriff auch besonders sensible Daten kann eine weitreichende Berechtigung sein.</p></td></tr><tr valign="top"><td>BER.5.5: Blockieren von Passwort Recycling</td><td><p>Berechtigung für Nutzende SOLLTE die Wiederverwendung von Passwörtern blockieren.</p></td><td><p>Hierzu können zum einen eine lokale Passworthistorie oder zum anderen elektronische Passwortmanager genutzt werden, die unabhängige sichere Passwörter generieren, wo die Wahrscheinlichkeit einer Passwortwiederholung ausgeschlossen werden kann.</p></td></tr><tr valign="top"><td>BER.5.6: Trivialpasswörter</td><td><p>Berechtigung SOLLTE die Verwendung von Trivialpassworten blockieren.</p></td><td><p>Trivialpasswörter sind leicht zu erratende oder zu diesem Zugangskonto bereits öffentlich bekannte Passwörter (erkennbar durch Nutzung sog. Leak Check Datenbanken). Leicht zu erraten sind Passwörter, wenn sie mit gängigen Wörterbuchangriffen (dictionary attacks) bzw. systematischem Ausprobieren (brute force) in kurzer Zeit zu kompromittieren sind. Dazu zählen etwa einfache Folgen wie „123456“, „Passwort“ oder „qwerty“ sowie häufig vorkommende, in Leaks dokumentierte Standardkombinationen. Der Zweck der Anforderung liegt darin, das Risiko unautorisierter Zugriffe zu reduzieren: Ein Angreifer könnte mit automatisierten Tools in Sekunden oder Minuten triviale Passwörter durchprobieren, was zu einem unbefugten Zugriff auf Benutzerkonten, Systemressourcen oder sensible Daten führen könnte. Die Blockierung solcher Passwörter kann dagegen sicherstellen, dass nur schwer vorhersehbare Kennwörter verwendet werden, wodurch ein entscheidender Schutz gegen automatisierte Angriffsverfahren erreicht werden kann.  Zudem können Passwortmanager beim Generieren nicht-trivialer Passwörter unterstützen.</p></td></tr><tr valign="top"><td>BER.5.7: Kriterien für die Qualität von Passwörtern</td><td><p>Berechtigung SOLLTE Kriterien für die Qualität von Passwörtern anhand von Lebensdauer und Angriffsmöglichkeiten verankern.</p></td><td><p>Kriterien für die Qualität von Passwörtern können z.B. eine minimale Entropie, Passwortlänge oder Verwendung verschiedener Symbole sein. Die Lebensdauer meint die erwartete Nutzungsdauer des Passwortes. Die erforderliche Qualität hängt von den Angriffsmöglichkeiten ab, z.B. Anzahl der Zugangskonten, verwendetes kryptografisches Verfahren (vgl. BSI TR-02102) und begleitenden Sicherheitsmaßnahmen wie maximale Passwortversuche oder Mehr-Faktor-Authentifizierung. Für Zugänge ohne begleitende Maßnahmen ist eine Passwortlänge nicht unter 14 Zeichen empfehlenswert. Die Kriterien können einmalig festgelegt werden oder zwischen Zugängen oder Anwendungen differenzieren.</p></td></tr><tr valign="top"><td>BER.5.8: Anlassbezogene Passwortwechsel</td><td><p>Berechtigung SOLLTE einen Passwortwechsel ausschließlich anlassbezogen ausführen.</p></td><td><p>Das Erzwingen eines Passwortwechsels ohne Anlass - z.B. nur anhand einer festegelegten Frist zum Passwortwechsel - führt in der Praxis dazu, dass Nutzende schwächere Passwörter wie z.B. <b>„sommer5“</b> wählen. Die Anforderung fordert jedoch Passwortwechsel aufgrund eines Anlasses, z.B. wenn Anzeichen auf ein Datenleak vorliegen oder Mitarbeitende ein Gerät verloren haben.</p></td></tr><tr valign="top"><td>BER.5.9: Monitoring von Zugangsdaten</td><td><p>Berechtigung SOLLTE Zugangsdaten auf Kompromittierung durch <i>einen automatisierten Mechanismus</i> überwachen.</p></td><td><p>Eine Kompromittierung meint hier, dass Zugangsdaten wie Benutzername und Passwort (englisch: credentials) von Unbefugten eingesehen, abgefangen oder manipuliert wurden, sodass ein Missbrauch für unautorisierte Zugriffe möglich wird. Dies könnte etwa durch Leaks in Datenbanken, durch Phishing-Angriffe oder durch das Abfangen unverschlüsselter Übertragungen entstehen. Ein automatisierter Mechanismus bezeichnet hierbei eine technische Lösung, die ohne manuelles Zutun kontinuierlich prüft, ob bekannte Indikatoren einer Kompromittierung vorliegen (englisch: credential monitoring system) . Geeignete Mechanismen können etwa Credential-Leak-Monitoring-Dienste, Data Breach Checker oder Darknet-Scanning-Tools sein. Der Zweck dieser Vorgabe liegt darin, dass ein frühzeitiges Erkennen von kompromittierten Zugangsdaten helfen kann, unautorisierte Logins und den Missbrauch sensibler Systeme zu verhindern; ohne eine solche Überwachung könnte ein Angreifer über lange Zeit unentdeckt mit gestohlenen Daten arbeiten und kritische Schäden verursachen. Ergeben sich hierbei Anzeichen auf eine Kompromittierung oder einen Leak der Zugangsdaten, so kann als Reaktion ein Wechsel der Zugangsdaten über einen nicht kompromittierten Kommunikationskanal veranlasst oder schlicht das betroffene Zugangskonto gesperrt werden.</p></td></tr></table><h2>BER.6: Authentifizierung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BER.6.1: Gruppenkonten - Passwortwechsel bei Weggang</td><td><p>Berechtigung SOLLTE für Gruppenkonten die Änderung von Zugangsdaten bei Weggang von Nutzenden ausführen.</p></td><td><p>Gruppenkonten werden von mehreren Nutzenden (z.B. Schichtdienst) verwendet. Verlassen Nutzende die Institution oder Wechseln das Tätigkeitsfeld und das Passwort des Gruppenkontos wird nicht gewechselt, so besteht die Gefahr, dass das Gruppenkonto unberechtigt verwendet wird.</p></td></tr><tr valign="top"><td>BER.6.2: Passwortmanager</td><td><p>Berechtigung für Nutzende SOLLTE einen Passwortmanager installieren.</p></td><td><p>Der Einsatz eines Passwortmanagers, der von der Institution den Nutzenden zur Verfügung gestellt wird, erleichtert die Generierung von sicheren Passwörtern und deren sicherer Verwahrung, indem eine verschlüsselte Datenbank genutzt wird und der Zugang zu dem Passwortmanager mit einem Masterpasswort oder Multi-Faktor Authentisierung geschützt ist.</p></td></tr><tr valign="top"><td>BER.6.3: Identitätsüberprüfung</td><td><p>Berechtigung SOLLTE eine Identitätsüberprüfung vor dem Zurücksetzen von Passworten ausführen.</p></td><td><p>Das unberechtigte Zurücksetzen von Zugangsdaten ist eine bekannte Angriffsmethode. Eine eindeutige Identifizierung des Inhabers des Zugangs z.B. anhand eines Personalausweises oder OTP ist eine zwingende Voraussetzung bevor eine Zurücksetzung erfolgen kann.</p></td></tr><tr valign="top"><td>BER.6.4: Hinweise bei Anmeldefehlern</td><td><p>Berechtigung für Anwendungen SOLLTE Hinweise darauf, ob ein Zugangskonto existiert bei erfolglosen Anmeldeversuchen deaktivieren.</p></td><td><p>Den Hinweis, dass bei erfolglosen Anmeldeversuchen das Passwort oder die Kennung falsch ist, könnte ein Angreifer als sogenannte User Enumeration (Benutzerkonten-Aufzählung) oder Account Discovery (Konto-Entdeckung) Schwachstelle ausnutzen. Dadurch wird das Risiko einer Brute-Force-Attacke oder eines Credential Stuffings erhöht, bei der ein Angreifer eine Liste potenzieller Benutzernamen durchprobieren könnte, um gültige Konten zu identifizieren. Der Schutz kann gewährleisten, dass ein Angreifer nicht automatisch weiß, welche Konten er als Nächstes mit Passwörtern attackieren muss oder Rückschlüsse auf registrierte Zugangskonten erhält. Zur Umsetzung kann die Institution alle Rückmeldungen bei fehlgeschlagenen Anmeldeversuchen so vereinheitlichen, dass sie keinen Aufschluss über den Grund des Fehlschlags geben, beispielsweise durch die generische Nachricht „Der eingegebene Benutzername oder das Passwort ist ungültig.“.</p></td></tr></table><h2>BER.7: Schlüsselmanagement</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>BER.7.1: Etablierte Algorithmen bei der Schlüsselerzeugung</td><td><p>Berechtigung SOLLTE die ausschließliche Verwendung etablierter kryptografischer Algorithmen bei der Schlüsselerzeugung nach <i>einem anerkannten Standard</i> verankern.</p></td><td><p>Etablierte kryptografische Algorithmen sind mathematisch fundierte Verschlüsselungsverfahren und Protokolle, die in der aktuellen Praxis nicht mit vertretbarem Aufwand gebrochen werden können. Sie basieren auf mathematisch schwer lösbaren Problemen, bieten Resistenz gegen bekannte kryptanalytische Angriffe, unterstützen ausreichend große Schlüssellängen und wurden von Experten gründlich geprüft und analysiert. Aktuelle etablierte Algorithmen sind in BSI TR-02102 zu finden. Für weitere Details zur Implementierung siehe Detailspezifikation kryptografischer Abläufe und Mechanismen des BSI.</p></td></tr><tr valign="top"><td>BER.7.2: Schlüssellänge</td><td><p>Berechtigung SOLLTE die Schlüssellängen nach <i>einem anerkannten Standard</i> bei der Schlüsselerzeugung zuweisen.</p></td><td><p>Für die Sicherheit von Schlüsseln wie Passwörter oder PINs ist die Länge von Bedeutung. Für Details siehe BSI TR-02102.</p></td></tr><tr valign="top"><td>BER.7.3: Verzeichnis öffentlicher Schlüssel</td><td><p>Berechtigung SOLLTE zu jedem öffentlichen Schlüssel die dazugehörige Identität, das Ablaufdatum, den Nutzungszweck, die Schlüsselart und den Algorithmus bei der Schlüsselbeglaubigung dokumentieren.</p></td><td><p>Im Verzeichnis öffentlicher Schlüssel werden die öffentlichen Schlüssel, die von der Institution erzeugt oder eingesetzt werden, aufgelistet. Hiermit werden kryptografische Schlüssel systematisch erfasst und dokumentiert.  Zweckmäßig ist es, die Angaben direkt im Schlüssel abzuspeichern.</p></td></tr><tr valign="top"><td>BER.7.4: Erzeugung auf sicheren IT-Systemen</td><td><p>Berechtigung SOLLTE die Verwendung eines IT-Systems, welches mindestens dasselbe Schutzniveau bietet, für das der Schlüssel eingesetzt werden soll, bei der Schlüsselerzeugung verankern.</p></td><td><p>Wird ein Schlüssel auf einem System erzeugt, dass einen geringeren Schutz bietet als auf dem späteren Einsatzsystem, dann könnte der Schlüssel bereits kompromittiert sein.</p></td></tr><tr valign="top"><td>BER.7.5: Kriterien für die Qualität von Zufallszahlen</td><td><p>Berechtigung SOLLTE <i>Kriterien</i> für die Qualität von Zufallszahlen bei der Schlüsselerzeugung verankern.</p></td><td><p>Wenn bei der Schlüsselerzeugung ein ungeeigneter Zufallszahlengenerator verwendet wird, könnte ein Angreifer Schlüssel errechnen. Daher sind Kriterien für Zufallszahlengeneratoren zu wählen, z.B. Verwendung etablierter, durch unabängige Dritte geprüfter Zufallszahlengeneratoren. Für Details siehe BSI TR-02102-1. Wichtig ist dabei auch, dass die verwendete Zufallsquelle tatsächlich eine nicht vorhersagbare Zahlenerzeugung erreicht. Inbesondere virtualisierte Systeme könnten ungeeignet sein zur Schlüsselerzeugung, da ihre Zufallszahlenquellen nicht direkt auf Hardwarefunktionen zurückgreifen.</p></td></tr><tr valign="top"><td>BER.7.6: Etablierte Algorithmen beim Transport</td><td><p>Berechtigung SOLLTE die ausschließliche Verwendung etablierter kryptografischer Algorithmen beim Transport geheimer Schlüssel verankern.</p></td><td><p>Aktuelle etablierte Algorithmen sind in BSI TR-02102 zu finden. Der Transport kann mit Public Key Cryptography Standards (PKCS), z.B. PKCS#12 Dateiformat erfolgen. Für weitere Details zur Implementierung siehe Detailspezifikation kryptografischer Abläufe und Mechanismen des BSI.</p></td></tr><tr valign="top"><td>BER.7.7: Kein Transport privater Schlüssel</td><td><p>Berechtigung KANN den Export privater Schlüssel durch <i>eine zuständige Person oder Rolle</i> autorisieren.</p></td><td><p>Im Allgemeinen ist es sinnvoll, private Schlüssel nur dort zu erzeugen, wo sie auch genutzt werden. Andernfalls könnten sie durch den Export kompromittiert werden. Hiervon sind allerdings zahlreiche Ausnahmen denkbar, z.B. zur Schlüsselerzeugung auf besonders abgesicherten Systemen, zum Transport auf Redundanzsysteme oder zur Datensicherung. Daher ist eine Abwägung sinnvoll, ob der Export zu genehmigen ist.</p></td></tr><tr valign="top"><td>BER.7.8: Etablierte Algorithmen bei der Schlüsselnutzung</td><td><p>Berechtigung SOLLTE die ausschließliche Verwendung etablierter Algorithmen bei der Schlüsselnutzung verankern.</p></td><td><p>Aktuelle etablierte Algorithmen sind in BSI TR-02102 zu finden. Für weitere Details zur Implementierung siehe Detailspezifikation kryptografischer Abläufe und Mechanismen des BSI.</p></td></tr><tr valign="top"><td>BER.7.9: Zweckbindung</td><td><p>Berechtigung SOLLTE Verstöße gegen die Zweckbindung bei der Schlüsselnutzung untersagen.</p></td><td><p>Zweckbindung bedeutet, dass der Schlüssel ausschließlich zu dem im Verzeichnis öffentlicher Schlüssel festgelegten Nutzungszweck verwendet werden darf. Die Zweckbindung gilt insbesondere auch für den privaten Schlüssel.</p></td></tr><tr valign="top"><td>BER.7.10: Abgelaufene Schlüssel</td><td><p>Berechtigung SOLLTE die Nutzung des Schlüssels zur Verschlüsselung oder Signierung nach Ablauf der Nutzungszeit untersagen.</p></td><td><p>Schlüssel dürfen nach Ablauf der Nutzungszeit nur noch zur Entschlüsselung oder Signaturprüfung alter Daten verwendet werden. Bei automatisierter Schlüsselnutzung ist der Schlüssel zu deaktivieren, bei manueller Schlüsselnutzung ist den Nutzenden weitere Verwendung des Schlüssels zu verbieten.</p></td></tr><tr valign="top"><td>BER.7.11: Integrität</td><td><p>Berechtigung SOLLTE die Verifikation der Integrität geheimer Schlüssel vor jeder Nutzung verankern.</p></td><td><p>Wird die Integrität von Schlüsseln vor der Verwendung nicht geprüft, so könnte er unbemerkt durch einen Angreifer ausgetauscht werden, wodurch der Angreifer den vermeintlich verschlüsselten Austausch mitlesen. Daher ist ein Integritätsschutz (z.B. eine bekannte Checksumme oder Fingerabdruck) von abgelegten Schlüsseln sinnvoll. Dies kann z.B. durch den Abgleich von Prüfsummen geschehen, welche auf einem anderen IT-System gespeichert sind. Für die Implementierung genügt es, wenn die eingesetzten IT-Produkte bereits so entwickelt oder beschafft worden sind, dass sie die Prüfung automatisiert durchführen.</p></td></tr><tr valign="top"><td>BER.7.12: Authentizität</td><td><p>Berechtigung SOLLTE die Verifikation der Authentizität öffentlicher Schlüssel vor jeder Nutzung verankern.</p></td><td><p>Für die Implementierung genügt es, wenn die eingesetzten IT-Produkte bereits so entwickelt oder beschafft worden sind, dass sie die Prüfung automatisiert durchführen.</p></td></tr><tr valign="top"><td>BER.7.13: Gültigkeit</td><td><p>Berechtigung SOLLTE die Verifikation der Gültigkeit des Schlüssels vor jeder Nutzung verankern.</p></td><td><p>Die Gültigkeit ergibt sich aus Nutzungszeit und Revocation-Status. Für die Implementierung genügt es, wenn die eingesetzten IT-Produkte bereits so entwickelt oder beschafft worden sind, dass sie die Prüfung automatisiert durchführen.</p></td></tr><tr valign="top"><td>BER.7.14: Schlüssel vor Ablauf prüfen</td><td><p>Berechtigung SOLLTE Schlüssel auf das baldige Auslaufen der Nutzungszeit <i>regelmäßig</i> überprüfen.</p></td><td><p>Wird die Gültigkeit von Schlüsseln vor dem Auslaufen nicht überwacht, so könnten Schlüssel ungültig werden, wodurch Schnittstellen oder Anwendungen plötzlich nicht mehr verfügbar sein könnten. Läuft ein Schlüssel bald ab, obwohl der Zweck weiterhin bestehen bleibt, so ist es sinnvoll den Schlüssel rechtzeitig durch einen neuen zu ersetzen. Hierbei ist zu beachten, dass bei Schlüsselwechsel verschlüsselte Daten entschlüsselt und erneut verschlüsselt werden.</p></td></tr><tr valign="top"><td>BER.7.15: Vorgehensweise nach Nutzung</td><td><p>Berechtigung SOLLTE eine Vorgehensweise zur Außerbetriebnahme geheimer Schlüssel , sobald sie nicht mehr benötigt werden, verankern.</p></td><td><p>Werden Schlüssen nicht mehr benötigt, so ist es sinnvoll diese im Einklang mit den Anforderungen zur Löschung von Informationen außer Betrieb zu nehmen. Hierbei ist zu beachten, dass bei einem Schlüsselwechsel verschlüsselte Daten entschlüsselt und erneut verschlüsselt werden. Flüchtige Schlüssel sind nach der Sitzung umgehend zu löschen.</p></td></tr><tr valign="top"><td>BER.7.16: Vorgaben für die Schlüsselbeglaubigung</td><td><p>Berechtigung SOLLTE Vorgaben für die Schlüsselbeglaubigung verankern.</p></td><td><p>Je nach Umfang der Beglaubigungstätigkeit gehören hierzu z.B. Algorithmen, Zweckbindung, Nutzungsdauer, sowie prozessuale Vorgaben für Speicherung, Beantragung, Revocation, Erneuerung und Verfügbarkeit. Für Details siehe IETF RFC 3647.</p></td></tr><tr valign="top"><td>BER.7.16.1: Zertifizierungsstelle</td><td><p>Berechtigung SOLLTE die Beglaubigung von Schlüsseln <i>einer zuständigen Person oder Rolle</i> zuweisen.</p></td><td><p>Die Beglaubigung von Schlüsseln ist technisch komplex. Gleichzeitig hängt von ihr die Vertrauensstellung von Systemen und Anwendungen im Informationsverbund ab. Daher ist es sinnvoll diese Aufgabe konkret bestimmten Personen oder Rollen zuzuweisen.</p></td></tr><tr valign="top"><td>BER.7.16.2: Beglaubigung</td><td><p>Berechtigung SOLLTE den Schlüssel anhand der Vorgaben für die Schlüsselbeglaubigung bei Beantragung einer Beglaubigung testen.</p></td><td><p>Hierbei wird getestet, ob die Vorgaben für die Genehmigung der Beglaubigung erfüllt sind.</p></td></tr><tr valign="top"><td>BER.7.16.3: Erneuerung</td><td><p>Berechtigung SOLLTE den Schlüssel anhand der Vorgaben für die Schlüsselbeglaubigung bei Erneuerung einer Beglaubigung testen.</p></td><td><p>Hierbei wird getestet, ob die Vorgaben für die Erneuerung der Beglaubigung erfüllt sind.</p></td></tr><tr valign="top"><td>BER.7.16.4: Revocation</td><td><p>Berechtigung SOLLTE den Schlüssel anhand der Vorgaben für die Schlüsselbeglaubigung bei Revocation einer Beglaubigung testen.</p></td><td><p>Hierbei wird getestet, ob die Vorgaben für die Revocation erfüllt sind.</p></td></tr><tr valign="top"><td>BER.7.16.5: Beglaubigungsstatus</td><td><p>Berechtigung SOLLTE den Beglaubigungsstatus des Schlüssels im Verzeichnis öffentlicher Schlüssel dokumentieren.</p></td><td><p>Der Beglaubigungsstatus erfasst, ob der Schlüssel von der Beglaubigungs- oder Zertifizierungsstelle der Institution beglaubigt wurde.</p></td></tr><tr valign="top"><td>BER.7.16.6: Revocationstatus</td><td><p>Berechtigung SOLLTE den Revocationstatus des Schlüssels im Verzeichnis öffentlicher Schlüssel dokumentieren.</p></td><td><p>Der Revocationsstatus des Schlüsseln erfasst, ob der Schlüssel zurückgezogen wurde, etwa weil er aufgrund einer Kompromittierung nicht mehr sicher verwendet werden kann.</p></td></tr></table><h1>DET: Detektion</h1><p>Die Praktik Detektion sorgt dafür, dass sicherheitsrelevante Ereignisse rechtzeitig erkannt werden. Zu diesem Zweck werden geeignete organisatorische, personelle und technische Maßnahmen im Vorfeld geplant, implementiert und regelmäßig geübt.   Damit die Detektion erfolgreich ist, muss umfassend protokolliert werden. Das Zusammenspiel zwischen den Praktiken Protokollierung und Detektion ist für die erfolgreiche Erkennung sicherheitsrelevanter Ereignisse unerlässlich.  Die Praktik Detektion regelt jedoch nicht den Umgang mit sicherheitsrelevanten Ereignissen nach deren Erkennung. Dies ist Aufgabe der Praktik Sicherheitsvorfallsbehandlung.</p><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th align="left">Group</th><th align="right">#Controls</th></tr><tr valign="top"><td>DET.1: Grundlagen</td><td align="right">5</td></tr><tr valign="top"><td>DET.2: Meldung von Ereignissen</td><td align="right">6</td></tr><tr valign="top"><td>DET.3: Protokollierung</td><td align="right">18</td></tr><tr valign="top"><td>DET.4: Überwachung von Aktivitäten</td><td align="right">23</td></tr><tr valign="top"><td>DET.5: Management von Schwachstellen</td><td align="right">23</td></tr><tr valign="top"><td>DET.6: Vorfallserkennung</td><td align="right">7</td></tr><tr valign="top"><td align="left">&sum;</td><td align="right"><b>82</b></td></tr></table><h2>DET.1: Grundlagen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DET.1.1: Verfahren und Regelungen</td><td><p>Detektion MUSS Verfahren und Regelungen zur Detektion von Sicherheitsvorfällen verankern.</p></td><td><p>Durch die steigende Menge und Komplexität von Datenverarbeitungen sind Sicherheitsvorfälle auch bei bester Prävention zu erwarten. Ein Verfahren zur Detektion stellt sicher, dass Sicherheitsvorfälle zeitnah entdeckt werden können. Hierzu gehört, wie aktiv und passiv Sicherheitsvorfälle erkannt werden, sowie wer bei der Erkennung dabei wofür zuständig ist. Die Umsetzung kann in einem eigenen Prozess, oder integriert in andere Prozesse und Aufgaben erfolgen. Die bei der Festlegung des Verfahrens im Einzelnen zu berücksichtigenden Inhalte ergeben sich aus den Anforderungen dieser Praktik.</p></td></tr><tr valign="top"><td>DET.1.1.1: Dokumentation</td><td><p>Detektion MUSS die Verfahren und Regelungen dokumentieren.</p></td><td><p>Ohne eine Dokumentation könnte die Einhaltung der Verfahren und Regelungen von der Tagesform oder dem individuellen Wissen einzelner Mitarbeiter abhängen, was zu inkonsistenten Entscheidungen und Fehlern führen könnte; insbesondere beim Ausscheiden eines langjährigen Administrators könnte wertvolles prozessuales Wissen verloren gehen. Eine klare Dokumentation sichert die Verbindlichkeit und Wiederholbarkeit und dient als unverzichtbare Grundlage für die Einarbeitung neuer Kollegen, für die Durchführung von Audits und zur einheitlichen Anwendung der Regeln in der gesamten Institution. Die Dokumentation kann in einem eigenständigen Dokument als Richtlinie erfolgen, aber auch als Abschnitt in einem bereits bestehenden Dokument oder über die digital strukturiere Erfassung von Maßnahmen zur Umsetzung der Anforderungen, etwa über eine Software zum Management der Informationssicherheit. Sinnvoll ist es Ort und Struktur der Dokumentation an der jeweiligen Zielgruppe, d.h. den für das Management und die Umsetzung verantwortlichen Personen oder Rollen, auszurichten.</p></td></tr><tr valign="top"><td>DET.1.1.2: Zuweisung der Aufgaben</td><td><p>Detektion MUSS die mit den Verfahren und Regelungen verbundenen Aufgaben <i>zuständigen Personen oder Rollen</i> zuweisen.</p></td><td><p>Die Zuweisung von Aufgaben bezeichnet die eindeutige und verbindliche Übertragung von konkreten Tätigkeiten und Verantwortlichkeiten des Änderungsprozesses, wie etwa die Risikobewertung, die technische Umsetzung oder die finale Freigabe, an definierte Stellen in der Institution. Der Sinn dieser Vorschrift ist es, die Verantwortlichkeit (<b>„Accountability“</b>) für jeden einzelnen Schritt im Prozess klarzustellen. Ohne eine solche Zuweisung könnten kritische Prüfungen unterbleiben, weil sich niemand explizit zuständig fühlt, was wiederum die Wahrscheinlichkeit fehlgeschlagener Änderungen erhöht. Eine klare Regelung kann sicherstellen, dass keine Aufgaben übersehen werden und jede Tätigkeit von einer dafür qualifizierten und befugten Stelle ausgeführt wird, was die Prozesssicherheit signifikant erhöht. Eine bewährte Methode zur Umsetzung ist die Erstellung einer RACI-Matrix (Responsible, Accountable, Consulted, Informed), die tabellarisch für jeden Prozessschritt darstellt, wer für die Durchführung verantwortlich ist, wer die Gesamtverantwortung trägt, wer zu konsultieren und wer zu informieren ist. Diese Zuständigkeiten können auch direkt in einem Workflow- oder Ticketsystem abgebildet werden, sodass Aufgaben, wie beispielsweise Genehmigungsschritte, automatisch an die richtige Gruppe oder Person weitergeleitet werden. Sinnvoll ist es die Zuweisung anhand von Rollen (z.B. <b>„Anwendungsverantwortlicher“</b>, <b>„Netzwerkadministrator“</b>, <b>„Change Manager“</b>) vorzunehmen, statt an konkrete Personen. Dieser Ansatz stellt sicher, dass die Prozesse auch bei Personalwechseln stabil weiterlaufen, da die Zuständigkeit an die Funktion und nicht an das Individuum gebunden ist.</p></td></tr><tr valign="top"><td>DET.1.1.3: Bekanntgabe</td><td><p>Detektion MUSS die zuständigen Personen oder Rollen über die Verfahren und Regelungen informieren.</p></td><td><p>Wenn die Zuständigen die etablierten Verfahren nicht kennen, besteht die Gefahr, dass diese – sei es aus Unwissenheit oder Bequemlichkeit – umgangen werden, was die Schutzwirkung des gesamten Managementsystems untergräbt. So könnte ein neuer Systemadministrator eine weitreichende Konfigurationsänderung vornehmen, ohne den vorgeschriebenen Genehmigungsprozess zu durchlaufen, was zu einem unbemerkten Sicherheitsrisiko führen könnte. Eine gezielte Information kann hingegen die Akzeptanz der Regelungen fördern und sicherstellen, dass alle Beteiligten ihre Rolle im Prozess verstehen und die Abläufe korrekt anwenden. Zur Umsetzung ist es sinnvoll die Dokumentation im Rahmen eines Onboarding-Prozesses bekanntzugeben und bei allen Änderungen eine automtatische Benachrichtigung aller zuständigen Personen oder Rollen anzustoßen.</p></td></tr><tr valign="top"><td>DET.1.2: Regelmäßige Überprüfung</td><td><p>Detektion MUSS die Verfahren und Regelungen <i>regelmäßig</i> und anlassbezogen auf Aktualität überprüfen.</p></td><td><p>Eine geplante der etablierten Verfahren und Regelungen dient dazu festzustellen, ob diese noch wirksam, effizient und an die aktuellen Gegebenheiten angepasst sind. Eine anlassbezogene Überprüfung wird durch spezifische Ereignisse ausgelöst, wie etwa einen schwerwiegenden Sicherheitsvorfall, eine strategische Neuausrichtung der IT oder neue gesetzliche Anforderungen. Der Zweck dieser Anforderung ist es, die kontinuierliche Verbesserung und Anpassungsfähigkeit des Prozesses sicherzustellen, da veraltete Regelungen neuen technologischen Entwicklungen oder Bedrohungen nicht mehr gerecht werden könnten; ein vor Jahren für monolithische Anwendungen konzipierter Prozess ist beispielsweise für agile Entwicklungsmethoden oder Microservice-Architekturen ungeeignet. Die regelmäßige Überprüfung kann die Effektivität des Sicherheitsmanagements langfristig aufrechterhalten und die Resilienz der Institution stärken.</p></td></tr></table><h2>DET.2: Meldung von Ereignissen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DET.2.1: Meldeverfahren</td><td><p>Detektion SOLLTE ein Meldeverfahren verankern.</p></td><td><p>Zweck ist es einerseits Nutzenden das schnelle Melden von potenziellen Sicherheitsproblemen zu ermöglichen und andererseits die zuständigen Stellen zu einer schnellen Reaktion auf Vorfälle anzuhalten.</p></td></tr><tr valign="top"><td>DET.2.1.1: Sofortmaßnahmen Nutzender</td><td><p>Detektion SOLLTE Regelungen für Sofortmaßnahmen durch Nutzende verankern.</p></td><td><p>Beispiele für Sofortmaßnahmen sind der sofortige Stopp weiterer Tätigkeiten an betroffenen Systemen, die Dokumentation von Beobachtungen oder zu meldende Informationen (W-Fragen). Hierfür kann die IT-Notfallkarte „Verhalten bei IT-Notfällen“ des BSI genutzt werden.</p></td></tr><tr valign="top"><td>DET.2.1.2: Meldeformulare</td><td><p>Detektion SOLLTE Meldeformulare für Vorfallsmeldungen installieren.</p></td><td><p>Die Angabe des Meldezeitpunktes oder der Name des Meldenden, kann auch durch ein Formular automatisch ausgefüllt werden.</p></td></tr><tr valign="top"><td>DET.2.1.3: Rückmeldungen</td><td><p>Detektion SOLLTE ein Verfahren für Rückmeldungen verankern.</p></td><td><p>Rückmeldungen an Personen, die potenzielle Vorfälle gemeldet haben, sind hilfreich, da sie zum besseren Verständnis beitragen, worauf bei künftigen Meldungen zu achten ist und wie die Meldenden zur Bearbeitung des Vorfalls beitragen können. Ohne Rückmeldung könnte Unsicherheit entstehen, ob ein Vorfall überhaupt aufgenommen oder ernst genommen wurde, was zu Frustration oder einer sinkenden Bereitschaft zur Meldung künftiger Ereignisse führen könnte. Eine zeitnahe und angemessene Rückmeldung kann dagegen die Nutzenden in ihrem sicherheitsbewussten Verhalten bestärken, die Relevanz ihrer Meldung verdeutlichen und Missverständnisse vermeiden. So kann beispielsweise eine Rückmeldung nach einem gemeldeten Phishing-Versuch klarstellen, ob es sich um einen bekannten Angriff handelte oder ob zusätzliche Maßnahmen wie das Zurücksetzen eines Passworts empfohlen werden. Ebenso kann eine Rückmeldung nach einem gemeldeten Systemausfall erläutern, ob dieser sicherheitsrelevant war oder eine rein technische Störung vorlag. Ein Rückmeldeverfahren kann in diesem Kontext als ein strukturierter Ablauf definiert werden, über den die meldende Person nach Eingang ihrer Meldung eine Information über den Status, die Relevanz und – falls sinnvoll – empfohlene Folgeschritte erhält. Ein automatisiertes Ticketsystem kann beispielsweise sofortige Eingangsbestätigungen generieren und Statusänderungen kommunizieren. Ebenso kann eine abgestufte Rückmeldepflicht sinnvoll sein, bei der kritische Vorfälle eine priorisierte persönliche Rückmeldung durch Fachpersonal erhalten, während unkritische Meldungen standardisierte Mitteilungen bekommen. Technische Hilfsmittel wie Mail-Vorlagen, interne Chatbots oder Self-Service-Portale können die Effizienz erhöhen</p></td></tr><tr valign="top"><td>DET.2.2: Security Operations Center</td><td><p>Detektion KANN die Erkennung, Beurteilung und initiale Behandlung von Vorfällen <i>dediziertem Personal</i> zuweisen.</p></td><td><p>Ein Security Operations Center (SOC) ist eine organisatorische Einheit, deren dedizierte Aufgabe die Überwachung von sicherheitskritischen Ereignissen, sowie die Reaktion auf Sicherheitsvorfälle ist. Für die Definition eines Sicherheitskritischen Ereignisses, siehe Glossar (Namensräume des Grundschutz++). Aufgrund der Komplexität und besonderen Bedeutung der Aufgabe leisten Spezialisten für Detektion und Reaktion auf Sicherheitsvorfälle einen wichtigen Beitrag zur effektiven Informationssicherheit einer Institution. Werden diese Aufgaben von speziell hierfür geschultem Personal übernommen und nicht „nebenbei“ von Betriebspersonal, so werden Zielkonflikte zwischen Informationssicherheit und reibungslosem Betrieb vermieden und die Qualität der Sicherheitsbeurteilungen steigt.  Kann durch ein selbst betriebenes SOC oder einen Dienstleister realisiert werden.</p></td></tr><tr valign="top"><td>DET.2.3: Ständiger Bereitschaftsdienst</td><td><p>Detektion KANN einen ständigen Bereitschaftsdienst verankern.</p></td><td><p>Dies erfordert, dass 24/7 eine Person bereitgehalten wird, welche bei sicherheitsrelevanter Alarmierung umgehend die Behebung des Vorfalls aufnimmt. Welche Ereignisse kritisch sind, ist dabei von der Kritikalität der betroffenen Systeme oder Anwendungen abhängig. Für die Definition eines Sicherheitskritischen Ereignisses, siehe Glossar (Namensräume des Grundschutz++).</p></td></tr></table><h2>DET.3: Protokollierung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DET.3.1: Protokollierung sicherheitsrelevanter Ereignisse</td><td><p>Detektion SOLLTE Sicherheitsrelevante Ereignisse mindestens für <i>eine bestimmte Frist</i> protokollieren.</p></td><td><p>Für die Definition eines Sicherheitsrelevanten Ereignisses, siehe Glossar (Namensräume des Grundschutz++). Relevant sind hierbei insbesondere die Protokollierung auf zentralen Diensten und Servern. Dazu gehören auch vorhandene Cloud-Anwendungen oder -Dienste.  Hier besteht ein enger Bezug zur Praktik Änderungen und Tests.</p></td></tr><tr valign="top"><td>DET.3.1.1: Was, Wann, Wo</td><td><p>Detektion SOLLTE zu jedem sicherheitsrelevanten Ereignis mindestens Zeitpunkt, die Quelle und das Zielobjekt protokollieren.</p></td><td><p>Für die Definition eines Sicherheitsrelevanten Ereignisses, siehe Glossar (Namensräume des Grundschutz++). Damit einem Ereignis zuverlässig ein bestimmter Zeitpunkt zugewiesen werden kann, ist eine einheitliche Zeitquelle für die Systemuhr (meist über NTP oder PTP) als Voraussetzung erforderlich.  Bei der Protokollierung der Herkunft oder Quelle (z.B. Gerätenamen, IP-Adresse) besteht ein enger Zusammenhang zu Compliance-Anforderungen, etwa zum Datenschutz.</p></td></tr><tr valign="top"><td>DET.3.1.2: Datenverarbeitungen</td><td><p>Detektion für Daten KANN die Verarbeitung von Daten protokollieren.</p></td><td><p>Bei Daten mit hohem Schutzbedarf kann es sinnvoll sein, bestimmte Verarbeitungen (z.B. Zugriffe, Veränderungen, Löschung, Datenexporte) zu protokollieren. Änderungen können mit Versionsverwaltungssystemen automatisch protokolliert werden. Beispiele sind Zugriffe auf Dateifreigaben, Webportale oder Datenbank-Abfragen durch eine Anwendung, der Export von Verbindungsdaten auf dem TK-Server, oder der Versand von Nachrichten mit bestimmten Schlüsselnwörtern.</p></td></tr><tr valign="top"><td>DET.3.1.3: Authentifizierungen</td><td><p>Detektion für IT-Systeme SOLLTE Authentifizierungen bei Erfolg und Fehlschlag protokollieren.</p></td><td><p>Relevant sind dabei z.B. die lokale Anmeldung, Anmeldung und Zugriffe auf Schnittstellen des Systems über das Netz, oder auch die physische Authentifizierung an einem Zutrittskontrollsystem.</p></td></tr><tr valign="top"><td>DET.3.1.4: Privilegierte Ereignisse</td><td><p>Detektion für Anwendungen SOLLTE privilegierte Ereignisse einschließlich der Aktivierung, Deaktivierung oder Blockierung privilegierter Funktionen protokollieren.</p></td><td><p>Privilegierte Ereignisse sind Vorgänge, bei denen besonders weitreichende Rechte genutzt werden – beispielsweise die Vergabe oder Entziehung von Administratorrechten, das Deaktivieren von Virenscannern oder Änderungen an Firewallregeln. Gerade solche Eingriffe könnten einen erheblichen Einfluss auf die Verfügbarkeit und Integrität von Daten haben. Ohne eine gezielte Aufzeichnung könnten sicherheitsrelevante Änderungen unentdeckt bleiben – etwa, wenn ein Angreifer unbefugt einen privilegierten Account übernimmt und Spuren verwischt, oder wenn ein interner Benutzer kritische Funktionen deaktiviert, wodurch Schutzmaßnahmen umgangen werden.</p></td></tr><tr valign="top"><td>DET.3.1.5: Ausgeführte Kommandozeilenbefehle</td><td><p>Detektion für IT-Systeme SOLLTE ausgeführte Kommandozeilenbefehle protokollieren.</p></td><td><p>Angreifer nutzen Kommandozeilenfunktionen wie Bash oder Windows PowerShell, um mit Bordmitteln schädliche Befehle auszuführen. Hier sind vor allem Living-off-the-Land-Binaries (LOLBins) und Nutzlasten (Malware Payloads) zu nennen.</p></td></tr><tr valign="top"><td>DET.3.1.6: Anbindung von Peripheriegeräten</td><td><p>Detektion für IT-Systeme SOLLTE das Anschließen von Peripheriegeräten protokollieren.</p></td><td><p>Das Protokollieren der Anbindung von Peripheriegeräten kann helfen, Manipulationsversuche an IT-Systemen frühzeitig zu erkennen und nachzuvollziehen. Ohne ein solches Protokoll könnte beispielsweise ein unbefugtes Speichermedium angeschlossen und vertrauliche Daten unbemerkt entwendet werden, oder es könnte Schadsoftware über ein USB-Gerät eingeschleust werden. Auch manipulierte Eingabegeräte könnten genutzt werden, um Tastatureingaben auszulesen oder unbemerkt Befehle einzuschleusen. Unter Peripheriegeräten sind in diesem Kontext externe Komponenten (aus Hardware oder virtuell) zu verstehen, die ein IT-System erweitern oder mit diesem verbunden werden – etwa USB-Sticks, externe Festplatten, Smartphones im Lade- oder Datenmodus, Drucker oder auch spezialisierte Geräte wie Diagnose- oder Messinstrumente. Zur praktischen Umsetzung kann eine Institution beispielsweise auf Betriebssystemfunktionen zurückgreifen, die Geräteanschlüsse im System-Log erfassen, oder ergänzende Endpoint-Management-Lösungen einsetzen, die eine zentralisierte Protokollierung erlauben.</p></td></tr><tr valign="top"><td>DET.3.1.7: Systemfehler</td><td><p>Detektion für IT-Systeme SOLLTE Fehlermeldungen des Systems protokollieren.</p></td><td><p>Die Protokollierung von Fehlermeldungen kann eine wesentliche Grundlage für die Früherkennung von Sicherheits- und Stabilitätsproblemen in IT-Systemen bilden. Ohne ein systematisches Logging könnte ein kritischer Hardwaredefekt, eine beschädigte Systemdatei oder ein fehlgeschlagener Sicherheits-Update-Prozess unentdeckt bleiben und dadurch die Integrität oder Verfügbarkeit von IT-Systemen gefährden. Ebenso könnte ein Angreifer, der wiederholt unautorisierte Befehle ausführt oder Dienste fehlerhaft anspricht, unbemerkt bleiben, wenn die resultierenden Fehlermeldungen nicht nachvollzogen werden. Auf technischer Ebene kann es zweckmäßig sein, das native Logging des Betriebssysteme zu aktivieren und so zu konfigurieren, dass Fehlermeldungen konsistent erfasst werden – beispielsweise über Syslog-Dienste oder Windows-Event-Logs. Eine zentrale Log-Sammlung kann helfen, auch bei verteilten Systemen eine einheitliche Auswertung vorzunehmen.</p></td></tr><tr valign="top"><td>DET.3.1.8: Störungen der Netzerreichbarkeit</td><td><p>Detektion für IT-Systeme KANN Störungen der Netzerreichbarkeit protokollieren.</p></td><td><p>Eine Störung der Netzerreichbarkeit kann ein Indiz für Überlastungen, Fehler oder Angriffe im Netz sein. Wann eine Störung vorliegt, kann anhand von Schwellwerten, z.B. durch das Ausbleiben eines regelmäßigen Heartbeat-Paketes, getestet werden.</p></td></tr><tr valign="top"><td>DET.3.1.9: Systemspezifische Ereignisse</td><td><p>Detektion für IT-Systeme KANN <i>bestimmte systemspezifische Ereignisse</i> protokollieren.</p></td><td><p>Bestimmte systemspezifische Ereignisse meint hier, dass von der Instiution konkret festgehalten wurde, welche für das System relevanten Ereignisse im Einzelnen protokolliert werden. Beispiele sind Aktionen mit spezifisch konfigurierten privilegierten Berechtigungen, Prozessaktivitäten des Betriebssystems, wie das Starten eines Systemprozesses, Dateierzeugung oder das Laden eines Treibers, die Modifikation von Systemkonfigurationsdateien oder die Installation oder Deinstallation von Systemdiensten und Anwendungen, sowie das Herunterfahren oder Neustarten des Systems. Die Festlegung, welche dieser oder weiterer systemspezifischer Ereignisse protokolliert werden, obliegt der Institution und hängt von der jeweiligen Systemumgebung und dem Schutzbedarf ab.</p></td></tr><tr valign="top"><td>DET.3.1.10: Fehler der Anwendung</td><td><p>Detektion für Anwendungen SOLLTE Fehlermeldungen der Anwendung protokollieren.</p></td><td><p>Fehlermeldungen können wichtige Hinweise auf technisches Versagen oder menschliches Fehlverhalten liefern. Insbesondere, wenn Fehlermeldungen neuartig sind, oder gehäuft auftreten, können sie Indiz für Probleme sein, die behandlungsbedürftig sind. Denken Sie insbesondere auch an Fehlermeldungen in automatisierten Prozessen, da diese möglicherweise sonst nicht zur Kenntnisnahme gelangen.</p></td></tr><tr valign="top"><td>DET.3.1.11: Nutzungsstatistik</td><td><p>Detektion für Anwendungen KANN eine Nutzungsstatistik protokollieren.</p></td><td><p>Bei der statistischen Protokollierung werden z.B. Anzahl oder Durchschnittswerte gespeichert, nicht jedoch die genaue Herkunft oder der Zeitstempel bestimmter Ereignisse. Nutzungsstatistiken wahren die Privatsphäre der einzelnen Nutzenden, ermöglichen jedoch eine Erkennung von Fehlern oder Anomalien in der Nutzung. Beispiele sind die Anzahl von Anfragen für eine bestimmte Ressource (etwa Webserver-URL oder DNS-Name), Anzahl der Anfragen einer bestimmten Anfrageart, Geräte- oder Anwendungskategorien (etwa pro Browseragent oder Betriebssystemversion), Anzahl bestimmter Antworttypen (z.B. Webserver-Fehlercodes), sowie Zugriffsversuche. Hierdurch können Betriebsprobleme wie Caching Fehler oder DoS-Angriffe erkannt werden.</p></td></tr><tr valign="top"><td>DET.3.1.12: Anwendungsspezifische Ereignisse</td><td><p>Detektion für Anwendungen KANN <i>bestimmte anwendungsspezifische Ereignisse</i> protokollieren.</p></td><td><p>Die Festlegung, welche spezifischen Ereignisse protokolliert werden, obliegt der Institution und hängt von der jeweiligen Systemumgebung und dem Schutzbedarf ab. Beispiele sind Änderungen an Zugangskonten im Verzeichnisdienst, Telekommunikationsverbindungen, ein Verstoß gegen eine konfigurierte Policy, unautorisierter Zugriff, API-Aufrufe zwischen verschiedenen Anwendungskomponenten, Transaktionen in einem Finanzsystem oder einer E-Commerce-Anwendung, Konfigurationsänderungen  oder ein Absturz der Anwendung. Die Protokollierung dieser Ereignisse kann helfen, die Behandlung durch das Betriebspersonal anzustoßen oder Indizien für Ermittler zu sichern.</p></td></tr><tr valign="top"><td>DET.3.1.13: Integration von Cloud-Diensten</td><td><p>Detektion für Cloud-Dienste KANN Ereignisse in der Cloud im Audit Log der Institution protokollieren.</p></td><td><p>Daten in Cloud-Diensten könnten von Angreifern über das Internet angegriffen werden, ohne dass Ereignisse im internen Netz hierauf Rückschlüsse geben. Dies könnte zum Beispiel durch Phishing geschehen, wodurch ein OAuth Token für den Cloud-Zugang missbraucht wird. Die Integration der Logs des Cloud-Dienstleisters in die institutionseigene Protokollierung kann hier helfen, z.B. bei Authentifizierung oder Berechtigungsänderungen, sowie bei Zugriff oder Veränderung von Daten. Insbesondere die Integration des Loggings mit einer bedingten Zugriffsrichtlinie kann hier helfen, z.B. indem Zugriffe von ungewöhnlichen IP-Adressen oder Browser Agents auf Angriffe hinweisen können. Die Integration von Cloud-Protokollen in ein internes Logging birgt oft erhebliche Herausforderungen, darunter die Bewältigung des enormen Volumens und der Vielfalt an Datenformaten, was durch selektive Protokollierung, Datennormalisierung und -anreicherung angegangen werden kann. Die Absicherung der Datenpipeline gegen Man-in-the-Middle-Angriffe kann durch die Einhaltung der technischen Anforderungen an die beteiligten IT-Systeme und Anwendungen bewältigt werden, z.B. Verschlüsselung und Authentifizierung. Da Cloud-Anbieter oftzusätzliche Gebühren für den Datentransfer (Egress-Kosten) verlangen bietet es sich an, die Protokolle vor der Übertragung zu filtern, um die Kosten für die Verbesserung der Sicherheit gering zu halten.</p></td></tr><tr valign="top"><td>DET.3.2: Filterung nicht benötigter Inhalte</td><td><p>Detektion KANN die Protokollierung nicht benötigter Inhalte anhand von <i>Kriterien</i> einschränken.</p></td><td><p>Je nach Anwendung und Konfigurationeinstellungen könnten Protokolle auch Daten enthalten, die dort nicht benötigt werden, z.B. um die Vertraulichkeit der Daten zu wahren oder aufgrund von Compliance-Anforderungen. Dem kommt eine noch höhere Bedeutung zu, wenn die Protokolle zwischen Institutionen ausgetauscht, oder bei Cloud-Dienstleistern gespeichert oder analysiert werden. Maßnahmen können z.B. Anonymisierung von IP-Adressen oder anderen personenbezogenen Daten oder Geschäftsgeheimnissen, sowie enge Löschfristen sein. Für Verkehrsdaten kann der BfDI Leitfaden Speicherung Verkehrsdaten als Grundlage genutzt werden. Soweit möglich, ist es sinnvoll, die Filterung minimalinvasiv zu gestalten, d.h. nur diejenigen Daten auszufiltern, deren Speicherung nicht rechtlich oder tatsächlich möglich ist, die restlichen Angaben zum Ergebnis jedoch zu protokollieren.</p></td></tr><tr valign="top"><td>DET.3.3: Speicherkapazität</td><td><p>Detektion SOLLTE den für die Protokollierung zur Verfügung stehenden Speicherplatz <i>bei Erreichen eines bestimmten Schwellwertes oder regelmäßig</i> überprüfen.</p></td><td><p>Diese Vorschrift zielt darauf ab, die Verfügbarkeit der Protokolldaten sicherzustellen. Das ist essenziell, da eine unterbrochene oder lückenhafte Aufzeichnung die Früherkennung von Angriffen unmöglich machen könnte, was dazu führen könnte, dass kritische forensische Beweise für eine Untersuchung fehlen. Die Umsetzung dieser Anforderung kann auf verschiedene Arten erfolgen. Es könnte ein Skript oder ein automatisierter Dienst eingesetzt werden, der den Füllstand des Speicherplatzes in regelmäßigen Abständen, zum Beispiel alle 15 Minuten oder einmal pro Stunde, prüft. Alternativ kann eine Überprüfung bei einem definierten Schwellenwert durchgeführt werden, etwa wenn 80 % oder 90 % des zugewiesenen Speicherplatzes belegt sind. Zur Behebung könnte bei Kapazitätsengpässen eine automatische Archivierung älterer Protokolldaten auf einem separaten, kostengünstigeren Speicher gestartet werden, um den primären Speicher zu entlasten. Es kann aber auch eine Rotationsstrategie für Log-Dateien konfiguriert werden, die bei Erreichen einer bestimmten Größe oder eines Alters die ältesten Dateien löscht oder archiviert.</p></td></tr><tr valign="top"><td>DET.3.4: Revisionssicherheit</td><td><p>Detektion SOLLTE Änderungen am Audit Log revisionssicher dokumentieren.</p></td><td><p>Wenn die Protokollaufzeichnung unzureichend vor Veränderung geschützt ist, könnten Innentäter diese manipulieren oder löschen, um nicht erkannt oder belangt zu werden. Hierzu gehört auch, dass Administrierende die Protokolldaten zu ihren eigenen Tätigkeiten manipulieren oder löschen könnten. Die Integrität kann durch die Erstellung und getrennte Aufbewahrung von kryptografischen Hashes oder ein Versionskontrollsystem sichergestellt werden. Um sicherzustellen, dass nur autorisierte Personen die Protokolle verändern können, können z.B. Verschlüsselung und getrennte Aufbewahrung des Schlüssels, einmalig beschreibare Datenträger, oder ein Protokollierungsserver/SIEM mit stark eingeschränkten Zugriffsrechten eingesetzt werden. Auch die Aufzeichnung in einer öffentlichen Transparenzdatei ist möglich, wenn die Protokolle keine vertraulichen Daten enthalten.</p></td></tr><tr valign="top"><td>DET.3.5: Unbestreitbarkeit</td><td><p>Detektion für Daten KANN Nachweise für den Zusammenhang <i>bestimter Ereignisse</i> mit <i>einer bestimmten Person oder Rolle</i> dokumentieren.</p></td><td><p>Für Handlungen, die eine besondere Bedeutung für die rechtliche Compliance oder die korrekte Verarbeitung von Daten in kritischen Geschäftsprozessen haben, kann es sinnvoll sein, eine zweifelsfreie Zuordnung des Ereignisses zu einer Person zu gewährleisten. Beispiele können das Senden von Nachrichten als Geschäftsleitung, die Überweisung hoher Beträge auf Konten im Ausland oder der Zugang einer Nachricht mit großer rechtlicher Bedeutung sein. Für einen zweifelsfreien Nachweis reicht die einfache Zuordnung zu einem Zugangskonto oft nicht aus, da das Konto auch von anderen missbraucht worden sein könnte. Zum Nachweis können verschiedene Maßnahmen eingesetzt werden: Digitale Signaturen auf Basis asymmetrischer Kryptographie können die Urheberschaft von Dokumenten verifizieren, während Zeitstempel von vertrauenswürdigen Zeitservern die chronologische Integrität sicherstellen. Eine dezentrale Speicherung der Logs auf verschiedenen Systemen erschwert Manipulationsversuche; ergänzend erhöht die Implementierung einer Blockchain-Technologie mit verketteten Hashwerten die Fälschungssicherheit erheblich. Hardwarebasierte Sicherheitsmodule (HSMs) können kryptografische Schlüssel vor unbefugtem Zugriff schützen.</p></td></tr></table><h2>DET.4: Überwachung von Aktivitäten</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DET.4.1: Überwachung der Protokollierung</td><td><p>Detektion SOLLTE die Funktionsfähigkeit der Protokollierung überwachen.</p></td><td><p>Zu den Kriterien kann beispielsweise die Aktivierung oder Deaktkvierung des Loggings auf Systemen, sowie die Datenmenge eingehender Logs in einem bestimmten Zeitraum gehören.</p></td></tr><tr valign="top"><td>DET.4.2: Automatische Angriffserkennung</td><td><p>Detektion für IT-Systeme SOLLTE diese auf Anzeichen für Angriffe durch <i>einen automatisierten Mechanismus</i> überwachen.</p></td><td><p>Wenn professionelle Tätergruppen Zugriff auf Systeme und Daten erhalten, nutzen sie diese zunehmend schneller für ihre Zwecke aus, z.B. um Daten abfließen zu lassen oder Ransomware zu verteilen. Zur Umsetzung können sowohl netz- als auch hostbasierte Erkennungssysteme (NIDS und HIDS) verwendet werden. Für die Detektion bei IT-Systemen ohne Installationsmöglichkeit wie Appliances, IoT-Geräte oder OT-Systeme kann ein kombinierter Ansatz aus Netzwerk- und Loganalyse sinnvoll sein. Angriffe können signaturbasiert, sowie durch Verhaltensanalyse und Anomalien erkannt werden. Die Anforderung kann auch mit bereits vorhandenen oder im System integrierten Angriffserkennungsmechanismen erfüllt werden. Zweckmäßig ist es Schwellwerte und Kategorien (Info, Warnung, Alarm) so festzulegen, dass Probleme frühzeitig erkannt werden können, aber beim Betriebspersonal keine Alarmmüdigkeit (alert fatigue) aufkommt. Hierzu ist es hilfreich die Ergebnisse regelmäßig auszuwerten und wenn nötig Korrekturmaßnahmen zu ergreifen.</p></td></tr><tr valign="top"><td>DET.4.3: Überwachung der Angriffserkennung</td><td><p>Detektion SOLLTE die Funktionsfähigkeit der automatisierten Angriffserkennung überwachen.</p></td><td><p>Hierzu gehört insbesondere die Aktivierung oder Deaktivierung der Angriffserkennung, oder das Stoppen zugehöriger Dienste.</p></td></tr><tr valign="top"><td>DET.4.4: Änderungen an Sicherheitsrichtlinien</td><td><p>Detektion SOLLTE Änderungen an Sicherheitsrichtlinien überwachen.</p></td><td><p>Wird die Aktivität von automatisierten Sicherheitswerkzeugen nicht überwacht, so könnten Angreifer diese Schutzmechanismen unbemerkt deaktivieren und die Person so in falscher Sicherheit wiegen. Zudem installieren Angreifer gerne permanente Hintertüren über neue Konten oder Gruppenwechsel.  Automatisierte Sicherheitsrichtlinien sind z.B. Ausnahmelisten von Antivirus- oder EDR, über den Verzeichnisdienst hinzugefügte Gruppenzugehörigkeiten zu sicherheitsrelevanten Gruppen (z.B. Admin), NAC oder Firewallregeln.</p></td></tr><tr valign="top"><td>DET.4.5: Anomale Nutzung der Anwendung</td><td><p>Detektion für Anwendungen KANN die Nutzung der Anwendung auf Anomalien überwachen.</p></td><td><p>Beispiele sind massenhafte Downloads von Dateiservern oder Cloud-Diensten, Datenbankabfragen die eine ungewöhnlich hohe Menge von Daten oder Einträgen, die unerreichbar sein sollen, zurückliefern, oder automatische E-Mail-Weiterleitungen an externe Domains.</p></td></tr><tr valign="top"><td>DET.4.5.1: Verhaltensanalyse von Zugangskonten</td><td><p>Detektion für Verzeichnisdienste KANN das Verhalten von Zugangskonten überwachen.</p></td><td><p>User and Entity Behaviour Analytics (UEBA) nutzt moderne Verfahren einschließlich KI, um Anomalien im Verhalten von Zugangskonten oder Systemen zu erkennen, z.B. Anmeldungen zu ungewöhnlichen Zeiten, von ungewöhnlichen Orten, durch Verwendung veralteter Authentifzierungsverfahren wie NTLMv1 oder die Ausführung ungewöhnlicher Anwendungen. Ungewöhnliches Verhalten kann Anzeichen für netzbasierte Angriffe oder Innentäter sein.   Allerdings gilt es hierbei auch rechtliche Vorgaben zum Datenschutz und betriebliche Mitbestimmungsrechte zu beachten. Ein sinnvoller Maßstab für die Ausgestaltung von Umfang und Detailltiefe der Überwachung können die Geschäfts- und Sicherheitsziele sein. Sinnvoll ist es hierbei begleitende Maßnahmen zur Compliance einzuführen, beispielsweise dass manuelle Analysen nur unter bestimmten Voraussetzungen oder Beteiligungen vorgenommen werden.</p></td></tr><tr valign="top"><td>DET.4.6: Auslaufen von Domains</td><td><p>Detektion für Webserver KANN das Auslaufen von Domains überwachen.</p></td><td><p>Wenn Registrierungsfristen und Verlängerungszeiträume nicht im Blick behalten werden, könnte eine Domain aus Versehen verfallen und damit einhergehend Erreichbarkeits­probleme, Vertrauensverluste oder gar Sicherheits­lücken entstehen. Als Beispiele können Domains dienen, die für Web­auftritte, E‑Mail-Systeme oder API-Endpunkte genutzt werden. Ebenso kann es sich um Subdomains handeln, die für interne Tools, Test­umgebungen oder automatisierte Monitoring­dienste registriert sind. Auch Domains, die nur der Weiterleitung auf Haupt­präsenzen dienen oder die für Zertifikats­ver­waltung (z. B. ACME-Challenges) verwendet werden, können unter diese Überwachung fallen. Jede dieser Anwendungsfälle kann potenziell betroffen sein, wenn die Registrierung unbemerkt abläuft.  Hilfreich ist hierfür ein zentrales Inventar aller genutzten Domains in dem Registrierungs­daten (Ablaufdatum, Registrar, Kontakt­email) erfasst werden. Automatisierte Scripts oder Aufgaben­tickets können eingerichtet werden, die in festgelegten Abständen (z. B. 60, 30 und 7 Tage vor Ablauf) eine Benachrichtigung auslösen. Auch Monitoring-Plattformen mit DNS-Plugins können verwendet werden, um Fristen zu prüfen und Erinnerungen zu generieren. Zusätzlich kann eine Prozess­beschreibung definiert werden, in der Verantwortlichkeiten und Eskalations­wege bei nahendem Domain­ablauf festgehalten sind, um schnelle Entscheidungen und Verlängerungen zu ermöglichen.</p></td></tr><tr valign="top"><td>DET.4.7: Ausstellung neuer HTTPS-Zertifikate</td><td><p>Detektion für Webserver KANN die rechtzeitige Ausstellung neuer HTTPS-Zertifikate für Server, die im Internet erreichbar sind, überwachen.</p></td><td><p>Dies kann mittels Certificate Transparency teilautomatisiert werden. Mit <b>„rechtzeitig“</b> ist hier vor Ablauf des Zertifikats gemeint.</p></td></tr><tr valign="top"><td>DET.4.8: Manipulations-Checkup</td><td><p>Detektion für IT-Systeme KANN das System auf Manipulationsversuche <i>regelmäßig</i> überprüfen.</p></td><td><p>Falls Systeme einem erhöhten Manipulationsrisiko ausgesetzt sind (z.B. wegen öffentlicher Aufstellung), die Vertraulichkeit oder Integrität des Systems oder damit verbundener Daten oder Netze jedoch nicht vernachlässigenswert ist, so ist eine regelmäßige Überprüfung auf Manipulationen empfehlenswert. Hierfür können Gerätesiegel verwendet werden.  Maßnahmen bei Feststellung einer Manipulation können z.B. das Zurücksetzen auf den Werkszustand oder die Aussonderung sein.</p></td></tr><tr valign="top"><td>DET.4.9: Host-basierte Köder</td><td><p>Detektion für IT-Systeme KANN Host-basierte Köder installieren.</p></td><td><p>Köder sind Anwendungen, Dateien oder Datensätze auf dem IT-System, welche die Aufmerksamkeit von Angreifern auf sich ziehen, um diese zu entdecken, nachzuverfolgen oder von echten Zielen abzulenken. Sie werden auch als Canaries oder Tripwire bezeichnet.  Beispielsweise kann das Sicherheitsteam eine gefälschte, aber verlockende Datei (z. B. „IBAN-Kontodaten.xlsx“) im System platzieren und eine Überwachung einrichten, die sie benachrichtigt, wenn die Datei berührt wird - da legitime Benutzer nicht darauf zugreifen können, signalisiert jede Interaktion potenziell unbefugte Aktivitäten. Ein weiteres Beispiel ist eine Datei „unattended.xml“, da sie für Angreifer nützliche Anmeldedaten für automatische Installationen enthalten könnte. Indem Sie eine gefälschte Version mit harmlosen Daten erstellen und den Zugriff auf die Datei oder Anmeldeversuche mit diesen Zugangsdaten überwachen, erhalten Sie eine frühzeitige Warnung, wenn jemand Ihr System auf der Suche nach einfachen Möglichkeiten zur Erlangung von Administratorrechten durchforstet, so dass Sie reagieren können, bevor es zu einem schwerwiegenderen Verstoß kommt. Allerdings kann es hierbei zu falsch-positiv Vorfallsmeldungen kommen, insbesondere wenn die Köder dort platziert werden wo sie für legitime Nutzende leicht zugänglich sind.</p></td></tr><tr valign="top"><td>DET.4.10: Anomalien in Netzen und am Perimeter</td><td><p>Detektion für Netze SOLLTE den Netzwerkverkehr auf Anomalien überwachen.</p></td><td><p>Beispiele sind ausgehende Netzverbindungen zu als bösartig bekannten oder gänzlich unbekannten DNS-Domains oder IP-Adressen, Anzeichen für DNS-Tunneling (ungewöhnlich lange Subdomains oder Spitzenwerte für TXT-Mengen), ungewöhnlich hohes Datenvolumen zu Cloud-Speicherlösungen, sowie unautorisierte Portscans oder Brute Force Angriffe auf Fernwartungsschnittstellen wie RDP oder SSH sein. Hierdurch können Verbindungen zu Angreiferservern (C2 Beacons), die Ausbreitung von Angriffen über das Netz, oder Datenabflüsse erkannt werden.</p></td></tr><tr valign="top"><td>DET.4.10.1: Authentifizierungsversuche an externen Schnittstellen</td><td><p>Detektion für Externe Netzanschlüsse KANN Authentifizierungsversuche auf unauthorisierte Verbindungen <i>regelmäßig</i> überprüfen.</p></td><td><p>Ohne solche Überprüfungen könnte ein Angreifer unbemerkt wiederholt Zugangsdaten erraten (Brute-Force- oder Wörterbuchangriffe) oder unautorisierte Geräte an Schnittstellen wie VPN-Gateways, Firewalls oder externen Modems anbinden. Auch ein unbemerktes Einschleusen von Schadsoftware über offene Remote-Desktop- oder SSH-Verbindungen könnte langfristig unentdeckt bleiben. Eine kontinuierliche Auswertung von Anmeldeversuchen kann dagegen Auffälligkeiten wie ungewöhnlich viele Fehlversuche, Anmeldungen aus geografisch atypischen Regionen oder Verbindungsaufbau außerhalb üblicher Betriebszeiten aufzeigen und so eine wirksame Schutzwirkung entfalten. Als Frist können Intervalle wie <b>„täglich“</b>, <b>„wöchentlich“</b> oder <b>„in Echtzeit“</b> je nach Kritikalität des Anschlusses angemessen sein. Verbindungen sind hier unautorisiert, wenn Anzeichen vorliegen, dass sie von unautorisierten Personen oder von unautorisierten Systemen stammen. Die Überprüfung kann manuell oder durch automatische Analyse von Logdateien erfolgen. Empfehlenswert ist eine kontinuierliche Überwachung. Dabei kann z.B. nach ungewöhnlichen vielen fehlgeschlagenen Anmeldungen, veralteten Berechtigungen, Einwahlen von Adminaccounts, ungewöhnlichen Einwahlorten/IP-Adressbereichen/User Agents oder Uhrzeiten gesucht werden. Als Reaktion kommen z.B. Sperren betroffener Adressbereiche, die Abschaltung angegriffener Schnittstellen oder stärkere Authentifizierungsmechanismen wie Mehr-Faktor-Authentifizierung in Betracht.</p></td></tr><tr valign="top"><td>DET.4.10.2: Netzwerk-Honeypots</td><td><p>Detektion für Netze KANN Netzwerk-Honeypots installieren.</p></td><td><p>Honeypots sind Systeme, die das Verhalten eines Betriebsservers simulieren, um bei netzbasierten Angriffen Informationen über den Angriff zu erhalten. Geeignet sind z.B. vermeintliche Rechnungsbearbeitungssysteme oder Datenbank-Server. Alarmierungsereignisse können hier z.B. Login-Versuche oder unerwartete API-Abfragen sein. Allerdings kann es hierbei zu falsch-positiv Vorfallsmeldungen kommen, insbesondere wenn die Honeypots dort platziert werden, wo sie für legitime Nutzende leicht zugänglich sind oder wenn legitime Netzwerkscans bereits eine Alarmierung auslösen. Daher ist es sinnvoll die konkreten Einsatzgegebenheiten mit den</p></td></tr><tr valign="top"><td>DET.4.10.3: Netzverkehrsfluss</td><td><p>Detektion für Netze KANN auf kritische Netzverkehrsflüsse anhand von <i>Kriterien</i> überwachen.</p></td><td><p>Ein Netzverkehrsfluss ist eine Aufzeichnung von Verkehrsdaten einer Netzwerkverbindung (wie Quell-/Ziel-IP, Ports, Protokoll, übertragene Datenmenge und Zeitdauer). Die Aufzeichnung des gesamten Verkehrs (Packet Capture) des vollständigen Inhalts aller Datenpakete ist hierzu nicht erforderlich, sodass die zu untersuchende Datenmenge überschaubar bleibt. Allerdings sind hier Compliance-Anforderungen zur Datenspeicherung relevant. Für datenschutzrechtliche Fragen zu Verkehrsdaten kann der BfDI Leitfaden Speicherung Verkehrsdaten als Grundlage genutzt werden. Beispiele für Kriterien sind die Aufzeichnung an wichtigen Netzgrenzen (DMS-Internet), in kritischen Netzen, zwischen Serversystemen oder bei Leistungsproblemen.</p></td></tr><tr valign="top"><td>DET.4.11: Monitoring der Netzverfügbarkeit</td><td><p>Detektion für Netze SOLLTE die Verfügbarkeit des Netzes anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>Die Verfügbarkeit von Netzen, insbesondere des Internetanschlusses, sowie im Kern- und Verteilernetz, ist von zentraler Bedeutung für die Verfügbarkeit von IT-Infrastrukturen. Ein Monitoring ermöglicht es dem Betriebspersonal, bei Netzproblemen reagieren zu können, bevor Beschwerden von Nutzenden aufkommen. Kann durch Hello-Packete von Netzkomponenten oder die Erreichbarkeit von Diensten über das Netz umgesetzt werden.</p></td></tr><tr valign="top"><td>DET.4.11.1: Auslastung des Netzes</td><td><p>Detektion für Netze KANN die Auslastung des Netzes anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>Die Überwachung der Netzauslastung ermöglicht eine schnelle Reaktion bei Verfügbarkeitsproblemen. Wichtige Indikatoren sind Auslastung der verfügbaren Bandbreite, Netzlatenz und Packverluste. Unerwartet hoher Datenverkehr kann auch ein Indiz für einen unautorisierten Zugriff auf große Datenmengen sein. Zur Umsetzung ist es zweckmäßig zunächst Normwerte zu ermitteln (Baselining).</p></td></tr><tr valign="top"><td>DET.4.12: Verfügbarkeit des Hostsystems</td><td><p>Detektion für Hostsysteme SOLLTE die Netzerreichbarkeit anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>Schwellwerte (engl. thresholds) sind hier Grenzwerte, die als Maßstab für die normale oder erwartete Netzerreichbarkeit des Hostsystems dienen. Diese Schwellwerte könnten beispielsweise eine bestimmte Anzahl an Fehlversuchen zur Erreichbarkeit in einem definierten Zeitfenster oder eine überdurchschnittlich hohe Anzahl an Verbindungsanfragen sein, die auf ungewöhnliche Netzwerkaktivität hindeuten. Ein Server könnte beispielsweise aufgrund eines Denial-of-Service-Angriffs (DoS) nicht mehr erreichbar sein, wodurch Dienste für Nutzende ausfallen. Ebenso könnte eine unerwartete Nichterreichbarkeit auf einen Hardwaredefekt, einen Konfigurationsfehler oder einen internen Angriff hindeuten, bei dem der Server vom Netz getrennt wurde, um Spuren zu verwischen. Die Überwachung anhand von Schwellwerten kann der Institution dabei helfen, solche Vorfälle frühzeitig zu erkennen und zu reagieren, bevor sie größeren Schaden anrichten. Die Überwachung kann über ein internes Monitoring-System umgesetzt werden, das kontinuierlich die Erreichbarkeit der Server mittels sogenannter Health-Checks oder Probes prüft. Dabei kann beispielsweise ein automatisches Ping-Verfahren eingesetzt werden, das in regelmäßigen Abständen die Antwortzeit des Servers misst. Die festgelegten Schwellwerte könnten zum Beispiel die maximal erlaubte Anzahl an aufeinanderfolgenden fehlgeschlagenen Ping-Antworten oder die durchschnittliche Antwortzeit sein.</p></td></tr><tr valign="top"><td>DET.4.13: Verfügbarkeit der Anwendung</td><td><p>Detektion für Anwendungen SOLLTE die Netzerreichbarkeit anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>Dabei wird die Erreichbarkeit des Dienstes der Anwendung selbst, z.B. auf den bereitstellenden Servern, nicht nur die Erreichbarkeit des Systems überwacht.</p></td></tr><tr valign="top"><td>DET.4.14: Ressourcenauslastung von Hostsystemen</td><td><p>Detektion für Hostsysteme SOLLTE die Ressourcenauslastung anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>Hierzu zählt z.B. die Auslastung der CPU, des Arbeitsspeichers, des Festspeichers.   Dazu ist es sinnvoll vorab Schwellwerte zu ermitteln (KPI Baselining). Mögliche Reaktionsmaßnahmen bei zu hoher Auslastung sind z.B. die Lastverteilung auf mehrere Host-Rechner oder die Beschränkung der Ressourcennutzung pro Client.</p></td></tr><tr valign="top"><td>DET.4.15: Ressourcenauslastung der Server-Dienste</td><td><p>Detektion für Anwendungen KANN die Ressourcenauslastung der für die Anwendung verwendeten Server-Dienste anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>Hierzu zählt z.B. die Auslastung der CPU, des Arbeitsspeichers, des Festspeichers und Anzahl der verbundenen Clients. Dazu ist es sinnvoll vorab Schwellwerte zu ermitteln (KPI Baselining). Mögliche Reaktionsmaßnahmen bei zu hoher Auslastung sind z.B. die Lastverteilung auf mehrere Host-Rechner oder die Beschränkung der Ressourcennutzung pro Client.</p></td></tr><tr valign="top"><td>DET.4.16: Anwendungsbasiertes Kapazitätsmanagement</td><td><p>Detektion für Anwendungen KANN die Ressourcenauslastung systemübergreifend anhand von <i>Schwellwerten</i> überwachen.</p></td><td><p>Hierbei kann nicht nur die aktuelle Auslastung einzelner Server, sondern die Auslastung der Anwendung insgesamt, auch über einen längeren Zeitverlauf inklusive Lastspitzen und Durchschnittswerten, betrachtet werden.</p></td></tr><tr valign="top"><td>DET.4.17: Öffentliche Blocklisten</td><td><p>Detektion für E-Mail KANN öffentliche Blocklisten auf Einträge für eigene E-Mail-Server <i>regelmäßig</i> überprüfen.</p></td><td><p>Die Überprüfung von E-Mail-Blocklisteneinträgen ist entscheidend, um sicherzustellen, dass Nachrichten zuverlässig zugestellt und nicht als Spam klassifiziert werden. Dazu kann zunächst mit Tools wie MXToolbox oder MultiRBL geprüft werden, ob und auf welchen Listen der Server geführt wird, um anschließend die genauen Ursachen zu ermitteln – häufig spielen kompromittierte Konten, unzureichende Authentifizierungsmethoden oder veraltete E-Mail-Listen eine Rolle. Nach der Identifikation können Admins die grundlegenden Probleme beheben, beispielsweise durch Implementierung von SPF-, DKIM- und DMARC-Protokollen, Bereinigung von E-Mail-Listen oder Beseitigung technischer Schwachstellen, bevor bei den jeweiligen Blocklistenbetreibern ein Antrag auf Entfernung gestellt werden kann, wobei in der Regel Nachweise für die durchgeführten Verbesserungen erforderlich sind; zur langfristigen Prävention kann eine regelmäßige Überwachung der Senderreputation, sowie die Einhaltung bewährter E-Mail-Praktiken beitragen, oder die Nutzung eines seriösen E-Mail-Dienstleisters in Betracht gezogen werden.</p></td></tr><tr valign="top"><td>DET.4.18: Unautorisierte Sendeanlagen</td><td><p>Detektion für Räume KANN diesen nach unautorisierten Sendeanlagen durch <i>einen automatisierten Mechanismus</i> überwachen.</p></td><td><p>Bleiben unautorisierte Sendeanlagen unbemerkt, so könnten hierüber Abhörversuche stattfinden oder Störungen legitimer Sender und Empfänger auftreten. Bedenklich sind beispielsweise versteckte Wanzen in Büromöbeln, manipulierte Peripheriegeräte mit eingebauten Sendern, ohne Erlaubnis mitgebrachte Access Points, modifizierte Smartphones mit verdeckten Fernzugriffsfunktionen oder getarnte IoT-Geräte mit Netzwerkverbindung, die sensible Informationen abgreifen und nach außen übertragen könnten.   Zum Aufspüren können Wireless Intrusion Detection Systems (WIDS) genutzt werden, welche Sendeanagen auffinden und unbekannte Sender melden. Um unautorisierte Sender effektiv zu erkennen sind auch begleitende Maßnahmen sinnvoll:  Die Implementierung von Zugangsbeschränkungen und Mitnahmeverboten für nicht geprüfte elektronische Geräte; die Schulung des Personals zur Erkennung verdächtiger Objekte; sowie die Dokumentation aller autorisierten Geräte in einem Inventar, um unbekannte Signalquellen schnell identifizieren zu können.</p></td></tr></table><h2>DET.5: Management von Schwachstellen</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DET.5.1: Zeitnahes Schwachstellenmanagement</td><td><p>Detektion SOLLTE Verfahren und Regelungen zur Erkennung und Behandlung von Schwachstellen verankern.</p></td><td><p>Relevant können hierbei verschiedene Arten von Schwachstellen sein (z.B. Physisch und im Netz, Orte, Adressbereiche, Anwendungen und Ports).   Zur Erkennung können Schwachstellenscans, Pentests und ein Abgleich der eigenen Infrastruktur mit öffentlichen Schwachstellendatenbanken genutzt werden.  Zur Beurteilung der Kritikalität können Scoring-Systeme wie CVSS oder Berichte der betroffenen Hersteller oder Dienstleister herangezogen werden.  Zur Behandlung können z.B. Sicherheitspatches, die Deaktivierung betroffener (Teil-)Funktionen oder Komponenten oder die Isolierung betroffenen Systeme oder Anwendungen in Frage kommen.  Für Details siehe ISO/IEC 30111.</p></td></tr><tr valign="top"><td>DET.5.1.1: Risikobasierte Priorisierung</td><td><p>Detektion KANN erkannte Schwachstellen anhand von <i>risikobasierten Kriterien</i> innerhalb <i>einer Frist</i> überprüfen.</p></td><td><p>Bei einer risikobasierten Priorisierung wird nicht nur die Ausnutzbarkeit der Schwachstelle im Allgemeinen, z.B. durch einen CVS-Score, zur Priorisierung herangezogen, sondern die Beurteilung erfolgt durch eine Kombination solcher generellen Informationen mit dem individuellen Risikoprofil der betroffenen Assets. Dies ermöglicht es, Schwachstellen deutlich passgenauer zu beurteilen und die wirklich kritischen Schwachstellen zuerst zu patchen oder mitigieren.   Hierzu können CVSS-Score, Informationen aus der Threat Intelligence und aus der Risikobewertung von Geschäftsprozessen kombiniert werden. Hierbei können  auch automatisierte Verfahren angewendet werden, z.BMultiplikation von Kennzahlen zur Risikobewertung und von CVSS in Kombination mit Schwellwerten. Ergebnisdokument kann z.B. eine Risikomatrix, oder eine eigene CVE-Bewertungsrubrik sein.</p></td></tr><tr valign="top"><td>DET.5.2: Schwachstellenregister</td><td><p>Detektion SOLLTE Schwachstellen bei Entdeckung inklusive betroffener Komponenten, Kritikalität und Status dokumentieren.</p></td><td><p>Da die Aktualität des Schwachstellenregisters von großer Bedeutung ist, ist die manuelle Pflege von Schwachstellen in einem Dokument nicht empfehlenswert. Stattdessen können automatisiert gepflegte Datenbanken oder spezielle Schwachstellenmanagement-Tools genutzt werden. Das Schwachstellenregister kann auch als verteiltes Register gepflegt werden (z.B. in Schwachstellenscannern, Patchmanagement-Servern, etc.), allerdings ist hierbei eine einheitliche Beurteilung und Priorisierung aufwändiger.</p></td></tr><tr valign="top"><td>DET.5.3: Schwachstellenscans</td><td><p>Detektion SOLLTE eine Vorgehensweise zum Scan nach Schwachstellen einschließlich deren Auswertung und Behandlung verankern.</p></td><td><p>Über das Netz erreichbare Schwachstellen bergen das Risiko, dass hierüber Angriffe in IT-Systeme und Anwendungen eindringen, Daten auslesen oder sich über das Netz verbreiten. Schwachstellenscans finden solche Lücken, indem sie Anfragen zu bekannten Schwachstellen im Netz stellen und die Antworten auswerten. Regelmäßige Scans tragen dazu bei, dass Sicherheitslücken entdeckt werden, bevor sie ausgenutzt werden.</p></td></tr><tr valign="top"><td>DET.5.3.1: Autorisierung kritischer Scans</td><td><p>Detektion SOLLTE kritische Scans durch <i>zuständige Personen oder Rollen</i> autorisieren.</p></td><td><p>Schwachstellenscans könnten aufgrund ihres Umfangs oder der breiten Abdeckung ihrer Aktivitäten selbst Fehlerzustände provozieren oder Schwachstellen auslösen. Wenn Scans besondere Berechtigungen benötigen - z.B. lokale Administrationsrechte oder Zugriff auf ein abgeschottetes Netz sensibler, betriebskritischer Systeme, so kann eine Autorisierung solcher Scans, vor der eine Abwägung der damit verbundenen Risiken vorgenommen wird, angezeigt sein.</p></td></tr><tr valign="top"><td>DET.5.3.2: Korrelation komplexer Angriffswege</td><td><p>Detektion KANN Schwachstellen anhand eines Abgleichs mehrerer Scans miteinander überprüfen.</p></td><td><p>Fortschrittliche Angreifer könnten mehrere, scheinbar unkritische Schwachstellen nacheinander ausnutzen, die erst in Kombination einen gefährlichen Angriff, etwa die Ausführung von Code aus der Ferne, erlauben. Um solche komplexen Angriffe zu erkennen, können Messergebnisse verschiedener Schwachstellenscanner miteinander abgeglichen werden. Komplexe Angriffswege können mit Methoden wie Attack Trees erkannt und bewertet werden.</p></td></tr><tr valign="top"><td>DET.5.3.3: Historische Analyse</td><td><p>Detektion KANN Schwachstellen in öffentlich erreichbaren Systemen oder Anwendungen anhand bekannter Anzeichen im Audit Log testen.</p></td><td><p>Die historische Analyse von Logdateien ermöglicht es, vergangene Systemaktivitäten systematisch zu untersuchen, um potenzielle Sicherheitsvorfälle zu identifizieren, die zum Zeitpunkt ihres Auftretens unbemerkt blieben. Nach der Entdeckung einer Schwachstelle kann so rückwirkend festgestellt werden, ob und wie diese bereits ausgenutzt wurde. Die Umsetzung kann durch Etablierung eines zentralisierten Log-Managements mit langer Aufbewahrungsdauer, Implementierung automatisierter Such- und Korrelationsalgorithmen zur Erkennung bekannter Angriffsmuster und Anomalien in den Logdaten, sowie durch forensische Analyse der Zeitstempel, Quell-IPs, Benutzeraktivitäten und Zugriffsversuche erfolgen. Bei der Feststellung von Schwachstellen in öffentlich zugänglichen Systemen ist es sinnvoll die Audit-Logs gezielt nach Indikatoren zu durchsuchen, die auf entsprechende Angriffsmuster hindeuten - darunter ungewöhnliche Zugriffszeiten, auffällige Authentifizierungsversuche, verdächtige Datenbankabfragen oder charakteristische Command-Injection-Versuche, wodurch potenzielle Kompromittierungen retrospektiv aufgedeckt und in ihrem vollen Umfang bewertet werden können.</p></td></tr><tr valign="top"><td>DET.5.4: Regelmäßige Penetrationstests</td><td><p>Detektion KANN die Abwehrfähigkeit durch Penetrationstests nach <i>einer anerkannten Vorgehensweise</i> <i>regelmäßig</i> überprüfen.</p></td><td><p>Ein Penetrationstest, oft auch als Pentest bezeichnet, ist eine von Sicherheitsexperten simulierte Cyberattacke, um Schwachstellen und Sicherheitslücken aufzudecken. Ziel ist es, komplexe Schwachstellen in konkreten Informationsumgebungen aufzuspüren, bevor sie von echten Angreifern ausgenutzt werden könnten. Dabei werden verschiedene Methoden und Techniken eingesetzt, die auch von Angreifern verwendet werden könnten, z.B. Informationssammlung, Scan und Ausnutzen von Schwachstellen, seitliches Ausbreiten über das Netz, sowie Versuche, durch Täuschung und Manipulation von Personen an Informationen oder Zugriff zu gelangen. Anerkannte Vorgehensweisen, die für Penetrationstests angewendet werden können, sind z.B. der BSI Praxis-Leitfaden für IS-Penetrationstests, OSSTMM, NIST SP 800-115, PTES (Penetration Testing Execution Standard) oder OWASP für Webanwendungen. Pentests können von externen Dienstleistern oder internem Personal vorgenommen werden. Entscheidend für ein gutes Ergebnis ist hierbei neben einer standardisierten, strukturierten Vorgehensweise die Qualifikation der ausführenden Personen, da Penetrationstests die Ausforschung komplexer Angriffsmöglickeiten erfordern, die weit über den isolierten Einsatz einzelner Werkzeuge hinausgehen können. Pentesting von Außen enthält sowohl die Suche nach angreifbaren Schwachstellen aus dem Internet, als auch die vorhergehende Recherche, um angreifbare Informationen aufzuspüren (Open Source Intelligence). Zur konsequenten Überprüfung gehört auch, dass deren gefundene Schwachstellen im Rahmen des Schwachstellenmanagements zeitnah behandelt werden. Zweckmäßig ist es dazu gefundene Schwachstellen bestimmten zuständigen Personen oder Rollen zur zuzuweisen und diese innerhalb der Fristen des Schwachstellenmanagements zu behandeln.</p></td></tr><tr valign="top"><td>DET.5.5: Red Teaming</td><td><p>Detektion KANN die Abwehrfähigkeit durch simulierte Angriffe, die von einem unabhängigen Team durchgeführt werden, <i>regelmäßig</i> überprüfen.</p></td><td><p>Regelmäßige Überprüfungen durch unabhängige Red Teams ermöglichen einen objektiven und unvoreingenommenen Blick auf die aktuellen Stärken und Schwächen der Sicherheitsmaßnahmen, wodurch Schwachstellen frühzeitig erkannt werden können. Unabhängig ist ein Red Team dabei, wenn es organisatorisch und personell getrennt vom Betriebspersonal (Blue Team) agiert, sodass keine Interessenkonlfikte die objektive Bewertung gefährden.</p></td></tr><tr valign="top"><td>DET.5.6: Threat Hunting</td><td><p>Detektion KANN den Informationsverbund durch Sicherheitsexperten auf Anzeichen für Angriffe <i>regelmäßig</i> überprüfen.</p></td><td><p>Threat Hunting bezeichnet eine proaktive Suche nach Anzeichen für Sicherheitsvorfälle durch Analyseexperten, da fortschrittliche Angriffe durch automatisierte Systeme zur Angriffserkennung häufig nicht detektiert werden können. Im Unterschied zum Penetrationstest steht dabei nicht das Aufsuchen von Schwachstellen, sondern das Finden bereits erfolgreicher Angriffe oder Bedrohungen in den eigenen Systemen und Anwendungen im Vordergrund.</p></td></tr><tr valign="top"><td>DET.5.7: Analyse verdeckter Kanäle</td><td><p>Detektion KANN den Informationsverbund auf verdeckte Kommunikationskanäle <i>regelmäßig</i> überprüfen.</p></td><td><p>Ein verdeckter Kanal (Covert Channel) ist ein heimlicher Kommunikationskanal, mit dem Angreifer legitime Verbindungen ausnutzen, um verdeckt Daten zu übertragen. Viele dieser verdeckten Kanäle können durch darauf spezialisierte Erkennungswerkzeuge (sog. Warden) erkannt werden. Aufgrund der Vielzahl denkbarer verdeckter Kommunikationswege können solche Kanäle jedoch kaum vollständig verhindert werden. Ergänzende Maßnahmen wie Traffic Normalization können sie jedoch ausbremsen oder unerkannt eliminieren. Relevant sind dabei sowohl Speicherkanäle (Storage Channel) als auch Zeitkanäle (Timing Channel).</p></td></tr><tr valign="top"><td>DET.5.8: Bedrohungsanalyse</td><td><p>Detektion SOLLTE verfügbare Informationen zu Bedrohungen, die für den Informationsverbund relevant sind, <i>regelmäßig</i> überprüfen.</p></td><td><p>Bedrohungsaufklärung (Threat Intelligence) dient dem Sammeln und Analysieren von Informationen über bestehende oder aufkommende Bedrohungen, um fundierte Maßnahmen zur Verhinderung von Schäden zu ermöglichen und die Auswirkungen solcher Bedrohungen zu reduzieren. Sie kann in drei Schichten unterteilt werden: strategische Bedrohungsaufklärung (Austausch von Informationen auf hoher Ebene über die sich verändernde Bedrohungslandschaft), taktische Bedrohungsaufklärung (Informationen über Angreifermethoden, beteiligte Werkzeuge und Technologien) und operative Bedrohungsaufklärung (Details zu spezifischen Angriffen, einschließlich technischer Indikatoren). Die gesammelten Bedrohungsinformationen können analysiert und später genutzt werden, indem Prozesse implementiert werden können, um die aus Bedrohungsaufklärungsquellen gesammelten Informationen in die Risikomanagementprozesse einzubeziehen. Sie können als zusätzlicher Input für technische Präventiv- und Erkennungskontrollen wie Firewalls, Intrusion-Detection-Systeme oder Anti-Malware-Lösungen dienen sowie als Eingabe für die Testprozesse und -techniken der Informationssicherheit verwendet werden. Die Institution kann Bedrohungsinformationen auf gegenseitiger Basis mit Anderen teilen, um die allgemeine Bedrohungsaufklärung zu verbessern. Dies kann einen kooperativen Ansatz zur Stärkung der gemeinsamen Sicherheitslage fördern.</p></td></tr><tr valign="top"><td>DET.5.8.1: Auswertung öffentlicher Quellen</td><td><p>Detektion KANN öffentliche Quellen auf Hinweise zu eigenen Schwachstellen anhand von <i>Kriterien zur Suche</i> <i>regelmäßig</i> überprüfen.</p></td><td><p>Öffentliche Quellen können Hinweise zu aktuellen Schwachstellen geben oder sogar auf die Vorbereitung von Angriffen geben, beispielsweise auf die Nachahmung von Webseiten oder Marken, sowie Typosquatting. Auch Datenleaks wie API-Keys oder falsch konfigurierte Cloud-Systeme können hierüber aufgedeckt werden.  Relevante öffentliche Quellen können z.B. Schwachstellendatenbanken, Fachmedien, Security Mailing Listen, Dark Web Foren, Code Repositories, Suchmaschinen oder Soziale Medien sein. Als Kriterien zur Auswahl können verschiedene Suchbegriffe oder Suchmuster herangezogen werden, z.B. Bezeichnungen verwendeter Betriebssysteme oder Komponenten, eigene DNS-Domains, E-Mailadressen, API-Schnittstellen, Markennamen.  Die Umsetzung kann durch eigenes Personal oder Threat Intelligence Dienstleister erfolgen.</p></td></tr><tr valign="top"><td>DET.5.8.1.1: Unautorisierte Publikation</td><td><p>Detektion KANN öffentliche Quellen automatisiert auf Hinweise zur unautorisierten Veröffentlichung vertraulicher Daten überwachen.</p></td><td><p>Unautorisierte Veröffentlichungen liegen vor, wenn vertrauliche Daten ohne Autorisierung der Institution öffentlich gemacht wurden, z.B. personenbezogene Kundendaten oder Geschäftsgeheimnisse. Typische Quellen sind Soziale Netzwerke und Code-Sharing-Plattformen. Kann z.B. durch die automatisierte Suche nach unkritischen, aber in den Quelldaten vorhandenen Begriffen umgesetzt werden.</p></td></tr><tr valign="top"><td>DET.5.9: Externe Schwachstellenmeldungen</td><td><p>Detektion SOLLTE eine Vorgehensweise zur Entgegennahme und Behandlung von externen Schwachstellenmeldungen verankern.</p></td><td><p>Ohne klar geregelten Umgang könnte eine Institution wertvolle Hinweise übersehen oder verzögert reagieren, was die Wahrscheinlichkeit eines Angriffs auf ungepatchte Ziele erhöht. Denkbar sind etwa Szenarien, in denen eine unbekannte Schwachstelle in einer öffentlich erreichbaren Webanwendung durch Dritte entdeckt wird und die Institution zwar kontaktiert wird, aber ohne geregelten Prozess keine Reaktion erfolgt – was einen erfolgreichen Angriff begünstigen könnte. Eine Institution kann diese Anforderung umsetzen, indem sie z. B. eine leicht auffindbare Kontaktmöglichkeit für Schwachstellenmeldungen bereitstellt – etwa eine dedizierte E-Mail-Adresse wie security@…, ein webbasiertes Formular oder die Eintragung eines „Security.txt“-Hinweises im Webauftritt (nach IETF RFC 9116). Sinnvoll kann es sein, klare Erwartungshaltungen zu kommunizieren, etwa welche Informationen eine Meldung enthalten sollte oder wie Rückmeldungen an Hinweisgeber erfolgen können. Auch ein internes Verfahren zur Kategorisierung und Priorisierung der eingehenden Hinweise kann helfen, Meldungen effizient zu bearbeiten. Eine Institution kann zudem in Erwägung ziehen, standardisierte Rückmeldungen vorzubereiten, um zeitnah bestätigen zu können, dass eine Meldung eingegangen ist, selbst wenn die inhaltliche Analyse noch aussteht. Sinnvoll ist auch ein freiwilliger Verhaltenskodex (z. B. ein „Responsible Disclosure Policy“-Hinweis) auf der eigenen Website, um Hinweisgebern einen rechtlich sicheren Rahmen für ihre Meldungen zu verdeutlichen. So entsteht ein klarer, reproduzierbarer Prozess, der externe Informationen in die eigene Sicherheitsarbeit einbindet und das Risiko minimiert, dass relevante Hinweise verloren gehen oder ungenutzt bleiben. Für Details siehe ISO/IEC 29147.</p></td></tr><tr valign="top"><td>DET.5.9.1: Bonusprogramm</td><td><p>Detektion KANN ein Bonusprogramm für externe Schwachstellenmeldungen verankern.</p></td><td><p>Ein Bonusprogramm für externe Schwachstellenmeldungen (englisch häufig Bug Bounty Program) bezeichnet ein strukturiertes Verfahren, bei dem eine Institution freiwilligen Sicherheitsforschenden oder interessierten Dritten eine Belohnung für das Melden bislang unbekannter Sicherheitslücken anbietet. Dabei geht es nicht nur um finanzielle Prämien, sondern auch um nicht-monetäre Anerkennungen wie öffentliche Danksagungen oder Zertifikate. Sinn und Zweck liegt darin, externen Sicherheitsforschern oder -expertenen einen Anreiz zu geben, um Schwachstellen frühzeitig zu finden und zu melden. Zur Umsetzung kann eine Institution (1) transparente Regeln definieren, welche Systeme oder Anwendungen einbezogen sind (in scope) und welche nicht, (2) einen abgestuften Belohnungsrahmen anbieten, der den Schweregrad einer Schwachstelle berücksichtigt, sowie (3) die rechtlichen Rahmenbedingungen durch eine sogenannte „Safe-Harbor-Policy“ festlegen, die den Meldenden Schutz vor rechtlichen Schritten zusichert, solange diese verantwortungsvoll handeln. Ergänzend kann die Institution durch einfache organisatorische Hilfsmittel wie Ticketnummern, automatische Eingangsbestätigungen und zeitnahe Rückmeldungen Vertrauen schaffen und den weiteren Ablauf für externe Meldende nachvollziehbar gestalten.</p></td></tr><tr valign="top"><td>DET.5.10: Zeitnahes Patchmanagement</td><td><p>Detektion SOLLTE ein zeitnahes Patchmanagement verankern.</p></td><td><p>Patches (Updates oder Sicherheitsaktualisierungen) sind neue Versionen, die Sicherheitslücken schließen. Je nach Aufbau der betroffenen Assets kann es bei der Aktualisierung auch erforderlich sein, Abhängigkeiten (Bibliotheken, Upstream Software) ebenfalls zu aktualisieren.  Kann durch automatisierte Installation oder nach einem Test umgesetzt werden. Die Umsetzung kann auch den schrittweisen Rollout von Patches vorsehen, sodass bei Fehlern im Patch nicht alle Systeme gleichzeitig betroffen sind und auch komplexe Fehlerbilder durch Rückmeldungen frühzeitig erkannt werden können. Dies kann zum Beispiel nach dem One-Many-All-Prinzip oder Blue-Green-Deployment erfolgen.  Zur Beurteilung der Kritikalität von Patches kann die Krititikalität der mit dem Patch verbundenen Schwachstellen, das Risikoprofil der zu patchenden Assets oder eine Korrelation komplexer Angriffswege herangezogen werden.</p></td></tr><tr valign="top"><td>DET.5.10.1: Autorisierte Bezugsquellen</td><td><p>Detektion SOLLTE Bezugsquellen für Patches autorisieren.</p></td><td><p>Eine Quelle ist unzuverlässig, wenn zukünftig mit Verstößen gegen die Schutzziele Vertraulichkeit, Verfügbarkeit oder Integrität durch die Entität zu rechnen ist (d.h. eine Prognose der Vertrauenswürdigkeit). Dies ist insbesondere der Fall, wenn erhebliche Verstöße gegen die Schutzziele durch die Entität begangen worden sind oder Anzeichen dafür vorliegen, dass bei einer Verwendung mit solchen Verstößen zu rechnen ist.</p></td></tr><tr valign="top"><td>DET.5.10.2: Integritätsprüfung</td><td><p>Detektion SOLLTE Patches vor der Installation auf Integrität testen.</p></td><td><p>Wenn Patches durch Fehler bei der Übertragung oder sogar bewusst von Angreifern verändert wurden, kann dies nach der Installation zu nicht behebbaren Fehlerzuständen oder zur Verbreitung von Schadcode führen.  Kann durch einen Abgleich von Prüfsummen umgesetzt werden, z.B. durch automatisierte Installationsroutinen oder einen manuellen Abgleich mit der Herstellerwebseite.</p></td></tr><tr valign="top"><td>DET.5.10.3: Schrittweiser Rollout</td><td><p>Detektion für IT-Systeme KANN die Installation von Patches stufenweise ausführen.</p></td><td><p>Ein schrittweiser Rollout (Staged Rollout) ist eine stufenweise Installation von Aktualisierungen (Updates oder Patches), um Probleme frühzeitig zu erkennen und zu verhindern, dass durch sie die gesamte Infrastruktur betroffen ist. Die Umsetzung kann z.B. durch Blue-Green-Deployment oder nach dem One-Some-All-Prinzip geschehen. Hierdurch soll verhindert werden, dass sich Probleme auf alle betroffenen Systeme oder Anwendungen gleichzeitig auswirken. Es empfiehlt sich demnach auf Betriebssysteme, die über ein Rolling-Release-Modell aktualisiert werden, zu verzichten.</p></td></tr><tr valign="top"><td>DET.5.10.4: Automatisierte Überwachung von Systemupdates</td><td><p>Detektion für IT-Systeme SOLLTE den Patchstatus durch <i>einen automatisierten Mechanismus</i> überwachen.</p></td><td><p>Der Patchsstatus des Informationsverbundes kann dabei durch Kennzahlen bestimmt werden, z.B. durchschnittliche Zeit bis zum Patch (Mean Time To Patch), Prozentsatz aktuell gepatchter Assets, Anzahl offener/geschlossener Ausnahmen.</p></td></tr><tr valign="top"><td>DET.5.10.5: Automatisierte Überwachung von Anwendungsupdates</td><td><p>Detektion für Anwendungen KANN den Patchstatus durch <i>einen automatisierten Mechanismus</i> überwachen.</p></td><td><p>Eine nicht gepatchte Anwendung könnte als Einfallstor für Angreifer dienen, die bekannte Schwachstellen ausnutzen, um sich Zugang zu Systemen oder Daten zu verschaffen. Die Umsetzung kann beispielsweise auf einem Patch Management System (PMS) oder einem Vulnerability Management System (VMS) basieren. Ein Patch-Managementsystem kann beispielsweise so konfiguriert werden, dass es kontinuierlich die Versionen der installierten Software mit einer zentralen Datenbank für verfügbare Updates abgleicht. Auch die Nutzung eines Schwachstellen-Scanners, der im Netzwerk nach ungepatchten Anwendungen sucht, ist eine wirksame Maßnahme. Ein solcher Scanner könnte beispielsweise wöchentlich oder sogar täglich einen Scan durchführen und die Ergebnisse in einem Dashboard visualisieren. Wichtige prozessuale Tipps sind die Einrichtung von Benachrichtigungsworkflows, die sicherstellen, dass kritische Patch-Status-Änderungen sofort an die richtigen Personen eskaliert werden, sowie die Integration der Überwachungsergebnisse in ein zentrales Incident Response System. Dies kann helfen, die Reaktionszeit zu verkürzen, sodass die Anwendungen schnellstmöglich aktualisiert werden.</p></td></tr><tr valign="top"><td>DET.5.10.6: Test gemäß Änderungsmanagement</td><td><p>Detektion KANN Patches entsprechend der Anforderungen der Praktik „Änderungen und Tests“ vor der Installation testen.</p></td><td><p>Stellt sicher, dass Patches zusammen mit anderen Änderungen geprüft werden und trennt zwischen „Routine“- und „Notfall“-Änderungen.</p></td></tr></table><h2>DET.6: Vorfallserkennung</h2><table border="1" rules="all" cellspacing="0" cellpadding="2" width="100%"><tr valign="top" bgcolor="#C0C0C0"><th>Control</th><th>Statement</th><th>Guidance</th></tr><tr valign="top"><td>DET.6.1: Beurteilung von Ereignissen</td><td><p>Detektion SOLLTE ein Verfahren zur Beurteilung von sicherheitsrelevanten Ereignissen anhand von <i>Kriterien</i> verankern.</p></td><td><p>Aus einer größeren Menge von sicherheitsrelevanten Ereignissen kann durch Filterung und Korrelation eine kleinere Menge sicherheitskritischer Ereignisse destilliert werden. Dies bedeutet, dass aus allen möglichen Sicherheitsereignissen (wie Zugriffsversuche, Systemänderungen, Netzwerkverkehr) besonders auf die potenziell gefährlicheren oder wichtigeren Ereignisse geachtet wird. Für die Definition eines Sicherheitskritischen Ereignisses, siehe Glossar (Namensräume des Grundschutz++). Die Filterung erfolgt sinnvollerweise automatisiert, z.B. durch SIEM, EDR. Die Überwachung kann anhand von bestimmten Begriffen (z.B. <b>„login from unknown device“</b>, <b>„blocked malware“</b>, <b>„permission changed“</b>) oder durch Anomalieerkennung erfolgen.  Aufgrund der Vielzahl an möglichen Ereignissen sind detallierte Kriterien nur schwer festzulegen. Die Kriterien können sich daher auch an einem überschaubaren Schema, etwa einer Abschätzung der Auswirkungen auf die Geschäftsprozesse und gesetzlichen Meldepflichten, orientieren. Sobald ein solches kritisches Ereignis erkannt wird, erfolgt eine Bewertung durch definierte Personen oder Rollen. Diese entscheiden, ob das Ereignis tatsächlich als Sicherheitsvorfall eingestuft werden kann.</p></td></tr><tr valign="top"><td>DET.6.1.1: Automatisierte Feststellung</td><td><p>Detektion SOLLTE kritische Vorfälle anhand von <i>Kriterien</i> durch <i>einen automatisierten Mechanismus</i> protokollieren.</p></td><td><p>Zur Erfüllung der Anforderung ist es nicht erforderlich, dass alle denkbaren Sicherheitsvorfälle automatisch erkannt werden, sondern nur, dass diejenigen Vorfälle, die in der vorhandenen Infrastruktur automatisch feststellbar sind und mit einem hohen Risiko verbunden sind, automatisch festgestellt werden. Beispiele sind hier ein Virenbefall des zentralen Verzeichnisdienstes, unautorisierte Datenabflüsse oder das Aufbrechen eines Fensters im Sicherheitsbereich. Ressourcen meint hier z.B. Systeme, Zugangskonten, Datenkategorien.</p></td></tr><tr valign="top"><td>DET.6.1.2: Automatische Alarmierung</td><td><p>Detektion SOLLTE bei sicherheitskritischen Ereignissen eine Alarmierung von <i>für die Vorfallsbehandlung zuständigen Personen oder Rollen</i> durch <i>einen automatisierten Mechanismus</i> ausführen.</p></td><td><p>Für die Definition eines Sicherheitskritischen Ereignisses, siehe Glossar (Namensräume des Grundschutz++). Bewährt hat sich hierzu der Einsatz eines Security Information and Event Management Systems (SIEM), das die Audit Logs verschiedener Hersteller auf Ereignisse überprüfen und diese korrelieren kann.  Passen Sie Schwellwerte und Kriterien so an, dass keine Alarmmüdigkeit (alert fatigue) beim Personal aufkommt.</p></td></tr><tr valign="top"><td>DET.6.1.3: Dokumentation von Ergebnissen</td><td><p>Detektion KANN Analyseergebnisse dokumentieren.</p></td><td><p>Die Aufzeichnung von Beurteilungsergebnissen und Entscheidungen bei Sicherheitsvorfällen dient als rechtssichere Nachweisführung und ermöglicht retrospektive Analysen zur kontinuierlichen Prozessverbesserung. Sie stellt außerdem sicher, dass die Vorfälle während und nach der Behandlung strukturiert aufgearbeitet werden können. Zweckmäßig ist es dabei, möglichst viele hilfreiche Informationen automatisch mitzuerfassen, z.B. welche Fehlermeldung genau aufgetreten ist oder welche Schwellwerte bis zu welchem Wert genau überschritten worden sind. Kann auch durch ein SIEM umgesetzt werden, welches Informationen zu kritischen Ereignissen abspeichert.  Die Umsetzung kann mit einem standardisierten Dokumentationssystem erfolgen, das alle relevanten Metadaten erfasst: Zeitstempel, beteiligte Personen, Begründungen für Entscheidungen sowie konkrete Maßnahmen.</p></td></tr><tr valign="top"><td>DET.6.2: Beurteilung  von Eingängen</td><td><p>Detektion SOLLTE ein Verfahren zur Beurteilung  von Datei-Eingängen verankern.</p></td><td><p>Kann beispielsweise ein Virenscanner eine Datei nicht überprüfen, weil sie mit einem Passwort geschützt ist, erhalten Nutzende die Datei erst, wenn sie durch das für Detektion zuständige Personal freigegeben wurde. Dazu muss die Datei aus einer vertrauenswürdigen Quelle stammen und keine Anzeichen für einen Angriff vorliegen.</p></td></tr><tr valign="top"><td>DET.6.2.1: Dynamische Sandbox-Analyse</td><td><p>Detektion KANN verdächtige Dateien in einer isolierten Umgebung mindestens anhand von aufgebauten Netzverbindungen, Systemaufrufen und Dateizugriffen testen.</p></td><td><p>Eine dynamische Sandbox Analyse ist die Ausführung des verdächtigen Codes in einer isolierten Umgebung, aus der eine Anwendung nicht durch Ausführung von Systembefehlen ausbrechen kann (Sandbox Detonation). Sie ermöglicht die sichere Untersuchung potenziell schädlicher Dateien in einer isolierten Umgebung, um deren tatsächliches Verhalten zu beobachten. Eine dynamische Analyse kann verschiedene verdächtige Aktivitäten erfassen: Dateisystemoperationen wie das Erstellen, Ändern oder Löschen von Dateien; Registry-Modifikationen, besonders in Autostart-Bereichen; Netzwerkverhalten einschließlich externer Verbindungsversuche und Datenexfiltration; Prozessverhalten wie Injektionstechniken oder unerwartete Kindprozesse; Speichermanipulationen; Persistenzmechanismen wie Dienste oder geplante Aufgaben; Anti-Analyse-Techniken zur Erkennung virtueller Umgebungen; sowie ungewöhnliche API-Aufrufe wie kryptografische Funktionen oder Sicherheitsumgehungen. Die Sandbox kann dabei mit ausreichender Laufzeit, Netzwerksimulation und Snapshot-Funktionen ausgestattet werden, um auch verzögerte oder umgebungsspezifische Schadfunktionen zu erkennen.</p></td></tr><tr valign="top"><td>DET.6.2.2: Datenträgerschleuse</td><td><p>Detektion KANN Datenträgerschleusen installieren.</p></td><td><p>Eine Datenträgerschleuse ist ein vom restlichen Netz der Institution getrenntes System zur Erkennung von Schadprogrammen.</p></td></tr></table></body></html>